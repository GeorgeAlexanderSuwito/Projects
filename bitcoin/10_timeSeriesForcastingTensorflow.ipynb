{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e0e54c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'wget'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-381d77ba2736>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mwget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'wget'"
     ]
    }
   ],
   "source": [
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "269a4aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential,load_model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12424a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71762dd",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2915079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wget.download(\"https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "938179b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f551df3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv',parse_dates=['Date'],\n",
    "              index_col=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2f1bffb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Currency</th>\n",
       "      <th>Closing Price (USD)</th>\n",
       "      <th>24h Open (USD)</th>\n",
       "      <th>24h High (USD)</th>\n",
       "      <th>24h Low (USD)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>BTC</td>\n",
       "      <td>123.654990</td>\n",
       "      <td>124.304660</td>\n",
       "      <td>124.751660</td>\n",
       "      <td>122.563490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>BTC</td>\n",
       "      <td>125.455000</td>\n",
       "      <td>123.654990</td>\n",
       "      <td>125.758500</td>\n",
       "      <td>123.633830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>BTC</td>\n",
       "      <td>108.584830</td>\n",
       "      <td>125.455000</td>\n",
       "      <td>125.665660</td>\n",
       "      <td>83.328330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>BTC</td>\n",
       "      <td>118.674660</td>\n",
       "      <td>108.584830</td>\n",
       "      <td>118.675000</td>\n",
       "      <td>107.058160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>BTC</td>\n",
       "      <td>121.338660</td>\n",
       "      <td>118.674660</td>\n",
       "      <td>121.936330</td>\n",
       "      <td>118.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>BTC</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>49596.778891</td>\n",
       "      <td>51448.798576</td>\n",
       "      <td>46294.720180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-15</th>\n",
       "      <td>BTC</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49717.354353</td>\n",
       "      <td>51578.312545</td>\n",
       "      <td>48944.346536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>BTC</td>\n",
       "      <td>47885.625255</td>\n",
       "      <td>49926.035067</td>\n",
       "      <td>50690.802950</td>\n",
       "      <td>47005.102292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>BTC</td>\n",
       "      <td>45604.615754</td>\n",
       "      <td>46805.537852</td>\n",
       "      <td>49670.414174</td>\n",
       "      <td>43868.638969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>BTC</td>\n",
       "      <td>43144.471291</td>\n",
       "      <td>46439.336570</td>\n",
       "      <td>46622.853437</td>\n",
       "      <td>42102.346430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2787 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Currency  Closing Price (USD)  24h Open (USD)  24h High (USD)  \\\n",
       "Date                                                                       \n",
       "2013-10-01      BTC           123.654990      124.304660      124.751660   \n",
       "2013-10-02      BTC           125.455000      123.654990      125.758500   \n",
       "2013-10-03      BTC           108.584830      125.455000      125.665660   \n",
       "2013-10-04      BTC           118.674660      108.584830      118.675000   \n",
       "2013-10-05      BTC           121.338660      118.674660      121.936330   \n",
       "...             ...                  ...             ...             ...   \n",
       "2021-05-14      BTC         49764.132082    49596.778891    51448.798576   \n",
       "2021-05-15      BTC         50032.693137    49717.354353    51578.312545   \n",
       "2021-05-16      BTC         47885.625255    49926.035067    50690.802950   \n",
       "2021-05-17      BTC         45604.615754    46805.537852    49670.414174   \n",
       "2021-05-18      BTC         43144.471291    46439.336570    46622.853437   \n",
       "\n",
       "            24h Low (USD)  \n",
       "Date                       \n",
       "2013-10-01     122.563490  \n",
       "2013-10-02     123.633830  \n",
       "2013-10-03      83.328330  \n",
       "2013-10-04     107.058160  \n",
       "2013-10-05     118.005660  \n",
       "...                   ...  \n",
       "2021-05-14   46294.720180  \n",
       "2021-05-15   48944.346536  \n",
       "2021-05-16   47005.102292  \n",
       "2021-05-17   43868.638969  \n",
       "2021-05-18   42102.346430  \n",
       "\n",
       "[2787 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4268dd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 2787 entries, 2013-10-01 to 2021-05-18\n",
      "Data columns (total 5 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Currency             2787 non-null   object \n",
      " 1   Closing Price (USD)  2787 non-null   float64\n",
      " 2   24h Open (USD)       2787 non-null   float64\n",
      " 3   24h High (USD)       2787 non-null   float64\n",
      " 4   24h Low (USD)        2787 non-null   float64\n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 130.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "130d81e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices = pd.DataFrame(df['Closing Price (USD)']).rename(columns={'Closing Price (USD)':\"Price\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a5addd5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d549e821c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "bitcoin_prices.plot(figsize=(12,8))\n",
    "plt.ylabel(\"BTC Price\")\n",
    "plt.title(\"Price of Bitcoin from this to this\",fontsize=16)\n",
    "plt.legend(fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3945b6f9",
   "metadata": {},
   "source": [
    "## Import time seires with csv module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf7e8b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([datetime.datetime(2013, 10, 1, 0, 0),\n",
       "  datetime.datetime(2013, 10, 2, 0, 0),\n",
       "  datetime.datetime(2013, 10, 3, 0, 0),\n",
       "  datetime.datetime(2013, 10, 4, 0, 0),\n",
       "  datetime.datetime(2013, 10, 5, 0, 0),\n",
       "  datetime.datetime(2013, 10, 6, 0, 0),\n",
       "  datetime.datetime(2013, 10, 7, 0, 0),\n",
       "  datetime.datetime(2013, 10, 8, 0, 0),\n",
       "  datetime.datetime(2013, 10, 9, 0, 0),\n",
       "  datetime.datetime(2013, 10, 10, 0, 0)],\n",
       " [123.65499,\n",
       "  125.455,\n",
       "  108.58483,\n",
       "  118.67466,\n",
       "  121.33866,\n",
       "  120.65533,\n",
       "  121.795,\n",
       "  123.033,\n",
       "  124.049,\n",
       "  125.96116])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from datetime import datetime\n",
    "timesteps = []\n",
    "\n",
    "btc_price = []\n",
    "\n",
    "with open(\"BTC_USD_2013-10-01_2021-05-18-CoinDesk.csv\",'r') as f:\n",
    "    csv_reader = csv.reader(f,delimiter=',')\n",
    "    next(csv_reader)\n",
    "    for line in csv_reader:\n",
    "        timesteps.append(datetime.strptime(line[1],\"%Y-%m-%d\"))\n",
    "        btc_price.append(float(line[2]))\n",
    "timesteps[:10],btc_price[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "50760e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f412f9a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d54a030160>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(timesteps,btc_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33eb738",
   "metadata": {},
   "source": [
    "## Create train test split data (wrong way)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba915897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2013-10-01  123.65499\n",
       "2013-10-02  125.45500\n",
       "2013-10-03  108.58483\n",
       "2013-10-04  118.67466\n",
       "2013-10-05  121.33866"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71d392b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = bitcoin_prices.index.to_numpy()\n",
    "prices = bitcoin_prices.Price.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96ca682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aefbccbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2229,), (558,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(timesteps,\n",
    "                                                    prices, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42)\n",
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58b5f64c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x169ee9b9b20>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABEzklEQVR4nO3deXhU5dn48e99JpPJvpCENYSwhU2RkAi41qUqLq28XRRqK7YqrXXr9lq3VutW7WbFtioqlb5VsG4/t1r3rbImgogsIawJBsgG2Sczc57fH3MyTCBAgCQzgftzXbky5zlnztwzkLnPsx4xxqCUUurYZkU6AKWUUpGnyUAppZQmA6WUUpoMlFJKoclAKaUUEBPpAA5XZmamyc3NjXQYSinVaxQXF1cZY7I62tdrk0Fubi5FRUWRDkMppXoNEdmyv33aTKSUUkqTgVJKKU0GSiml6MV9Bh3x+XyUl5fT0tIS6VCOCnFxcWRnZ+N2uyMdilKqmx1VyaC8vJzk5GRyc3MRkUiH06sZY6iurqa8vJyhQ4dGOhylVDc7qpqJWlpayMjI0ETQBUSEjIwMrWUpdYw4qpIBoImgC+lnqVTk2bahst5Ld68wfVQ1Eyml1NHE77e5ZM4iPivbRWFuH+ZfPQXL6p6LtKOuZhAp1dXVTJgwgQkTJtC/f38GDRoU2m5tbT3gc4uKirjhhhsO+7WfeuoprrvuugMe88EHH7Bw4cLDfg2lVM+ybcO35yzi0627CBhYtrmG6sYDf5ccCa0ZdJGMjAxWrFgBwJ133klSUhK/+MUvQvv9fj8xMR1/3IWFhRQWFnZrfB988AFJSUmcfPLJ3fo6SqmuUd3Yysry3aHt+FgXfRK6b2Sf1gy60RVXXMGPfvQjJk+ezE033cTSpUs56aSTyM/P5+STT2bdunVA8Iv6oosuAoKJ5Ac/+AFnnHEGw4YNY/bs2R2e++9//zt5eXlMmjSJTz75JFT+6quvMnnyZPLz8/nqV7/Kjh072Lx5M48++igPPvggEyZM4OOPP+7wOKVU9MhMimV8dmpou9kboKbJ122vd8zXDGzbUN3YSmZSbLd0mJaXl7Nw4UJcLhd1dXV8/PHHxMTE8M4773Drrbfywgsv7POctWvX8v7771NfX8+oUaO45ppr2o31r6io4I477qC4uJjU1FTOPPNM8vPzATj11FNZvHgxIsITTzzB7373O/74xz/yox/9qF1tpba2tsPjlFLRQUR4/ocnccmjn1BWXsbQIblkJsV22+sd08nAtg0zHl9M8ZZaCoakd0vnzLe//W1cLhcAu3fvZubMmaxfvx4RwefrOMtfeOGFeDwePB4Pffv2ZceOHWRnZ4f2L1myhDPOOIOsrODig5deeiklJSVAMPlceumlVFRU0Nraut85Ap09TikVOS6B5+N/C/FLwDMZMa9BN43yO6abiaobWyneUovfNhRvqe2WzpnExMTQ41/96leceeaZrFq1ildffXW/Y/g9Hk/oscvlwu/3d/r1rr/+eq677jo+//xzHnvssf2+RmePU0pFUFMVUr4Esf1I2RJoquq2lzqmk0FmUiwFQ9KJsYSCIendWgWDYM1g0KBBQHAE0OGaPHkyH374IdXV1fh8Pp577rkOX2PevHmh8uTkZOrr6w96nFIqstrNK0jMgsGTwYoJ/k7s8FYEXeKYTgYiwvyrp7DolrNZMGtKt0+yuummm7jlllvIz88/pKv9vQ0YMIA777yTk046iVNOOYUxY8aE9t155518+9vfpqCggMzMzFD51772NV566aVQB/L+jlNKRU5b0/VJv32X6XMWYxuwL3+VqlkrMDO7r4kIQDozq01E0oAngOMAA/wAWAc8C+QCm4FLjDG1EvxGfQi4AGgCrjDGfOqcZyZwu3Pae4wx85zyAuApIB74N3CjOUhghYWFZu+b26xZs6bdF6M6cvqZKtVzKuu9TLnvHQIm2F+w8JazuWH+8i7r1xSRYmNMh+PYO1szeAj4jzFmNHACsAa4GXjXGDMSeNfZBjgfGOn8zAIecYLoA9wBTAYmAXeISLrznEeAq8OeN/VQ3qBSSh0N+iS4SfAEx/UkeGLw+wMs21zTrf2abQ6aDEQkFTgdeBLAGNNqjNkFXAy0NTbPA6Y5jy8G/mGCFgNpIjIAOA942xhTY4ypBd4Gpjr7Uowxi53awD/CzqWUUseMmiYfTa0BABq9fs7988fYThtJ/uC0bu3X7EzNYChQCfxdRJaLyBMikgj0M8ZUOMdsB/o5jwcBZWHPL3fKDlRe3kH5PkRklogUiUhRZWVlJ0JXSqneIzMplkJnUMvYgSk0OokB4K6Lx3Vrv2ZnkkEMMBF4xBiTDzSyp0kIAOeKvnuX1Au+zhxjTKExprBtjL1SSh0twge1PHfVZNq++i1geGZit65e2plkUA6UG2OWONvPE0wOO5wmHpzfO53924DBYc/PdsoOVJ7dQblSSh2TfL4AE+55O3SFbQOXhI8ysrs+IRw0GRhjtgNlIjLKKTobWA28Asx0ymYCLzuPXwEul6ApwG6nOelN4FwRSXc6js8F3nT21YnIFGck0uVh51JKqWOGbRumz1nMyb97H28ABJtMdgOGleW7u7UjubOjia4HnhaRlcAE4D7gfuAcEVkPfNXZhuDQ0I1AKfA48GMAY0wNcDewzPm5yynDOeYJ5zkbgDeO6F1FwJEsYQ2HtsR0bm4uVVUHnol43333depcSqnoUd3YSvHWWiCYCOa772GR51peTbyPwsGpuCxhYjdNkO3U2kTGmBVAR2NTz+7gWANcu5/zzAXmdlBeRHAOQ691sCWsD6arl5i+7777uPXWW7vkXEqpnpGZFMvxg1JYUbabDOopsEpwi80Y/xrifNUYOwaMwZiun392TM9A7m7FxcV85StfoaCggPPOO4+KiuDgq9mzZzN27FjGjx/P9OnTO1xiOlx1dTXnnnsu48aN46qrrmrXgTRt2jQKCgoYN24cc+bMAeDmm2+mubmZCRMmcNlll+33OKVUdDEGjNMfUEUKxXYePmNRZOfxUYULG1i2uXuaiTo1AzkaddkMZNsOLv6UmNVlqfbOO+8kMTGRl156iZdffpmsrCyeffZZ3nzzTebOncvAgQPZtGkTHo+HXbt2kZaWdsDaxA033EBmZia//vWvef3117nooouorKwkMzOTmpoa+vTpQ3NzMyeeeCIffvghGRkZJCUl0dDQEDrH/o47GJ2BrFTPsG3D2u11XDD7v6EywSaDeqpIAWdskQAld0/F7XYd8mscaAbyMb2ENbYN8y6CsiXBRaBmvgZW11SWvF4vq1at4pxzzgEgEAgwYMAAAMaPH89ll13GtGnTmDZt2kHP9dFHH/Hiiy8CweWt09PTQ/tmz57NSy+9BEBZWRnr16/v8Eu+s8cppXpe25pEyzbXtCs3WDTGpIHfhJVBSWUD4wam0pWO7WaipqpgIrD9wd9duDysMYZx48axYsUKVqxYweeff85bb70FwOuvv861117Lp59+yoknnnjYi9Z98MEHvPPOOyxatIjPPvuM/Pz8Dpei7uxxSqnIaFtO3zbtRxD9+dLjMc4A0/DyW19c2eXDS4/tZNCNy8N6PB4qKytZtGgRAD6fjy+++ALbtikrK+PMM8/kgQceYPfu3TQ0NOyzxHS4008/nWeeeQaAN954g9ra4GiD3bt3k56eTkJCAmvXrmXx4sWh57jd7tDNcw50nFIq8tqW03eFjSBa4L6bnz77GS3+9iOLFrjvZlX5ri7vNzi2k4FIsGnoZ2vgite7tHvesiyef/55fvnLX3LCCScwYcIEFi5cSCAQ4Lvf/S7HH388+fn53HDDDaSlpe2zxHS4O+64g48++ohx48bx4osvkpOTA8DUqVPx+/2MGTOGm2++mSlTpoSeM2vWrFBz1IGOU0pFnojw9JWTeeOqMRS61uMWmwKrhAyCF4jhI4sKrBLOGmx1+fBS7UBWB6SfqVLdb88teGt4OfE+xgbWstoaxcyGa6ki2DewwH03BVYJ69xjGXPzR7hiurYD+diuGSilVBTYcwtemNZ4C9VXf8rYgaksS7iB15J+i4Vhhu92TvL+lWlNt1LTfPg3x9ofTQZKKRVhmUmxTMxJwyWQn9OH9AQPlC9FbD/j7LWcPkgwWFSRysSc7pmBfNQlg97a7BWN9LNUqmcE/9QERDDAN+etZbl/KH5c+AacyMcVwf5MlyX85TsTu2Up66MqGcTFxVFdXa1fYl3AGEN1dTVxcXGRDkWpo17bmkQB21C0uZqbK3/J8VLKZ4Gh7PyffxHnTDBLiHWRkdg9N7g5qiadZWdnU15ejt74pmvExcWRnZ198AOVUkekT4KbhFgX9S3+sJFDhvHWRr7/z/dp9Aa/qhu9fmqafGQle7o8hqMqGbjdboYOHRrpMJRS6pDUNPlo8gY7hdvWJGobObRw+55RQ2MHJJOR6O6WGI6qZiKllOqNMpNiKcztQ4wlTMrNIPfn77HrR58x9paPKMztEzpu1Zf13XZzm6OqZqCUUr1R2+0uqxtbyUyKxRiodsUglsXs6flMuf+90LFFzqqlXd1UpMlAKaWigGUJWcmesAlotRQMSeeh6RPaHXfC4FQdWqqUUkcj2zahm91XN7ZStKUWv20o2lKLJcKk3HQsgROyU3j0uwXdEoMmA6WUiqC2mkDbze7T4mJIiN0zlDQ93s3DMyay8Oaz8LhjOOWB97ul30CbiZRSKoL2LEVhKNpcQ8nOehqdkUWNLX4ueXwxn5fv5vjsVFaW7SJgoHhL1/cbaM1AKaUiqG0pCoCAgUvnLKbtov+EwWmsLN+N3zasLN/NCYPTiLGEgiFdvySFJgOllIogEeHhGRNxWcElJhq8AQBcAo9+dyKFQ9KJsYTCIek898OTWHTL2SyYNaXLl6TQZiKllIqwvikeCnLSWRp228uCIen0TYlj/tVT2FHfwq7GVkToltnH0MmagYhsFpHPRWSFiBQ5ZX1E5G0RWe/8TnfKRURmi0ipiKwUkYlh55npHL9eRGaGlRc45y91ntv1qzAppVSUEhEemjGhXdnsGfmICLZtOPfBjzh/9n854a638fvtbonhUJqJzjTGTAi7McLNwLvGmJHAu842wPnASOdnFvAIBJMHcAcwGZgE3NGWQJxjrg573tTDfkdKKdULufa6Brac7dLKBupbgh3KDS2tbNqyqW2Z0y51JH0GFwPznMfzgGlh5f8wQYuBNBEZAJwHvG2MqTHG1AJvA1OdfSnGmMUmuNzoP8LOpZRSx4SsZA+TcvvgsoRJQ/uEmoPy+iWRHBeDYPNc3L2MePpEeOpCsLu2htDZPgMDvCUiBnjMGDMH6GeMqXD2bwf6OY8HAWVhzy13yg5UXt5B+T5EZBbB2kboPsBKKXU0EBGeuWoypZUN5PVLCnUQW5bF8tvPYdPmDYz451rENrBlITTshJT+Xfb6nU0GpxpjtolIX+BtEVkbvtMYY5xE0a2cJDQHgvdA7u7XU0qpntA2A/nap4v5tGwXBUPSeXbWSVjOCKOYGIuR/VIIXpcT/B2J0UTGmG3O750i8hLBNv8dIjLAGFPhNPXsdA7fBgwOe3q2U7YNOGOv8g+c8uwOjldKqaOebRumzwmuRRRw+gKWba5lR10LA9Li9xyY1BdyToayJTB4cnC7Cx20z0BEEkUkue0xcC6wCngFaBsRNBN42Xn8CnC5M6poCrDbaU56EzhXRNKdjuNzgTedfXUiMsUZRXR52LmUUuqoVlnvZenmmlAiaLOrqTX02LYNlQ2tmCteg5+vhe//OyI1g37AS077VQzwjDHmPyKyDPiXiFwJbAEucY7/N3ABUAo0Ad8HMMbUiMjdwDLnuLuMMW2Dan8MPAXEA284P0opddRr+04XbDKop4oULBFG9k0C2GcV0/lXTwmNNOpKB00GxpiNwAkdlFcDZ3dQboBr93OuucDcDsqLgOM6Ea9SSh1VMhJjSXLbzOM3jLc2UGzn8d3Ar6ht9pOV7Np37aId9Yzqn9zlM5B1OQqllIqgmkYv8+ROJlrrcYtNgVVCdmwjfRKCt7fMTIqlYEg6LoEETwwXPvzfblm1VJOBUkpFUCa7mGiVIhKcS7bSHkaZN5GaJh+w5y5or99wGk2tAQK2Ca1a2pU0GSilVATJXhs/DtxIQW5Gu1VJLUsY1T85tGhdd6xaqgvVKaVUBNlG9iQEA8Z2gTGYvaYS7H2fZO0zUEqpo0i1pLHUHo3fWCyxR7OTVD7duqvDZqC2+yR3x1qeWjNQSqkIykz2cP3AP7FxyxYaY9OxsLulGehgtGaglFIRJCL886qTGDR4CC0+wwk5aTxz1eSOr/5tO7gmUZStWqqUUqoL1DZ5+bJ8CwHbZmVZx01E2DbMuwj+NKZbVi3VZKCUUhFkBwKkPvs/fBJ7HQvcd2Mbm+vmL993HkFTVXBdItsf/N1U1aVxaDJQSqkIsW3Djx57E6t8CTEEKLBKyKCeTzuaR5CYFVygzooJ/k7M6tJYtANZKaUipLqxlffKDUWuPAqsEtbFjmWXL7XjDmQRmPlasEaQmBWZJayVUkp1veBSE3343pZfceYAi0dmnceiZv/+5xFYVpcvXd1Gk4FSSkVIRxPJspJdEYlF+wyUUiqCDmkimQ4tVUqpY5wOLVVKKaVDS5VSSunQUqWUUujQUqWUUo5uHFqqzURKKaU0GSillNJkoJRSikNIBiLiEpHlIvKasz1URJaISKmIPCsisU65x9kudfbnhp3jFqd8nYicF1Y+1SkrFZGbu/D9KaVU1PH7bdZW1GHbdrdOJDsUh9KBfCOwBkhxth8AHjTGLBCRR4ErgUec37XGmBEiMt057lIRGQtMB8YBA4F3RCTPOddfgXOAcmCZiLxijFl9hO9NKaWijt9vk3/P29S3+EmJs1iRMxurfGlwuOjM14KdxBHQqVcVkWzgQuAJZ1uAs4DnnUPmAdOcxxc72zj7z3aOvxhYYIzxGmM2AaXAJOen1Biz0RjTCixwjlVKqaNOaWUD9S1+AGJbapGypd02kexQdDYF/Rm4CWib/5wB7DLG+J3tcmCQ83gQUAbg7N/tHB8q3+s5+yvfh4jMEpEiESmqrKzsZOhKKRU9RmQl4nKmCNRKCmbwpG6bSHYoDtpMJCIXATuNMcUicka3R3QAxpg5wByAwsLCyDawKaXUYaht9oe6B4wRqr/1IllWfbdMJDsUnekzOAX4uohcAMQR7DN4CEgTkRjn6j8b2OYcvw0YDJSLSAyQClSHlbcJf87+ypVS6qiSmRTLpNw0Nm3dQm5OLpnJcSDxkQ7r4M1ExphbjDHZxphcgh3A7xljLgPeB77lHDYTeNl5/IqzjbP/PWOMccqnO6ONhgIjgaXAMmCkMzop1nmNV7rk3SmlVJQRY5gfey+L465nQcyvkYC/140m2tsvgQUicg+wHHjSKX8S+D8RKQVqCH65Y4z5QkT+BawG/MC1xpgAgIhcB7wJuIC5xpgvjiAupZSKXk1VSLmz+mj5MvhdLviaIWdKREcTiYlwNjpchYWFpqioKNJhKKXUoTEGnjwnmAgAAwhgrBjkZ2u6be0hABEpNsYUdrRPZyArpVRPEoEfvAnZJ2LERZMk4DPCatdo7PjMiIWlq5YqpVRPs1zwg7eo2lHOpIdWkEEDVd4UljS20i8lLiIhaTJQSqkIsI2husGLwaKKVAAi2WyvzURKKdXD7ECANfefzvB/TmKB+27Emc9rRfk8A6WUUl2ocvs28lpX4xabAquELKknN3coWcmeiMWkyUAppXqQbRtmvbCJW+w8CqwSiu08/n7t+YwdlIZozUAppY4N1Y2tfPZlAzO4nQzqqSKFfzb7Ih2W9hkopVRPykyKZUJ2SljHsXD53GVMn7MY29YOZKWUOiaICC9ccwrjByWHymwDxVtqqW5sjVhcmgyUUqqHiQiemBgEm0x2A4aJOWlkJsVGLCbtM1BKqR62o76Foi3VzHffQ4FVwqcmj6Ez3tcOZKWUOlb4/Tbn/ukjMqinwCoJDi+V9biseiAhYnFpM5FSSvWg0soG6r1+qkih2M7DZyy8Awojepcz0GSglFI9Kq9fEslxMYDwHd+tfMP+Lcdvvp7pjy+J6GgibSZSSqkeZFkWy287m9JNG/E9ewWj/Wsojsnjss23U93YGrFZyJoMlFKqJ9k2Mf/8OqO2LsbYASyBAquEQbGN9ElwRywsbSZSSqme1FQFZUsQEwABv7EotvPY5kumpilyM5G1ZqCUUj0pIQMG5mO2fcqywAiubb2RKlIp1HkGSil1jLBtmPc1+HI59RnjmV7+MwwuAH5ybl5E5xloM5FSSvUUp4kI209y9edk0BDaNSIzMYKBaTJQSqmek5iFyZ6MHxdLAyNodqchQOGQNPqlxkc0NG0mUkqpniJC1bde4KL7X2KHnYJLDG/ceBqj+idHtIkIOlEzEJE4EVkqIp+JyBci8hunfKiILBGRUhF5VkRinXKPs13q7M8NO9ctTvk6ETkvrHyqU1YqIjd3w/tUSqmokJkcR+6QobhEGJ+dSnoEh5OG60wzkRc4yxhzAjABmCoiU4AHgAeNMSOAWuBK5/grgVqn/EHnOERkLDAdGAdMBf4mIi4RcQF/Bc4HxgIznGOVUuqoIyI8feVkxmensbxsN5N/+x6XPrYoorOPoRPJwAS19XK4nR8DnAU875TPA6Y5jy92tnH2ny3B+s/FwAJjjNcYswkoBSY5P6XGmI3GmFZggXOsUkodlWqbfazctju0Hel7GUAnO5CdK/gVwE7gbWADsMsY43cOKQcGOY8HAWUAzv7dQEZ4+V7P2V95R3HMEpEiESmqrKzsTOhKKRV1MpNiKRiSHtouGJIe0TkG0MkOZGNMAJggImnAS8Do7gzqAHHMAeYAFBYWRrZOpZRShyPgR6pKWHDlJCobfYhAVrIn4h3IhzSayBizS0TeB04C0kQkxrn6zwa2OYdtAwYD5SISA6QC1WHlbcKfs79ypZQ6egT8mN8NBW8d4kmh302bwBUdgzo7M5ooy6kRICLxwDnAGuB94FvOYTOBl53HrzjbOPvfM8YYp3y6M9poKDASWAosA0Y6o5NiCXYyv9IF700ppaKKvXNdMBEAeOuC21GiMylpADDPGfVjAf8yxrwmIquBBSJyD7AceNI5/kng/0SkFKgh+OWOMeYLEfkXsBrwA9c6zU+IyHXAm4ALmGuM+aLL3qFSSkWJ6oRheEw8yTRTTzzehGFE9pY2e0jwor33KSwsNEVFRZEOQymlOs0Yw3ce/S+7yr4gZfDxLPjRyT3aVyAixcaYwo72RUdjlVJKHQNEhKd/eCrVjZPITIqNeKdxOE0GSinVgyxLInY3swPRheqUUqoH2bahst5LtDXRa81AKaV6iG0bps9ZTPHWWgqGpLPg6ilYVnQ0FWnNQCmlekhlvZelm2sI2Ialm2qorPdGOqQQTQZKKdVDArZ9wO1I0mSglFI9ZHez74DbkaTJQCmlesio/skke4JdtcmeGEb1T45wRHtoB7JSSvUQy7JY/qtzKK1sIK9fEpYVPdfj0ROJUkodAyxLyEiK/Cqle9OagVJK9RDbNsx4fDHFW4JDS+fr0FKllDr2VDe2UrylFr9touLuZuE0GSilVA/pE+/itIE2LjFRcXezcNpMpJRSPcAOBFj3wFd4vHU1axPHMubKD6Oq30BrBkop1QOqd5QzunUVMWIz1reKmp3RdUNHTQZKKdUDbH+AtnqAONvRRJOBUkr1gNoWP23rlBpnO5poMlBKqR6Q3jebpfZo/MZiqT2a9L7ZkQ6pHe1AVkqpHtA3NZ4bBv6RTVu3kpszhGdT4yMdUjuaDJRSqgeICPN/eArVjSdG3S0vQZuJlFJKoTUDpZTqEdG8FAVozUAppXpENC9FAZ1IBiIyWETeF5HVIvKFiNzolPcRkbdFZL3zO90pFxGZLSKlIrJSRCaGnWumc/x6EZkZVl4gIp87z5kt0daYppRSRygzKZaCIenEWBJ1S1EAiDHmwAeIDAAGGGM+FZFkoBiYBlwB1Bhj7heRm4F0Y8wvReQC4HrgAmAy8JAxZrKI9AGKgEKCw2yLgQJjTK2ILAVuAJYA/wZmG2PeOFBchYWFpqio6HDft1JK9TjbNlQ3tkasA1lEio0xhR3tO2jNwBhTYYz51HlcD6wBBgEXA/Ocw+YRTBA45f8wQYuBNCehnAe8bYypMcbUAm8DU519KcaYxSaYmf4Rdi6llOr1bNtQWdeMNO4kKwpHEsEh9hmISC6QT/AKvp8xpsLZtR3o5zweBJSFPa3cKTtQeXkH5R29/iwRKRKRosrKykMJXalewbYNlfVeDlZjV72HbRumP/pfNvz+DAJ/HIP5+wVg25EOax+dTgYikgS8APzEGFMXvs+5ou/2/73GmDnGmEJjTGFWVlZ3v5xSPcq2DdPnLGLKfe9w6WOLsG1NCEeDirpmNm4to8BaRwwBAlsXYzdE38Vsp5KBiLgJJoKnjTEvOsU7nCaetn6FnU75NmBw2NOznbIDlWd3UK7UMaWywcuyzdWkm90s3VxDZYM30iGpI2TbhqvmLaOaJJqJwxhoMh52+BMjHdo+OjOaSIAngTXGmD+F7XoFaBsRNBN4Oaz8cmdU0RRgt9Oc9CZwroikOyOPzgXedPbVicgU57UuDzuXUscMMTbz3fewyHMtC9x3Iyb6mhLUofmypok1FQ1k0EA8XkQgHi+7qisO/uQe1plJZ6cA3wM+F5EVTtmtwP3Av0TkSmALcImz798ERxKVAk3A9wGMMTUicjewzDnuLmNMjfP4x8BTQDzwhvOj1DEly6qnj2s9MdgUutbjsuqBhEiHpY7AZ9t2AVBFCsV2HgVWCcV2HknxmZENrAMHTQbGmP8C++v6PruD4w1w7X7ONReY20F5EXDcwWJR6mgmSX1x5UzBlC/BNXgyktQ30iGpI3TcoGTnkTDDdzsZ1FNFCouSPBGNqyO6HIVS0UIEufz/QdlSyDkJonD4oeo8v9/mgocXhrYNFlWkAuCyom/xB00GSkWLgB/z++HgrQNPCnLTJnDpn2hvVVrZQKN337uZ5Q9OIys5+moG0ZeelDpG+bevBW9dsE3WW0f1mg8wUTgeXXVOXr8kEt3tv2JPGJTCC9ec1PsnnSmluodtG771XCUNJjj8MGAsUp77NmvuPx07EF33ylWdJQzLTCCT3bRNw7r/m+OxorCJCDQZKBUVtu9q5Obqm4nDy2o7BwO4xSbP+wU1lV9GOjx1GCrrmrmt6iYWO0OFk2KFUf2TD/7ECNFkoFQU2LatjAKrBLcY8qwyPjfD8BuLktixZPTtcHUWFeWkcSeTrLXEiM0kay3vzBodtbUC0GSgVFSYOHo4zXgwBpqJw4eAwJj+yfsd162imx3wh/7tBHBFYT9BOE0GSkUBl3cXyVYrIpBACxOllBhs2LYMmqoiHZ46RH6fn4onp4e2DZAWH30jiMJpMlAqGiRmITlTMFYMa93jKLbz8BmLosAI/J6MSEenDtGmrVs4jlJEwBhYbo9gQ0v0rUcUTgcxKxUNRLAvf5VZj/yHd8oNggnNVn1tZz3HDUqLdITqEAzNGUKxPYqJ1jpW2sOZad3NyijuPAZNBkpFjeomP++V22Q6SaBttqp0/+rwqovVtgT4jv920k091aSw+JYzo7rzGLSZSKmo0SfexctJv92zainBCWeXPLYYv18nn/UmaXExeGJiqCKVhNgYMqNwLaK9aTJQKgrYtuGaOW8x2rcGt9gUWCVkUA9AY6tNaWVDhCNUnWXbhm/97SMSfLWAobE1wI66lkiHdVCaDJSKAtWNrbxbbkIdx8V2HlWkhPYPy9ClrHuLHXVN3FJ1E4s817DA/RsEm41V0Z/Mtc9AqSjQJ8FNQmwMM1r2LHMcvnJ8aVUjYwemRi5A1Sm2bbh13lvMtUoQgclWCVnUMrJvUqRDOyitGSgVBWqafDR5/WHLHLefoJQWfxRft9k2dt0OKutaCN4OpRewbWjYGRw3Gqa6sZVtFdvblZ2YZeibEt+T0R0WTQZKRYHMpFgKhqRjCSTGuvbZf+38Fdh2L/miPBS2jXnqQsyfRrH1D6cw49FPov992jbMuwj+NAaeujC47chMisXKGkU98RgD9cTzna9NjcpVSvemyUCpKBC8wBREhHEDU1j4yzM5btCePoOVZbuobmyNWHzdpmEnbF2IC8NEKeWmihup2FVP0edrCfj9kY6uQ/66nZiti8H2Y7YupmpHeahGIyK89ONTmdj6GOd5HyC/9XGmDI++W1x2RJOBUlGgurGV4q21BGxD8dZduGNcvPzjU8gfkEAeZeRnp5CZFIttGyrrvb2nOeUg/AETamkRgXwpZcefz+SE50+i6K5T8LZEVwL0+23G/7GYJf6R2AaMHWDL36Zxyd8+xrYNra0BCu57F7+JYatrMKvvnIrLtW9NLxppMlAqCvSJdzE4th4wJMS66JPgxtvsZV7NDN70/JK5O79NU2Mz3/7rh3zv3r9z6SO9oDmlE0qa4lluDw8lBAOMl424xWailDDzr/+Oqve5fHM1zT6bO3wzCQCWwERrAzdv/xnbahu4+G8f0+zzk8luWgKGksrGSIfcaUdxr5RSvYRt4//7RbxtllDszuO73tvZ2eBl1h/+j1esZkQg2TRz8f1z+afrHpI9zdTviKeyrpR+adE/SuVA0uLdXOT7NZ95ribJtCJAEx7ijZdiO4/SykZ27m6mf3rkh9a2tPi55InFzHffQ4G1jhbiiDEtiMB4awPP/Pt5qra7mO/+CwXWeortPGoaXgLSIh16p2jNQKkI89ftxFW+NDTZ7Mxsi9rGVj73DaCeuNBV893yGMk4yYFmXDvXRDbwI+T323z1wY/oQ1Nw0W4h9N6+5r0bMCzyXEvsvPOwd23bZ+ROT3uvZCcZ1IfuOxFHCyvtofiMhQCXl/6EpZ7rmWStC/1b9nP1nprBQZOBiMwVkZ0isiqsrI+IvC0i653f6U65iMhsESkVkZUiMjHsOTOd49eLyMyw8gIR+dx5zmzpDd3uSnWhksY4iuyRoclmP7n4ZDISYwGLr3p/TwALERhrbW33vPveWBdVTSiHqrSygSafTRUprLSHtvuuFwIUWOtwiyG9diU8OJbqB0/F3+o9rNfyt7ZS+vkSdtQ2dqq/paO+mfzBqVSREjYxcDTTfHcx0/u/uLBDyUxwVio1I8gbNuyw4o2EztQMngKm7lV2M/CuMWYk8K6zDXA+MNL5mQU8AsHkAdwBTAYmAXe0JRDnmKvDnrf3ayl1VEtPjGWG73ZO8v6V6b5f0SfJQ9+UOAoGp7CTPhTZefgMtBALBL9oDPDajqR2I4x6W+fyiKxEBJtM6rjVd2W7ffe7/46L4HsVCbbN99m9is/uPpmW5kPrVG5t8dJ07xCGP38u8X8ezqV//bDDJGoHAlRtLyPgDzDj8cVMue8dvvnIQgKB4NDR/mkJnDg4het913N58ly8l/0/XPj4p+cBcGJtixcg7ZsPYfWSzmPoRDIwxnwE1OxVfDEwz3k8D5gWVv4PE7QYSBORAcB5wNvGmBpjTC3wNjDV2ZdijFlsgv+D/xF2LqWOCS7LajfZzGVZiAjPXXMqH/38DH5gbmO1nUsSre2uPi8a0ERmUjBB2LZhxmMLufC3L3DpY4t6RY2htqmV+e57WOS5lt+454XG5jfiYay1BWuvNoK2tvkPP1vd6cTn99v8ePZ8kmkKNUHtKl9LZUP7GoYdCLD2/tNJfeQ41t4zhWWbdtDH1FK2dSPfe+gVAv4AYgd41n0nS+Ou55k+czhleCZnsRJhTwJowhWaXzBi3KQu/LS63+F2IPczxlQ4j7cD/ZzHg4CysOPKnbIDlZd3UN4hEZlFsMZBTk7OYYauVHRJ9cR0uG1ZQpPfJtFfx/GezaEbpQAEgHIGhq5Et9fUc9OX1zPevYHibaOorHuffmnRfTOVPmY36VYJMWJTYJVyqvdB5rgfZKy1mWbiwLTSTCxJpiXY9AIU23nEpfRl+qOfsGnrZgalxvHsT7+GJ27fVUFt2/CNv33MypoM6j3xJJtm6omnhEG0tPggJS50bM3Ocka3rsISGGtKWOm5mkScGshuWHlPHoPiA2Q0bQj+O2xdSM2ObbxrFQQXGHdqa2fIXP7x9UxGjZ+CFdO7xucccbTGGCMiPXIZYoyZA8wBKCwsjP5LH6U64dOyXftsnzQiOFEpr18SiXEWbX9hbVegLgO37byBipr/0i81ge2zz2SiFfyimmSt4wfz3mbu9Rdj7X15HUV2mhS22HkUWCUU23nYuDje2owl4DItnO/9LSVkk0kdYEK1p5cT3fys4mdM8qxDWmDJvaM5/uYPSUyMa3f+irpmVn7ZAFhM8D7GCCpYzwAyqec/q75k1pl5oZnB6fGxe+5XLJBoWgnvvRxvSqBpz+dvDOxq9lEwJIu8TXM5k5VU9j+DJTd8JervW7A/h5sMdojIAGNMhdPUs9Mp3wYMDjsu2ynbBpyxV/kHTnl2B8crdcyYNDQdl0DAgEuC220s4N3sf2DKIfweN8Emky2sePhMqmb8k+NlQ+iLSoBVFY1U1nvpl9r+CzIa+H1+SjdtZGNlPdf6biODBqpIIZPd7Y679ZtTmPlCBZXs+TzyByWxY/s2zrTWhZqRJltr+cbsV3nhl98KJT+/32bqn94jj3JKGIRNDOsZxHz3PRRaJRS9n8ela//Agh+dimUJX/riGYDgMibUFLe38JpZkRlJ4bBhLBg+gsp6LyIXkpXs6RXLTuzP4aawV4C2EUEzgZfDyi93RhVNAXY7zUlvAueKSLrTcXwu8Kazr05EpjijiC4PO5dSxwQRi/zBaQiQn5OGyJ4/S7uhElO+BAvwA9O9t4Q9D45jA7/+f18Er6ydDsxP7RGAIRDYdzmH1tYAi0qrCAQC3f6+OuL3+Vl+z6nkPX0iU986i/nuu6kmGRAys/qz1B6N31gUM5pT88dTMDi4JEd8jCDYlG/bxqyXylgZNlEN4Pam+/iyZs8y0avLqvlEruJNzy/53HMVFj4y2c0kay0xYjPJWsumrVuobmzF77e59uF/4cK0+8Jv6xC2TbBZLrxz2Dr/D1guF5Yl9EuNo29KXK9OBNC5oaXzgUXAKBEpF5ErgfuBc0RkPfBVZxvg38BGoBR4HPgxgDGmBrgbWOb83OWU4RzzhPOcDcAbXfPWlOoddtTuImPrWxj8rCjb3W6EULVJpsl4MAZaiGMpo1lijw59SRXbI1m5K5brfTcwxTubT+1h5FulLPVcS/mfz8Lv25MQWlsDjL7jP8x4Ygkjb/8PXm/Pr/1Tunkz+QSv6i2BSVYJmdQS7xZeu/EMhvz8PTZ+bxkFv16IKyaG5645lf/ceBpef4D57rtY6LmGF9y/4ve+b4UqSsFa0kZWlqwPvc6OzZ+F5mQk0cJL7jthr9uHZqfEkpkUS2llAytbB9DgzOloSwgr7RzmFbzIJO/fyPP+nUY8oc7h/MJTeuwz6ykHbSYyxszYz66zOzjWANfu5zxzgbkdlBcBxx0sDqWORv6WJvrNzuVRT/Cr6rLMF0MjhAD6UIfBG/xSMy08776b25Pv5Z762zjB2gAI8933UmCVsNIeRr61MdR8ks86Pv7kA75y2plYLhdLNlVjGxBs+ph6vv6Xj3njp2f0WL+C328z7e9redo1jIlWaWhU1Hue/2X3tWuJiXExIC2RAWkjQs+xLGFU/2Qm9/EyuTF4j4CJ1ibmex4gwJ7L+GJ7FD9+5UvWFYzHGJj1ZiPrPXuafcZamxmSHsfShlFMstYBcEvLHwj4v0FevySSPTGc7f0dj7sfZKy1hZX2cO7J/D0vfu0MvnFWK0/8dyPrRixHajdxwoTJuNzuHvnMelLv6u5W6ihi24Y1H7/AcTjNDwbuP2Fnu+aGGkljqz2cidb60NDK/vaXjLc2EiOGAqsEQYgRmxOsjaHnGRP84/7K+9+k+P1R5N++EK/fSxa1POx+ONhpuyuP6rp3yPKWQdZo6OaOz3U762mxhW/Zd/C6+zbGWFtDSa6iYh30ndLh80SEn5+WBf9p2w7+dhnDdO+tbGQgxmnkOPW3b/L903KZxDpMWLPPKkYw/6fT+M6DhmeaZuEWQz7rWb9pE4GEDJ40d5DvKWG5GUnpjEVk98/hxdR4RISUJA8/mzrGiWa/gx17vd7Z7a1UL2fbhkv+9jE/eDeAYc9Esvqcr7Y7LjPZw+/7/5GVdi4+A8sZxQe7strdHrPIeVxk57FSRuE3wW/LtslaBayjZGMJyc9+i4We65hkrXWWS1hLxl9HYx45CfNADnTQx9CVjLPuv8HFhb57Qs0y9cTj75N3wOfmF54cmofQ9lNPPMsYzcPu2Szy/JgF7jtxtezgex+dwQLPvcQQbEpbLSMZf/si3LFuHp51IcX2qNBn9z9PreP7f/k3hRKc7VwoJWAJ/dISen0fwKHSmoFSEbB9VyO/2PG/TPKsBaDEHshU330sTm+/8JwYw/z4ByCmnOasiRRc/SYnPlnEjM17bo8pGDKop3+//jzwrRP4zl+f5FnPvXvOATRWbWeiBNfUsQ34jcVqO5vxrcGrc9NST/3WlZTFDqWP2U2tpDFqQEqXDpNMi9/TtGKI4QTvHEZQwVbXIFYPSjvgc11uN56bN/PDh+ezokZIo5kSsulLLZNDt5hcz0LPT9tNAgsYwfWdZ0LNOv3SErhx4B/ZtGUriRn9aaluJiXY4BTm2EoCbTQZKBUBZeVbKbRKQu37w6wKTu0n9E3ZayhoUxWUL0GMn/iqlYh3FwtmncTHpTuZObcIAINQRSr3nTuKMYPS+SJ2HPUEJ1m1yX/rf/jCzmGstZViexQ3+q7hHU9wFZngVbaHCY9t4Tn3VWRYG9hs53Gq74c8cKKf5v6FnDXpBGKOsJ18a21zu+3/PXc0p+edzpiBqZ1KOp74OB79xRVU1rfw1T99BF4//WPbnzO8+8MYWGmGM2H48FCZiPB/V55E/j0N7KxuxsLPO56bQscvs0eR2zebY5E2EykVAdmDBlPkDAcNjgrK40cXnLRP04Qdn8mamDH4jcWamDHY8ZlYlpCVtO/8gc2VTViWxYpfTWVa7FxK7eDCACLgAsZbW2khjst8NzPH/WeSaAldQf/Iex1vuW9iorUBt3Mj9088P+fUlb/knLfOpviuQ18TaG8Fg9PabV912nDGZacfUu0jOJQznuW/Oof/3HgaL97+/VDzUQBpNyz0czuXvte9u8/6QKVVDTS1BoeajuBLksM+hyeSrqFvavTfr7g7aM1AqR7W6vVx45NvUey7jUzqQlf264dl7HNsdZOPixtuJtWuY5cvlUVNPrKSPYzun0xirEVj6577715x8hAA3G4Xf/32CHKf3tlu3HxbZ20h6zne2rO8RQB42vPH0DFtwh8XWqW8t3It50wef1jv2bYNl8xZsufcwK6WAFnuw/sKiomxGD0gOAch4batbFi3nNiEVAb/32Qg2P/yYMadzM1K3ee5qbHwvPtOxlsbKLZHUU8cyaaFeuJ55KeXHXN9BW00GSjVg/w+PyvuPZX5UkKxO48ZvttDI2Fqmv302+vLMTMplolDMijeYlEwJD007NSyLD779Xms3FZL8aZaZp6cQ2zsniGpo4YPp8iMYiLrsDBYzhd/A3FsYGDouPCx+rCnI7sBD8lmz2JuK+yhHDci97Df96btu9i2bSuQAgjHD0xpN4T2SMTExjLi+MnB4HNOxpQvwT9gEnOvvHjfL3bbJu3ZaQx0hrYWWOs4xTub3543gDNOPeOoHDLaWZoMlOpBazZtIF9KQjc/CXYCB69eO7oeFRHmXz2F6sZWMpNi2325xcRYTBySwcQh+9YoLJeLCbd9zGm/eY4HXQ9RYK1jtZ3Lxb67AYul9ihnTaCRQLBZCIKJYJJ3NtWkM4DtvO25hQT8TLQ2sPpv59Hv1v92fllm26a1ppwVxZ+Q9N+7WezZRpE9mhm+27nw+P5dfwUuAle8jjRVEZuY1eGaEnZDJZ7Kz8Imlg1nJ304vuC0YzoRgCYDpbqV329TWtlAXr+k4NV8dQyNdh6FzuJsVQSbOiYN7UNW8r4rb0KwnXx/+w4k1hPLR7+ZzrS/DGDHju0MyR7MM+eNZvKwPgT857F8XSlDc3JIcrt4btEysnavJu/US3gtLg4B6rZ8RsIL/tB3ap5/NTWVX5LZf/ABXxcA28aeez7ussWcCGDhjPhZSxa1XHh8v4Od4fBYFiT13e/uHXYyWwIjnUl6w/mm7w6OG5h6WJ/v0UaTgVLdwLYNO+taOON37+G1bfpLPe/e/k3u//cXzMOPCc4uINEN7/3irG5b28btdvHqjWfuU7NwuVxMGj8mdNwlXz0NOK3dc/uOO5GmlxJIsJsAaBUPGVkDOvfCDTuR8sUdLviWRmO7Jq2etKvJxwzfnmG5lggvXbNvx/2xSJOBUl3Mtg2XPLqQ4q01ZFHLI+4/M97ayPL7H+RpvIy3tgSXmo4p5fOfFmKldO/olcOtWYjLhee6JZiHj8cC4vHi31WBO6PjmoFtmw6bs2BPJ3Y9sSQNHBOxK/FR/ZNJiHVT1bqnY/lIOrKPJvoJKNXFKnY38+nWKp5338VEqxQINpGc6LTLt7VX12ccR2pyNzWXdJHaZptMAwiIgZV/vgj3tL+wtD6TL+v83HTuSOLi4rBtw/S/vI/15VICcckMHDyGHwQGM94K3tOqWWJZfPI/GFNwKi/0SYrYlXhw6O05fOPRhayuqKcwrFP+WKfJQKkutqWqnufcvwndbCZcaNQOsPa0vzE5ypsnjAhOLnAWidsMr1zEUOI42/s75i1cz+8K6kkfPolnqr+ByxMcjmS2QttK3I3EUHTJp5w1thN9DT3A7Xbx8rWn7rcWc6zSZKBUF8tPacTjJILwNffDh28ut4dSeNzoyAR4COzELJbae1b6bEsKSaaFxZ4bgmWrgFXB40Pfq2Fr/ycaP8kNW2h/36vIOtyms6OZzkBW6jC1NLXw0ccfUFFdH7oxu7+1FfuRk9sNE73Aew8r7Zw9s2OBgVc9j6sX3CPXsixm+H7FFO/DLLeDyzq0rflvCe3WAWpLfm1zFfYsKOdhQv7kiL0H1TnR/79RqShj24ay6t2k/2U0p9FM0ztuLpfbOH/CMD5YXcFjpjlsHPtQbrnim0x7agjPu3/DeGsDa2PGcNzgYZF+G52SlezhxNwMNm6u5wRr0z6T04IbexLBFjuLWb6fUBs3hFmjWzghO4OCyTqGvzcQE16P7UUKCwtNUVFRpMNQx5jgSKFPaNpazOueX+/TFBQguA4QBL8sx5t/8NkdFzHj8SV8uqWGUwfC3B+f3/mJW1HAtg3bqurY9vC5TLKCq6yukZFkff8ZTnnkM9Z6rsbCEEDYcuUaktPSe/39gI9WIlJsjCnscJ8mA6U678vaJk574E3Wea7Axb6TXMPvk2sMrP/GG+SdcPIBh132Fk2NXt5c9jknD+9D30G5iGXh99us2rKTqrUf85Wzv4Y7bt8F9FT0OFAy0GYipTqppcXPkx+t4SxWhBLB3tdS4WX1xDNi3CTg6OiwTEj08D9ntP8eiYmxmDC8Pwz/doSiUl1Fk4FSYVq9PpatWUtDUyv5OX3I6J9Dxa4GPv10Ife+V8Ec92zGejYH28udZZO/6/1fdpHEA+4nnfvnDqNs8l18fer5WL2gk1gp0GQQ0tTk4/lPN5Ht28KAAdkMHzqC0qoGsthNn0QPNVY6mdoOelRoqG/ilffeIs004Bo0iYbSj0g2jWxrgpO3PMJJVgXOLYlZbueQZ+3ga3j5mnNhLwJ+I1zjvZHbb7yeP8cnUlnfzNf/OowM6qkmhdLze1e/gFKaDIC6+ma+eu+zvOu5iSSCy/autLMRXGRaWzDAVnsY080N/GBCOpn9+7NkYxVj3TvJzcklf9K+oyWa6hv54L2XaGpsIYBQGuhPi8/HoNgmUi0vn/qGMzFtN9887xxitZ21Q3V1jTz7xhs0NbYSG2OT6Wqh1iSQZjXRGJPKNm88SXY9m81ARrl3UBeIZ7BrB3V2PEmBBhpjUqm1E8h17aTWpLDOHkyrt4EHyr/LDFqCL7J8rxe1woZKAhOtrcHHe91B6ws7lx39TienfwYiQv+0eNbddQHFW2uZNDQdlyYC1ctETQeyiEwFHiI4GOMJY8z9Bzq+qzqQa3bVs/mPXyHf2uDEESwPvyFI+HZHGohl3tA/Ue9KZ5C/DMv4mL7l17g4+GfbTCyPD3mQ1fZgBrnr8biEHGs7m+wBBAIBbBvy3OX0sVrZ6k/nOPeXfOYfQoOJ5SL3MooHzmRsbhYet5th6XEUrV3H1spaYmtKCfgD7JI06lx9uP7iU4iLj9+nI7Olxc8rK8pZUlpBBrWkUM8GM4j+1FDo2cbA477C8OEj2VjTTF6/JPx+w4clZdSu+oCKRou+nlY2MYAss5vBsp06SaXE3w+v35DkFnJidrLJ1xfb5QLjJ9HfQHNMKraxsVwWqfZuGkgmx6qgqsXNhPjtvOo7ibF8wTc3/pokfAf9DNtmyB5MPXFstvuHbuzS9u/aUWVv7/Lwf/8G4qj54SpyBmRqTVH1KlE/mkhEXEAJcA5QDiwDZhhjVu/vOYebDOoavPzlgxIqauvB28x1W64jz/pynz/8Q/kb399HeKBzGNO+szFAcAbg4Xy1TPPeRise7nc/zvFWWYfn+NzOZsOwK3hoQz82+/uQGuPjF6OqeOiLOKpJZb777tCa9gGkXSJbaWdzte9/ASGDXbzquaNTia4rdObfobP/Xm23RowR0y7Zd/Tvt/cQ0c/tHK72/YzZF2Zz4pRj+yYoqvfqDcngJOBOY8x5zvYtAMaY3+7vOYeTDOoavIy/5x0AXLSyzvN9XJh9JtLY7Pki6DjefWsOHenMR3uwK9SD6Wg0y8GOW2oPp8DaGPpCX24P53jn3rcdxdLR++jOC+K9h2ce9Hg6XzNYbedSYK1jjZ2DCz95VgXr7YFsHfkDKn1x9Es0tA4opMWTgV21htK6WBI9seQOGcaFE7KJ0Q5h1Yv1hqGlg4CysO1yYJ/56yIyC5gFkJOTc8gvMnfh5tDjAkpDiaDtC6eBWK5K+BtFtW4mxX3J+eP60+BKptUvBGw/b6+t5IHAHxhnbeYzeyhxtDDG6WzsSBMufspPOCtvEBvsPX0GKdLCg+vTWGK+H5rGGQAsc+g1g/01cRzouEJrQ7AW4pSNtzbxmT2MidZGJxbBFXaSjsbSd/c1RNv5V9rZvJd9E3HxrlCfQdH6zWzxJuOLSeZrIzxsofN9BoYA/5FGvn/OieBy8fqaDVw45TjGdri+/sjufZNKRZFoqRl8C5hqjLnK2f4eMNkYc93+nnM4NQOv18uoO95xtgKUembiwiYATAv8lhdv/wExsZ79Tg6ybcOX1Q2s3biJMyaOwbbhv5+vomj9TpIDtewySQzylxEb66bJncG5Z5zJoKzUDtuVbdtQvr2adf/9FxtaMlje2v+Q+gzq/DFcuvEmcqyafc7dQAxXe3/KxWMzqQkkcfnmG0giENq/xB5BobUhVDNYYo9mhu82hrCLbx4Xy0aTTaZvJ1tKivmjZw5JtLY7fz1uZnl/zonD+jEwwe6WPoN89wa+tHK41unr2Puz6+0TuJSKBG0mChPeZxBrApwct4lRk6YyNicTy+pd6/a1en0s/eILKivKsP0Bapt8jBmYxq6UUZx3/MBQk0ZdXSPP/ed1Bvi2s7B1GL7YTPwBH4UxpWw2A8jOGc7Z4wYwID2x3ZdrQ2MrT32yjsCOL4hJyGR3cysZrmbszNFc+ZWREbtblVLq8PSGZBBDsAP5bGAbwQ7k7xhjvtjfc3Q5CqWUOjRR32dgjPGLyHXAmwT7buceKBEopZTqWlGRDACMMf8G/h3pOJRS6ljUuxrJlVJKdQtNBkoppTQZKKWU0mSglFKKKBlaejhEpBLY0s0vkwlUdfNrHAmN78hEc3zRHBtofEcqUvENMcZkdbSj1yaDniAiRfsbkxsNNL4jE83xRXNsoPEdqWiMT5uJlFJKaTJQSimlyeBg5kQ6gIPQ+I5MNMcXzbGBxnekoi4+7TNQSimlNQOllFKaDJRSSnGMJQMRGSwi74vIahH5QkRudMr7iMjbIrLe+Z3ulI8WkUUi4hWRX3RwPpeILBeR16ItPhHZLCKfi8gKEemStb67OL40EXleRNaKyBrnnhZREZ+IjHI+t7afOhH5SbTE5+z7qXOOVSIyX0Tioii2G524vuiKz+0w47tMRFY6fwMLReSEsHNNFZF1IlIqIjdHYXxzRWSniKzqitg6zRhzzPwAA4CJzuNkgvdQGAv8DrjZKb8ZeMB53Bc4EbgX+EUH5/sZ8AzwWrTFB2wGMqP18wPmAVc5j2OBtGiKL+ycLmA7wck6UREfwdvEbgLine1/AVdESWzHAauABIKrIr8DjIjAZ3cykO48Ph9YEvbvuQEY5vy/+wwYGy3xOdunAxOBVUca16H8HFM1A2NMhTHmU+dxPbCG4B/WxQS/nHB+T3OO2WmMWQb49j6XiGQDFwJPRGN83aGr4hORVIL/4Z90jms1xuyKlvj2cjawwRhzxLPduzi+GCBegjeGSgC+jJLYxhD8YmsyxviBD4FvHElshxnfQmNMrVO+GMh2Hk8CSo0xG40xrcAC5xzREh/GmI+Afe9n282OqWQQTkRygXxgCdDPGFPh7NoO9OvEKf4M3ATYURqfAd4SkWIRmRVl8Q0FKoG/S7CZ7QkRSYyi+MJNB+Z3ZWxwZPEZY7YBfwC2AhXAbmPMW9EQG8FawWkikiEiCcAFwOCuiu0w47sSeMN5PAgoC9tX7pRFS3wRc0wmAxFJAl4AfmKMqQvfZ4L1tAOOtxWRi4CdxpjiaIzPcaoxZiLBKui1InJ6FMUXQ7Aa/IgxJh9oJFiFjpb42s4TC3wdeK6rYuuK+Jx254sJJtWBQKKIfDcaYjPGrAEeAN4C/gOsAAJdEdvhxCciZxL8sv1lV8XQm+M7kGMuGYiIm+A/1tPGmBed4h0iMsDZPwDYeZDTnAJ8XUQ2E6xmniUi/4yi+NquHjHG7AReIlg9jpb4yoFyY8wSZ/t5gskhWuJrcz7wqTFmR1fE1oXxfRXYZIypNMb4gBcJtkFHQ2wYY540xhQYY04Hagm2nx+xQ41PRMYTbMa92BhT7RRvo31NJdspi5b4IuaYSgYiIgTbqdcYY/4UtusVYKbzeCbw8oHOY4y5xRiTbYzJJdiM8J4x5oivzLoqPhFJFJHktsfAuQSr71ERnzFmO1AmIqOcorOB1dESX5gZdGETURfGtxWYIiIJzjnPJthGHQ2xISJ9nd85BPsLnjmS2A4nPue1XwS+Z4wJT0bLgJEiMtSp+U13zhEt8UVOR73KR+sPcCrBatpKgtXXFQTbNDOAd4H1BEc/9HGO70/wKrYO2OU8TtnrnGfQdaOJuiQ+giMlPnN+vgBui6b4nH0TgCLnXP8PZ2RFFMWXCFQDqdH4/w/4DbCWYJL/P8ATRbF9TDC5fwacHaHP7gmCtZK2Y4vCznUBwdrKBiL3t3Gg+OYT7AvyOZ/rlV31f/BAP7ochVJKqWOrmUgppVTHNBkopZTSZKCUUkqTgVJKKTQZKKWUQpOBUkopNBkopZQC/j9Bchi0ngYwNQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train,y_train,s=5,label='Train data')\n",
    "plt.scatter(X_test,y_test,s=5,label='Test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2402613",
   "metadata": {},
   "source": [
    "## Split with right way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af495ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2229"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_size = int(0.8*len(prices))\n",
    "split_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db971c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = timesteps[:split_size]\n",
    "y_train = prices[:split_size]\n",
    "X_test = timesteps[split_size:]\n",
    "y_test = prices[split_size:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0eca46a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2229, 558)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06588351",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d54a010be0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_train,y_train,s=5,label='Train data')\n",
    "plt.scatter(X_test,y_test,s=5,label='Test data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4753162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_time_series(timesteps, values, format='.', start=0, end=None, label=None):\n",
    "  \"\"\"\n",
    "  Plots a timesteps (a series of points in time) against values (a series of values across timesteps).\n",
    "  \n",
    "  Parameters\n",
    "  ---------\n",
    "  timesteps : array of timesteps\n",
    "  values : array of values across time\n",
    "  format : style of plot, default \".\"\n",
    "  start : where to start the plot (setting a value will index from start of timesteps & values)\n",
    "  end : where to end the plot (setting a value will index from end of timesteps & values)\n",
    "  label : label to show on plot of values\n",
    "  \"\"\"\n",
    "  # Plot the series\n",
    "  plt.plot(timesteps[start:end], values[start:end], format, label=label)\n",
    "  plt.xlabel(\"Time\")\n",
    "  plt.ylabel(\"BTC Price\")\n",
    "  if label:\n",
    "    plt.legend(fontsize=14) # make label bigger\n",
    "  plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e367ec75",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8));\n",
    "plot_time_series(X_train,y_train,label='Train data');\n",
    "plot_time_series(X_test,y_test,label='Test data');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f3232c0",
   "metadata": {},
   "source": [
    "## Modeling Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fd60a9",
   "metadata": {},
   "source": [
    "### Model 0 Naive forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e7f4bce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([9226.48582088, 8794.35864452, 8798.04205463, 9081.18687849,\n",
       "        8711.53433917, 8760.89271814, 8749.52059102, 8656.97092235,\n",
       "        8500.64355816, 8469.2608989 ]),\n",
       " array([57107.12067189, 58788.20967893, 58102.19142623, 55715.54665129,\n",
       "        56573.5554719 , 52147.82118698, 49764.1320816 , 50032.69313676,\n",
       "        47885.62525472, 45604.61575361]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_forecast = y_test[:-1]\n",
    "naive_forecast[:10],naive_forecast[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c56b1dcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1d54e60f7f0>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(X_test,y_test)\n",
    "plt.plot(X_test[1:],naive_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95e02f9",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "796387ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7233f66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20076.076674945223"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[1:].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42af43ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1071.2362601330744"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test[1:],naive_forecast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0468b7cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "567.9802273457542"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(y_test[1:],naive_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f9b729",
   "metadata": {},
   "source": [
    "#### MASE Implementation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e231ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_scaled_error(y_true,y_pred):\n",
    "    mae = tf.reduce_mean(tf.abs(y_true-y_pred))\n",
    "    mae_naive_no_season = tf.reduce_mean(tf.abs(y_true[1:]-y_true[:-1]))\n",
    "    return mae / mae_naive_no_season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "64370594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float64, numpy=0.9995699939182624>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_scaled_error(y_test[1:],naive_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e692313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_preds(y_true, y_pred):\n",
    "  # Make sure float32 (for metric calculations)\n",
    "  y_true = tf.cast(y_true, dtype=tf.float32)\n",
    "  y_pred = tf.cast(y_pred, dtype=tf.float32)\n",
    "\n",
    "  # Calculate various metrics\n",
    "  mae = tf.keras.metrics.mean_absolute_error(y_true, y_pred)\n",
    "  mse = tf.keras.metrics.mean_squared_error(y_true, y_pred) # puts and emphasis on outliers (all errors get squared)\n",
    "  rmse = tf.sqrt(mse)\n",
    "  mape = tf.keras.metrics.mean_absolute_percentage_error(y_true, y_pred)\n",
    "  mase = mean_absolute_scaled_error(y_true, y_pred)\n",
    "  \n",
    "  return {\"mae\": mae.numpy(),\n",
    "          \"mse\": mse.numpy(),\n",
    "          \"rmse\": rmse.numpy(),\n",
    "          \"mape\": mape.numpy(),\n",
    "          \"mase\": mase.numpy()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "991e3928",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_results = evaluate_preds(y_test[1:],naive_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16d8d565",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 567.9802,\n",
       " 'mse': 1147547.0,\n",
       " 'rmse': 1071.2362,\n",
       " 'mape': 2.516525,\n",
       " 'mase': 0.99957}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a70097",
   "metadata": {},
   "source": [
    "### Format Dataset windowed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "316b580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1\n",
    "BATCH_SIZE = 32\n",
    "WINDOW_SIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb713904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelled_windows(x,horizon=HORIZON):\n",
    "  \n",
    "    return x[:,:-horizon],x[:,-horizon:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d148a188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(1, 31), dtype=int32, numpy=\n",
       " array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "         17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]])>,\n",
       " <tf.Tensor: shape=(1, 1), dtype=int32, numpy=array([[32]])>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_labelled_windows(tf.expand_dims(tf.range(32)+1,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "39f52dc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.arange(7+1),axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5551421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.arange(10-7+1-1),axis=0).T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c87d2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_windows(x,window_size =WINDOW_SIZE,horizon=HORIZON):\n",
    "    \n",
    "    window_step = np.expand_dims(np.arange(window_size+horizon),axis=0)\n",
    "    \n",
    "    window_indexes = window_step +np.expand_dims(np.arange(len(x)-(window_size+horizon-1)),axis=0).T\n",
    "#     print(window_step)\n",
    "#     print(f\"widow indexes:\\n{window_indexes,window_indexes.shape}\")\n",
    "    \n",
    "    windowed_array = x[window_indexes]\n",
    "    windows,labels = get_labelled_windows(windowed_array,horizon)\n",
    "    return windows,labels\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "849c0eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to view NumPy arrays as windows \n",
    "def make_windows(x, window_size=7, horizon=1):\n",
    "  \"\"\"\n",
    "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
    "  \"\"\"\n",
    "  # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n",
    "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
    "  # print(f\"Window step:\\n {window_step}\")\n",
    "\n",
    "  # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n",
    "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
    "  # print(f\"Window indexes:\\n {window_indexes[:3], window_indexes[-3:], window_indexes.shape}\")\n",
    "\n",
    "  # 3. Index on the target array (time series) with 2D array of multiple window steps\n",
    "  windowed_array = x[window_indexes]\n",
    "\n",
    "  # 4. Get the labelled windows\n",
    "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
    "\n",
    "  return windows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aef1d23c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  123.65499   ,   125.455     ,   108.58483   , ...,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f564a9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_windows,full_labels =make_windows(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9972fd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58788.20967893 58102.19142623 55715.54665129 56573.5554719\n",
      " 52147.82118698 49764.1320816  50032.69313676] -> [47885.62525472]\n",
      "[58102.19142623 55715.54665129 56573.5554719  52147.82118698\n",
      " 49764.1320816  50032.69313676 47885.62525472] -> [45604.61575361]\n",
      "[55715.54665129 56573.5554719  52147.82118698 49764.1320816\n",
      " 50032.69313676 47885.62525472 45604.61575361] -> [43144.47129086]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"{full_windows[i-3]} -> {full_labels[i-3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "47adab89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  123.65499   ,   125.455     ,   108.58483   , ...,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9dd06090",
   "metadata": {},
   "outputs": [],
   "source": [
    "def window(x,window=WINDOW_SIZE,horizon=HORIZON):\n",
    "    windowed_size = np.expand_dims(np.arange(window+horizon),axis=0)\n",
    "    \n",
    "    window_first = np.expand_dims(np.arange(len(x)-window+horizon-1),axis=1)\n",
    "    \n",
    "    window_index = windowed_size+window_first\n",
    "    \n",
    "    windowed_value = x[window_index]\n",
    "    \n",
    "    return windowed_value[:,:window],windowed_value[:,-horizon:]\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "50ff0bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "s,t=window(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "dd5c5402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123.65499, 125.455  , 108.58483, 118.67466, 121.33866, 120.65533,\n",
       "       121.795  ])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cce91690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123.033])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6db64b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58788.20967893 58102.19142623 55715.54665129 56573.5554719\n",
      " 52147.82118698 49764.1320816  50032.69313676] ->[47885.62525472]\n",
      "[58102.19142623 55715.54665129 56573.5554719  52147.82118698\n",
      " 49764.1320816  50032.69313676 47885.62525472] ->[45604.61575361]\n",
      "[55715.54665129 56573.5554719  52147.82118698 49764.1320816\n",
      " 50032.69313676 47885.62525472 45604.61575361] ->[43144.47129086]\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(f\"{s[i-3]} ->{t[i-3]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd97101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39e60bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2787"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c63d335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2780"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_windows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9d2118",
   "metadata": {},
   "source": [
    "## Turning windows into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ab96fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_train_test_splits(windows,labels,test_split=0.2):\n",
    "    split_size = int(len(windows)* (1-test_split))\n",
    "    train_windows = windows[:split_size]\n",
    "    train_labels = labels[:split_size]\n",
    "    \n",
    "    test_windows = windows[split_size:]\n",
    "    test_labels = labels[split_size:]\n",
    "    return train_windows,test_windows,train_labels,test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "130ad639",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_windows,test_windows,train_labels,test_labels = make_train_test_splits(full_windows,full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "388d6cea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 556, 2224)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_windows),len(test_labels),len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "c708ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f45837ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 7)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c466ade7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(train_labels.flatten()[:-HORIZON-1],y_train[WINDOW_SIZE:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01884e72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 123.033     ,  124.049     ,  125.96116   , ..., 9369.62808116,\n",
       "       9326.59962378, 9335.75240233])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(train_labels[:-HORIZON-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed12e906",
   "metadata": {},
   "source": [
    "### Make model checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dd69bf02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "454b5f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5bd6470a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_checkpoint(model_name,save_path=\"model_experiment\"):\n",
    "    return ModelCheckpoint(filepath=os.path.join(save_path,model_name),\n",
    "                          save_best_only=True,\n",
    "                          verbose=0,\n",
    "                           monitor='val_loss'\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3d4cc2",
   "metadata": {},
   "source": [
    "### Model 1 Dense model (window = 7,horizon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "68d0baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1579410f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 835.4289 - mae: 835.4289 - mse: 2590211.7500  INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 3s 50ms/step - loss: 780.3455 - mae: 780.3455 - mse: 2312725.7500 - val_loss: 2279.6528 - val_mae: 2279.6528 - val_mse: 12772731.0000\n",
      "Epoch 2/100\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 266.6907 - mae: 266.6907 - mse: 344379.9688INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 247.6756 - mae: 247.6756 - mse: 285481.1875 - val_loss: 1005.9993 - val_mae: 1005.9993 - val_mse: 3441833.2500\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 188.4116 - mae: 188.4116 - mse: 171891.6094INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 188.4116 - mae: 188.4116 - mse: 171891.6094 - val_loss: 923.2862 - val_mae: 923.2861 - val_mse: 2868220.7500\n",
      "Epoch 4/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 169.7341 - mae: 169.7341 - mse: 155006.6094INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 169.4340 - mae: 169.4340 - mse: 151700.5781 - val_loss: 900.5872 - val_mae: 900.5872 - val_mse: 2683715.5000\n",
      "Epoch 5/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 172.5016 - mae: 172.5016 - mse: 161320.4375INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 165.0894 - mae: 165.0894 - mse: 145490.7812 - val_loss: 895.2237 - val_mae: 895.2237 - val_mse: 2564574.5000\n",
      "Epoch 6/100\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 153.5240 - mae: 153.5240 - mse: 113963.5938INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 158.5210 - mae: 158.5210 - mse: 133817.7344 - val_loss: 855.1984 - val_mae: 855.1984 - val_mse: 2481873.2500\n",
      "Epoch 7/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 156.2905 - mae: 156.2905 - mse: 130819.6953INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 151.3566 - mae: 151.3566 - mse: 123446.9766 - val_loss: 840.9166 - val_mae: 840.9166 - val_mse: 2276451.5000\n",
      "Epoch 8/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 145.2025 - mae: 145.2025 - mse: 119825.4375INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 145.2560 - mae: 145.2560 - mse: 117694.5000 - val_loss: 803.5956 - val_mae: 803.5956 - val_mse: 2140573.5000\n",
      "Epoch 9/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 144.6505 - mae: 144.6505 - mse: 116260.0781INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 144.3546 - mae: 144.3546 - mse: 115269.3047 - val_loss: 799.5454 - val_mae: 799.5454 - val_mse: 2049207.7500\n",
      "Epoch 10/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 139.8629 - mae: 139.8629 - mse: 111866.4688INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 141.2943 - mae: 141.2943 - mse: 112394.5938 - val_loss: 763.5010 - val_mae: 763.5010 - val_mse: 1933140.7500\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 135.6595 - mae: 135.6595 - mse: 104118.2344 - val_loss: 771.3356 - val_mae: 771.3356 - val_mse: 1885849.7500\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.1700 - mae: 134.1700 - mse: 101780.8672 - val_loss: 782.8079 - val_mae: 782.8079 - val_mse: 1881727.1250\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.6015 - mae: 134.6015 - mse: 102345.2266 - val_loss: 784.4449 - val_mae: 784.4449 - val_mse: 1860996.1250\n",
      "Epoch 14/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 127.6786 - mae: 127.6786 - mse: 91905.3438INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 130.6127 - mae: 130.6127 - mse: 96225.1328 - val_loss: 751.3234 - val_mae: 751.3233 - val_mse: 1749609.0000\n",
      "Epoch 15/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 131.5350 - mae: 131.5350 - mse: 65715.5938INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 128.8347 - mae: 128.8347 - mse: 94306.9922 - val_loss: 696.5756 - val_mae: 696.5756 - val_mse: 1606352.3750\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.7739 - mae: 124.7739 - mse: 90394.9375 - val_loss: 702.4698 - val_mae: 702.4698 - val_mse: 1592416.2500\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 123.4474 - mae: 123.4474 - mse: 89247.7031 - val_loss: 704.9239 - val_mae: 704.9239 - val_mse: 1580782.7500\n",
      "Epoch 18/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 137.2540 - mae: 137.2540 - mse: 95732.8359INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 122.2105 - mae: 122.2105 - mse: 87607.5938 - val_loss: 667.9724 - val_mae: 667.9724 - val_mse: 1498881.8750\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 121.7263 - mae: 121.7263 - mse: 86632.2422 - val_loss: 718.8796 - val_mae: 718.8796 - val_mse: 1589299.3750\n",
      "Epoch 20/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 119.0797 - mae: 119.0797 - mse: 84785.0938 INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 119.2420 - mae: 119.2420 - mse: 84334.3203 - val_loss: 657.0666 - val_mae: 657.0666 - val_mse: 1447501.1250\n",
      "Epoch 21/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 120.6400 - mae: 120.6400 - mse: 80809.7266INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 121.2275 - mae: 121.2275 - mse: 85743.3828 - val_loss: 637.0333 - val_mae: 637.0333 - val_mse: 1401774.2500\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 119.9544 - mae: 119.9544 - mse: 84050.1094 - val_loss: 671.2488 - val_mae: 671.2488 - val_mse: 1447895.7500\n",
      "Epoch 23/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 121.4971 - mae: 121.4971 - mse: 80902.4922INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 121.9248 - mae: 121.9248 - mse: 83746.1250 - val_loss: 633.3592 - val_mae: 633.3592 - val_mse: 1367377.8750\n",
      "Epoch 24/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 117.6122 - mae: 117.6122 - mse: 89962.4219INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 116.3665 - mae: 116.3665 - mse: 81446.6562 - val_loss: 624.4852 - val_mae: 624.4852 - val_mse: 1348960.6250\n",
      "Epoch 25/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 119.5410 - mae: 119.5410 - mse: 83412.9141INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 114.6816 - mae: 114.6816 - mse: 78912.8359 - val_loss: 619.7570 - val_mae: 619.7570 - val_mse: 1351089.7500\n",
      "Epoch 26/100\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 117.8695 - mae: 117.8695 - mse: 73583.8516INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 116.4455 - mae: 116.4455 - mse: 79365.5938 - val_loss: 615.6364 - val_mae: 615.6364 - val_mse: 1321514.3750\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 116.5868 - mae: 116.5868 - mse: 78672.9062 - val_loss: 615.9629 - val_mae: 615.9629 - val_mse: 1313077.5000\n",
      "Epoch 28/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 110.8923 - mae: 110.8923 - mse: 71582.1016INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 113.4691 - mae: 113.4691 - mse: 77440.0938 - val_loss: 608.0921 - val_mae: 608.0921 - val_mse: 1309775.3750\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 113.7598 - mae: 113.7598 - mse: 78506.9531 - val_loss: 621.9305 - val_mae: 621.9305 - val_mse: 1313324.6250\n",
      "Epoch 30/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 115.9323 - mae: 115.9323 - mse: 80062.6016INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 116.8613 - mae: 116.8613 - mse: 79236.4609 - val_loss: 604.4056 - val_mae: 604.4056 - val_mse: 1283408.0000\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 111.9375 - mae: 111.9375 - mse: 74849.0703 - val_loss: 609.3882 - val_mae: 609.3882 - val_mse: 1284506.2500\n",
      "Epoch 32/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 113.0948 - mae: 113.0948 - mse: 77198.0156INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 112.4175 - mae: 112.4175 - mse: 77178.5859 - val_loss: 603.0588 - val_mae: 603.0588 - val_mse: 1273059.5000\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.6697 - mae: 112.6697 - mse: 75787.9766 - val_loss: 645.6973 - val_mae: 645.6973 - val_mse: 1353255.7500\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.9867 - mae: 111.9867 - mse: 77245.7266 - val_loss: 604.7634 - val_mae: 604.7634 - val_mse: 1289360.3750\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 110.9451 - mae: 110.9451 - mse: 75301.7812INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 110.9451 - mae: 110.9451 - mse: 75301.7812 - val_loss: 593.4648 - val_mae: 593.4648 - val_mse: 1250491.3750\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.4816 - mae: 114.4816 - mse: 76138.5391 - val_loss: 608.0074 - val_mae: 608.0074 - val_mse: 1269272.3750\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.2016 - mae: 110.2016 - mse: 74635.3047 - val_loss: 597.2308 - val_mae: 597.2308 - val_mse: 1248474.0000\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 112.2372 - mae: 112.2372 - mse: 75821.6953 - val_loss: 637.9798 - val_mae: 637.9798 - val_mse: 1366130.8750\n",
      "Epoch 39/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 117.7033 - mae: 117.7033 - mse: 81882.5547 INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 115.1289 - mae: 115.1289 - mse: 76339.6797 - val_loss: 587.4680 - val_mae: 587.4680 - val_mse: 1233512.3750\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.0854 - mae: 110.0854 - mse: 73528.4766 - val_loss: 592.7117 - val_mae: 592.7117 - val_mse: 1251474.6250\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.6344 - mae: 110.6344 - mse: 73528.7891 - val_loss: 593.8997 - val_mae: 593.8997 - val_mse: 1253678.5000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 113.5762 - mae: 113.5762 - mse: 77076.7031 - val_loss: 636.3674 - val_mae: 636.3674 - val_mse: 1317283.5000\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 116.2285 - mae: 116.2285 - mse: 74712.2031 - val_loss: 662.9263 - val_mae: 662.9263 - val_mse: 1419201.7500\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 120.0192 - mae: 120.0192 - mse: 80971.8750 - val_loss: 635.6360 - val_mae: 635.6360 - val_mse: 1345999.3750\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.9675 - mae: 110.9675 - mse: 74941.2891 - val_loss: 601.9926 - val_mae: 601.9926 - val_mse: 1244816.7500\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 111.6012 - mae: 111.6012 - mse: 74565.6016 - val_loss: 593.3531 - val_mae: 593.3531 - val_mse: 1248764.3750\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.6161 - mae: 109.6161 - mse: 74190.7109 - val_loss: 637.0011 - val_mae: 637.0011 - val_mse: 1314970.2500\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.1368 - mae: 109.1368 - mse: 72792.5547 - val_loss: 598.4197 - val_mae: 598.4197 - val_mse: 1234610.1250\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 112.4355 - mae: 112.4355 - mse: 73980.3359 INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 112.4355 - mae: 112.4355 - mse: 73980.3359 - val_loss: 579.7042 - val_mae: 579.7042 - val_mse: 1208301.8750\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.2108 - mae: 110.2108 - mse: 72939.7109 - val_loss: 639.2327 - val_mae: 639.2327 - val_mse: 1347994.1250\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 111.0958 - mae: 111.0958 - mse: 73281.9062 - val_loss: 597.3571 - val_mae: 597.3571 - val_mse: 1229791.1250\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.7351 - mae: 110.7351 - mse: 74529.6328 - val_loss: 580.7227 - val_mae: 580.7227 - val_mse: 1215477.1250\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 111.1785 - mae: 111.1785 - mse: 74149.4766 - val_loss: 648.3586 - val_mae: 648.3586 - val_mse: 1336951.1250\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 114.0831 - mae: 114.0831 - mse: 74815.0781 - val_loss: 593.2006 - val_mae: 593.2006 - val_mse: 1220661.2500\n",
      "Epoch 55/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 114.3634 - mae: 114.3634 - mse: 78397.8359 INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 110.4910 - mae: 110.4910 - mse: 74711.2500 - val_loss: 579.5067 - val_mae: 579.5067 - val_mse: 1211580.3750\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.0488 - mae: 108.0488 - mse: 71844.1562 - val_loss: 807.3853 - val_mae: 807.3853 - val_mse: 1859292.5000\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 125.0614 - mae: 125.0614 - mse: 84025.2812 - val_loss: 674.1658 - val_mae: 674.1658 - val_mse: 1437686.8750\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.4340 - mae: 115.4340 - mse: 73710.7422 - val_loss: 582.2697 - val_mae: 582.2697 - val_mse: 1202679.3750\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.0881 - mae: 110.0881 - mse: 72845.1172 - val_loss: 606.7640 - val_mae: 606.7640 - val_mse: 1267544.0000\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.7156 - mae: 108.7156 - mse: 72675.7734 - val_loss: 602.3099 - val_mae: 602.3099 - val_mse: 1234690.0000\n",
      "Epoch 61/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 108.0080 - mae: 108.0080 - mse: 72060.4375INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 108.1525 - mae: 108.1525 - mse: 72252.1250 - val_loss: 573.9990 - val_mae: 573.9990 - val_mse: 1189583.5000\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.3726 - mae: 107.3726 - mse: 70822.7891 - val_loss: 581.7015 - val_mae: 581.7015 - val_mse: 1214006.6250\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.7667 - mae: 110.7667 - mse: 73178.4453 - val_loss: 637.5243 - val_mae: 637.5243 - val_mse: 1311201.6250\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.1539 - mae: 110.1539 - mse: 72588.2188 - val_loss: 586.6598 - val_mae: 586.6598 - val_mse: 1207116.3750\n",
      "Epoch 65/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 107.9784 - mae: 107.9784 - mse: 73852.8281 INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 32ms/step - loss: 108.2325 - mae: 108.2325 - mse: 71962.0859 - val_loss: 573.5618 - val_mae: 573.5618 - val_mse: 1188986.2500\n",
      "Epoch 66/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 105.7377 - mae: 105.7377 - mse: 66057.4922INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 108.6825 - mae: 108.6825 - mse: 71026.3516 - val_loss: 572.2206 - val_mae: 572.2206 - val_mse: 1187818.3750\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 106.6371 - mae: 106.6371 - mse: 70166.2578 - val_loss: 646.6359 - val_mae: 646.6359 - val_mse: 1356393.0000\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 114.1603 - mae: 114.1603 - mse: 71297.3203 - val_loss: 681.8572 - val_mae: 681.8572 - val_mse: 1455430.5000\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 124.5514 - mae: 124.5514 - mse: 81238.9609 - val_loss: 655.9892 - val_mae: 655.9892 - val_mse: 1383324.6250\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 125.0234 - mae: 125.0234 - mse: 83058.2109 - val_loss: 601.0039 - val_mae: 601.0039 - val_mse: 1256963.6250\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 110.3652 - mae: 110.3652 - mse: 71691.4922 - val_loss: 595.3957 - val_mae: 595.3957 - val_mse: 1222771.6250\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 107.9285 - mae: 107.9285 - mse: 71745.5312 - val_loss: 573.7084 - val_mae: 573.7084 - val_mse: 1192818.5000\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.5085 - mae: 109.5085 - mse: 71691.1484 - val_loss: 580.4183 - val_mae: 580.4183 - val_mse: 1211317.6250\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.7380 - mae: 108.7380 - mse: 72051.1094 - val_loss: 576.1216 - val_mae: 576.1216 - val_mse: 1199670.7500\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.9404 - mae: 107.9404 - mse: 71043.1328 - val_loss: 591.1470 - val_mae: 591.1470 - val_mse: 1211107.6250\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 109.4232 - mae: 109.4232 - mse: 72295.0312 - val_loss: 597.8611 - val_mae: 597.8611 - val_mse: 1243936.2500\n",
      "Epoch 77/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 111.2408 - mae: 111.2408 - mse: 73717.8438INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 107.5879 - mae: 107.5879 - mse: 70333.8359 - val_loss: 571.9301 - val_mae: 571.9301 - val_mse: 1186830.0000\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.1598 - mae: 108.1598 - mse: 70200.0781 - val_loss: 575.2387 - val_mae: 575.2387 - val_mse: 1195318.0000\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.9175 - mae: 107.9175 - mse: 72451.5859 - val_loss: 617.3083 - val_mae: 617.3083 - val_mse: 1285512.3750\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.9510 - mae: 108.9510 - mse: 72158.7812 - val_loss: 583.4841 - val_mae: 583.4841 - val_mse: 1194356.7500\n",
      "Epoch 81/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 105.6603 - mae: 105.6603 - mse: 69466.9375INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 106.0505 - mae: 106.0505 - mse: 69690.9219 - val_loss: 570.0803 - val_mae: 570.0803 - val_mse: 1177237.8750\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.6827 - mae: 115.6827 - mse: 76903.4922 - val_loss: 575.7388 - val_mae: 575.7388 - val_mse: 1194662.6250\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.9379 - mae: 110.9379 - mse: 72968.3047 - val_loss: 659.6579 - val_mae: 659.6579 - val_mse: 1388829.8750\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.4836 - mae: 111.4836 - mse: 73017.9453 - val_loss: 570.1957 - val_mae: 570.1957 - val_mse: 1177492.2500\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.5949 - mae: 107.5949 - mse: 70728.2266 - val_loss: 601.5939 - val_mae: 601.5939 - val_mse: 1228450.7500\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.9425 - mae: 108.9425 - mse: 70066.7422 - val_loss: 592.8101 - val_mae: 592.8101 - val_mse: 1209680.7500\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 105.7717 - mae: 105.7717 - mse: 68382.3516 - val_loss: 603.6174 - val_mae: 603.6174 - val_mse: 1252409.5000\n",
      "Epoch 88/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 112.7661 - mae: 112.7661 - mse: 78939.3203 INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 107.9217 - mae: 107.9217 - mse: 71668.0469 - val_loss: 569.0500 - val_mae: 569.0500 - val_mse: 1174588.3750\n",
      "Epoch 89/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 101.2451 - mae: 101.2451 - mse: 61805.3203INFO:tensorflow:Assets written to: model_experiment\\Model_1\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 106.0344 - mae: 106.0344 - mse: 68979.1484 - val_loss: 568.9510 - val_mae: 568.9510 - val_mse: 1171743.5000\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 105.4977 - mae: 105.4977 - mse: 67516.5000 - val_loss: 581.7677 - val_mae: 581.7677 - val_mse: 1190160.5000\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.8468 - mae: 108.8468 - mse: 71112.3281 - val_loss: 573.6025 - val_mae: 573.6025 - val_mse: 1185216.0000\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.8884 - mae: 110.8884 - mse: 73287.8125 - val_loss: 576.8243 - val_mae: 576.8243 - val_mse: 1181628.3750\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 113.8781 - mae: 113.8781 - mse: 75236.4375 - val_loss: 608.3022 - val_mae: 608.3022 - val_mse: 1264206.1250\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.5763 - mae: 110.5763 - mse: 72590.8672 - val_loss: 601.6042 - val_mae: 601.6042 - val_mse: 1229105.1250\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 106.5906 - mae: 106.5906 - mse: 68612.3281 - val_loss: 570.3651 - val_mae: 570.3651 - val_mse: 1175759.6250\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.9515 - mae: 116.9515 - mse: 75082.1172 - val_loss: 615.2584 - val_mae: 615.2584 - val_mse: 1277124.3750\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 108.0739 - mae: 108.0739 - mse: 71321.4219 - val_loss: 580.3076 - val_mae: 580.3076 - val_mse: 1202622.3750\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.7102 - mae: 108.7102 - mse: 70248.0625 - val_loss: 586.6510 - val_mae: 586.6510 - val_mse: 1200831.2500\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.0488 - mae: 109.0488 - mse: 70913.1562 - val_loss: 570.0628 - val_mae: 570.0628 - val_mse: 1177064.5000\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 106.1845 - mae: 106.1845 - mse: 68681.7344 - val_loss: 585.9758 - val_mae: 585.9758 - val_mse: 1197802.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d554c58580>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_1 = Sequential(name='Model_1')\n",
    "#model_1.add(Input(shape=(128,WINDOW_SIZE)))\n",
    "model_1.add(Dense(128,activation='relu'))\n",
    "model_1.add(Dense(HORIZON,activation='linear'))\n",
    "\n",
    "model_1.compile(metrics=['mae','mse'],optimizer=Adam(),loss='mae')\n",
    "\n",
    "model_1.fit(x=train_windows,\n",
    "            y=train_labels,\n",
    "           epochs=100,\n",
    "           batch_size=128,\n",
    "           validation_data=(test_windows,test_labels),\n",
    "           callbacks=[create_model_checkpoint(model_name=model_1.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6622f798",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 567.9802,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.516525,\n",
       " 'MASE': 0.99957}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "11477852",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 585.9758 - mae: 585.9758 - mse: 1197802.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[585.9757690429688, 585.9757690429688, 1197802.0]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8fb3c5c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 568.9510 - mae: 568.9510 - mse: 1171743.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[568.9510498046875, 568.9510498046875, 1171743.75]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = tf.keras.models.load_model(\"model_experiment/Model_1/\")\n",
    "model_1.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ba921ba1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x21a74bb06a0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "start = 500\n",
    "plt.plot(X_test[start:-2],model_1.predict(test_windows).flatten()[start:],label='Predict')\n",
    "plt.plot(X_test[start:-2],y_test[start:-2],label='True')\n",
    "plt.plot(X_test[start:-2],y_test[start+1:-1])\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "bb857701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model,input_data):\n",
    "    forecast = model.predict(input_data)\n",
    "    return tf.squeeze(forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2f1c9656",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_preds = make_preds(model_1,test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3bc1580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(556, 556)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels),len(model_1_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e178850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((556, 1), TensorShape([556]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape,model_1_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0f51c6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 568.9511,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.5448983,\n",
       " 'MASE': 0.99948955}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results = evaluate_preds(test_labels.flatten(),model_1_preds)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9825f9e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 567.9802,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.516525,\n",
       " 'MASE': 0.99957}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7517aa1d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "offset = 450\n",
    "plt.figure(figsize=(10,7))\n",
    "plot_time_series(timesteps=X_test[-len(test_windows):],\n",
    "                 values=test_labels[:,0],\n",
    "                 start=offset,\n",
    "                 label='Test Data')\n",
    "plot_time_series(timesteps=X_test[-len(test_windows):],\n",
    "                 values=model_1_preds,\n",
    "                 start=offset,\n",
    "                 label='Pred Data',\n",
    "                format=\"-\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8fab4f",
   "metadata": {},
   "source": [
    "### Model 2 : same as model 1 (window size = 30), (horizon = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c929ba9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bbeb21e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_windows,full_labels =make_windows(prices,window_size=30,horizon=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9890d095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2757, 30), (2757, 1))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_windows.shape,full_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3679b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_windows,test_windows,train_labels,test_labels = make_train_test_splits(full_windows,full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "07ebcfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2205"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c2a74fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 1411.7307 - mae: 1411.7307 - mse: 6959537.0000 INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 1s 46ms/step - loss: 1097.0399 - mae: 1097.0399 - mse: 4741506.0000 - val_loss: 3900.2537 - val_mae: 3900.2537 - val_mse: 32752730.0000\n",
      "Epoch 2/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 445.7693 - mae: 445.7693 - mse: 865215.4375 INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 428.0732 - mae: 428.0732 - mse: 811548.2500 - val_loss: 1587.0745 - val_mae: 1587.0745 - val_mse: 6817661.5000\n",
      "Epoch 3/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 293.0821 - mae: 293.0821 - mse: 398205.9375INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 279.7655 - mae: 279.7655 - mse: 363083.0625 - val_loss: 1220.6888 - val_mae: 1220.6888 - val_mse: 4447002.0000\n",
      "Epoch 4/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 221.6801 - mae: 221.6801 - mse: 223690.7031INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 224.3637 - mae: 224.3637 - mse: 225072.2188 - val_loss: 1160.1572 - val_mae: 1160.1572 - val_mse: 3837504.2500\n",
      "Epoch 5/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 186.6047 - mae: 186.6047 - mse: 171997.9062INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 187.9681 - mae: 187.9681 - mse: 173777.0312 - val_loss: 1007.6487 - val_mae: 1007.6487 - val_mse: 3224229.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 182.9174 - mae: 182.9174 - mse: 162950.3750 - val_loss: 1019.5818 - val_mae: 1019.5818 - val_mse: 3408885.2500\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 187.7612 - mae: 187.7612 - mse: 159475.8750 - val_loss: 1145.1758 - val_mae: 1145.1758 - val_mse: 4078532.2500\n",
      "Epoch 8/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 194.8690 - mae: 194.8690 - mse: 178098.0312INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 192.2202 - mae: 192.2202 - mse: 172722.5469 - val_loss: 967.8077 - val_mae: 967.8077 - val_mse: 2845453.7500\n",
      "Epoch 9/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 169.7850 - mae: 169.7850 - mse: 147184.0312INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 167.4042 - mae: 167.4042 - mse: 141257.4688 - val_loss: 896.5217 - val_mae: 896.5217 - val_mse: 2643020.0000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 161.6689 - mae: 161.6689 - mse: 132314.9688INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 161.6689 - mae: 161.6689 - mse: 132314.9688 - val_loss: 881.9178 - val_mae: 881.9178 - val_mse: 2558588.0000\n",
      "Epoch 11/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 162.7377 - mae: 162.7377 - mse: 128465.7969INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 162.2630 - mae: 162.2630 - mse: 127474.1406 - val_loss: 862.7010 - val_mae: 862.7010 - val_mse: 2432215.0000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 157.6156 - mae: 157.6156 - mse: 126629.2812INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 157.6156 - mae: 157.6156 - mse: 126629.2812 - val_loss: 855.2238 - val_mae: 855.2238 - val_mse: 2351040.0000\n",
      "Epoch 13/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 161.7501 - mae: 161.7501 - mse: 126826.4922INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 164.3571 - mae: 164.3571 - mse: 130452.2422 - val_loss: 845.0386 - val_mae: 845.0386 - val_mse: 2380580.0000\n",
      "Epoch 14/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 151.7793 - mae: 151.7793 - mse: 115971.3906INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 152.4233 - mae: 152.4233 - mse: 119918.8594 - val_loss: 835.7405 - val_mae: 835.7405 - val_mse: 2279386.5000\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 165.0978 - mae: 165.0978 - mse: 126962.9844 - val_loss: 920.6229 - val_mae: 920.6229 - val_mse: 2756908.7500\n",
      "Epoch 16/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 164.6484 - mae: 164.6484 - mse: 121376.0000INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 166.0639 - mae: 166.0639 - mse: 126534.0625 - val_loss: 814.6472 - val_mae: 814.6472 - val_mse: 2187638.0000\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 165.1733 - mae: 165.1733 - mse: 130918.6875 - val_loss: 939.7372 - val_mae: 939.7372 - val_mse: 2560630.7500\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 158.3085 - mae: 158.3085 - mse: 122879.3594 - val_loss: 929.8369 - val_mae: 929.8369 - val_mse: 2522551.7500\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 151.6603 - mae: 151.6603 - mse: 113185.5625 - val_loss: 1071.7583 - val_mae: 1071.7583 - val_mse: 3444894.7500\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 155.9877 - mae: 155.9877 - mse: 123244.1797 - val_loss: 906.9962 - val_mae: 906.9962 - val_mse: 2416914.0000\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 150.9352 - mae: 150.9352 - mse: 115268.9297 - val_loss: 1259.6165 - val_mae: 1259.6165 - val_mse: 3904281.0000\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 186.2315 - mae: 186.2315 - mse: 149336.4688 - val_loss: 821.1555 - val_mae: 821.1555 - val_mse: 2226543.7500\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 149.3854 - mae: 149.3854 - mse: 109965.0781 - val_loss: 1061.1250 - val_mae: 1061.1250 - val_mse: 2973403.5000\n",
      "Epoch 24/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 159.6859 - mae: 159.6859 - mse: 116721.3906INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 161.7742 - mae: 161.7742 - mse: 121110.6250 - val_loss: 794.9154 - val_mae: 794.9154 - val_mse: 2019348.3750\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 147.8488 - mae: 147.8488 - mse: 110879.7656 - val_loss: 1092.2104 - val_mae: 1092.2104 - val_mse: 3088394.7500\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 150.0337 - mae: 150.0337 - mse: 111213.2812 - val_loss: 802.3950 - val_mae: 802.3950 - val_mse: 2125820.2500\n",
      "Epoch 27/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 117.7188 - mae: 117.7188 - mse: 46695.1172INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 154.9933 - mae: 154.9933 - mse: 109837.4766 - val_loss: 748.0327 - val_mae: 748.0327 - val_mse: 1870825.3750\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 141.5399 - mae: 141.5399 - mse: 101088.8594 - val_loss: 960.1356 - val_mae: 960.1356 - val_mse: 2812905.7500\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 148.5069 - mae: 148.5069 - mse: 110140.6641 - val_loss: 758.3329 - val_mae: 758.3329 - val_mse: 1871426.0000\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 148.1240 - mae: 148.1240 - mse: 108366.9297 - val_loss: 988.7416 - val_mae: 988.7416 - val_mse: 2639810.2500\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 142.3972 - mae: 142.3972 - mse: 100558.5703 - val_loss: 847.3676 - val_mae: 847.3676 - val_mse: 2286142.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 184.5251 - mae: 184.5251 - mse: 154605.8281INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 148.1294 - mae: 148.1294 - mse: 106817.7812 - val_loss: 726.4918 - val_mae: 726.4918 - val_mse: 1772761.8750\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 141.7309 - mae: 141.7309 - mse: 102930.2734 - val_loss: 767.2233 - val_mae: 767.2233 - val_mse: 1945827.2500\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 135.4458 - mae: 135.4458 - mse: 92370.8281INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 135.4458 - mae: 135.4458 - mse: 92370.8281 - val_loss: 721.9368 - val_mae: 721.9368 - val_mse: 1763867.0000\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 131.7838 - mae: 131.7838 - mse: 91448.7891 - val_loss: 759.3353 - val_mae: 759.3353 - val_mse: 1836807.0000\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 131.5018 - mae: 131.5018 - mse: 92934.0938 - val_loss: 814.7689 - val_mae: 814.7689 - val_mse: 1997793.3750\n",
      "Epoch 37/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 125.6488 - mae: 125.6488 - mse: 60332.1250INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 143.4647 - mae: 143.4647 - mse: 100143.1094 - val_loss: 708.7821 - val_mae: 708.7821 - val_mse: 1696078.6250\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.5705 - mae: 134.5705 - mse: 92221.2344 - val_loss: 821.9357 - val_mae: 821.9357 - val_mse: 2149077.7500\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 137.7672 - mae: 137.7672 - mse: 98614.1953 - val_loss: 969.4777 - val_mae: 969.4777 - val_mse: 2517117.5000\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 142.7820 - mae: 142.7820 - mse: 91609.3047 - val_loss: 901.4053 - val_mae: 901.4053 - val_mse: 2259121.5000\n",
      "Epoch 41/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 117.7906 - mae: 117.7906 - mse: 38178.6523INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 142.1888 - mae: 142.1888 - mse: 98998.3359 - val_loss: 689.8060 - val_mae: 689.8060 - val_mse: 1620425.2500\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 130.9877 - mae: 130.9877 - mse: 88242.9141 - val_loss: 751.3142 - val_mae: 751.3142 - val_mse: 1782372.8750\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.4450 - mae: 131.4450 - mse: 90820.2266 - val_loss: 746.7275 - val_mae: 746.7275 - val_mse: 1830367.7500\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 137.5511 - mae: 137.5511 - mse: 96568.3281 - val_loss: 751.4652 - val_mae: 751.4652 - val_mse: 1842565.7500\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.3822 - mae: 134.3822 - mse: 93087.4297 - val_loss: 694.2699 - val_mae: 694.2699 - val_mse: 1617442.1250\n",
      "Epoch 46/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 125.8232 - mae: 125.8232 - mse: 87157.9531INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 127.4527 - mae: 127.4527 - mse: 87612.0781 - val_loss: 676.5610 - val_mae: 676.5610 - val_mse: 1555773.0000\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 136.6635 - mae: 136.6635 - mse: 92716.2344 - val_loss: 1113.9982 - val_mae: 1113.9982 - val_mse: 3065015.7500\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 164.2887 - mae: 164.2887 - mse: 117708.3984INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 164.2887 - mae: 164.2887 - mse: 117708.3984 - val_loss: 667.6456 - val_mae: 667.6456 - val_mse: 1524165.5000\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 127.9774 - mae: 127.9774 - mse: 85549.1797 - val_loss: 718.8885 - val_mae: 718.8885 - val_mse: 1691650.7500\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 141.8780 - mae: 141.8780 - mse: 93444.8984 - val_loss: 829.6292 - val_mae: 829.6292 - val_mse: 2098737.5000\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.4569 - mae: 129.4569 - mse: 87931.0703 - val_loss: 987.5338 - val_mae: 987.5338 - val_mse: 2758906.0000\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 141.4287 - mae: 141.4287 - mse: 98486.4609 - val_loss: 715.3037 - val_mae: 715.3037 - val_mse: 1633319.6250\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 146.1227 - mae: 146.1227 - mse: 98856.7734 - val_loss: 1116.8126 - val_mae: 1116.8126 - val_mse: 3300862.5000\n",
      "Epoch 54/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 205.2889 - mae: 205.2889 - mse: 147244.3438INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 162.9252 - mae: 162.9252 - mse: 116505.1250 - val_loss: 658.4476 - val_mae: 658.4476 - val_mse: 1469404.1250\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 134.5520 - mae: 134.5520 - mse: 88455.0234 - val_loss: 906.1519 - val_mae: 906.1519 - val_mse: 2212985.0000\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 132.1189 - mae: 132.1189 - mse: 88770.3125 - val_loss: 658.8979 - val_mae: 658.8979 - val_mse: 1476355.6250\n",
      "Epoch 57/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 127.2736 - mae: 127.2736 - mse: 82781.3984INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 128.6264 - mae: 128.6264 - mse: 84349.8281 - val_loss: 648.7651 - val_mae: 648.7651 - val_mse: 1439428.0000\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 133.0039 - mae: 133.0039 - mse: 89231.0938 - val_loss: 760.6868 - val_mae: 760.6868 - val_mse: 1814641.8750\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 167.5204 - mae: 167.5204 - mse: 119260.3438 - val_loss: 699.1824 - val_mae: 699.1824 - val_mse: 1592398.1250\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 121.4026 - mae: 121.4026 - mse: 78786.4297 - val_loss: 784.7621 - val_mae: 784.7621 - val_mse: 1797242.2500\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.8212 - mae: 131.8212 - mse: 87380.6250 - val_loss: 761.1855 - val_mae: 761.1855 - val_mse: 1800775.5000\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 133.7610 - mae: 133.7610 - mse: 90872.0625 - val_loss: 830.7225 - val_mae: 830.7225 - val_mse: 2052535.6250\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 128.0924 - mae: 128.0924 - mse: 86278.4688 - val_loss: 662.2833 - val_mae: 662.2833 - val_mse: 1462994.7500\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 125.7873 - mae: 125.7873 - mse: 83929.3047 - val_loss: 725.7394 - val_mae: 725.7394 - val_mse: 1622991.8750\n",
      "Epoch 65/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 129.0102 - mae: 129.0102 - mse: 77550.9219INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 129.3582 - mae: 129.3582 - mse: 84437.2812 - val_loss: 638.4762 - val_mae: 638.4762 - val_mse: 1393845.1250\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 121.8753 - mae: 121.8753 - mse: 81456.2109 - val_loss: 735.8253 - val_mae: 735.8253 - val_mse: 1694805.5000\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.5709 - mae: 124.5709 - mse: 82757.4375 - val_loss: 702.7538 - val_mae: 702.7538 - val_mse: 1596079.2500\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 134.1436 - mae: 134.1436 - mse: 89529.9453 - val_loss: 640.6722 - val_mae: 640.6722 - val_mse: 1398268.8750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 123.1770 - mae: 123.1770 - mse: 80330.8672 - val_loss: 1110.4432 - val_mae: 1110.4432 - val_mse: 2994969.0000\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 135.9602 - mae: 135.9602 - mse: 92325.2969 - val_loss: 778.5548 - val_mae: 778.5548 - val_mse: 1764892.6250\n",
      "Epoch 71/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 136.5198 - mae: 136.5198 - mse: 69798.0547INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 128.7049 - mae: 128.7049 - mse: 86091.0781 - val_loss: 636.7365 - val_mae: 636.7365 - val_mse: 1380941.6250\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 120.7498 - mae: 120.7498 - mse: 80539.0547INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 120.7498 - mae: 120.7498 - mse: 80539.0547 - val_loss: 636.1567 - val_mae: 636.1567 - val_mse: 1384186.6250\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.8846 - mae: 119.8846 - mse: 78536.1172 - val_loss: 722.2628 - val_mae: 722.2628 - val_mse: 1590577.5000\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 128.0455 - mae: 128.0455 - mse: 83733.4062INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 128.0455 - mae: 128.0455 - mse: 83733.4062 - val_loss: 622.5280 - val_mae: 622.5280 - val_mse: 1334697.0000\n",
      "Epoch 75/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 127.1582 - mae: 127.1582 - mse: 87346.4688INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 122.0446 - mae: 122.0446 - mse: 79881.0156 - val_loss: 619.5175 - val_mae: 619.5175 - val_mse: 1324510.2500\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.6730 - mae: 122.6730 - mse: 80796.2812 - val_loss: 856.6989 - val_mae: 856.6988 - val_mse: 2004174.6250\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 126.3470 - mae: 126.3470 - mse: 80182.0469 - val_loss: 641.5902 - val_mae: 641.5902 - val_mse: 1378807.6250\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 118.5847 - mae: 118.5847 - mse: 78303.8281 - val_loss: 690.7908 - val_mae: 690.7908 - val_mse: 1531805.1250\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.4505 - mae: 131.4505 - mse: 85134.6875 - val_loss: 621.2333 - val_mae: 621.2333 - val_mse: 1327195.3750\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 125.0166 - mae: 125.0166 - mse: 82027.0312 - val_loss: 790.1846 - val_mae: 790.1846 - val_mse: 1786557.8750\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.7429 - mae: 120.7429 - mse: 79155.5859 - val_loss: 657.8801 - val_mae: 657.8801 - val_mse: 1414974.1250\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.6583 - mae: 119.6583 - mse: 77666.8828 - val_loss: 799.6915 - val_mae: 799.6915 - val_mse: 1808157.5000\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 131.6879 - mae: 131.6879 - mse: 84360.2109 - val_loss: 651.2426 - val_mae: 651.2426 - val_mse: 1393561.6250\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 125.4594 - mae: 125.4594 - mse: 79191.6953 - val_loss: 695.7399 - val_mae: 695.7399 - val_mse: 1503768.7500\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 123.6267 - mae: 123.6267 - mse: 81975.1562 - val_loss: 825.9113 - val_mae: 825.9113 - val_mse: 1895494.1250\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 139.2674 - mae: 139.2674 - mse: 89564.3984 - val_loss: 711.2962 - val_mae: 711.2962 - val_mse: 1579855.1250\n",
      "Epoch 87/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 136.1700 - mae: 136.1700 - mse: 132347.1719INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 139.8416 - mae: 139.8416 - mse: 90350.6797 - val_loss: 616.3276 - val_mae: 616.3276 - val_mse: 1309630.0000\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 134.8590 - mae: 134.8590 - mse: 85241.6250 - val_loss: 1100.9899 - val_mae: 1100.9899 - val_mse: 2912869.5000\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 152.7612 - mae: 152.7612 - mse: 104070.4531 - val_loss: 815.0580 - val_mae: 815.0580 - val_mse: 1857857.1250\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 160.4490 - mae: 160.4490 - mse: 107181.4141 - val_loss: 1111.4733 - val_mae: 1111.4733 - val_mse: 2971819.5000\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 134.0435 - mae: 134.0435 - mse: 86288.1016 - val_loss: 810.8096 - val_mae: 810.8096 - val_mse: 1923505.3750\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 127.9937 - mae: 127.9937 - mse: 85649.0469 - val_loss: 781.3551 - val_mae: 781.3551 - val_mse: 1748799.5000\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 137.5326 - mae: 137.5326 - mse: 87676.9922 - val_loss: 776.2223 - val_mae: 776.2223 - val_mse: 1733238.1250\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 135.8670 - mae: 135.8670 - mse: 86816.2578 - val_loss: 731.3998 - val_mae: 731.3998 - val_mse: 1596562.7500\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 148.7159 - mae: 148.7159 - mse: 100474.5938 - val_loss: 635.4964 - val_mae: 635.4964 - val_mse: 1343190.5000\n",
      "Epoch 96/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 108.0598 - mae: 108.0598 - mse: 42107.8047INFO:tensorflow:Assets written to: model_experiment\\Model_2\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 133.0909 - mae: 133.0909 - mse: 91028.2344 - val_loss: 605.8741 - val_mae: 605.8741 - val_mse: 1273361.1250\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 117.5806 - mae: 117.5806 - mse: 75189.4219 - val_loss: 706.8725 - val_mae: 706.8725 - val_mse: 1551657.5000\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 120.7865 - mae: 120.7865 - mse: 76582.7031 - val_loss: 718.7263 - val_mae: 718.7263 - val_mse: 1555904.8750\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 125.8117 - mae: 125.8117 - mse: 78376.3047 - val_loss: 988.9795 - val_mae: 988.9795 - val_mse: 2610509.5000\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 124.1724 - mae: 124.1724 - mse: 83770.4688 - val_loss: 659.3332 - val_mae: 659.3332 - val_mse: 1397247.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a74605e50>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_2 = Sequential(name='Model_2')\n",
    "#model_1.add(Input(shape=(128,WINDOW_SIZE)))\n",
    "model_2.add(Dense(128,activation='relu'))\n",
    "model_2.add(Dense(HORIZON,activation='linear'))\n",
    "\n",
    "model_2.compile(metrics=['mae','mse'],optimizer=Adam(),loss='mae')\n",
    "\n",
    "model_2.fit(x=train_windows,\n",
    "            y=train_labels,\n",
    "           epochs=100,\n",
    "           batch_size=128,\n",
    "           validation_data=(test_windows,test_labels),\n",
    "           callbacks=[create_model_checkpoint(model_name=model_2.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4e0c5bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step - loss: 659.3332 - mae: 659.3332 - mse: 1397247.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[659.3331909179688, 659.3331909179688, 1397247.5]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "604d1702",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = tf.keras.models.load_model(\"model_experiment/Model_2/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "28d1b021",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_preds = make_preds(model_2,test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f574b5da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(552,), dtype=float32, numpy=\n",
       "array([ 8882.84  ,  8904.423 ,  8762.442 ,  8559.087 ,  8428.983 ,\n",
       "        8327.641 ,  8256.728 ,  8126.8335,  8171.7334,  7796.058 ,\n",
       "        7325.6577,  7209.108 ,  7086.571 ,  7088.627 ,  7125.4873,\n",
       "        7328.0757,  7507.9004,  7594.797 ,  7616.422 ,  7437.9917,\n",
       "        7401.9155,  7259.2407,  7303.4756,  7365.538 ,  7525.4897,\n",
       "        7530.848 ,  7548.2666,  7428.255 ,  7184.106 ,  7258.7397,\n",
       "        7140.139 ,  7315.1187,  7133.9297,  7208.6655,  6967.998 ,\n",
       "        6742.6772,  7080.0107,  7248.492 ,  7093.139 ,  7293.914 ,\n",
       "        7237.0957,  7260.9443,  7262.6865,  7210.3843,  7192.7495,\n",
       "        7244.186 ,  7230.772 ,  7403.2314,  7343.5273,  7169.8228,\n",
       "        7253.465 ,  6980.7856,  7178.303 ,  7273.955 ,  7418.6357,\n",
       "        7659.6807,  7985.743 ,  8056.751 ,  7966.3237,  7972.895 ,\n",
       "        8097.725 ,  8179.08  ,  8190.518 ,  8560.984 ,  8853.662 ,\n",
       "        8800.606 ,  8928.045 ,  8896.012 ,  8778.657 ,  8637.83  ,\n",
       "        8713.627 ,  8697.609 ,  8530.2705,  8458.576 ,  8400.165 ,\n",
       "        8525.976 ,  8688.139 ,  9039.509 ,  9270.307 ,  9521.265 ,\n",
       "        9431.086 ,  9498.315 ,  9442.281 ,  9296.389 ,  9198.423 ,\n",
       "        9526.756 ,  9646.616 ,  9764.346 ,  9925.462 , 10081.853 ,\n",
       "        9942.0625, 10088.758 , 10316.664 , 10326.468 , 10411.32  ,\n",
       "       10137.697 ,  9975.144 ,  9769.77  ,  9922.384 ,  9841.895 ,\n",
       "        9615.576 ,  9684.796 ,  9598.322 ,  9966.365 ,  9649.748 ,\n",
       "        9521.247 ,  8944.791 ,  8803.968 ,  8726.947 ,  8642.04  ,\n",
       "        8615.255 ,  8736.186 ,  8905.2295,  8640.027 ,  8999.796 ,\n",
       "        8985.453 ,  9093.803 ,  8404.649 ,  8006.35  ,  7913.189 ,\n",
       "        7962.695 ,  6497.283 ,  5658.1426,  5518.6133,  5296.576 ,\n",
       "        5464.6636,  5535.3945,  5883.208 ,  6297.575 ,  6485.8965,\n",
       "        6252.215 ,  6178.2935,  6320.687 ,  6767.513 ,  6857.8667,\n",
       "        6650.83  ,  6846.44  ,  6442.5977,  6158.553 ,  6024.7397,\n",
       "        6466.5464,  6340.222 ,  6920.126 ,  6638.9536,  7141.602 ,\n",
       "        6842.5664,  7290.99  ,  7137.8447,  7391.5396,  7389.6006,\n",
       "        7114.9795,  6969.187 ,  6985.5815,  6969.501 ,  6838.2793,\n",
       "        6728.398 ,  6865.9307,  7163.876 ,  7266.5527,  7256.6523,\n",
       "        6972.3633,  6896.002 ,  7031.709 ,  7394.2334,  7569.733 ,\n",
       "        7600.6357,  7689.2275,  7688.952 ,  7797.765 ,  8344.692 ,\n",
       "        8840.366 ,  8846.864 ,  9090.595 ,  8923.841 ,  9016.648 ,\n",
       "        8972.512 ,  9267.638 ,  9746.025 , 10017.735 ,  9730.283 ,\n",
       "        9113.801 ,  8781.508 ,  8689.858 ,  9186.785 ,  9518.103 ,\n",
       "        9539.645 ,  9405.069 ,  9749.083 ,  9752.007 ,  9718.238 ,\n",
       "        9491.295 ,  9249.557 ,  9166.8955,  9276.004 ,  9103.274 ,\n",
       "        9069.779 ,  8849.886 ,  8891.304 ,  9270.979 ,  9331.62  ,\n",
       "        9585.384 ,  9655.423 , 10126.393 ,  9842.048 ,  9591.407 ,\n",
       "        9764.882 ,  9676.084 ,  9772.12  ,  9747.773 ,  9797.564 ,\n",
       "        9748.367 ,  9860.269 ,  9404.862 ,  9425.694 ,  9514.454 ,\n",
       "        9267.74  ,  9605.167 ,  9393.757 ,  9587.35  ,  9390.099 ,\n",
       "        9409.113 ,  9188.076 ,  9375.156 ,  9497.66  ,  9697.971 ,\n",
       "        9404.449 ,  9277.75  ,  9247.501 ,  9055.67  ,  9095.999 ,\n",
       "        9029.086 ,  9213.034 ,  9220.196 ,  9175.305 ,  9087.476 ,\n",
       "        9189.517 ,  9028.707 ,  9219.409 ,  9238.118 ,  9421.572 ,\n",
       "        9383.682 ,  9300.965 ,  9264.443 ,  9262.601 ,  9230.449 ,\n",
       "        9221.966 ,  9256.836 ,  9164.364 ,  9232.196 ,  9182.327 ,\n",
       "        9197.371 ,  9156.629 ,  9303.006 ,  9538.505 ,  9590.455 ,\n",
       "        9659.53  ,  9684.729 ,  9941.4   , 10764.843 , 11082.717 ,\n",
       "       11187.774 , 11330.969 , 11298.7295, 11781.848 , 11347.076 ,\n",
       "       11265.98  , 11273.832 , 11568.049 , 11811.845 , 11708.023 ,\n",
       "       11775.839 , 11656.716 , 11902.297 , 11373.017 , 11571.206 ,\n",
       "       11647.216 , 11918.426 , 11944.173 , 11902.947 , 12217.454 ,\n",
       "       12163.738 , 11849.228 , 11769.145 , 11645.121 , 11666.896 ,\n",
       "       11704.49  , 11683.344 , 11528.134 , 11447.722 , 11320.015 ,\n",
       "       11370.995 , 11444.343 , 11592.544 , 11757.472 , 11921.8955,\n",
       "       11618.597 , 10960.495 , 10686.075 , 10131.858 , 10080.973 ,\n",
       "       10273.453 , 10103.754 , 10235.119 , 10283.237 , 10393.536 ,\n",
       "       10353.215 , 10354.377 , 10437.191 , 10928.644 , 11021.265 ,\n",
       "       11062.242 , 11045.586 , 11072.956 , 10892.496 , 10585.539 ,\n",
       "       10459.137 , 10343.216 , 10570.574 , 10781.96  , 10779.257 ,\n",
       "       10786.062 , 10847.806 , 10777.967 , 10779.007 , 10705.128 ,\n",
       "       10605.501 , 10669.235 , 10659.8955, 10705.665 , 10709.657 ,\n",
       "       10573.608 , 10825.477 , 10934.936 , 11284.086 , 11343.138 ,\n",
       "       11637.566 , 11580.398 , 11496.272 , 11499.261 , 11435.404 ,\n",
       "       11358.581 , 11452.654 , 11710.905 , 11907.986 , 12783.58  ,\n",
       "       13149.324 , 13053.325 , 13162.512 , 12996.717 , 13148.607 ,\n",
       "       13555.396 , 13502.74  , 13476.934 , 13711.85  , 13729.021 ,\n",
       "       13816.162 , 13648.148 , 13728.948 , 14089.353 , 15063.3   ,\n",
       "       15558.099 , 15124.309 , 15510.599 , 15365.557 , 15441.761 ,\n",
       "       15616.087 , 16100.238 , 16346.2705, 16332.431 , 15969.27  ,\n",
       "       16519.62  , 17347.752 , 17668.088 , 17979.451 , 18533.209 ,\n",
       "       18636.781 , 18830.426 , 18663.088 , 18921.088 , 18900.092 ,\n",
       "       17701.824 , 17091.424 , 17513.746 , 17971.26  , 19070.076 ,\n",
       "       19115.854 , 19063.002 , 19347.56  , 19054.504 , 19109.371 ,\n",
       "       19165.559 , 19107.012 , 18962.5   , 18667.256 , 18329.445 ,\n",
       "       18143.799 , 18751.816 , 18817.838 , 19098.695 , 19182.266 ,\n",
       "       20827.236 , 22606.844 , 23194.547 , 23873.176 , 23820.613 ,\n",
       "       23448.912 , 23400.414 , 23313.287 , 23728.295 , 24501.59  ,\n",
       "       25879.955 , 26492.129 , 26750.521 , 26929.537 , 28266.969 ,\n",
       "       29222.658 , 29357.018 , 31498.576 , 33054.637 , 32493.338 ,\n",
       "       33881.293 , 35834.977 , 38716.457 , 40631.06  , 40460.2   ,\n",
       "       39718.543 , 36345.47  , 34421.367 , 36131.06  , 37823.63  ,\n",
       "       37232.887 , 36353.625 , 36553.207 , 36156.324 , 36438.83  ,\n",
       "       34967.305 , 32206.32  , 32174.889 , 32409.771 , 32306.24  ,\n",
       "       32946.055 , 31991.566 , 31102.457 , 32029.293 , 33549.96  ,\n",
       "       33794.344 , 34281.867 , 33957.47  , 35257.305 , 37033.49  ,\n",
       "       36852.11  , 37909.285 , 39595.902 , 39491.324 , 42795.234 ,\n",
       "       46580.89  , 45330.574 , 47963.832 , 47859.06  , 48203.875 ,\n",
       "       48537.457 , 48819.625 , 48654.28  , 52218.242 , 51783.805 ,\n",
       "       54460.36  , 55895.992 , 56054.785 , 55786.78  , 50155.33  ,\n",
       "       48975.453 , 47803.312 , 46887.766 , 46297.863 , 45971.152 ,\n",
       "       47186.29  , 48345.43  , 49147.266 , 48627.836 , 48954.52  ,\n",
       "       48800.36  , 50412.26  , 51494.33  , 53587.254 , 56876.727 ,\n",
       "       57769.047 , 57465.19  , 59475.445 , 59825.188 , 58364.594 ,\n",
       "       56487.543 , 58447.926 , 58264.8   , 59298.555 , 58207.082 ,\n",
       "       58537.402 , 55283.203 , 55076.266 , 52468.85  , 52683.547 ,\n",
       "       53608.715 , 55968.094 , 56208.844 , 56916.824 , 58199.45  ,\n",
       "       58638.12  , 59230.47  , 58318.902 , 57763.504 , 58643.79  ,\n",
       "       58758.26  , 58505.85  , 57199.64  , 57518.508 , 57512.234 ,\n",
       "       58668.266 , 59368.383 , 60239.758 , 62496.633 , 63657.758 ,\n",
       "       63472.14  , 62898.906 , 61096.723 , 58395.19  , 56403.26  ,\n",
       "       56455.055 , 54518.902 , 52926.492 , 50550.918 , 50549.938 ,\n",
       "       48864.68  , 51326.227 , 54388.613 , 54655.26  , 54275.57  ,\n",
       "       55861.48  , 58423.742 , 56796.867 , 57416.86  , 54488.434 ,\n",
       "       56742.535 , 56391.312 , 56642.395 , 58849.08  , 58155.273 ,\n",
       "       56814.    , 55866.465 , 53989.594 , 49664.375 , 51058.297 ,\n",
       "       48383.844 , 46939.277 ], dtype=float32)>"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d677ae1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 605.8741,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.7264452,\n",
       " 'MASE': 1.0590738}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_results = evaluate_preds(test_labels.flatten(),model_2_preds)\n",
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0648574c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 568.9511,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.5448983,\n",
       " 'MASE': 0.99948955}"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "0211df71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8749.52059102,  8656.97092235,  8500.64355816,  8469.2608989 ,\n",
       "        8537.33965197,  8205.80636599,  8118.4885358 ,  8074.84317361,\n",
       "        7612.7405735 ,  7262.11053495,  7303.40575852,  7041.73293642,\n",
       "        7211.86180875,  7141.06944869,  7523.4806726 ,  7390.20746923,\n",
       "        7729.26593894,  7542.23560864,  7381.96300782,  7333.43293049,\n",
       "        7315.36776456,  7213.73376172,  7398.78704961,  7511.88058312,\n",
       "        7532.12351309,  7550.23919987,  7333.09604316,  7239.76257544,\n",
       "        7198.06667705,  7190.27236926,  7238.87432299,  7087.02498535,\n",
       "        7112.73147612,  6883.49639377,  6584.02884335,  7424.01540023,\n",
       "        7147.56832379,  7139.93337053,  7286.33508116,  7236.98620461,\n",
       "        7166.17237853,  7235.6266505 ,  7212.80939522,  7183.70653603,\n",
       "        7227.29371168,  7311.56064392,  7385.46484791,  7251.27679432,\n",
       "        7179.95781929,  7174.74401195,  6955.48757967,  7291.21950532,\n",
       "        7337.63667014,  7347.43326444,  7713.86075365,  8039.60370082,\n",
       "        8067.60636906,  7808.70136382,  8087.45288524,  8078.99353199,\n",
       "        8149.31371715,  8116.96100795,  8735.14243914,  8843.67573222,\n",
       "        8711.6375779 ,  8925.29902845,  8939.86430025,  8638.18144046,\n",
       "        8652.68376299,  8708.78601343,  8635.07435696,  8384.08877677,\n",
       "        8451.23229602,  8347.56750541,  8562.30747044,  8881.96239146,\n",
       "        9131.11498806,  9320.97840625,  9545.07795659,  9388.88075189,\n",
       "        9363.19338276,  9385.26038584,  9269.70703484,  9177.89463721,\n",
       "        9625.4566372 ,  9681.37741131,  9795.34406595,  9927.77825642,\n",
       "       10132.70649911,  9838.90001628, 10236.63514823, 10364.92628823,\n",
       "       10218.0997373 , 10367.52799811,  9926.35369057,  9876.23496321,\n",
       "        9636.62409482, 10189.99598297,  9701.0371915 ,  9631.48494596,\n",
       "        9670.85865437,  9689.08674285,  9919.55144784,  9640.46950506,\n",
       "        9392.86962872,  8787.97836316,  8784.99535244,  8778.4705108 ,\n",
       "        8639.5914173 ,  8548.94832242,  8923.04439826,  8791.11205813,\n",
       "        8756.96106241,  9078.57877713,  9126.63682222,  8925.21348778,\n",
       "        8166.31389402,  7875.75087522,  7959.22827421,  7955.30628418,\n",
       "        5800.20890483,  5672.68120103,  5304.14995219,  5355.18737353,\n",
       "        4944.70233598,  5465.58259412,  5363.82285325,  6301.06340407,\n",
       "        6185.27983852,  6187.05375022,  5884.34013347,  6455.45468825,\n",
       "        6784.31801143,  6706.98508913,  6721.49539238,  6682.7800492 ,\n",
       "        6229.48834283,  5922.48983509,  6483.73944553,  6446.42134684,\n",
       "        6537.3364615 ,  6850.55871169,  6776.37009357,  6855.93326446,\n",
       "        6805.3622869 ,  7278.24396977,  7175.66747656,  7367.29339845,\n",
       "        7321.81661389,  6866.39818901,  6873.84849516,  7043.43886352,\n",
       "        6889.86377235,  6887.55490783,  6718.79995028,  7166.58281714,\n",
       "        7065.08238904,  7277.14058556,  7185.87030343,  6856.14643454,\n",
       "        6904.4757727 ,  7118.38874792,  7562.03283175,  7497.86176383,\n",
       "        7542.3034007 ,  7624.85378592,  7776.50754257,  7761.75878408,\n",
       "        8773.10648796,  8767.67262337,  8853.77448401,  8963.0575578 ,\n",
       "        8904.71381654,  8887.50589259,  8978.28358712,  9371.68427279,\n",
       "        9900.67886662,  9917.24841434,  9617.51819493,  8786.65518165,\n",
       "        8608.12524504,  8815.2312449 ,  9330.9864847 ,  9757.29658559,\n",
       "        9362.63555697,  9418.91855051,  9684.70195935,  9723.68015045,\n",
       "        9719.48085448,  9540.88656658,  9141.15063742,  9192.84513581,\n",
       "        9220.07588747,  9048.71511916,  8905.78160454,  8835.72722404,\n",
       "        9112.97917559,  9507.52466466,  9425.28186919,  9688.32439037,\n",
       "        9427.67008414, 10268.58198473,  9516.13544309,  9667.06075426,\n",
       "        9811.3670946 ,  9659.66129819,  9677.05099451,  9737.45855879,\n",
       "        9791.92789977,  9786.14202048,  9874.96704752,  9260.83264099,\n",
       "        9464.22809682,  9458.6597544 ,  9351.95372801,  9441.76899555,\n",
       "        9510.66063729,  9457.62707441,  9398.64209362,  9279.76076517,\n",
       "        9353.07819619,  9289.10449144,  9680.9471279 ,  9609.68024553,\n",
       "        9311.13631832,  9252.63337177,  9171.73208577,  9022.153768  ,\n",
       "        9101.85005736,  9188.06137546,  9148.44485856,  9236.31677043,\n",
       "        9097.79736639,  9094.32456102,  9124.6535344 ,  9055.46448252,\n",
       "        9278.80563704,  9244.41581454,  9471.75997342,  9236.14325371,\n",
       "        9243.17525915,  9229.85975494,  9286.73704209,  9238.99375486,\n",
       "        9260.47098018,  9211.02643289,  9133.77783034,  9160.41059149,\n",
       "        9176.6863901 ,  9190.2715342 ,  9172.58833257,  9395.06444588,\n",
       "        9530.79088535,  9617.37786138,  9568.97472596,  9708.9491401 ,\n",
       "        9938.95122286, 11187.77972696, 10939.67014155, 11284.45898685,\n",
       "       11118.91841243, 11373.31725664, 11766.74829709, 11139.09838035,\n",
       "       11261.80633174, 11228.02632402, 11653.40758556, 11796.81736499,\n",
       "       11639.93541013, 11744.9120755 , 11673.12323754, 11832.22730813,\n",
       "       11340.58234064, 11549.54631437, 11752.16865623, 11783.28341126,\n",
       "       11895.62694989, 11896.94717019, 12399.11188466, 12071.73890908,\n",
       "       11749.82950876, 11833.8973487 , 11583.13894263, 11674.62435391,\n",
       "       11666.41012224, 11744.01269665, 11378.72602981, 11458.82259649,\n",
       "       11302.1209645 , 11482.22568651, 11515.04443069, 11657.00393423,\n",
       "       11678.37325542, 11964.20867246, 11427.70260497, 10712.92064607,\n",
       "       10563.89693862, 10042.85485437, 10207.60500296, 10381.77610693,\n",
       "       10043.19644129, 10268.46091575, 10341.01598385, 10380.53959723,\n",
       "       10436.36540836, 10313.06857949, 10680.29756117, 10829.5053072 ,\n",
       "       11033.38352648, 10937.1112591 , 10933.9311624 , 11048.87927816,\n",
       "       10852.91013894, 10526.2028872 , 10531.16456263, 10260.03301241,\n",
       "       10672.95680806, 10729.06960742, 10741.47646752, 10752.34544975,\n",
       "       10863.06572391, 10764.28437072, 10741.5795495 , 10626.6009565 ,\n",
       "       10567.33019523, 10555.02867878, 10660.61118264, 10756.40458492,\n",
       "       10589.62639353, 10645.75478678, 10897.59543151, 11052.39508367,\n",
       "       11360.85271687, 11334.02674203, 11666.21170032, 11443.73279182,\n",
       "       11395.54736637, 11504.54900671, 11355.16043945, 11358.70637963,\n",
       "       11471.00254779, 11776.59299733, 11936.36291334, 13102.93446155,\n",
       "       13140.66928406, 12933.82356549, 13081.67255949, 13008.45325775,\n",
       "       13033.52427008, 13721.28222485, 13282.26034792, 13467.73178281,\n",
       "       13573.71050315, 13891.21683316, 13730.19731094, 13633.69821689,\n",
       "       13832.93840977, 14163.9768155 , 15424.52767669, 15540.59659081,\n",
       "       14783.98167853, 15500.33425474, 15283.78013873, 15374.04438576,\n",
       "       15820.49524108, 16253.31027194, 16347.04492035, 15991.8330244 ,\n",
       "       15918.08012811, 16752.00298996, 17593.48641493, 17834.63653371,\n",
       "       17954.8580091 , 18612.87067218, 18591.85660475, 18629.99553726,\n",
       "       18469.20046948, 19045.73646565, 18746.9348067 , 17187.40627633,\n",
       "       17023.96140009, 17814.78027844, 18114.41434928, 19382.36058587,\n",
       "       18980.97745012, 19184.89784774, 19464.53170456, 18813.12476029,\n",
       "       19045.0202726 , 19113.93339509, 19107.59979531, 18682.45783321,\n",
       "       18543.00704922, 18359.47660034, 18137.31937461, 18882.26017106,\n",
       "       19060.27690128, 19251.22400471, 19443.47635283, 21310.65626223,\n",
       "       22895.97623755, 23008.77625674, 23890.82264887, 23537.36989089,\n",
       "       23177.27099799, 23433.98075814, 23224.45413785, 23623.88553323,\n",
       "       24581.00617127, 26381.29623292, 26389.29026494, 26718.0294634 ,\n",
       "       26975.72956452, 28768.83620753, 29111.52156712, 29333.60512062,\n",
       "       32154.16736327, 33002.53642704, 31431.61227972, 34433.60651384,\n",
       "       36275.75634767, 39713.50785672, 40519.44859753, 40258.92398866,\n",
       "       38709.76537488, 34409.64237522, 34214.61026205, 37017.00750345,\n",
       "       38435.86351466, 36751.58497369, 36016.77960594, 36375.81137926,\n",
       "       36346.60950223, 36577.51964639, 35004.53262688, 30606.18267565,\n",
       "       33368.36593189, 32070.0974252 , 32285.72613244, 32500.25596269,\n",
       "       32324.55565073, 30534.99937302, 33408.21833739, 34842.55739312,\n",
       "       34622.37323153, 33087.36986452, 33613.32076431, 35632.90195152,\n",
       "       37397.42636409, 37256.25211087, 37851.59659008, 40302.79979284,\n",
       "       38461.6814033 , 44716.68546906, 46674.85168811, 45237.47568925,\n",
       "       47500.8975242 , 47884.1828623 , 47005.1906489 , 49151.16757632,\n",
       "       48125.99219541, 48840.41447458, 52165.30255522, 51728.50879673,\n",
       "       55719.2043617 , 54801.64864399, 57128.64260647, 54181.91464919,\n",
       "       48172.87747693, 48745.43298434, 48291.41208335, 45752.11491941,\n",
       "       46642.60607658, 45092.8065726 , 49248.91401331, 47900.77687833,\n",
       "       50811.85517444, 48259.48707666, 49149.73082884, 48879.15190416,\n",
       "       50594.69857451, 51503.25813218, 54458.03781142, 56915.17393505,\n",
       "       57636.75796197, 57306.16626299, 60743.04182491, 60197.9019918 ,\n",
       "       56300.33410863, 56639.78394967, 58567.28378106, 57983.09474357,\n",
       "       58451.73146595, 58593.60245406, 57796.46737122, 54329.35863463,\n",
       "       54794.29771371, 52787.74552575, 52173.86798025, 54483.0457323 ,\n",
       "       56234.356105  , 55343.92581533, 57627.6792491 , 58734.47543372,\n",
       "       58724.66451663, 58984.61292993, 58821.62699444, 57517.79877314,\n",
       "       58177.40276373, 58843.55954021, 58040.18760188, 56508.94286388,\n",
       "       57880.90568386, 58171.9090187 , 59295.95004401, 59822.90167743,\n",
       "       59853.19724227, 63223.88439079, 62926.5571759 , 63346.78903511,\n",
       "       61965.7825981 , 60574.44472823, 56850.83016569, 56224.10158771,\n",
       "       56608.76974839, 54144.42747606, 51965.05955941, 50669.14438218,\n",
       "       50733.76950364, 48542.95220298, 53558.70784462, 55123.86198142,\n",
       "       54591.51532554, 53260.29534115, 57302.64642408, 57677.9752219 ,\n",
       "       56427.04312502, 57255.30683756, 53658.84312082, 57252.7021845 ,\n",
       "       56583.84987917, 57107.12067189, 58788.20967893, 58102.19142623,\n",
       "       55715.54665129, 56573.5554719 , 52147.82118698, 49764.1320816 ,\n",
       "       50032.69313676, 47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "481d9ffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "offset = 300\n",
    "plt.figure(figsize=(10,7))\n",
    "plot_time_series(X_test[-len(test_windows):],test_labels[:,0],start=offset,label='Test data')\n",
    "plot_time_series(X_test[-len(test_windows):],values=model_2_preds,start=offset,format=\"-\",label='MOdel_2_preds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6963ee23",
   "metadata": {},
   "source": [
    "### Model 3: Dense (window = 30, horizon = 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79bbac34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to view NumPy arrays as windows \n",
    "def make_windows(x, window_size=7, horizon=1):\n",
    "  \"\"\"\n",
    "  Turns a 1D array into a 2D array of sequential windows of window_size.\n",
    "  \"\"\"\n",
    "  # 1. Create a window of specific window_size (add the horizon on the end for later labelling)\n",
    "  window_step = np.expand_dims(np.arange(window_size+horizon), axis=0)\n",
    "  # print(f\"Window step:\\n {window_step}\")\n",
    "\n",
    "  # 2. Create a 2D array of multiple window steps (minus 1 to account for 0 indexing)\n",
    "  window_indexes = window_step + np.expand_dims(np.arange(len(x)-(window_size+horizon-1)), axis=0).T # create 2D array of windows of size window_size\n",
    "  # print(f\"Window indexes:\\n {window_indexes[:3], window_indexes[-3:], window_indexes.shape}\")\n",
    "\n",
    "  # 3. Index on the target array (time series) with 2D array of multiple window steps\n",
    "  windowed_array = x[window_indexes]\n",
    "\n",
    "  # 4. Get the labelled windows\n",
    "  windows, labels = get_labelled_windows(windowed_array, horizon=horizon)\n",
    "\n",
    "  return windows, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2762ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to label windowed data\n",
    "def get_labelled_windows(x, horizon=1):\n",
    "  \"\"\"\n",
    "  Creates labels for windowed dataset.\n",
    "\n",
    "  E.g. if horizon=1 (default)\n",
    "  Input: [1, 2, 3, 4, 5, 6] -> Output: ([1, 2, 3, 4, 5], [6])\n",
    "  \"\"\"\n",
    "  return x[:, :-horizon], x[:, -horizon:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9ff9179",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Make the train/test splits\n",
    "def make_train_test_splits(windows, labels, test_split=0.2):\n",
    "  \"\"\"\n",
    "  Splits matching pairs of windows and labels into train and test splits.\n",
    "  \"\"\"\n",
    "  split_size = int(len(windows) * (1-test_split)) # this will default to 80% train/20% test\n",
    "  train_windows = windows[:split_size]\n",
    "  train_labels = labels[:split_size]\n",
    "  test_windows = windows[split_size:]\n",
    "  test_labels = labels[split_size:]\n",
    "  return train_windows, test_windows, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb6dc47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_preds(model, input_data):\n",
    "  \"\"\"\n",
    "  Uses model to make predictions on input_data.\n",
    "\n",
    "  Parameters\n",
    "  ----------\n",
    "  model: trained model \n",
    "  input_data: windowed input data (same kind of data model was trained on)\n",
    "\n",
    "  Returns model predictions on input_data.\n",
    "  \"\"\"\n",
    "  forecast = model.predict(input_data)\n",
    "  return tf.squeeze(forecast) # return 1D array of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0431fc56",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prices' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16776/3974046447.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfull_window\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfull_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_windows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhorizon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'prices' is not defined"
     ]
    }
   ],
   "source": [
    "full_window,full_label=make_windows(prices,window_size=30,horizon=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dbff6a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2751, 2751)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(full_window),len(full_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "015f74b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_windows,test_windows,train_labels,test_labels = make_train_test_splits(full_windows,full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d01e928b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2205, 552)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_windows),len(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "29ff39c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/18 [>.............................] - ETA: 4s - loss: 2841.2119 - mae: 2841.2119 - mse: 26212516.0000INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 1s 25ms/step - loss: 1419.9785 - mae: 1419.9785 - mse: 9499607.0000 - val_loss: 2896.7302 - val_mae: 2896.7302 - val_mse: 22171014.0000\n",
      "Epoch 2/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 760.2163 - mae: 760.2163 - mse: 2210430.7500INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 509.2082 - mae: 509.2082 - mse: 1164875.8750 - val_loss: 2203.5601 - val_mae: 2203.5601 - val_mse: 13893363.0000\n",
      "Epoch 3/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 412.6923 - mae: 412.6923 - mse: 950900.6250INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 376.6431 - mae: 376.6431 - mse: 661162.0000 - val_loss: 1770.1362 - val_mae: 1770.1362 - val_mse: 9183264.0000\n",
      "Epoch 4/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 321.4966 - mae: 321.4966 - mse: 483462.2812INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 316.1041 - mae: 316.1041 - mse: 474431.3125 - val_loss: 1438.7616 - val_mae: 1438.7616 - val_mse: 6428630.5000\n",
      "Epoch 5/100\n",
      " 9/18 [==============>...............] - ETA: 0s - loss: 273.9894 - mae: 273.9894 - mse: 355715.7812INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 270.5205 - mae: 270.5205 - mse: 349479.7500 - val_loss: 1345.9634 - val_mae: 1345.9634 - val_mse: 5618038.5000\n",
      "Epoch 6/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 237.5902 - mae: 237.5902 - mse: 277453.7188INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 235.6161 - mae: 235.6161 - mse: 270872.6875 - val_loss: 1195.5881 - val_mae: 1195.5881 - val_mse: 4527893.0000\n",
      "Epoch 7/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 208.1223 - mae: 208.1223 - mse: 257235.9062INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 212.2349 - mae: 212.2349 - mse: 218945.5312 - val_loss: 1141.1726 - val_mae: 1141.1726 - val_mse: 4051458.2500\n",
      "Epoch 8/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 196.4206 - mae: 196.4206 - mse: 196399.7656INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 196.9950 - mae: 196.9950 - mse: 191880.2344 - val_loss: 1107.6022 - val_mae: 1107.6022 - val_mse: 3765069.5000\n",
      "Epoch 9/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 194.8741 - mae: 194.8741 - mse: 232601.4062INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 190.8071 - mae: 190.8071 - mse: 177822.9531 - val_loss: 1052.8580 - val_mae: 1052.8580 - val_mse: 3658995.0000\n",
      "Epoch 10/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 237.8959 - mae: 237.8959 - mse: 283694.8750INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 182.9261 - mae: 182.9261 - mse: 166058.5312 - val_loss: 1039.4724 - val_mae: 1039.4724 - val_mse: 3301634.5000\n",
      "Epoch 11/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 178.6383 - mae: 178.6383 - mse: 156162.1094INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 178.7132 - mae: 178.7132 - mse: 154754.0938 - val_loss: 990.7954 - val_mae: 990.7954 - val_mse: 3233492.7500\n",
      "Epoch 12/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 175.9784 - mae: 175.9784 - mse: 153172.2188INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 175.5236 - mae: 175.5236 - mse: 152152.9062 - val_loss: 978.5878 - val_mae: 978.5878 - val_mse: 3002561.0000\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 169.2337 - mae: 169.2337 - mse: 142464.1406 - val_loss: 1056.4128 - val_mae: 1056.4128 - val_mse: 3634651.2500\n",
      "Epoch 14/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 229.0181 - mae: 229.0181 - mse: 244746.6250INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 169.8337 - mae: 169.8337 - mse: 143108.8125 - val_loss: 927.7024 - val_mae: 927.7024 - val_mse: 2770862.2500\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 169.7207 - mae: 169.7207 - mse: 137198.3750 - val_loss: 955.2618 - val_mae: 955.2618 - val_mse: 2935628.0000\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 165.6600 - mae: 165.6600 - mse: 136511.8438 - val_loss: 933.4062 - val_mae: 933.4062 - val_mse: 2814324.7500\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 161.2481 - mae: 161.2481 - mse: 129100.6875 - val_loss: 1059.5754 - val_mae: 1059.5754 - val_mse: 3092258.5000\n",
      "Epoch 18/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 218.5317 - mae: 218.5317 - mse: 188288.4219INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 161.6880 - mae: 161.6880 - mse: 127821.5000 - val_loss: 879.1934 - val_mae: 879.1934 - val_mse: 2497605.7500\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 157.8816 - mae: 157.8816 - mse: 122796.2344 - val_loss: 1034.6173 - val_mae: 1034.6173 - val_mse: 3341879.7500\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 166.5552 - mae: 166.5552 - mse: 132927.0469 - val_loss: 952.6659 - val_mae: 952.6659 - val_mse: 2639566.2500\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 159.2501 - mae: 159.2501 - mse: 124467.7188 - val_loss: 885.0565 - val_mae: 885.0565 - val_mse: 2461361.0000\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 153.6812 - mae: 153.6812 - mse: 115763.6016 - val_loss: 879.2694 - val_mae: 879.2694 - val_mse: 2525975.0000\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 154.7535 - mae: 154.7535 - mse: 117232.0547 - val_loss: 1138.0829 - val_mae: 1138.0829 - val_mse: 3376428.5000\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 158.2491 - mae: 158.2491 - mse: 121538.9609 - val_loss: 1041.7242 - val_mae: 1041.7242 - val_mse: 3346621.7500\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 168.5573 - mae: 168.5573 - mse: 130755.6016 - val_loss: 1150.1262 - val_mae: 1150.1262 - val_mse: 3403966.5000\n",
      "Epoch 26/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 160.4513 - mae: 160.4513 - mse: 78216.0312INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 159.9756 - mae: 159.9756 - mse: 118739.7500 - val_loss: 841.6326 - val_mae: 841.6326 - val_mse: 2238203.5000\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 147.4083 - mae: 147.4083 - mse: 108039.1094 - val_loss: 855.3028 - val_mae: 855.3028 - val_mse: 2254938.2500\n",
      "Epoch 28/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 113.6696 - mae: 113.6696 - mse: 75386.5781INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 148.7409 - mae: 148.7409 - mse: 110275.3594 - val_loss: 819.9998 - val_mae: 819.9998 - val_mse: 2185826.2500\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 145.4224 - mae: 145.4224 - mse: 105142.3516 - val_loss: 843.8730 - val_mae: 843.8730 - val_mse: 2165800.2500\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 144.7306 - mae: 144.7306 - mse: 105038.7109 - val_loss: 933.0418 - val_mae: 933.0418 - val_mse: 2464313.7500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 173.1391 - mae: 173.1391 - mse: 98588.2656INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 143.9066 - mae: 143.9066 - mse: 105396.4844 - val_loss: 785.1982 - val_mae: 785.1982 - val_mse: 2000653.2500\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 144.0237 - mae: 144.0237 - mse: 105779.3281 - val_loss: 799.9732 - val_mae: 799.9732 - val_mse: 2063492.6250\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 142.4292 - mae: 142.4292 - mse: 103349.1797 - val_loss: 851.1090 - val_mae: 851.1090 - val_mse: 2301959.7500\n",
      "Epoch 34/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 150.0158 - mae: 150.0158 - mse: 87264.1562INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 142.6656 - mae: 142.6656 - mse: 104335.4375 - val_loss: 775.7852 - val_mae: 775.7852 - val_mse: 1957619.7500\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 149.6742 - mae: 149.6742 - mse: 106495.5781 - val_loss: 799.8508 - val_mae: 799.8508 - val_mse: 2041696.8750\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 140.3359 - mae: 140.3359 - mse: 98991.5547 - val_loss: 805.2061 - val_mae: 805.2061 - val_mse: 2008649.0000\n",
      "Epoch 37/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 141.7415 - mae: 141.7415 - mse: 93873.0078INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 144.4693 - mae: 144.4693 - mse: 103584.9375 - val_loss: 763.4276 - val_mae: 763.4276 - val_mse: 1904252.2500\n",
      "Epoch 38/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 162.5117 - mae: 162.5117 - mse: 108964.7812INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 138.0420 - mae: 138.0420 - mse: 96085.1797 - val_loss: 759.1661 - val_mae: 759.1661 - val_mse: 1859654.2500\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 141.2909 - mae: 141.2909 - mse: 101019.1328 - val_loss: 833.6237 - val_mae: 833.6237 - val_mse: 2076212.0000\n",
      "Epoch 40/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 115.4412 - mae: 115.4412 - mse: 44592.1406INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 149.7971 - mae: 149.7971 - mse: 106670.8281 - val_loss: 742.2130 - val_mae: 742.2130 - val_mse: 1814937.7500\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 145.3395 - mae: 145.3395 - mse: 99439.1328INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 145.3395 - mae: 145.3395 - mse: 99439.1328 - val_loss: 742.0081 - val_mae: 742.0081 - val_mse: 1777202.5000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.7266 - mae: 134.7266 - mse: 94931.5312 - val_loss: 745.2015 - val_mae: 745.2016 - val_mse: 1797306.3750\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 132.8106 - mae: 132.8106 - mse: 91526.4609 - val_loss: 799.2739 - val_mae: 799.2739 - val_mse: 2043595.6250\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 136.1444 - mae: 136.1444 - mse: 95505.7656 - val_loss: 742.8997 - val_mae: 742.8997 - val_mse: 1823944.7500\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 138.0275 - mae: 138.0275 - mse: 94576.4922 - val_loss: 756.7063 - val_mae: 756.7063 - val_mse: 1877953.8750\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 132.5326 - mae: 132.5326 - mse: 91942.8281 - val_loss: 757.1632 - val_mae: 757.1632 - val_mse: 1849353.0000\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.8898 - mae: 131.8898 - mse: 90191.2500 - val_loss: 743.2062 - val_mae: 743.2062 - val_mse: 1753281.6250\n",
      "Epoch 48/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 94.6876 - mae: 94.6876 - mse: 47290.1562INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 131.7159 - mae: 131.7159 - mse: 89492.1172 - val_loss: 714.9431 - val_mae: 714.9431 - val_mse: 1671037.2500\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 130.5567 - mae: 130.5567 - mse: 88043.0000INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 130.5567 - mae: 130.5567 - mse: 88043.0000 - val_loss: 713.7778 - val_mae: 713.7778 - val_mse: 1686406.1250\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 137.6748 - mae: 137.6748 - mse: 92854.5703 - val_loss: 769.1965 - val_mae: 769.1965 - val_mse: 1887218.8750\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.6973 - mae: 129.6973 - mse: 86551.8750 - val_loss: 804.5941 - val_mae: 804.5941 - val_mse: 2044175.7500\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 131.4565 - mae: 131.4565 - mse: 90780.5234INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 131.4565 - mae: 131.4565 - mse: 90780.5234 - val_loss: 705.6606 - val_mae: 705.6606 - val_mse: 1628056.5000\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 132.3177 - mae: 132.3177 - mse: 89491.8750 - val_loss: 753.1001 - val_mae: 753.1001 - val_mse: 1834365.5000\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.0270 - mae: 129.0270 - mse: 87659.4609 - val_loss: 745.4220 - val_mae: 745.4220 - val_mse: 1732401.8750\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 134.7200 - mae: 134.7200 - mse: 89937.0000 - val_loss: 717.2012 - val_mae: 717.2012 - val_mse: 1648121.1250\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 138.1481 - mae: 138.1481 - mse: 93848.5156INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 138.1481 - mae: 138.1481 - mse: 93848.5156 - val_loss: 696.3286 - val_mae: 696.3286 - val_mse: 1622094.3750\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 127.1147 - mae: 127.1147 - mse: 86182.3750 - val_loss: 732.8561 - val_mae: 732.8561 - val_mse: 1700179.5000\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.3315 - mae: 131.3315 - mse: 86688.4375 - val_loss: 770.1647 - val_mae: 770.1647 - val_mse: 1895120.7500\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 150.2133 - mae: 150.2133 - mse: 103938.4297 - val_loss: 848.0865 - val_mae: 848.0865 - val_mse: 2046358.2500\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 133.8430 - mae: 133.8430 - mse: 89221.3906 - val_loss: 702.3999 - val_mae: 702.3999 - val_mse: 1583859.2500\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 130.6570 - mae: 130.6570 - mse: 86264.4375 - val_loss: 738.5184 - val_mae: 738.5184 - val_mse: 1749628.3750\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 143.6847 - mae: 143.6847 - mse: 97044.6875 - val_loss: 707.4288 - val_mae: 707.4288 - val_mse: 1661190.3750\n",
      "Epoch 63/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 116.8548 - mae: 116.8548 - mse: 96725.3906INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 128.0612 - mae: 128.0612 - mse: 85328.1484 - val_loss: 690.0695 - val_mae: 690.0695 - val_mse: 1549936.0000\n",
      "Epoch 64/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 93.9232 - mae: 93.9232 - mse: 48694.5508INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 122.3353 - mae: 122.3353 - mse: 80349.8750 - val_loss: 672.4990 - val_mae: 672.4990 - val_mse: 1520484.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 126.6794 - mae: 126.6794 - mse: 82947.2422 - val_loss: 679.6969 - val_mae: 679.6969 - val_mse: 1537554.7500\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.9393 - mae: 122.9393 - mse: 81822.8125 - val_loss: 681.6487 - val_mae: 681.6487 - val_mse: 1546166.5000\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.3991 - mae: 124.3991 - mse: 82480.7578 - val_loss: 713.3689 - val_mae: 713.3689 - val_mse: 1610660.1250\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.6320 - mae: 124.6320 - mse: 81818.1953 - val_loss: 722.2766 - val_mae: 722.2766 - val_mse: 1640370.3750\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.5237 - mae: 124.5237 - mse: 82463.2344 - val_loss: 707.2946 - val_mae: 707.2946 - val_mse: 1588631.1250\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 124.0199 - mae: 124.0199 - mse: 82480.3047 - val_loss: 812.7258 - val_mae: 812.7258 - val_mse: 1896788.1250\n",
      "Epoch 71/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 145.7226 - mae: 145.7226 - mse: 80760.5312INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 127.2586 - mae: 127.2586 - mse: 84379.2578 - val_loss: 669.3141 - val_mae: 669.3141 - val_mse: 1489749.8750\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 120.0566 - mae: 120.0566 - mse: 78886.4844 - val_loss: 669.7871 - val_mae: 669.7871 - val_mse: 1477947.1250\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.4532 - mae: 120.4532 - mse: 79437.1641 - val_loss: 670.4429 - val_mae: 670.4429 - val_mse: 1475953.2500\n",
      "Epoch 74/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 124.0466 - mae: 124.0466 - mse: 82144.6953INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 123.6666 - mae: 123.6666 - mse: 81453.9219 - val_loss: 654.8104 - val_mae: 654.8104 - val_mse: 1444032.3750\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.9300 - mae: 124.9300 - mse: 81698.7188 - val_loss: 709.2625 - val_mae: 709.2625 - val_mse: 1632596.0000\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.8669 - mae: 129.8669 - mse: 83677.0391 - val_loss: 730.9800 - val_mae: 730.9800 - val_mse: 1704732.7500\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 132.9590 - mae: 132.9590 - mse: 87510.8984 - val_loss: 718.8456 - val_mae: 718.8456 - val_mse: 1666731.3750\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.3320 - mae: 129.3320 - mse: 85946.9375 - val_loss: 751.7963 - val_mae: 751.7963 - val_mse: 1779886.8750\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 123.3260 - mae: 123.3260 - mse: 79102.6875 - val_loss: 713.7136 - val_mae: 713.7136 - val_mse: 1582317.6250\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 128.7506 - mae: 128.7506 - mse: 83362.8047 - val_loss: 661.6880 - val_mae: 661.6880 - val_mse: 1445702.7500\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.1504 - mae: 120.1504 - mse: 77466.9297 - val_loss: 708.6705 - val_mae: 708.6705 - val_mse: 1577440.5000\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 123.4104 - mae: 123.4104 - mse: 79473.3594 - val_loss: 912.3063 - val_mae: 912.3063 - val_mse: 2222459.2500\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 139.8631 - mae: 139.8631 - mse: 90466.4688 - val_loss: 789.4473 - val_mae: 789.4473 - val_mse: 1900536.7500\n",
      "Epoch 84/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 129.9550 - mae: 129.9550 - mse: 68091.0000INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 123.6934 - mae: 123.6934 - mse: 80314.5938 - val_loss: 647.4924 - val_mae: 647.4924 - val_mse: 1414406.1250\n",
      "Epoch 85/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 101.4090 - mae: 101.4090 - mse: 49323.5625INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 120.7195 - mae: 120.7195 - mse: 80005.3203 - val_loss: 644.5706 - val_mae: 644.5706 - val_mse: 1405777.1250\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.1994 - mae: 119.1994 - mse: 77121.4297 - val_loss: 671.4754 - val_mae: 671.4754 - val_mse: 1460323.8750\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.3260 - mae: 119.3260 - mse: 77048.3516 - val_loss: 663.8690 - val_mae: 663.8690 - val_mse: 1480263.5000\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 118.4260 - mae: 118.4260 - mse: 76247.2891 - val_loss: 655.4185 - val_mae: 655.4185 - val_mse: 1422528.0000\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 117.3524 - mae: 117.3524 - mse: 77485.8828 - val_loss: 745.3688 - val_mae: 745.3688 - val_mse: 1672230.3750\n",
      "Epoch 90/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 119.6423 - mae: 119.6423 - mse: 75232.1172INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 122.0275 - mae: 122.0275 - mse: 80510.3125 - val_loss: 643.5964 - val_mae: 643.5964 - val_mse: 1402068.5000\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 117.2895 - mae: 117.2895 - mse: 76269.0625 - val_loss: 662.5339 - val_mae: 662.5339 - val_mse: 1454393.5000\n",
      "Epoch 92/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 170.1475 - mae: 170.1475 - mse: 158015.2344INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 118.2971 - mae: 118.2971 - mse: 77997.2422 - val_loss: 639.4782 - val_mae: 639.4782 - val_mse: 1392053.6250\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 129.1322 - mae: 129.1322 - mse: 85279.9844 - val_loss: 720.1777 - val_mae: 720.1777 - val_mse: 1597207.6250\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 139.6327 - mae: 139.6327 - mse: 90961.3828 - val_loss: 646.2414 - val_mae: 646.2414 - val_mse: 1421073.8750\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 123.1416 - mae: 123.1416 - mse: 80892.9922 - val_loss: 681.4133 - val_mae: 681.4133 - val_mse: 1489647.2500\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 117.7663 - mae: 117.7663 - mse: 78266.2188 - val_loss: 641.4172 - val_mae: 641.4172 - val_mse: 1389317.1250\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 118.0942 - mae: 118.0942 - mse: 76705.8594 - val_loss: 644.3568 - val_mae: 644.3568 - val_mse: 1422502.2500\n",
      "Epoch 98/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 117.0174 - mae: 117.0174 - mse: 75697.4141INFO:tensorflow:Assets written to: model_experiment\\Model_3\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 118.4688 - mae: 118.4688 - mse: 77282.2500 - val_loss: 626.5259 - val_mae: 626.5259 - val_mse: 1346312.7500\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 118.6458 - mae: 118.6458 - mse: 77333.6719 - val_loss: 701.9293 - val_mae: 701.9293 - val_mse: 1601912.7500\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.5855 - mae: 122.5855 - mse: 80638.2109 - val_loss: 702.3416 - val_mae: 702.3416 - val_mse: 1541646.3750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a7b58cd90>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_3 = Sequential(name='Model_3')\n",
    "#model_1.add(Input(shape=(128,WINDOW_SIZE)))\n",
    "model_3.add(Dense(128,activation='relu'))\n",
    "model_3.add(Dense(7,activation='linear'))\n",
    "\n",
    "model_3.compile(metrics=['mae','mse'],optimizer=Adam(),loss='mae')\n",
    "\n",
    "model_3.fit(x=train_windows,\n",
    "            y=train_labels,\n",
    "           epochs=100,\n",
    "           batch_size=128,\n",
    "           validation_data=(test_windows,test_labels),\n",
    "           callbacks=[create_model_checkpoint(model_name=model_3.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "364d3944",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 702.3416 - mae: 702.3416 - mse: 1541646.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[702.3416137695312, 702.3416137695312, 1541646.5]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d7cad1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = tf.keras.models.load_model(\"model_experiment/Model_3/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24bd83a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 626.5261 - mae: 626.5261 - mse: 1346312.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[626.5260620117188, 626.5260620117188, 1346312.75]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4aeb25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_preds = make_preds(model_3,test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf4f5c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([552, 7])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "72c7eab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 7), dtype=float32, numpy=\n",
       "array([[8991.691, 8937.682, 8830.556, 8852.853, 8898.763, 8986.724,\n",
       "        8848.014],\n",
       "       [8902.945, 8987.835, 8996.881, 8833.55 , 8781.812, 9019.121,\n",
       "        8918.478],\n",
       "       [8752.008, 8767.166, 8830.347, 8720.877, 8805.518, 8745.545,\n",
       "        8769.534],\n",
       "       [8622.495, 8520.005, 8619.766, 8544.339, 8690.359, 8572.103,\n",
       "        8518.903],\n",
       "       [8687.354, 8545.392, 8525.108, 8553.687, 8534.289, 8485.646,\n",
       "        8434.34 ]], dtype=float32)>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "95524737",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8991.691,  8937.682,  8830.556, ..., 46763.344, 46612.496,\n",
       "       46092.22 ], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds.numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "0f11a2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(10).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "18b0d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "066e9cbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "       [ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10],\n",
       "       [ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
       "       [ 3,  4,  5,  6,  7,  8,  9, 10, 11, 12],\n",
       "       [ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13],\n",
       "       [ 5,  6,  7,  8,  9, 10, 11, 12, 13, 14],\n",
       "       [ 6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
       "       [ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
       "       [ 8,  9, 10, 11, 12, 13, 14, 15, 16, 17],\n",
       "       [ 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cc4d5620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[3, 0, 1, 3, 6]],\n",
       "\n",
       "       [[5, 9, 7, 6, 5]]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(np.random.randint(10,size=(2,5)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "71c02398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4, 8, 3, 6, 1],\n",
       "       [3, 4, 4, 5, 9]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.randint(10,size=(2,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "fd28290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ufunc 'exp'>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "60d0dbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3],\n",
       "       [4],\n",
       "       [5],\n",
       "       [6],\n",
       "       [7],\n",
       "       [8],\n",
       "       [9]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "f9f3eaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8749.52059102],\n",
       "       [ 8656.97092235],\n",
       "       [ 8500.64355816],\n",
       "       [ 8469.2608989 ],\n",
       "       [ 8537.33965197],\n",
       "       [ 8205.80636599],\n",
       "       [ 8118.4885358 ],\n",
       "       [ 8074.84317361],\n",
       "       [ 7612.7405735 ],\n",
       "       [ 7262.11053495],\n",
       "       [ 7303.40575852],\n",
       "       [ 7041.73293642],\n",
       "       [ 7211.86180875],\n",
       "       [ 7141.06944869],\n",
       "       [ 7523.4806726 ],\n",
       "       [ 7390.20746923],\n",
       "       [ 7729.26593894],\n",
       "       [ 7542.23560864],\n",
       "       [ 7381.96300782],\n",
       "       [ 7333.43293049],\n",
       "       [ 7315.36776456],\n",
       "       [ 7213.73376172],\n",
       "       [ 7398.78704961],\n",
       "       [ 7511.88058312],\n",
       "       [ 7532.12351309],\n",
       "       [ 7550.23919987],\n",
       "       [ 7333.09604316],\n",
       "       [ 7239.76257544],\n",
       "       [ 7198.06667705],\n",
       "       [ 7190.27236926],\n",
       "       [ 7238.87432299],\n",
       "       [ 7087.02498535],\n",
       "       [ 7112.73147612],\n",
       "       [ 6883.49639377],\n",
       "       [ 6584.02884335],\n",
       "       [ 7424.01540023],\n",
       "       [ 7147.56832379],\n",
       "       [ 7139.93337053],\n",
       "       [ 7286.33508116],\n",
       "       [ 7236.98620461],\n",
       "       [ 7166.17237853],\n",
       "       [ 7235.6266505 ],\n",
       "       [ 7212.80939522],\n",
       "       [ 7183.70653603],\n",
       "       [ 7227.29371168],\n",
       "       [ 7311.56064392],\n",
       "       [ 7385.46484791],\n",
       "       [ 7251.27679432],\n",
       "       [ 7179.95781929],\n",
       "       [ 7174.74401195],\n",
       "       [ 6955.48757967],\n",
       "       [ 7291.21950532],\n",
       "       [ 7337.63667014],\n",
       "       [ 7347.43326444],\n",
       "       [ 7713.86075365],\n",
       "       [ 8039.60370082],\n",
       "       [ 8067.60636906],\n",
       "       [ 7808.70136382],\n",
       "       [ 8087.45288524],\n",
       "       [ 8078.99353199],\n",
       "       [ 8149.31371715],\n",
       "       [ 8116.96100795],\n",
       "       [ 8735.14243914],\n",
       "       [ 8843.67573222],\n",
       "       [ 8711.6375779 ],\n",
       "       [ 8925.29902845],\n",
       "       [ 8939.86430025],\n",
       "       [ 8638.18144046],\n",
       "       [ 8652.68376299],\n",
       "       [ 8708.78601343],\n",
       "       [ 8635.07435696],\n",
       "       [ 8384.08877677],\n",
       "       [ 8451.23229602],\n",
       "       [ 8347.56750541],\n",
       "       [ 8562.30747044],\n",
       "       [ 8881.96239146],\n",
       "       [ 9131.11498806],\n",
       "       [ 9320.97840625],\n",
       "       [ 9545.07795659],\n",
       "       [ 9388.88075189],\n",
       "       [ 9363.19338276],\n",
       "       [ 9385.26038584],\n",
       "       [ 9269.70703484],\n",
       "       [ 9177.89463721],\n",
       "       [ 9625.4566372 ],\n",
       "       [ 9681.37741131],\n",
       "       [ 9795.34406595],\n",
       "       [ 9927.77825642],\n",
       "       [10132.70649911],\n",
       "       [ 9838.90001628],\n",
       "       [10236.63514823],\n",
       "       [10364.92628823],\n",
       "       [10218.0997373 ],\n",
       "       [10367.52799811],\n",
       "       [ 9926.35369057],\n",
       "       [ 9876.23496321],\n",
       "       [ 9636.62409482],\n",
       "       [10189.99598297],\n",
       "       [ 9701.0371915 ],\n",
       "       [ 9631.48494596],\n",
       "       [ 9670.85865437],\n",
       "       [ 9689.08674285],\n",
       "       [ 9919.55144784],\n",
       "       [ 9640.46950506],\n",
       "       [ 9392.86962872],\n",
       "       [ 8787.97836316],\n",
       "       [ 8784.99535244],\n",
       "       [ 8778.4705108 ],\n",
       "       [ 8639.5914173 ],\n",
       "       [ 8548.94832242],\n",
       "       [ 8923.04439826],\n",
       "       [ 8791.11205813],\n",
       "       [ 8756.96106241],\n",
       "       [ 9078.57877713],\n",
       "       [ 9126.63682222],\n",
       "       [ 8925.21348778],\n",
       "       [ 8166.31389402],\n",
       "       [ 7875.75087522],\n",
       "       [ 7959.22827421],\n",
       "       [ 7955.30628418],\n",
       "       [ 5800.20890483],\n",
       "       [ 5672.68120103],\n",
       "       [ 5304.14995219],\n",
       "       [ 5355.18737353],\n",
       "       [ 4944.70233598],\n",
       "       [ 5465.58259412],\n",
       "       [ 5363.82285325],\n",
       "       [ 6301.06340407],\n",
       "       [ 6185.27983852],\n",
       "       [ 6187.05375022],\n",
       "       [ 5884.34013347],\n",
       "       [ 6455.45468825],\n",
       "       [ 6784.31801143],\n",
       "       [ 6706.98508913],\n",
       "       [ 6721.49539238],\n",
       "       [ 6682.7800492 ],\n",
       "       [ 6229.48834283],\n",
       "       [ 5922.48983509],\n",
       "       [ 6483.73944553],\n",
       "       [ 6446.42134684],\n",
       "       [ 6537.3364615 ],\n",
       "       [ 6850.55871169],\n",
       "       [ 6776.37009357],\n",
       "       [ 6855.93326446],\n",
       "       [ 6805.3622869 ],\n",
       "       [ 7278.24396977],\n",
       "       [ 7175.66747656],\n",
       "       [ 7367.29339845],\n",
       "       [ 7321.81661389],\n",
       "       [ 6866.39818901],\n",
       "       [ 6873.84849516],\n",
       "       [ 7043.43886352],\n",
       "       [ 6889.86377235],\n",
       "       [ 6887.55490783],\n",
       "       [ 6718.79995028],\n",
       "       [ 7166.58281714],\n",
       "       [ 7065.08238904],\n",
       "       [ 7277.14058556],\n",
       "       [ 7185.87030343],\n",
       "       [ 6856.14643454],\n",
       "       [ 6904.4757727 ],\n",
       "       [ 7118.38874792],\n",
       "       [ 7562.03283175],\n",
       "       [ 7497.86176383],\n",
       "       [ 7542.3034007 ],\n",
       "       [ 7624.85378592],\n",
       "       [ 7776.50754257],\n",
       "       [ 7761.75878408],\n",
       "       [ 8773.10648796],\n",
       "       [ 8767.67262337],\n",
       "       [ 8853.77448401],\n",
       "       [ 8963.0575578 ],\n",
       "       [ 8904.71381654],\n",
       "       [ 8887.50589259],\n",
       "       [ 8978.28358712],\n",
       "       [ 9371.68427279],\n",
       "       [ 9900.67886662],\n",
       "       [ 9917.24841434],\n",
       "       [ 9617.51819493],\n",
       "       [ 8786.65518165],\n",
       "       [ 8608.12524504],\n",
       "       [ 8815.2312449 ],\n",
       "       [ 9330.9864847 ],\n",
       "       [ 9757.29658559],\n",
       "       [ 9362.63555697],\n",
       "       [ 9418.91855051],\n",
       "       [ 9684.70195935],\n",
       "       [ 9723.68015045],\n",
       "       [ 9719.48085448],\n",
       "       [ 9540.88656658],\n",
       "       [ 9141.15063742],\n",
       "       [ 9192.84513581],\n",
       "       [ 9220.07588747],\n",
       "       [ 9048.71511916],\n",
       "       [ 8905.78160454],\n",
       "       [ 8835.72722404],\n",
       "       [ 9112.97917559],\n",
       "       [ 9507.52466466],\n",
       "       [ 9425.28186919],\n",
       "       [ 9688.32439037],\n",
       "       [ 9427.67008414],\n",
       "       [10268.58198473],\n",
       "       [ 9516.13544309],\n",
       "       [ 9667.06075426],\n",
       "       [ 9811.3670946 ],\n",
       "       [ 9659.66129819],\n",
       "       [ 9677.05099451],\n",
       "       [ 9737.45855879],\n",
       "       [ 9791.92789977],\n",
       "       [ 9786.14202048],\n",
       "       [ 9874.96704752],\n",
       "       [ 9260.83264099],\n",
       "       [ 9464.22809682],\n",
       "       [ 9458.6597544 ],\n",
       "       [ 9351.95372801],\n",
       "       [ 9441.76899555],\n",
       "       [ 9510.66063729],\n",
       "       [ 9457.62707441],\n",
       "       [ 9398.64209362],\n",
       "       [ 9279.76076517],\n",
       "       [ 9353.07819619],\n",
       "       [ 9289.10449144],\n",
       "       [ 9680.9471279 ],\n",
       "       [ 9609.68024553],\n",
       "       [ 9311.13631832],\n",
       "       [ 9252.63337177],\n",
       "       [ 9171.73208577],\n",
       "       [ 9022.153768  ],\n",
       "       [ 9101.85005736],\n",
       "       [ 9188.06137546],\n",
       "       [ 9148.44485856],\n",
       "       [ 9236.31677043],\n",
       "       [ 9097.79736639],\n",
       "       [ 9094.32456102],\n",
       "       [ 9124.6535344 ],\n",
       "       [ 9055.46448252],\n",
       "       [ 9278.80563704],\n",
       "       [ 9244.41581454],\n",
       "       [ 9471.75997342],\n",
       "       [ 9236.14325371],\n",
       "       [ 9243.17525915],\n",
       "       [ 9229.85975494],\n",
       "       [ 9286.73704209],\n",
       "       [ 9238.99375486],\n",
       "       [ 9260.47098018],\n",
       "       [ 9211.02643289],\n",
       "       [ 9133.77783034],\n",
       "       [ 9160.41059149],\n",
       "       [ 9176.6863901 ],\n",
       "       [ 9190.2715342 ],\n",
       "       [ 9172.58833257],\n",
       "       [ 9395.06444588],\n",
       "       [ 9530.79088535],\n",
       "       [ 9617.37786138],\n",
       "       [ 9568.97472596],\n",
       "       [ 9708.9491401 ],\n",
       "       [ 9938.95122286],\n",
       "       [11187.77972696],\n",
       "       [10939.67014155],\n",
       "       [11284.45898685],\n",
       "       [11118.91841243],\n",
       "       [11373.31725664],\n",
       "       [11766.74829709],\n",
       "       [11139.09838035],\n",
       "       [11261.80633174],\n",
       "       [11228.02632402],\n",
       "       [11653.40758556],\n",
       "       [11796.81736499],\n",
       "       [11639.93541013],\n",
       "       [11744.9120755 ],\n",
       "       [11673.12323754],\n",
       "       [11832.22730813],\n",
       "       [11340.58234064],\n",
       "       [11549.54631437],\n",
       "       [11752.16865623],\n",
       "       [11783.28341126],\n",
       "       [11895.62694989],\n",
       "       [11896.94717019],\n",
       "       [12399.11188466],\n",
       "       [12071.73890908],\n",
       "       [11749.82950876],\n",
       "       [11833.8973487 ],\n",
       "       [11583.13894263],\n",
       "       [11674.62435391],\n",
       "       [11666.41012224],\n",
       "       [11744.01269665],\n",
       "       [11378.72602981],\n",
       "       [11458.82259649],\n",
       "       [11302.1209645 ],\n",
       "       [11482.22568651],\n",
       "       [11515.04443069],\n",
       "       [11657.00393423],\n",
       "       [11678.37325542],\n",
       "       [11964.20867246],\n",
       "       [11427.70260497],\n",
       "       [10712.92064607],\n",
       "       [10563.89693862],\n",
       "       [10042.85485437],\n",
       "       [10207.60500296],\n",
       "       [10381.77610693],\n",
       "       [10043.19644129],\n",
       "       [10268.46091575],\n",
       "       [10341.01598385],\n",
       "       [10380.53959723],\n",
       "       [10436.36540836],\n",
       "       [10313.06857949],\n",
       "       [10680.29756117],\n",
       "       [10829.5053072 ],\n",
       "       [11033.38352648],\n",
       "       [10937.1112591 ],\n",
       "       [10933.9311624 ],\n",
       "       [11048.87927816],\n",
       "       [10852.91013894],\n",
       "       [10526.2028872 ],\n",
       "       [10531.16456263],\n",
       "       [10260.03301241],\n",
       "       [10672.95680806],\n",
       "       [10729.06960742],\n",
       "       [10741.47646752],\n",
       "       [10752.34544975],\n",
       "       [10863.06572391],\n",
       "       [10764.28437072],\n",
       "       [10741.5795495 ],\n",
       "       [10626.6009565 ],\n",
       "       [10567.33019523],\n",
       "       [10555.02867878],\n",
       "       [10660.61118264],\n",
       "       [10756.40458492],\n",
       "       [10589.62639353],\n",
       "       [10645.75478678],\n",
       "       [10897.59543151],\n",
       "       [11052.39508367],\n",
       "       [11360.85271687],\n",
       "       [11334.02674203],\n",
       "       [11666.21170032],\n",
       "       [11443.73279182],\n",
       "       [11395.54736637],\n",
       "       [11504.54900671],\n",
       "       [11355.16043945],\n",
       "       [11358.70637963],\n",
       "       [11471.00254779],\n",
       "       [11776.59299733],\n",
       "       [11936.36291334],\n",
       "       [13102.93446155],\n",
       "       [13140.66928406],\n",
       "       [12933.82356549],\n",
       "       [13081.67255949],\n",
       "       [13008.45325775],\n",
       "       [13033.52427008],\n",
       "       [13721.28222485],\n",
       "       [13282.26034792],\n",
       "       [13467.73178281],\n",
       "       [13573.71050315],\n",
       "       [13891.21683316],\n",
       "       [13730.19731094],\n",
       "       [13633.69821689],\n",
       "       [13832.93840977],\n",
       "       [14163.9768155 ],\n",
       "       [15424.52767669],\n",
       "       [15540.59659081],\n",
       "       [14783.98167853],\n",
       "       [15500.33425474],\n",
       "       [15283.78013873],\n",
       "       [15374.04438576],\n",
       "       [15820.49524108],\n",
       "       [16253.31027194],\n",
       "       [16347.04492035],\n",
       "       [15991.8330244 ],\n",
       "       [15918.08012811],\n",
       "       [16752.00298996],\n",
       "       [17593.48641493],\n",
       "       [17834.63653371],\n",
       "       [17954.8580091 ],\n",
       "       [18612.87067218],\n",
       "       [18591.85660475],\n",
       "       [18629.99553726],\n",
       "       [18469.20046948],\n",
       "       [19045.73646565],\n",
       "       [18746.9348067 ],\n",
       "       [17187.40627633],\n",
       "       [17023.96140009],\n",
       "       [17814.78027844],\n",
       "       [18114.41434928],\n",
       "       [19382.36058587],\n",
       "       [18980.97745012],\n",
       "       [19184.89784774],\n",
       "       [19464.53170456],\n",
       "       [18813.12476029],\n",
       "       [19045.0202726 ],\n",
       "       [19113.93339509],\n",
       "       [19107.59979531],\n",
       "       [18682.45783321],\n",
       "       [18543.00704922],\n",
       "       [18359.47660034],\n",
       "       [18137.31937461],\n",
       "       [18882.26017106],\n",
       "       [19060.27690128],\n",
       "       [19251.22400471],\n",
       "       [19443.47635283],\n",
       "       [21310.65626223],\n",
       "       [22895.97623755],\n",
       "       [23008.77625674],\n",
       "       [23890.82264887],\n",
       "       [23537.36989089],\n",
       "       [23177.27099799],\n",
       "       [23433.98075814],\n",
       "       [23224.45413785],\n",
       "       [23623.88553323],\n",
       "       [24581.00617127],\n",
       "       [26381.29623292],\n",
       "       [26389.29026494],\n",
       "       [26718.0294634 ],\n",
       "       [26975.72956452],\n",
       "       [28768.83620753],\n",
       "       [29111.52156712],\n",
       "       [29333.60512062],\n",
       "       [32154.16736327],\n",
       "       [33002.53642704],\n",
       "       [31431.61227972],\n",
       "       [34433.60651384],\n",
       "       [36275.75634767],\n",
       "       [39713.50785672],\n",
       "       [40519.44859753],\n",
       "       [40258.92398866],\n",
       "       [38709.76537488],\n",
       "       [34409.64237522],\n",
       "       [34214.61026205],\n",
       "       [37017.00750345],\n",
       "       [38435.86351466],\n",
       "       [36751.58497369],\n",
       "       [36016.77960594],\n",
       "       [36375.81137926],\n",
       "       [36346.60950223],\n",
       "       [36577.51964639],\n",
       "       [35004.53262688],\n",
       "       [30606.18267565],\n",
       "       [33368.36593189],\n",
       "       [32070.0974252 ],\n",
       "       [32285.72613244],\n",
       "       [32500.25596269],\n",
       "       [32324.55565073],\n",
       "       [30534.99937302],\n",
       "       [33408.21833739],\n",
       "       [34842.55739312],\n",
       "       [34622.37323153],\n",
       "       [33087.36986452],\n",
       "       [33613.32076431],\n",
       "       [35632.90195152],\n",
       "       [37397.42636409],\n",
       "       [37256.25211087],\n",
       "       [37851.59659008],\n",
       "       [40302.79979284],\n",
       "       [38461.6814033 ],\n",
       "       [44716.68546906],\n",
       "       [46674.85168811],\n",
       "       [45237.47568925],\n",
       "       [47500.8975242 ],\n",
       "       [47884.1828623 ],\n",
       "       [47005.1906489 ],\n",
       "       [49151.16757632],\n",
       "       [48125.99219541],\n",
       "       [48840.41447458],\n",
       "       [52165.30255522],\n",
       "       [51728.50879673],\n",
       "       [55719.2043617 ],\n",
       "       [54801.64864399],\n",
       "       [57128.64260647],\n",
       "       [54181.91464919],\n",
       "       [48172.87747693],\n",
       "       [48745.43298434],\n",
       "       [48291.41208335],\n",
       "       [45752.11491941],\n",
       "       [46642.60607658],\n",
       "       [45092.8065726 ],\n",
       "       [49248.91401331],\n",
       "       [47900.77687833],\n",
       "       [50811.85517444],\n",
       "       [48259.48707666],\n",
       "       [49149.73082884],\n",
       "       [48879.15190416],\n",
       "       [50594.69857451],\n",
       "       [51503.25813218],\n",
       "       [54458.03781142],\n",
       "       [56915.17393505],\n",
       "       [57636.75796197],\n",
       "       [57306.16626299],\n",
       "       [60743.04182491],\n",
       "       [60197.9019918 ],\n",
       "       [56300.33410863],\n",
       "       [56639.78394967],\n",
       "       [58567.28378106],\n",
       "       [57983.09474357],\n",
       "       [58451.73146595],\n",
       "       [58593.60245406],\n",
       "       [57796.46737122],\n",
       "       [54329.35863463],\n",
       "       [54794.29771371],\n",
       "       [52787.74552575],\n",
       "       [52173.86798025],\n",
       "       [54483.0457323 ],\n",
       "       [56234.356105  ],\n",
       "       [55343.92581533],\n",
       "       [57627.6792491 ],\n",
       "       [58734.47543372],\n",
       "       [58724.66451663],\n",
       "       [58984.61292993],\n",
       "       [58821.62699444],\n",
       "       [57517.79877314],\n",
       "       [58177.40276373],\n",
       "       [58843.55954021],\n",
       "       [58040.18760188],\n",
       "       [56508.94286388],\n",
       "       [57880.90568386],\n",
       "       [58171.9090187 ],\n",
       "       [59295.95004401],\n",
       "       [59822.90167743],\n",
       "       [59853.19724227],\n",
       "       [63223.88439079],\n",
       "       [62926.5571759 ],\n",
       "       [63346.78903511],\n",
       "       [61965.7825981 ],\n",
       "       [60574.44472823],\n",
       "       [56850.83016569],\n",
       "       [56224.10158771],\n",
       "       [56608.76974839],\n",
       "       [54144.42747606],\n",
       "       [51965.05955941],\n",
       "       [50669.14438218],\n",
       "       [50733.76950364],\n",
       "       [48542.95220298],\n",
       "       [53558.70784462],\n",
       "       [55123.86198142],\n",
       "       [54591.51532554],\n",
       "       [53260.29534115],\n",
       "       [57302.64642408],\n",
       "       [57677.9752219 ],\n",
       "       [56427.04312502],\n",
       "       [57255.30683756],\n",
       "       [53658.84312082],\n",
       "       [57252.7021845 ],\n",
       "       [56583.84987917],\n",
       "       [57107.12067189],\n",
       "       [58788.20967893],\n",
       "       [58102.19142623],\n",
       "       [55715.54665129],\n",
       "       [56573.5554719 ],\n",
       "       [52147.82118698],\n",
       "       [49764.1320816 ],\n",
       "       [50032.69313676],\n",
       "       [47885.62525472],\n",
       "       [45604.61575361],\n",
       "       [43144.47129086]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f069b31a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(552,), dtype=float32, numpy=\n",
       "array([ 8991.691 ,  8902.945 ,  8752.008 ,  8622.495 ,  8687.354 ,\n",
       "        8585.898 ,  8242.637 ,  8089.9595,  8213.25  ,  7890.641 ,\n",
       "        7473.8213,  7415.5923,  7234.916 ,  7200.032 ,  7211.8477,\n",
       "        7518.626 ,  7493.001 ,  7683.3745,  7688.037 ,  7573.2876,\n",
       "        7517.9863,  7419.6924,  7389.9644,  7416.3447,  7579.4673,\n",
       "        7548.479 ,  7562.9565,  7434.6255,  7306.3545,  7286.387 ,\n",
       "        7311.7705,  7398.5513,  7258.2397,  7300.659 ,  7046.287 ,\n",
       "        6806.498 ,  7196.173 ,  7281.967 ,  7180.964 ,  7337.6455,\n",
       "        7338.744 ,  7266.827 ,  7299.4775,  7377.841 ,  7262.261 ,\n",
       "        7286.92  ,  7376.519 ,  7455.6255,  7285.693 ,  7220.0737,\n",
       "        7275.8086,  7115.89  ,  7307.945 ,  7420.614 ,  7469.835 ,\n",
       "        7664.58  ,  8042.757 ,  8115.295 ,  8023.645 ,  8083.119 ,\n",
       "        8136.1206,  8188.323 ,  8253.336 ,  8711.663 ,  8863.549 ,\n",
       "        8809.113 ,  8972.641 ,  8983.787 ,  8773.0625,  8722.631 ,\n",
       "        8875.449 ,  8767.141 ,  8567.862 ,  8576.103 ,  8519.783 ,\n",
       "        8528.511 ,  8791.341 ,  9164.174 ,  9345.336 ,  9552.61  ,\n",
       "        9501.41  ,  9565.126 ,  9514.646 ,  9429.508 ,  9292.082 ,\n",
       "        9630.486 ,  9708.046 ,  9766.504 ,  9892.684 , 10130.496 ,\n",
       "        9963.758 , 10234.844 , 10499.928 , 10466.231 , 10466.307 ,\n",
       "       10220.671 , 10077.33  ,  9785.794 , 10118.613 ,  9867.264 ,\n",
       "        9706.975 ,  9719.89  ,  9759.759 ,  9985.029 ,  9793.873 ,\n",
       "        9679.303 ,  9051.487 ,  9006.967 ,  8899.037 ,  8814.861 ,\n",
       "        8603.02  ,  8886.87  ,  8889.506 ,  8810.023 ,  9099.989 ,\n",
       "        9143.5205,  9101.678 ,  8450.156 ,  8266.119 ,  8072.722 ,\n",
       "        8119.126 ,  6509.01  ,  6106.2773,  5815.6714,  5552.6475,\n",
       "        5506.732 ,  5606.845 ,  5616.392 ,  5931.0874,  6406.7285,\n",
       "        6349.0024,  6073.2812,  6324.7983,  6961.218 ,  6899.397 ,\n",
       "        6775.1313,  6724.163 ,  6338.9385,  5930.1396,  6156.743 ,\n",
       "        6366.034 ,  6392.172 ,  6790.346 ,  6461.1396,  6838.3525,\n",
       "        6837.6387,  7549.283 ,  7207.864 ,  7457.804 ,  7423.9893,\n",
       "        7221.527 ,  6839.6562,  6949.324 ,  6932.0674,  6954.2153,\n",
       "        6855.139 ,  7056.8945,  7102.6753,  7273.0522,  7319.298 ,\n",
       "        7059.004 ,  7067.473 ,  7213.365 ,  7552.1494,  7536.382 ,\n",
       "        7578.9326,  7681.992 ,  7740.223 ,  7825.6704,  8527.58  ,\n",
       "        8813.872 ,  8911.339 ,  9092.57  ,  9094.326 ,  9070.1455,\n",
       "        8983.092 ,  9385.391 ,  9804.571 , 10119.737 ,  9885.617 ,\n",
       "        9157.723 ,  8714.529 ,  8780.301 ,  9359.701 ,  9790.982 ,\n",
       "        9647.936 ,  9482.584 ,  9682.811 ,  9744.301 ,  9807.76  ,\n",
       "        9666.818 ,  9471.652 ,  9313.155 ,  9358.894 ,  9168.546 ,\n",
       "        8986.691 ,  8853.605 ,  9059.354 ,  9455.3   ,  9544.475 ,\n",
       "        9673.698 ,  9571.561 , 10155.251 ,  9917.765 ,  9953.422 ,\n",
       "        9947.206 ,  9763.391 ,  9640.43  ,  9752.543 ,  9916.193 ,\n",
       "        9792.253 ,  9909.596 ,  9480.225 ,  9559.129 ,  9589.775 ,\n",
       "        9582.303 ,  9620.315 ,  9582.62  ,  9618.84  ,  9505.424 ,\n",
       "        9505.581 ,  9308.842 ,  9405.547 ,  9598.182 ,  9851.425 ,\n",
       "        9447.791 ,  9374.519 ,  9304.997 ,  9183.011 ,  9167.686 ,\n",
       "        9218.688 ,  9306.478 ,  9287.376 ,  9246.715 ,  9165.846 ,\n",
       "        9233.951 ,  9188.974 ,  9378.612 ,  9365.615 ,  9539.591 ,\n",
       "        9404.278 ,  9363.972 ,  9287.354 ,  9373.483 ,  9340.719 ,\n",
       "        9378.3545,  9322.049 ,  9211.617 ,  9267.651 ,  9293.023 ,\n",
       "        9320.388 ,  9259.502 ,  9459.137 ,  9605.283 ,  9690.98  ,\n",
       "        9683.91  ,  9786.402 , 10001.169 , 10915.961 , 11111.838 ,\n",
       "       11330.622 , 11295.22  , 11393.838 , 11771.744 , 11424.271 ,\n",
       "       11438.453 , 11301.662 , 11679.687 , 11844.238 , 11809.078 ,\n",
       "       11781.66  , 11723.349 , 11955.66  , 11618.581 , 11757.808 ,\n",
       "       11821.403 , 11988.414 , 11973.701 , 12063.848 , 12328.77  ,\n",
       "       12251.97  , 11870.994 , 11864.9   , 11732.259 , 11818.144 ,\n",
       "       11896.87  , 11824.1875, 11551.624 , 11539.625 , 11520.363 ,\n",
       "       11537.717 , 11496.365 , 11767.982 , 11866.18  , 12086.229 ,\n",
       "       11692.66  , 11089.157 , 10813.568 , 10275.571 , 10281.429 ,\n",
       "       10401.059 , 10302.344 , 10248.589 , 10324.522 , 10501.262 ,\n",
       "       10511.811 , 10546.178 , 10727.303 , 11027.955 , 11156.393 ,\n",
       "       11155.109 , 11062.326 , 11102.508 , 10914.33  , 10686.732 ,\n",
       "       10590.85  , 10427.125 , 10648.936 , 10804.533 , 10925.3955,\n",
       "       10922.401 , 11022.168 , 10946.961 , 10861.936 , 10830.225 ,\n",
       "       10753.999 , 10750.315 , 10768.187 , 10818.245 , 10742.516 ,\n",
       "       10678.828 , 10880.608 , 11035.827 , 11368.018 , 11478.686 ,\n",
       "       11762.072 , 11607.221 , 11608.189 , 11633.35  , 11583.637 ,\n",
       "       11443.925 , 11526.741 , 11791.191 , 11956.543 , 12871.039 ,\n",
       "       13182.766 , 13109.885 , 13188.885 , 13226.139 , 13252.855 ,\n",
       "       13698.732 , 13596.965 , 13559.6045, 13695.151 , 13894.927 ,\n",
       "       13840.336 , 13644.746 , 13888.219 , 14192.781 , 15284.862 ,\n",
       "       15709.458 , 15252.097 , 15517.925 , 15443.124 , 15565.569 ,\n",
       "       15803.35  , 16372.0625, 16426.686 , 16203.802 , 16106.428 ,\n",
       "       16695.207 , 17402.75  , 17920.367 , 18155.23  , 18673.781 ,\n",
       "       18828.105 , 18977.184 , 18762.56  , 19026.545 , 18971.49  ,\n",
       "       17948.668 , 17428.662 , 17673.783 , 17897.836 , 19121.361 ,\n",
       "       19307.074 , 19376.043 , 19456.363 , 19306.295 , 19354.14  ,\n",
       "       19254.258 , 19400.664 , 19211.838 , 18965.592 , 18450.064 ,\n",
       "       18035.426 , 18688.4   , 19024.45  , 19335.668 , 19530.273 ,\n",
       "       21211.848 , 22692.629 , 23117.133 , 23959.617 , 24199.898 ,\n",
       "       23689.73  , 23631.564 , 23508.746 , 23691.988 , 24552.496 ,\n",
       "       26243.3   , 26775.932 , 26972.604 , 27094.139 , 28526.906 ,\n",
       "       29303.053 , 29882.996 , 32195.201 , 33528.184 , 32616.906 ,\n",
       "       34280.09  , 36241.082 , 39379.83  , 41163.71  , 41375.098 ,\n",
       "       39983.8   , 35966.6   , 34549.746 , 36130.797 , 37850.375 ,\n",
       "       37333.266 , 36960.832 , 36476.45  , 35654.062 , 36046.152 ,\n",
       "       35404.277 , 32454.8   , 33359.34  , 33361.56  , 33147.168 ,\n",
       "       32528.662 , 31857.428 , 30990.484 , 32626.266 , 34723.793 ,\n",
       "       34386.43  , 33581.78  , 33984.38  , 35770.    , 37611.7   ,\n",
       "       38150.633 , 38234.152 , 39254.41  , 38645.977 , 43846.695 ,\n",
       "       46779.715 , 45986.496 , 47677.16  , 47674.617 , 48860.992 ,\n",
       "       49291.65  , 49476.97  , 49112.996 , 51947.71  , 52449.176 ,\n",
       "       56196.86  , 55667.816 , 56882.266 , 54989.094 , 50567.98  ,\n",
       "       49432.645 , 48421.543 , 46913.535 , 46190.3   , 46360.566 ,\n",
       "       47945.44  , 48204.367 , 50118.465 , 48864.15  , 49140.504 ,\n",
       "       49793.242 , 51779.805 , 52394.11  , 54102.73  , 56695.105 ,\n",
       "       57954.97  , 57481.19  , 60034.652 , 60499.094 , 57843.617 ,\n",
       "       57131.504 , 58905.285 , 59278.91  , 59720.246 , 59324.81  ,\n",
       "       58556.07  , 54871.375 , 56079.11  , 53799.45  , 53301.883 ,\n",
       "       54056.785 , 57199.18  , 56640.723 , 57580.754 , 58783.395 ,\n",
       "       59088.207 , 59034.074 , 59141.75  , 58592.383 , 58935.03  ,\n",
       "       59374.71  , 58633.88  , 57204.574 , 58113.375 , 58410.98  ,\n",
       "       59158.668 , 59772.137 , 60808.406 , 63032.703 , 64037.375 ,\n",
       "       64508.457 , 63565.754 , 61916.297 , 58628.605 , 57005.92  ,\n",
       "       57083.33  , 55051.293 , 53067.863 , 51312.43  , 51206.027 ,\n",
       "       49260.73  , 52996.074 , 55402.34  , 55581.633 , 54358.67  ,\n",
       "       57638.098 , 58738.918 , 57094.4   , 57798.473 , 55078.73  ,\n",
       "       57042.55  , 56368.52  , 57665.684 , 58019.207 , 58136.684 ,\n",
       "       56853.26  , 57335.52  , 54805.105 , 51066.082 , 51253.8   ,\n",
       "       49485.73  , 47789.348 ], dtype=float32)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4c80bb76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(552,), dtype=float64, numpy=\n",
       "array([ 8749.52059102,  8656.97092235,  8500.64355816,  8469.2608989 ,\n",
       "        8537.33965197,  8205.80636599,  8118.4885358 ,  8074.84317361,\n",
       "        7612.7405735 ,  7262.11053495,  7303.40575852,  7041.73293642,\n",
       "        7211.86180875,  7141.06944869,  7523.4806726 ,  7390.20746923,\n",
       "        7729.26593894,  7542.23560864,  7381.96300782,  7333.43293049,\n",
       "        7315.36776456,  7213.73376172,  7398.78704961,  7511.88058312,\n",
       "        7532.12351309,  7550.23919987,  7333.09604316,  7239.76257544,\n",
       "        7198.06667705,  7190.27236926,  7238.87432299,  7087.02498535,\n",
       "        7112.73147612,  6883.49639377,  6584.02884335,  7424.01540023,\n",
       "        7147.56832379,  7139.93337053,  7286.33508116,  7236.98620461,\n",
       "        7166.17237853,  7235.6266505 ,  7212.80939522,  7183.70653603,\n",
       "        7227.29371168,  7311.56064392,  7385.46484791,  7251.27679432,\n",
       "        7179.95781929,  7174.74401195,  6955.48757967,  7291.21950532,\n",
       "        7337.63667014,  7347.43326444,  7713.86075365,  8039.60370082,\n",
       "        8067.60636906,  7808.70136382,  8087.45288524,  8078.99353199,\n",
       "        8149.31371715,  8116.96100795,  8735.14243914,  8843.67573222,\n",
       "        8711.6375779 ,  8925.29902845,  8939.86430025,  8638.18144046,\n",
       "        8652.68376299,  8708.78601343,  8635.07435696,  8384.08877677,\n",
       "        8451.23229602,  8347.56750541,  8562.30747044,  8881.96239146,\n",
       "        9131.11498806,  9320.97840625,  9545.07795659,  9388.88075189,\n",
       "        9363.19338276,  9385.26038584,  9269.70703484,  9177.89463721,\n",
       "        9625.4566372 ,  9681.37741131,  9795.34406595,  9927.77825642,\n",
       "       10132.70649911,  9838.90001628, 10236.63514823, 10364.92628823,\n",
       "       10218.0997373 , 10367.52799811,  9926.35369057,  9876.23496321,\n",
       "        9636.62409482, 10189.99598297,  9701.0371915 ,  9631.48494596,\n",
       "        9670.85865437,  9689.08674285,  9919.55144784,  9640.46950506,\n",
       "        9392.86962872,  8787.97836316,  8784.99535244,  8778.4705108 ,\n",
       "        8639.5914173 ,  8548.94832242,  8923.04439826,  8791.11205813,\n",
       "        8756.96106241,  9078.57877713,  9126.63682222,  8925.21348778,\n",
       "        8166.31389402,  7875.75087522,  7959.22827421,  7955.30628418,\n",
       "        5800.20890483,  5672.68120103,  5304.14995219,  5355.18737353,\n",
       "        4944.70233598,  5465.58259412,  5363.82285325,  6301.06340407,\n",
       "        6185.27983852,  6187.05375022,  5884.34013347,  6455.45468825,\n",
       "        6784.31801143,  6706.98508913,  6721.49539238,  6682.7800492 ,\n",
       "        6229.48834283,  5922.48983509,  6483.73944553,  6446.42134684,\n",
       "        6537.3364615 ,  6850.55871169,  6776.37009357,  6855.93326446,\n",
       "        6805.3622869 ,  7278.24396977,  7175.66747656,  7367.29339845,\n",
       "        7321.81661389,  6866.39818901,  6873.84849516,  7043.43886352,\n",
       "        6889.86377235,  6887.55490783,  6718.79995028,  7166.58281714,\n",
       "        7065.08238904,  7277.14058556,  7185.87030343,  6856.14643454,\n",
       "        6904.4757727 ,  7118.38874792,  7562.03283175,  7497.86176383,\n",
       "        7542.3034007 ,  7624.85378592,  7776.50754257,  7761.75878408,\n",
       "        8773.10648796,  8767.67262337,  8853.77448401,  8963.0575578 ,\n",
       "        8904.71381654,  8887.50589259,  8978.28358712,  9371.68427279,\n",
       "        9900.67886662,  9917.24841434,  9617.51819493,  8786.65518165,\n",
       "        8608.12524504,  8815.2312449 ,  9330.9864847 ,  9757.29658559,\n",
       "        9362.63555697,  9418.91855051,  9684.70195935,  9723.68015045,\n",
       "        9719.48085448,  9540.88656658,  9141.15063742,  9192.84513581,\n",
       "        9220.07588747,  9048.71511916,  8905.78160454,  8835.72722404,\n",
       "        9112.97917559,  9507.52466466,  9425.28186919,  9688.32439037,\n",
       "        9427.67008414, 10268.58198473,  9516.13544309,  9667.06075426,\n",
       "        9811.3670946 ,  9659.66129819,  9677.05099451,  9737.45855879,\n",
       "        9791.92789977,  9786.14202048,  9874.96704752,  9260.83264099,\n",
       "        9464.22809682,  9458.6597544 ,  9351.95372801,  9441.76899555,\n",
       "        9510.66063729,  9457.62707441,  9398.64209362,  9279.76076517,\n",
       "        9353.07819619,  9289.10449144,  9680.9471279 ,  9609.68024553,\n",
       "        9311.13631832,  9252.63337177,  9171.73208577,  9022.153768  ,\n",
       "        9101.85005736,  9188.06137546,  9148.44485856,  9236.31677043,\n",
       "        9097.79736639,  9094.32456102,  9124.6535344 ,  9055.46448252,\n",
       "        9278.80563704,  9244.41581454,  9471.75997342,  9236.14325371,\n",
       "        9243.17525915,  9229.85975494,  9286.73704209,  9238.99375486,\n",
       "        9260.47098018,  9211.02643289,  9133.77783034,  9160.41059149,\n",
       "        9176.6863901 ,  9190.2715342 ,  9172.58833257,  9395.06444588,\n",
       "        9530.79088535,  9617.37786138,  9568.97472596,  9708.9491401 ,\n",
       "        9938.95122286, 11187.77972696, 10939.67014155, 11284.45898685,\n",
       "       11118.91841243, 11373.31725664, 11766.74829709, 11139.09838035,\n",
       "       11261.80633174, 11228.02632402, 11653.40758556, 11796.81736499,\n",
       "       11639.93541013, 11744.9120755 , 11673.12323754, 11832.22730813,\n",
       "       11340.58234064, 11549.54631437, 11752.16865623, 11783.28341126,\n",
       "       11895.62694989, 11896.94717019, 12399.11188466, 12071.73890908,\n",
       "       11749.82950876, 11833.8973487 , 11583.13894263, 11674.62435391,\n",
       "       11666.41012224, 11744.01269665, 11378.72602981, 11458.82259649,\n",
       "       11302.1209645 , 11482.22568651, 11515.04443069, 11657.00393423,\n",
       "       11678.37325542, 11964.20867246, 11427.70260497, 10712.92064607,\n",
       "       10563.89693862, 10042.85485437, 10207.60500296, 10381.77610693,\n",
       "       10043.19644129, 10268.46091575, 10341.01598385, 10380.53959723,\n",
       "       10436.36540836, 10313.06857949, 10680.29756117, 10829.5053072 ,\n",
       "       11033.38352648, 10937.1112591 , 10933.9311624 , 11048.87927816,\n",
       "       10852.91013894, 10526.2028872 , 10531.16456263, 10260.03301241,\n",
       "       10672.95680806, 10729.06960742, 10741.47646752, 10752.34544975,\n",
       "       10863.06572391, 10764.28437072, 10741.5795495 , 10626.6009565 ,\n",
       "       10567.33019523, 10555.02867878, 10660.61118264, 10756.40458492,\n",
       "       10589.62639353, 10645.75478678, 10897.59543151, 11052.39508367,\n",
       "       11360.85271687, 11334.02674203, 11666.21170032, 11443.73279182,\n",
       "       11395.54736637, 11504.54900671, 11355.16043945, 11358.70637963,\n",
       "       11471.00254779, 11776.59299733, 11936.36291334, 13102.93446155,\n",
       "       13140.66928406, 12933.82356549, 13081.67255949, 13008.45325775,\n",
       "       13033.52427008, 13721.28222485, 13282.26034792, 13467.73178281,\n",
       "       13573.71050315, 13891.21683316, 13730.19731094, 13633.69821689,\n",
       "       13832.93840977, 14163.9768155 , 15424.52767669, 15540.59659081,\n",
       "       14783.98167853, 15500.33425474, 15283.78013873, 15374.04438576,\n",
       "       15820.49524108, 16253.31027194, 16347.04492035, 15991.8330244 ,\n",
       "       15918.08012811, 16752.00298996, 17593.48641493, 17834.63653371,\n",
       "       17954.8580091 , 18612.87067218, 18591.85660475, 18629.99553726,\n",
       "       18469.20046948, 19045.73646565, 18746.9348067 , 17187.40627633,\n",
       "       17023.96140009, 17814.78027844, 18114.41434928, 19382.36058587,\n",
       "       18980.97745012, 19184.89784774, 19464.53170456, 18813.12476029,\n",
       "       19045.0202726 , 19113.93339509, 19107.59979531, 18682.45783321,\n",
       "       18543.00704922, 18359.47660034, 18137.31937461, 18882.26017106,\n",
       "       19060.27690128, 19251.22400471, 19443.47635283, 21310.65626223,\n",
       "       22895.97623755, 23008.77625674, 23890.82264887, 23537.36989089,\n",
       "       23177.27099799, 23433.98075814, 23224.45413785, 23623.88553323,\n",
       "       24581.00617127, 26381.29623292, 26389.29026494, 26718.0294634 ,\n",
       "       26975.72956452, 28768.83620753, 29111.52156712, 29333.60512062,\n",
       "       32154.16736327, 33002.53642704, 31431.61227972, 34433.60651384,\n",
       "       36275.75634767, 39713.50785672, 40519.44859753, 40258.92398866,\n",
       "       38709.76537488, 34409.64237522, 34214.61026205, 37017.00750345,\n",
       "       38435.86351466, 36751.58497369, 36016.77960594, 36375.81137926,\n",
       "       36346.60950223, 36577.51964639, 35004.53262688, 30606.18267565,\n",
       "       33368.36593189, 32070.0974252 , 32285.72613244, 32500.25596269,\n",
       "       32324.55565073, 30534.99937302, 33408.21833739, 34842.55739312,\n",
       "       34622.37323153, 33087.36986452, 33613.32076431, 35632.90195152,\n",
       "       37397.42636409, 37256.25211087, 37851.59659008, 40302.79979284,\n",
       "       38461.6814033 , 44716.68546906, 46674.85168811, 45237.47568925,\n",
       "       47500.8975242 , 47884.1828623 , 47005.1906489 , 49151.16757632,\n",
       "       48125.99219541, 48840.41447458, 52165.30255522, 51728.50879673,\n",
       "       55719.2043617 , 54801.64864399, 57128.64260647, 54181.91464919,\n",
       "       48172.87747693, 48745.43298434, 48291.41208335, 45752.11491941,\n",
       "       46642.60607658, 45092.8065726 , 49248.91401331, 47900.77687833,\n",
       "       50811.85517444, 48259.48707666, 49149.73082884, 48879.15190416,\n",
       "       50594.69857451, 51503.25813218, 54458.03781142, 56915.17393505,\n",
       "       57636.75796197, 57306.16626299, 60743.04182491, 60197.9019918 ,\n",
       "       56300.33410863, 56639.78394967, 58567.28378106, 57983.09474357,\n",
       "       58451.73146595, 58593.60245406, 57796.46737122, 54329.35863463,\n",
       "       54794.29771371, 52787.74552575, 52173.86798025, 54483.0457323 ,\n",
       "       56234.356105  , 55343.92581533, 57627.6792491 , 58734.47543372,\n",
       "       58724.66451663, 58984.61292993, 58821.62699444, 57517.79877314,\n",
       "       58177.40276373, 58843.55954021, 58040.18760188, 56508.94286388,\n",
       "       57880.90568386, 58171.9090187 , 59295.95004401, 59822.90167743,\n",
       "       59853.19724227, 63223.88439079, 62926.5571759 , 63346.78903511,\n",
       "       61965.7825981 , 60574.44472823, 56850.83016569, 56224.10158771,\n",
       "       56608.76974839, 54144.42747606, 51965.05955941, 50669.14438218,\n",
       "       50733.76950364, 48542.95220298, 53558.70784462, 55123.86198142,\n",
       "       54591.51532554, 53260.29534115, 57302.64642408, 57677.9752219 ,\n",
       "       56427.04312502, 57255.30683756, 53658.84312082, 57252.7021845 ,\n",
       "       56583.84987917, 57107.12067189, 58788.20967893, 58102.19142623,\n",
       "       55715.54665129, 56573.5554719 , 52147.82118698, 49764.1320816 ,\n",
       "       50032.69313676, 47885.62525472, 45604.61575361, 43144.47129086])>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "22b0a7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(552, 7), dtype=float32, numpy=\n",
       "array([[ 8991.691,  8937.682,  8830.556, ...,  8898.763,  8986.724,\n",
       "         8848.014],\n",
       "       [ 8902.945,  8987.835,  8996.881, ...,  8781.812,  9019.121,\n",
       "         8918.478],\n",
       "       [ 8752.008,  8767.166,  8830.347, ...,  8805.518,  8745.545,\n",
       "         8769.534],\n",
       "       ...,\n",
       "       [51253.8  , 50584.8  , 51033.855, ..., 50386.344, 51481.305,\n",
       "        50259.45 ],\n",
       "       [49485.73 , 48552.9  , 49714.06 , ..., 49237.168, 49417.137,\n",
       "        49000.54 ],\n",
       "       [47789.348, 47434.152, 46863.664, ..., 46763.344, 46612.496,\n",
       "        46092.22 ]], dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2272152d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8749.52059102],\n",
       "       [ 8656.97092235],\n",
       "       [ 8500.64355816],\n",
       "       [ 8469.2608989 ],\n",
       "       [ 8537.33965197],\n",
       "       [ 8205.80636599],\n",
       "       [ 8118.4885358 ],\n",
       "       [ 8074.84317361],\n",
       "       [ 7612.7405735 ],\n",
       "       [ 7262.11053495],\n",
       "       [ 7303.40575852],\n",
       "       [ 7041.73293642],\n",
       "       [ 7211.86180875],\n",
       "       [ 7141.06944869],\n",
       "       [ 7523.4806726 ],\n",
       "       [ 7390.20746923],\n",
       "       [ 7729.26593894],\n",
       "       [ 7542.23560864],\n",
       "       [ 7381.96300782],\n",
       "       [ 7333.43293049],\n",
       "       [ 7315.36776456],\n",
       "       [ 7213.73376172],\n",
       "       [ 7398.78704961],\n",
       "       [ 7511.88058312],\n",
       "       [ 7532.12351309],\n",
       "       [ 7550.23919987],\n",
       "       [ 7333.09604316],\n",
       "       [ 7239.76257544],\n",
       "       [ 7198.06667705],\n",
       "       [ 7190.27236926],\n",
       "       [ 7238.87432299],\n",
       "       [ 7087.02498535],\n",
       "       [ 7112.73147612],\n",
       "       [ 6883.49639377],\n",
       "       [ 6584.02884335],\n",
       "       [ 7424.01540023],\n",
       "       [ 7147.56832379],\n",
       "       [ 7139.93337053],\n",
       "       [ 7286.33508116],\n",
       "       [ 7236.98620461],\n",
       "       [ 7166.17237853],\n",
       "       [ 7235.6266505 ],\n",
       "       [ 7212.80939522],\n",
       "       [ 7183.70653603],\n",
       "       [ 7227.29371168],\n",
       "       [ 7311.56064392],\n",
       "       [ 7385.46484791],\n",
       "       [ 7251.27679432],\n",
       "       [ 7179.95781929],\n",
       "       [ 7174.74401195],\n",
       "       [ 6955.48757967],\n",
       "       [ 7291.21950532],\n",
       "       [ 7337.63667014],\n",
       "       [ 7347.43326444],\n",
       "       [ 7713.86075365],\n",
       "       [ 8039.60370082],\n",
       "       [ 8067.60636906],\n",
       "       [ 7808.70136382],\n",
       "       [ 8087.45288524],\n",
       "       [ 8078.99353199],\n",
       "       [ 8149.31371715],\n",
       "       [ 8116.96100795],\n",
       "       [ 8735.14243914],\n",
       "       [ 8843.67573222],\n",
       "       [ 8711.6375779 ],\n",
       "       [ 8925.29902845],\n",
       "       [ 8939.86430025],\n",
       "       [ 8638.18144046],\n",
       "       [ 8652.68376299],\n",
       "       [ 8708.78601343],\n",
       "       [ 8635.07435696],\n",
       "       [ 8384.08877677],\n",
       "       [ 8451.23229602],\n",
       "       [ 8347.56750541],\n",
       "       [ 8562.30747044],\n",
       "       [ 8881.96239146],\n",
       "       [ 9131.11498806],\n",
       "       [ 9320.97840625],\n",
       "       [ 9545.07795659],\n",
       "       [ 9388.88075189],\n",
       "       [ 9363.19338276],\n",
       "       [ 9385.26038584],\n",
       "       [ 9269.70703484],\n",
       "       [ 9177.89463721],\n",
       "       [ 9625.4566372 ],\n",
       "       [ 9681.37741131],\n",
       "       [ 9795.34406595],\n",
       "       [ 9927.77825642],\n",
       "       [10132.70649911],\n",
       "       [ 9838.90001628],\n",
       "       [10236.63514823],\n",
       "       [10364.92628823],\n",
       "       [10218.0997373 ],\n",
       "       [10367.52799811],\n",
       "       [ 9926.35369057],\n",
       "       [ 9876.23496321],\n",
       "       [ 9636.62409482],\n",
       "       [10189.99598297],\n",
       "       [ 9701.0371915 ],\n",
       "       [ 9631.48494596],\n",
       "       [ 9670.85865437],\n",
       "       [ 9689.08674285],\n",
       "       [ 9919.55144784],\n",
       "       [ 9640.46950506],\n",
       "       [ 9392.86962872],\n",
       "       [ 8787.97836316],\n",
       "       [ 8784.99535244],\n",
       "       [ 8778.4705108 ],\n",
       "       [ 8639.5914173 ],\n",
       "       [ 8548.94832242],\n",
       "       [ 8923.04439826],\n",
       "       [ 8791.11205813],\n",
       "       [ 8756.96106241],\n",
       "       [ 9078.57877713],\n",
       "       [ 9126.63682222],\n",
       "       [ 8925.21348778],\n",
       "       [ 8166.31389402],\n",
       "       [ 7875.75087522],\n",
       "       [ 7959.22827421],\n",
       "       [ 7955.30628418],\n",
       "       [ 5800.20890483],\n",
       "       [ 5672.68120103],\n",
       "       [ 5304.14995219],\n",
       "       [ 5355.18737353],\n",
       "       [ 4944.70233598],\n",
       "       [ 5465.58259412],\n",
       "       [ 5363.82285325],\n",
       "       [ 6301.06340407],\n",
       "       [ 6185.27983852],\n",
       "       [ 6187.05375022],\n",
       "       [ 5884.34013347],\n",
       "       [ 6455.45468825],\n",
       "       [ 6784.31801143],\n",
       "       [ 6706.98508913],\n",
       "       [ 6721.49539238],\n",
       "       [ 6682.7800492 ],\n",
       "       [ 6229.48834283],\n",
       "       [ 5922.48983509],\n",
       "       [ 6483.73944553],\n",
       "       [ 6446.42134684],\n",
       "       [ 6537.3364615 ],\n",
       "       [ 6850.55871169],\n",
       "       [ 6776.37009357],\n",
       "       [ 6855.93326446],\n",
       "       [ 6805.3622869 ],\n",
       "       [ 7278.24396977],\n",
       "       [ 7175.66747656],\n",
       "       [ 7367.29339845],\n",
       "       [ 7321.81661389],\n",
       "       [ 6866.39818901],\n",
       "       [ 6873.84849516],\n",
       "       [ 7043.43886352],\n",
       "       [ 6889.86377235],\n",
       "       [ 6887.55490783],\n",
       "       [ 6718.79995028],\n",
       "       [ 7166.58281714],\n",
       "       [ 7065.08238904],\n",
       "       [ 7277.14058556],\n",
       "       [ 7185.87030343],\n",
       "       [ 6856.14643454],\n",
       "       [ 6904.4757727 ],\n",
       "       [ 7118.38874792],\n",
       "       [ 7562.03283175],\n",
       "       [ 7497.86176383],\n",
       "       [ 7542.3034007 ],\n",
       "       [ 7624.85378592],\n",
       "       [ 7776.50754257],\n",
       "       [ 7761.75878408],\n",
       "       [ 8773.10648796],\n",
       "       [ 8767.67262337],\n",
       "       [ 8853.77448401],\n",
       "       [ 8963.0575578 ],\n",
       "       [ 8904.71381654],\n",
       "       [ 8887.50589259],\n",
       "       [ 8978.28358712],\n",
       "       [ 9371.68427279],\n",
       "       [ 9900.67886662],\n",
       "       [ 9917.24841434],\n",
       "       [ 9617.51819493],\n",
       "       [ 8786.65518165],\n",
       "       [ 8608.12524504],\n",
       "       [ 8815.2312449 ],\n",
       "       [ 9330.9864847 ],\n",
       "       [ 9757.29658559],\n",
       "       [ 9362.63555697],\n",
       "       [ 9418.91855051],\n",
       "       [ 9684.70195935],\n",
       "       [ 9723.68015045],\n",
       "       [ 9719.48085448],\n",
       "       [ 9540.88656658],\n",
       "       [ 9141.15063742],\n",
       "       [ 9192.84513581],\n",
       "       [ 9220.07588747],\n",
       "       [ 9048.71511916],\n",
       "       [ 8905.78160454],\n",
       "       [ 8835.72722404],\n",
       "       [ 9112.97917559],\n",
       "       [ 9507.52466466],\n",
       "       [ 9425.28186919],\n",
       "       [ 9688.32439037],\n",
       "       [ 9427.67008414],\n",
       "       [10268.58198473],\n",
       "       [ 9516.13544309],\n",
       "       [ 9667.06075426],\n",
       "       [ 9811.3670946 ],\n",
       "       [ 9659.66129819],\n",
       "       [ 9677.05099451],\n",
       "       [ 9737.45855879],\n",
       "       [ 9791.92789977],\n",
       "       [ 9786.14202048],\n",
       "       [ 9874.96704752],\n",
       "       [ 9260.83264099],\n",
       "       [ 9464.22809682],\n",
       "       [ 9458.6597544 ],\n",
       "       [ 9351.95372801],\n",
       "       [ 9441.76899555],\n",
       "       [ 9510.66063729],\n",
       "       [ 9457.62707441],\n",
       "       [ 9398.64209362],\n",
       "       [ 9279.76076517],\n",
       "       [ 9353.07819619],\n",
       "       [ 9289.10449144],\n",
       "       [ 9680.9471279 ],\n",
       "       [ 9609.68024553],\n",
       "       [ 9311.13631832],\n",
       "       [ 9252.63337177],\n",
       "       [ 9171.73208577],\n",
       "       [ 9022.153768  ],\n",
       "       [ 9101.85005736],\n",
       "       [ 9188.06137546],\n",
       "       [ 9148.44485856],\n",
       "       [ 9236.31677043],\n",
       "       [ 9097.79736639],\n",
       "       [ 9094.32456102],\n",
       "       [ 9124.6535344 ],\n",
       "       [ 9055.46448252],\n",
       "       [ 9278.80563704],\n",
       "       [ 9244.41581454],\n",
       "       [ 9471.75997342],\n",
       "       [ 9236.14325371],\n",
       "       [ 9243.17525915],\n",
       "       [ 9229.85975494],\n",
       "       [ 9286.73704209],\n",
       "       [ 9238.99375486],\n",
       "       [ 9260.47098018],\n",
       "       [ 9211.02643289],\n",
       "       [ 9133.77783034],\n",
       "       [ 9160.41059149],\n",
       "       [ 9176.6863901 ],\n",
       "       [ 9190.2715342 ],\n",
       "       [ 9172.58833257],\n",
       "       [ 9395.06444588],\n",
       "       [ 9530.79088535],\n",
       "       [ 9617.37786138],\n",
       "       [ 9568.97472596],\n",
       "       [ 9708.9491401 ],\n",
       "       [ 9938.95122286],\n",
       "       [11187.77972696],\n",
       "       [10939.67014155],\n",
       "       [11284.45898685],\n",
       "       [11118.91841243],\n",
       "       [11373.31725664],\n",
       "       [11766.74829709],\n",
       "       [11139.09838035],\n",
       "       [11261.80633174],\n",
       "       [11228.02632402],\n",
       "       [11653.40758556],\n",
       "       [11796.81736499],\n",
       "       [11639.93541013],\n",
       "       [11744.9120755 ],\n",
       "       [11673.12323754],\n",
       "       [11832.22730813],\n",
       "       [11340.58234064],\n",
       "       [11549.54631437],\n",
       "       [11752.16865623],\n",
       "       [11783.28341126],\n",
       "       [11895.62694989],\n",
       "       [11896.94717019],\n",
       "       [12399.11188466],\n",
       "       [12071.73890908],\n",
       "       [11749.82950876],\n",
       "       [11833.8973487 ],\n",
       "       [11583.13894263],\n",
       "       [11674.62435391],\n",
       "       [11666.41012224],\n",
       "       [11744.01269665],\n",
       "       [11378.72602981],\n",
       "       [11458.82259649],\n",
       "       [11302.1209645 ],\n",
       "       [11482.22568651],\n",
       "       [11515.04443069],\n",
       "       [11657.00393423],\n",
       "       [11678.37325542],\n",
       "       [11964.20867246],\n",
       "       [11427.70260497],\n",
       "       [10712.92064607],\n",
       "       [10563.89693862],\n",
       "       [10042.85485437],\n",
       "       [10207.60500296],\n",
       "       [10381.77610693],\n",
       "       [10043.19644129],\n",
       "       [10268.46091575],\n",
       "       [10341.01598385],\n",
       "       [10380.53959723],\n",
       "       [10436.36540836],\n",
       "       [10313.06857949],\n",
       "       [10680.29756117],\n",
       "       [10829.5053072 ],\n",
       "       [11033.38352648],\n",
       "       [10937.1112591 ],\n",
       "       [10933.9311624 ],\n",
       "       [11048.87927816],\n",
       "       [10852.91013894],\n",
       "       [10526.2028872 ],\n",
       "       [10531.16456263],\n",
       "       [10260.03301241],\n",
       "       [10672.95680806],\n",
       "       [10729.06960742],\n",
       "       [10741.47646752],\n",
       "       [10752.34544975],\n",
       "       [10863.06572391],\n",
       "       [10764.28437072],\n",
       "       [10741.5795495 ],\n",
       "       [10626.6009565 ],\n",
       "       [10567.33019523],\n",
       "       [10555.02867878],\n",
       "       [10660.61118264],\n",
       "       [10756.40458492],\n",
       "       [10589.62639353],\n",
       "       [10645.75478678],\n",
       "       [10897.59543151],\n",
       "       [11052.39508367],\n",
       "       [11360.85271687],\n",
       "       [11334.02674203],\n",
       "       [11666.21170032],\n",
       "       [11443.73279182],\n",
       "       [11395.54736637],\n",
       "       [11504.54900671],\n",
       "       [11355.16043945],\n",
       "       [11358.70637963],\n",
       "       [11471.00254779],\n",
       "       [11776.59299733],\n",
       "       [11936.36291334],\n",
       "       [13102.93446155],\n",
       "       [13140.66928406],\n",
       "       [12933.82356549],\n",
       "       [13081.67255949],\n",
       "       [13008.45325775],\n",
       "       [13033.52427008],\n",
       "       [13721.28222485],\n",
       "       [13282.26034792],\n",
       "       [13467.73178281],\n",
       "       [13573.71050315],\n",
       "       [13891.21683316],\n",
       "       [13730.19731094],\n",
       "       [13633.69821689],\n",
       "       [13832.93840977],\n",
       "       [14163.9768155 ],\n",
       "       [15424.52767669],\n",
       "       [15540.59659081],\n",
       "       [14783.98167853],\n",
       "       [15500.33425474],\n",
       "       [15283.78013873],\n",
       "       [15374.04438576],\n",
       "       [15820.49524108],\n",
       "       [16253.31027194],\n",
       "       [16347.04492035],\n",
       "       [15991.8330244 ],\n",
       "       [15918.08012811],\n",
       "       [16752.00298996],\n",
       "       [17593.48641493],\n",
       "       [17834.63653371],\n",
       "       [17954.8580091 ],\n",
       "       [18612.87067218],\n",
       "       [18591.85660475],\n",
       "       [18629.99553726],\n",
       "       [18469.20046948],\n",
       "       [19045.73646565],\n",
       "       [18746.9348067 ],\n",
       "       [17187.40627633],\n",
       "       [17023.96140009],\n",
       "       [17814.78027844],\n",
       "       [18114.41434928],\n",
       "       [19382.36058587],\n",
       "       [18980.97745012],\n",
       "       [19184.89784774],\n",
       "       [19464.53170456],\n",
       "       [18813.12476029],\n",
       "       [19045.0202726 ],\n",
       "       [19113.93339509],\n",
       "       [19107.59979531],\n",
       "       [18682.45783321],\n",
       "       [18543.00704922],\n",
       "       [18359.47660034],\n",
       "       [18137.31937461],\n",
       "       [18882.26017106],\n",
       "       [19060.27690128],\n",
       "       [19251.22400471],\n",
       "       [19443.47635283],\n",
       "       [21310.65626223],\n",
       "       [22895.97623755],\n",
       "       [23008.77625674],\n",
       "       [23890.82264887],\n",
       "       [23537.36989089],\n",
       "       [23177.27099799],\n",
       "       [23433.98075814],\n",
       "       [23224.45413785],\n",
       "       [23623.88553323],\n",
       "       [24581.00617127],\n",
       "       [26381.29623292],\n",
       "       [26389.29026494],\n",
       "       [26718.0294634 ],\n",
       "       [26975.72956452],\n",
       "       [28768.83620753],\n",
       "       [29111.52156712],\n",
       "       [29333.60512062],\n",
       "       [32154.16736327],\n",
       "       [33002.53642704],\n",
       "       [31431.61227972],\n",
       "       [34433.60651384],\n",
       "       [36275.75634767],\n",
       "       [39713.50785672],\n",
       "       [40519.44859753],\n",
       "       [40258.92398866],\n",
       "       [38709.76537488],\n",
       "       [34409.64237522],\n",
       "       [34214.61026205],\n",
       "       [37017.00750345],\n",
       "       [38435.86351466],\n",
       "       [36751.58497369],\n",
       "       [36016.77960594],\n",
       "       [36375.81137926],\n",
       "       [36346.60950223],\n",
       "       [36577.51964639],\n",
       "       [35004.53262688],\n",
       "       [30606.18267565],\n",
       "       [33368.36593189],\n",
       "       [32070.0974252 ],\n",
       "       [32285.72613244],\n",
       "       [32500.25596269],\n",
       "       [32324.55565073],\n",
       "       [30534.99937302],\n",
       "       [33408.21833739],\n",
       "       [34842.55739312],\n",
       "       [34622.37323153],\n",
       "       [33087.36986452],\n",
       "       [33613.32076431],\n",
       "       [35632.90195152],\n",
       "       [37397.42636409],\n",
       "       [37256.25211087],\n",
       "       [37851.59659008],\n",
       "       [40302.79979284],\n",
       "       [38461.6814033 ],\n",
       "       [44716.68546906],\n",
       "       [46674.85168811],\n",
       "       [45237.47568925],\n",
       "       [47500.8975242 ],\n",
       "       [47884.1828623 ],\n",
       "       [47005.1906489 ],\n",
       "       [49151.16757632],\n",
       "       [48125.99219541],\n",
       "       [48840.41447458],\n",
       "       [52165.30255522],\n",
       "       [51728.50879673],\n",
       "       [55719.2043617 ],\n",
       "       [54801.64864399],\n",
       "       [57128.64260647],\n",
       "       [54181.91464919],\n",
       "       [48172.87747693],\n",
       "       [48745.43298434],\n",
       "       [48291.41208335],\n",
       "       [45752.11491941],\n",
       "       [46642.60607658],\n",
       "       [45092.8065726 ],\n",
       "       [49248.91401331],\n",
       "       [47900.77687833],\n",
       "       [50811.85517444],\n",
       "       [48259.48707666],\n",
       "       [49149.73082884],\n",
       "       [48879.15190416],\n",
       "       [50594.69857451],\n",
       "       [51503.25813218],\n",
       "       [54458.03781142],\n",
       "       [56915.17393505],\n",
       "       [57636.75796197],\n",
       "       [57306.16626299],\n",
       "       [60743.04182491],\n",
       "       [60197.9019918 ],\n",
       "       [56300.33410863],\n",
       "       [56639.78394967],\n",
       "       [58567.28378106],\n",
       "       [57983.09474357],\n",
       "       [58451.73146595],\n",
       "       [58593.60245406],\n",
       "       [57796.46737122],\n",
       "       [54329.35863463],\n",
       "       [54794.29771371],\n",
       "       [52787.74552575],\n",
       "       [52173.86798025],\n",
       "       [54483.0457323 ],\n",
       "       [56234.356105  ],\n",
       "       [55343.92581533],\n",
       "       [57627.6792491 ],\n",
       "       [58734.47543372],\n",
       "       [58724.66451663],\n",
       "       [58984.61292993],\n",
       "       [58821.62699444],\n",
       "       [57517.79877314],\n",
       "       [58177.40276373],\n",
       "       [58843.55954021],\n",
       "       [58040.18760188],\n",
       "       [56508.94286388],\n",
       "       [57880.90568386],\n",
       "       [58171.9090187 ],\n",
       "       [59295.95004401],\n",
       "       [59822.90167743],\n",
       "       [59853.19724227],\n",
       "       [63223.88439079],\n",
       "       [62926.5571759 ],\n",
       "       [63346.78903511],\n",
       "       [61965.7825981 ],\n",
       "       [60574.44472823],\n",
       "       [56850.83016569],\n",
       "       [56224.10158771],\n",
       "       [56608.76974839],\n",
       "       [54144.42747606],\n",
       "       [51965.05955941],\n",
       "       [50669.14438218],\n",
       "       [50733.76950364],\n",
       "       [48542.95220298],\n",
       "       [53558.70784462],\n",
       "       [55123.86198142],\n",
       "       [54591.51532554],\n",
       "       [53260.29534115],\n",
       "       [57302.64642408],\n",
       "       [57677.9752219 ],\n",
       "       [56427.04312502],\n",
       "       [57255.30683756],\n",
       "       [53658.84312082],\n",
       "       [57252.7021845 ],\n",
       "       [56583.84987917],\n",
       "       [57107.12067189],\n",
       "       [58788.20967893],\n",
       "       [58102.19142623],\n",
       "       [55715.54665129],\n",
       "       [56573.5554719 ],\n",
       "       [52147.82118698],\n",
       "       [49764.1320816 ],\n",
       "       [50032.69313676],\n",
       "       [47885.62525472],\n",
       "       [45604.61575361],\n",
       "       [43144.47129086]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "242098ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([552]), TensorShape([552, 7]))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.squeeze(test_labels).shape,model_3_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "bed9fdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(552,), dtype=float32, numpy=\n",
       "array([ 8906.611 ,  8920.089 ,  8770.143 ,  8583.995 ,  8537.974 ,\n",
       "        8434.936 ,  8199.192 ,  8081.566 ,  8128.383 ,  7826.5317,\n",
       "        7499.0347,  7352.9185,  7149.521 ,  7130.7085,  7082.8135,\n",
       "        7389.404 ,  7452.954 ,  7631.203 ,  7642.2383,  7525.53  ,\n",
       "        7450.255 ,  7330.9907,  7329.307 ,  7358.472 ,  7475.172 ,\n",
       "        7522.723 ,  7562.228 ,  7379.5312,  7260.5264,  7227.046 ,\n",
       "        7225.546 ,  7268.371 ,  7209.7334,  7224.288 ,  6985.2476,\n",
       "        6799.685 ,  7108.8257,  7161.804 ,  7104.893 ,  7269.7925,\n",
       "        7247.487 ,  7265.8975,  7280.435 ,  7314.1694,  7207.9443,\n",
       "        7216.0146,  7294.173 ,  7359.9644,  7296.297 ,  7225.9106,\n",
       "        7193.366 ,  7095.0757,  7174.263 ,  7299.56  ,  7441.202 ,\n",
       "        7614.011 ,  7945.712 ,  8082.2495,  7985.0083,  7998.676 ,\n",
       "        8118.4995,  8127.9497,  8165.2085,  8601.82  ,  8815.299 ,\n",
       "        8795.586 ,  8914.452 ,  8949.427 ,  8736.757 ,  8658.638 ,\n",
       "        8774.973 ,  8688.226 ,  8502.89  ,  8510.435 ,  8487.981 ,\n",
       "        8455.881 ,  8711.744 ,  9030.56  ,  9242.265 ,  9475.533 ,\n",
       "        9462.6455,  9551.291 ,  9472.273 ,  9372.511 ,  9246.657 ,\n",
       "        9519.446 ,  9589.51  ,  9727.636 ,  9897.377 , 10059.467 ,\n",
       "        9930.192 , 10175.893 , 10348.503 , 10345.132 , 10427.154 ,\n",
       "       10180.483 , 10005.435 ,  9773.529 , 10002.163 ,  9766.861 ,\n",
       "        9642.547 ,  9630.5625,  9652.072 ,  9922.904 ,  9776.143 ,\n",
       "        9567.154 ,  9048.308 ,  8907.351 ,  8746.153 ,  8737.515 ,\n",
       "        8551.384 ,  8793.494 ,  8794.746 ,  8796.005 ,  8953.601 ,\n",
       "        9083.268 ,  9098.323 ,  8419.826 ,  8172.587 ,  7967.882 ,\n",
       "        8037.8784,  6544.223 ,  5985.3257,  5556.7803,  5413.281 ,\n",
       "        5333.726 ,  5580.153 ,  5591.999 ,  6039.204 ,  6445.184 ,\n",
       "        6379.1846,  6120.7417,  6374.9365,  6819.6885,  6782.6753,\n",
       "        6765.4487,  6645.4297,  6471.388 ,  6080.241 ,  6081.4263,\n",
       "        6228.114 ,  6341.6016,  6681.0547,  6521.8213,  6864.718 ,\n",
       "        6775.155 ,  7423.297 ,  7198.9766,  7327.102 ,  7243.938 ,\n",
       "        7167.728 ,  6891.5107,  6988.768 ,  6890.0894,  6916.6304,\n",
       "        6715.204 ,  6962.3306,  7102.8237,  7230.4956,  7284.2007,\n",
       "        7048.2925,  7011.522 ,  7052.9185,  7444.106 ,  7514.6606,\n",
       "        7513.153 ,  7681.5415,  7728.858 ,  7754.241 ,  8418.901 ,\n",
       "        8745.2   ,  8868.672 ,  9005.99  ,  9050.701 ,  9040.868 ,\n",
       "        8971.445 ,  9331.635 ,  9661.721 ,  9940.367 ,  9777.799 ,\n",
       "        9192.642 ,  8774.792 ,  8762.401 ,  9160.541 ,  9602.474 ,\n",
       "        9476.976 ,  9425.899 ,  9728.5205,  9743.735 ,  9765.772 ,\n",
       "        9588.42  ,  9345.415 ,  9156.526 ,  9272.46  ,  9171.768 ,\n",
       "        9006.127 ,  8901.5205,  8979.277 ,  9231.544 ,  9387.368 ,\n",
       "        9583.701 ,  9608.654 , 10139.721 ,  9845.333 ,  9806.948 ,\n",
       "        9862.851 ,  9703.505 ,  9633.281 ,  9697.486 ,  9762.467 ,\n",
       "        9755.702 ,  9885.825 ,  9472.352 ,  9441.167 ,  9476.861 ,\n",
       "        9488.187 ,  9492.464 ,  9556.038 ,  9482.899 ,  9432.692 ,\n",
       "        9466.187 ,  9233.444 ,  9315.462 ,  9513.202 ,  9719.869 ,\n",
       "        9377.891 ,  9411.081 ,  9218.589 ,  9136.134 ,  9125.909 ,\n",
       "        9083.201 ,  9172.086 ,  9224.147 ,  9190.831 ,  9122.186 ,\n",
       "        9193.399 ,  9105.091 ,  9242.936 ,  9274.278 ,  9421.748 ,\n",
       "        9332.023 ,  9361.047 ,  9269.026 ,  9274.966 ,  9252.655 ,\n",
       "        9282.962 ,  9212.028 ,  9185.756 ,  9213.899 ,  9217.686 ,\n",
       "        9246.124 ,  9187.487 ,  9347.001 ,  9483.9795,  9621.9795,\n",
       "        9620.585 ,  9732.953 ,  9929.537 , 10767.467 , 11007.239 ,\n",
       "       11241.873 , 11265.342 , 11353.53  , 11720.911 , 11383.884 ,\n",
       "       11345.261 , 11225.859 , 11562.232 , 11750.867 , 11719.189 ,\n",
       "       11752.547 , 11693.209 , 11824.311 , 11556.413 , 11533.683 ,\n",
       "       11718.518 , 11918.841 , 11902.829 , 11987.525 , 12175.912 ,\n",
       "       12220.279 , 11845.717 , 11824.798 , 11606.58  , 11694.523 ,\n",
       "       11810.981 , 11750.585 , 11546.248 , 11430.753 , 11431.391 ,\n",
       "       11441.171 , 11393.5205, 11640.313 , 11714.271 , 11994.002 ,\n",
       "       11647.364 , 11084.808 , 10775.618 , 10200.513 , 10141.65  ,\n",
       "       10236.603 , 10149.408 , 10156.249 , 10327.161 , 10432.835 ,\n",
       "       10404.683 , 10437.873 , 10592.408 , 10840.065 , 11062.239 ,\n",
       "       11095.944 , 11006.141 , 11143.651 , 10861.951 , 10596.556 ,\n",
       "       10496.328 , 10293.764 , 10566.259 , 10756.937 , 10811.7705,\n",
       "       10821.683 , 10933.76  , 10862.47  , 10747.493 , 10720.482 ,\n",
       "       10629.585 , 10638.453 , 10712.107 , 10723.489 , 10664.242 ,\n",
       "       10649.271 , 10788.901 , 10945.88  , 11249.276 , 11357.143 ,\n",
       "       11674.187 , 11598.029 , 11546.989 , 11542.366 , 11497.971 ,\n",
       "       11358.011 , 11434.548 , 11665.732 , 11859.287 , 12716.701 ,\n",
       "       13125.344 , 13075.49  , 13121.288 , 13140.563 , 13137.92  ,\n",
       "       13585.844 , 13487.132 , 13474.179 , 13615.781 , 13799.087 ,\n",
       "       13776.143 , 13617.836 , 13793.884 , 13989.814 , 15091.954 ,\n",
       "       15535.703 , 15166.925 , 15562.022 , 15423.292 , 15411.8125,\n",
       "       15684.969 , 16111.5625, 16259.071 , 16211.448 , 16079.089 ,\n",
       "       16527.205 , 17284.986 , 17831.592 , 17908.645 , 18514.246 ,\n",
       "       18670.818 , 18819.92  , 18839.309 , 18946.762 , 18766.84  ,\n",
       "       17847.338 , 17279.025 , 17487.545 , 17855.297 , 18976.557 ,\n",
       "       19065.182 , 19208.746 , 19347.021 , 19201.621 , 19284.22  ,\n",
       "       19134.223 , 19205.598 , 18986.697 , 18765.607 , 18438.229 ,\n",
       "       18033.613 , 18648.799 , 18886.607 , 18993.902 , 19336.982 ,\n",
       "       20871.848 , 22470.527 , 23189.125 , 23860.848 , 23981.098 ,\n",
       "       23563.104 , 23545.725 , 23297.635 , 23555.941 , 24300.607 ,\n",
       "       25833.5   , 26540.887 , 26747.693 , 27010.17  , 28307.11  ,\n",
       "       29085.434 , 29521.012 , 31570.057 , 33200.625 , 32548.771 ,\n",
       "       34100.05  , 35968.29  , 38803.883 , 40516.15  , 41069.54  ,\n",
       "       39870.945 , 36014.87  , 34694.46  , 35734.21  , 37207.676 ,\n",
       "       36874.883 , 36383.633 , 36294.41  , 35705.145 , 35891.184 ,\n",
       "       35482.605 , 32151.576 , 32637.014 , 32744.775 , 32813.805 ,\n",
       "       32790.086 , 32158.373 , 31142.734 , 31983.986 , 33796.637 ,\n",
       "       33977.473 , 33831.55  , 34226.8   , 35332.08  , 37204.32  ,\n",
       "       37791.68  , 37771.54  , 39509.133 , 38647.688 , 42710.96  ,\n",
       "       46157.81  , 46006.25  , 47366.777 , 47682.242 , 48359.785 ,\n",
       "       48533.492 , 49254.664 , 49020.8   , 51236.438 , 51818.492 ,\n",
       "       55168.637 , 55072.3   , 56990.45  , 54645.562 , 50663.125 ,\n",
       "       49006.863 , 47421.973 , 46814.49  , 46063.57  , 45423.805 ,\n",
       "       47581.074 , 48012.332 , 49445.78  , 48948.98  , 48703.91  ,\n",
       "       49284.707 , 50831.742 , 52078.348 , 53841.652 , 56260.992 ,\n",
       "       58048.492 , 57230.105 , 59330.723 , 60083.008 , 57844.617 ,\n",
       "       57014.996 , 58206.633 , 58820.723 , 59053.957 , 59065.65  ,\n",
       "       58463.207 , 54717.418 , 55304.223 , 53072.78  , 52715.16  ,\n",
       "       53360.945 , 56216.59  , 56147.57  , 57310.883 , 58274.715 ,\n",
       "       59095.312 , 58835.945 , 58455.805 , 58011.137 , 58578.465 ,\n",
       "       59005.137 , 58555.5   , 57472.043 , 57560.652 , 57664.29  ,\n",
       "       58840.543 , 59190.973 , 59875.355 , 62624.27  , 63751.742 ,\n",
       "       63767.98  , 63283.535 , 61692.527 , 58308.383 , 56643.914 ,\n",
       "       56538.156 , 54340.652 , 52680.438 , 51299.312 , 50574.125 ,\n",
       "       48863.688 , 52205.785 , 54312.22  , 55000.355 , 54044.836 ,\n",
       "       56850.348 , 58140.434 , 57275.76  , 57503.992 , 54823.402 ,\n",
       "       56395.445 , 55938.965 , 57255.133 , 58013.957 , 58145.145 ,\n",
       "       56515.52  , 56922.895 , 54101.56  , 50696.863 , 50744.555 ,\n",
       "       49159.184 , 46766.758 ], dtype=float32)>"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(model_3_preds,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1ad3b265",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3_results =evaluate_preds(tf.squeeze(test_labels),tf.reduce_mean(model_3_preds,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d3c9dd30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 608.67633,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.788347,\n",
       " 'MASE': 1.0639722}"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8c684a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 3ms/step - loss: 626.5261 - mae: 626.5261 - mse: 1346312.7500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[626.5260620117188, 626.5260620117188, 1346312.75]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757ee438",
   "metadata": {},
   "source": [
    "### Make our evaluation function work for larger horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "99487150",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (Temp/ipykernel_12608/1110568225.py, line 19)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GEORGE\\AppData\\Local\\Temp/ipykernel_12608/1110568225.py\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    return metric\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "def evaluate_preds(y_true,y_pred):\n",
    "    y_true = tf.cast(y_true,tf.float32)\n",
    "    y_pred = tf.cast(y_pred,tf.float32)\n",
    "    metric = {}\n",
    "    mae = tf.reduce_mean(tf.abs(y_true-y_pred))\n",
    "    mae_naive_no_season = tf.reduce_mean(tf.abs(y_true[1:]-y_true[:-1]))\n",
    "    \n",
    "    mse = mean_squared_error(y_test[1:],naive_forecast)\n",
    "    rmse=np.sqrt(mean_squared_error(y_test[1:],naive_forecast))\n",
    "\n",
    "    metric[\"MAE\"] = mae.numpy()\n",
    "    metric[\"MSE\"] = mse\n",
    "    metric[\"RMSE\"] = rmse\n",
    "    metric[\"MAPE\"] = tf.keras.metrics.mean_absolute_percentage_error(y_true,y_pred).numpy()\n",
    "    metric[\"MASE\"] = (mae / mae_naive_no_season).numpy()\n",
    "    \n",
    "    if mae.ndim>0:\n",
    "        \n",
    "    return metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35c977",
   "metadata": {},
   "source": [
    "## which of our models is performing the best so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "472d0e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {\"naive\":naive_results,\"horizon_1_window7\":model_1_results,\n",
    "     \"horizon_1_window30\":model_2_results,\"horizon_7_window_3-\":model_3_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "56dae14b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>naive</th>\n",
       "      <th>horizon_1_window7</th>\n",
       "      <th>horizon_1_window30</th>\n",
       "      <th>horizon_7_window_3-</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MAE</th>\n",
       "      <td>5.679802e+02</td>\n",
       "      <td>5.689511e+02</td>\n",
       "      <td>6.058741e+02</td>\n",
       "      <td>6.086763e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSE</th>\n",
       "      <td>1.147547e+06</td>\n",
       "      <td>1.147547e+06</td>\n",
       "      <td>1.147547e+06</td>\n",
       "      <td>1.147547e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMSE</th>\n",
       "      <td>1.071236e+03</td>\n",
       "      <td>1.071236e+03</td>\n",
       "      <td>1.071236e+03</td>\n",
       "      <td>1.071236e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MAPE</th>\n",
       "      <td>2.516525e+00</td>\n",
       "      <td>2.544898e+00</td>\n",
       "      <td>2.726445e+00</td>\n",
       "      <td>2.788347e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MASE</th>\n",
       "      <td>9.995700e-01</td>\n",
       "      <td>9.994895e-01</td>\n",
       "      <td>1.059074e+00</td>\n",
       "      <td>1.063972e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             naive  horizon_1_window7  horizon_1_window30  horizon_7_window_3-\n",
       "MAE   5.679802e+02       5.689511e+02        6.058741e+02         6.086763e+02\n",
       "MSE   1.147547e+06       1.147547e+06        1.147547e+06         1.147547e+06\n",
       "RMSE  1.071236e+03       1.071236e+03        1.071236e+03         1.071236e+03\n",
       "MAPE  2.516525e+00       2.544898e+00        2.726445e+00         2.788347e+00\n",
       "MASE  9.995700e-01       9.994895e-01        1.059074e+00         1.063972e+00"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3bc5c4fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(df,index=['MAE']).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c31434ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 567.9802,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.516525,\n",
       " 'MASE': 0.99957}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a742b57",
   "metadata": {},
   "source": [
    "## Model 4 Conv1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "0207d20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1\n",
    "WINDOW_SIZE =7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cce788fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create windowed data\n",
    "full_windows,full_labels = make_windows(prices,window_size=WINDOW_SIZE,horizon=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "67017e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buat_windows(prices,window_size=WINDOW_SIZE,horizon=HORIZON):\n",
    "    window_sized = np.arange(window_size+horizon)\n",
    "    index_window = window_sized+np.arange(len(prices)-(window_size+horizon-1)).reshape(-1,1)\n",
    "    window_fix = prices[index_window]\n",
    "    window,label = window_fix[:,:window_size],window_fix[:,-horizon:]\n",
    "    return window,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "033ed8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=buat_windows(prices,window_size=WINDOW_SIZE,horizon=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5cf9a54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 556)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows,test_windows,train_labels,test_labels = make_train_test_splits(full_windows,full_labels)\n",
    "len(train_windows),len(test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "0c28887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to use conv1D : batch_size,timesteps,input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f346c7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7,)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_windows[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b64b0e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(train_windows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ccae8925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "14eb4187",
   "metadata": {},
   "outputs": [],
   "source": [
    "expand_dims_layer = layers.Lambda(lambda x: tf.expand_dims(x,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "30a0361f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=float64, numpy=\n",
       "array([123.65499, 125.455  , 108.58483, 118.67466, 121.33866, 120.65533,\n",
       "       121.795  ])>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8894bdad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7, 1), dtype=float32, numpy=\n",
       "array([[123.65499],\n",
       "       [125.455  ],\n",
       "       [108.58483],\n",
       "       [118.67466],\n",
       "       [121.33866],\n",
       "       [120.65533],\n",
       "       [121.795  ]], dtype=float32)>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expand_dims_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f2b2ff64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4 = Sequential(name='model_4Conv1D')\n",
    "model_4.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "model_4.add(layers.Conv1D(128,activation='relu',padding='causal',kernel_size=5,strides=1))\n",
    "model_4.add(layers.Dense(HORIZON))\n",
    "\n",
    "model_4.compile(loss='mae',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "8dab6d77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 2373.9048 INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 3s 36ms/step - loss: 2373.9048 - val_loss: 5913.6226\n",
      "Epoch 2/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 698.1063INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 391.7078 - val_loss: 1261.0900\n",
      "Epoch 3/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 167.5612INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 209.3953 - val_loss: 1074.7179\n",
      "Epoch 4/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 261.7132INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 194.7531 - val_loss: 1041.6313\n",
      "Epoch 5/100\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 194.3428INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 185.0958 - val_loss: 1031.7551\n",
      "Epoch 6/100\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 182.0190INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 184.2087 - val_loss: 1029.3267\n",
      "Epoch 7/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 194.0139INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 182.3945 - val_loss: 1001.5028\n",
      "Epoch 8/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 174.6729INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 177.2024 - val_loss: 1000.5951\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 174.5581 - val_loss: 1003.6070\n",
      "Epoch 10/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 167.5150INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 172.2355 - val_loss: 967.9227\n",
      "Epoch 11/100\n",
      "10/18 [===============>..............] - ETA: 0s - loss: 169.4239INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 169.5968 - val_loss: 943.2490\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 170.5143 - val_loss: 947.7239\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 165.8917 - val_loss: 996.2909\n",
      "Epoch 14/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 156.9153INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 162.8355 - val_loss: 916.5764\n",
      "Epoch 15/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 160.4433INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 163.2397 - val_loss: 899.6814\n",
      "Epoch 16/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 155.1955INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 156.4074 - val_loss: 878.8237\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 153.3354 - val_loss: 917.7924\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 151.7694 - val_loss: 890.9282\n",
      "Epoch 19/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 154.7496INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 148.3685 - val_loss: 843.8820\n",
      "Epoch 20/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 146.8828INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 146.1417 - val_loss: 815.4083\n",
      "Epoch 21/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 144.3849INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 144.6934 - val_loss: 796.6483\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 141.3039 - val_loss: 798.3596\n",
      "Epoch 23/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 136.3727INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 138.5618 - val_loss: 793.4435\n",
      "Epoch 24/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 137.0783INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 138.5321 - val_loss: 772.8486\n",
      "Epoch 25/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 140.2998INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 135.3021 - val_loss: 748.7429\n",
      "Epoch 26/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 129.0195INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 132.5627 - val_loss: 732.8300\n",
      "Epoch 27/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 136.3689INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 132.0758 - val_loss: 719.5884\n",
      "Epoch 28/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 125.9873INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 128.6346 - val_loss: 708.2429\n",
      "Epoch 29/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 128.7273INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 127.8978 - val_loss: 697.6255\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 127.0851 - val_loss: 744.8641\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 132.0231 - val_loss: 822.4292\n",
      "Epoch 32/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 133.6198INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 133.9084 - val_loss: 682.4522\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 130.7890 - val_loss: 684.8889\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 122.3547INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 122.3547 - val_loss: 662.3096\n",
      "Epoch 35/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 123.4689INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 121.0187 - val_loss: 659.4155\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.4132 - val_loss: 714.9786\n",
      "Epoch 37/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 123.0394INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 120.9136 - val_loss: 642.6025\n",
      "Epoch 38/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 119.2810INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 118.4120 - val_loss: 638.4052\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 117.6049 - val_loss: 648.5795\n",
      "Epoch 40/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 112.2812INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 116.0143 - val_loss: 631.4584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 118.9783INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 116.9355 - val_loss: 623.6300\n",
      "Epoch 42/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 118.4545INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 119.0874 - val_loss: 619.0330\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.8294 - val_loss: 627.2701\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.1608 - val_loss: 634.6339\n",
      "Epoch 45/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 116.0696INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 116.9051 - val_loss: 611.1183\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.7334 - val_loss: 626.7640\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.4477 - val_loss: 707.7922\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 117.2898 - val_loss: 679.0837\n",
      "Epoch 49/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 117.7496INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 117.0481 - val_loss: 600.6093\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.4487 - val_loss: 605.8607\n",
      "Epoch 51/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 113.4597INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 112.9928 - val_loss: 597.2398\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.4319 - val_loss: 626.6485\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.3752 - val_loss: 618.8570\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.6799 - val_loss: 685.5676\n",
      "Epoch 55/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 117.6964INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 114.3888 - val_loss: 592.7709\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.0599 - val_loss: 772.0572\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 131.3105 - val_loss: 634.1644\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.9932 - val_loss: 622.6703\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 110.4792INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 110.4792 - val_loss: 589.8719\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.6209 - val_loss: 601.0742\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.3178 - val_loss: 597.4731\n",
      "Epoch 62/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 110.5080INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 110.2184 - val_loss: 586.1464\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.7868 - val_loss: 586.4508\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.1068 - val_loss: 637.1649\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 112.3310INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 112.3310 - val_loss: 582.4491\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.2738 - val_loss: 594.2973\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.6237 - val_loss: 606.3218\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 114.9453 - val_loss: 679.5665\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 123.2751 - val_loss: 693.2647\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 122.0995 - val_loss: 634.3417\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.6157 - val_loss: 624.2563\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.6548 - val_loss: 583.9187\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 108.1029INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 108.1029 - val_loss: 580.1818\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 109.4704INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 109.4704 - val_loss: 577.4161\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.5212 - val_loss: 595.5109\n",
      "Epoch 76/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 79.7593INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 109.9715 - val_loss: 574.1191\n",
      "Epoch 77/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 113.0533INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 110.2664 - val_loss: 573.6545\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.8185 - val_loss: 587.3452\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.3145 - val_loss: 590.2826\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.8420 - val_loss: 579.6203\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.5840 - val_loss: 613.7510\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 118.4723 - val_loss: 631.5334\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.0759 - val_loss: 668.1487\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.0277 - val_loss: 573.9379\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 107.4798 - val_loss: 581.9024\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.1668 - val_loss: 623.4380\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 109.4286INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 109.4286 - val_loss: 571.2811\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.8239 - val_loss: 592.7592\n",
      "Epoch 89/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 105.0470INFO:tensorflow:Assets written to: model_experiment\\model_4Conv1D\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 110.6100 - val_loss: 569.7347\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.6668 - val_loss: 619.2398\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.1797 - val_loss: 616.8679\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.6112 - val_loss: 572.0049\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.0264 - val_loss: 620.9109\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.4091 - val_loss: 580.8029\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.4353 - val_loss: 571.5100\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.2167 - val_loss: 583.4259\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.7407 - val_loss: 589.2702\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 108.7158 - val_loss: 571.4984\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 108.6431 - val_loss: 571.2127\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.1723 - val_loss: 632.1910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21a723879a0>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.fit(train_windows,\n",
    "           train_labels,\n",
    "           batch_size=128,\n",
    "           epochs=100,\n",
    "           validation_data=(test_windows,test_labels),\n",
    "           callbacks=[create_model_checkpoint(model_4.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a3430c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9d65256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 7ms/step - loss: 632.1910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "632.1909790039062"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e9387f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "087ea285",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = layers.Input(shape=(7))\n",
    "x = layers.Lambda(lambda x: tf.expand_dims(x,axis=1))(inputs)\n",
    "x = layers.Conv1D(128,activation='relu',padding='causal',kernel_size=5,strides=1)(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model_try = Model(inputs,outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "27b251fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_try.compile(loss='mae',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "7a1a2953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 7)]               0         \n",
      "                                                                 \n",
      " lambda_2 (Lambda)           (None, 1, 7)              0         \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 1, 128)            4608      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1, 1)              129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,737\n",
      "Trainable params: 4,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_try.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7e0ec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_try.fit(train_windows,\n",
    "           train_labels,\n",
    "           batch_size=128,\n",
    "           epochs=100,\n",
    "           validation_data=(test_windows,test_labels),\n",
    "           callbacks=[create_model_checkpoint(model_4.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "22622abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 632.1910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "632.1909790039062"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "030b3315",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_preds = make_preds(model_4,test_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "9c5c0df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 4ms/step - loss: 569.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "569.7347412109375"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4 = tf.keras.models.load_model(\"model_experiment/model_4Conv1D/\")\n",
    "model_4.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "374abd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_4_results = evaluate_preds(tf.squeeze(test_labels),model_4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "26e85dac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 569.73474,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.5618482,\n",
       " 'MASE': 1.0008662}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "537a8b52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 567.9802,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.516525,\n",
       " 'MASE': 0.99957}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328ed21b",
   "metadata": {},
   "source": [
    "## Model 5: RNN (LSTM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "867c78ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "model_5 = Sequential(name='model_5')\n",
    "model_5.add(layers.Lambda(lambda x: tf.expand_dims(x,axis=1)))\n",
    "model_5.add(layers.LSTM(128,activation='relu'))\n",
    "model_5.add(layers.Dense(1))\n",
    "\n",
    "model_5.compile(loss='mae',metrics=['accuracy'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "2ea275eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "inputs = layers.Input(shape=(WINDOW_SIZE))\n",
    "x = layers.Lambda(lambda x: tf.expand_dims(x,axis=1))(inputs)\n",
    "x = layers.LSTM(128,activation='relu',return_sequences=True)(x)\n",
    "x = layers.LSTM(128,activation='relu')(x)\n",
    "x = layers.Dense(32,activation='relu')(x)\n",
    "outputs = layers.Dense(1)(x)\n",
    "model_5 = Model(inputs,outputs,name='model_5')\n",
    "\n",
    "model_5.compile(loss='mae',metrics=['mae'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71c4c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1e99e971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 2918.5029 - mae: 2918.5029INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 4s 153ms/step - loss: 2875.5540 - mae: 2875.5540 - val_loss: 13620.0742 - val_mae: 13620.0742\n",
      "Epoch 2/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 1013.9755 - mae: 1013.9755INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 139ms/step - loss: 918.7966 - mae: 918.7966 - val_loss: 1746.8885 - val_mae: 1746.8885\n",
      "Epoch 3/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 262.6417 - mae: 262.6417INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 125ms/step - loss: 255.3156 - mae: 255.3156 - val_loss: 1119.5110 - val_mae: 1119.5110\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 198.5002 - mae: 198.5002 - val_loss: 1122.9869 - val_mae: 1122.9869\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 181.3917 - mae: 181.3917 - val_loss: 1258.1344 - val_mae: 1258.1343\n",
      "Epoch 6/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 218.3880 - mae: 218.3880INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 125ms/step - loss: 217.3841 - mae: 217.3841 - val_loss: 1098.7205 - val_mae: 1098.7205\n",
      "Epoch 7/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 198.9717 - mae: 198.9717INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 148ms/step - loss: 193.4641 - mae: 193.4641 - val_loss: 1058.7927 - val_mae: 1058.7927\n",
      "Epoch 8/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 183.8747 - mae: 183.8747INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 130ms/step - loss: 185.5048 - mae: 185.5048 - val_loss: 1029.8318 - val_mae: 1029.8318\n",
      "Epoch 9/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 181.6335 - mae: 181.6335INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 131ms/step - loss: 187.1121 - mae: 187.1121 - val_loss: 1021.5370 - val_mae: 1021.5370\n",
      "Epoch 10/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 179.6274 - mae: 179.6274INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 133ms/step - loss: 186.7847 - mae: 186.7847 - val_loss: 1008.1106 - val_mae: 1008.1106\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 178.6390 - mae: 178.6390 - val_loss: 1034.4514 - val_mae: 1034.4514\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 176.4663 - mae: 176.4663 - val_loss: 1120.2516 - val_mae: 1120.2516\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 175.9056 - mae: 175.9056 - val_loss: 1096.4294 - val_mae: 1096.4294\n",
      "Epoch 14/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 170.0367 - mae: 170.0367INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 148ms/step - loss: 167.7624 - mae: 167.7624 - val_loss: 929.9609 - val_mae: 929.9609\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 173.1443 - mae: 173.1443 - val_loss: 1103.6666 - val_mae: 1103.6666\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 172.7199 - mae: 172.7199 - val_loss: 1080.2573 - val_mae: 1080.2573\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 161.4872 - mae: 161.4872 - val_loss: 1049.2767 - val_mae: 1049.2767\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 157.9532 - mae: 157.9532 - val_loss: 1001.1401 - val_mae: 1001.1401\n",
      "Epoch 19/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 153.0993 - mae: 153.0993INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 125ms/step - loss: 150.4510 - mae: 150.4510 - val_loss: 929.3134 - val_mae: 929.3134\n",
      "Epoch 20/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 149.8583 - mae: 149.8583INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 127ms/step - loss: 147.9166 - mae: 147.9166 - val_loss: 803.8445 - val_mae: 803.8445\n",
      "Epoch 21/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 146.3045 - mae: 146.3045INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 148ms/step - loss: 144.8992 - mae: 144.8992 - val_loss: 762.3257 - val_mae: 762.3257\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 139.1248 - mae: 139.1248 - val_loss: 855.2712 - val_mae: 855.2712\n",
      "Epoch 23/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 138.2703 - mae: 138.2703INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 126ms/step - loss: 140.7372 - mae: 140.7372 - val_loss: 749.1221 - val_mae: 749.1221\n",
      "Epoch 24/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 142.0711 - mae: 142.0711INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 131ms/step - loss: 140.2391 - mae: 140.2391 - val_loss: 726.5942 - val_mae: 726.5942\n",
      "Epoch 25/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 129.9137 - mae: 129.9137INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 153ms/step - loss: 126.7591 - mae: 126.7591 - val_loss: 686.2021 - val_mae: 686.2021\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 123.6515 - mae: 123.6515 - val_loss: 703.3519 - val_mae: 703.3519\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 126.8286 - mae: 126.8286 - val_loss: 917.2612 - val_mae: 917.2612\n",
      "Epoch 28/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 146.1976 - mae: 146.1976INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 134ms/step - loss: 141.6601 - mae: 141.6601 - val_loss: 685.4144 - val_mae: 685.4144\n",
      "Epoch 29/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 122.1333 - mae: 122.1333INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 130ms/step - loss: 121.0870 - mae: 121.0870 - val_loss: 647.1138 - val_mae: 647.1138\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 124.5269 - mae: 124.5269 - val_loss: 655.0502 - val_mae: 655.0502\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 141.9045 - mae: 141.9045 - val_loss: 650.6709 - val_mae: 650.6709\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 120.7682 - mae: 120.7682 - val_loss: 728.0540 - val_mae: 728.0540\n",
      "Epoch 33/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 114.2825 - mae: 114.2825INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 152ms/step - loss: 116.0171 - mae: 116.0171 - val_loss: 608.1118 - val_mae: 608.1118\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 116.4930 - mae: 116.4930 - val_loss: 615.5547 - val_mae: 615.5547\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 118.1282 - mae: 118.1282 - val_loss: 615.0082 - val_mae: 615.0082\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 114.5624 - mae: 114.5624 - val_loss: 659.0589 - val_mae: 659.0589\n",
      "Epoch 37/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 120.6513 - mae: 120.6513INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 128ms/step - loss: 119.3990 - mae: 119.3990 - val_loss: 594.6495 - val_mae: 594.6495\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 111.8781 - mae: 111.8781 - val_loss: 667.7733 - val_mae: 667.7733\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 114.7373 - mae: 114.7373 - val_loss: 628.8559 - val_mae: 628.8559\n",
      "Epoch 40/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 114.8331 - mae: 114.8331INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 124ms/step - loss: 114.7887 - mae: 114.7887 - val_loss: 588.9144 - val_mae: 588.9144\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 112.6445 - mae: 112.6445 - val_loss: 593.5850 - val_mae: 593.5850\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 128.0735 - mae: 128.0735 - val_loss: 678.6779 - val_mae: 678.6779\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 122.3775 - mae: 122.3775 - val_loss: 786.3043 - val_mae: 786.3043\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 120.7775 - mae: 120.7775 - val_loss: 593.9819 - val_mae: 593.9819\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 110.6469 - mae: 110.6469 - val_loss: 592.9319 - val_mae: 592.9319\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 110.3204 - mae: 110.3204 - val_loss: 711.2012 - val_mae: 711.2012\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 117.0050 - mae: 117.0050 - val_loss: 615.1935 - val_mae: 615.1935\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 110.0139 - mae: 110.0139 - val_loss: 593.6558 - val_mae: 593.6558\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 109.6349 - mae: 109.6349 - val_loss: 590.3989 - val_mae: 590.3989\n",
      "Epoch 50/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 104.8764 - mae: 104.8764INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 128ms/step - loss: 108.4778 - mae: 108.4778 - val_loss: 587.3065 - val_mae: 587.3065\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 12ms/step - loss: 110.1228 - mae: 110.1228 - val_loss: 602.8280 - val_mae: 602.8280\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 111.9425 - mae: 111.9425 - val_loss: 610.6999 - val_mae: 610.6999\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 114.9949 - mae: 114.9949 - val_loss: 637.2376 - val_mae: 637.2376\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 112.1152 - mae: 112.1152 - val_loss: 600.8710 - val_mae: 600.8710\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 114.0751 - mae: 114.0751 - val_loss: 614.1237 - val_mae: 614.1237\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 109.0947 - mae: 109.0947 - val_loss: 637.3969 - val_mae: 637.3969\n",
      "Epoch 57/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 110.9355 - mae: 110.9355INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 149ms/step - loss: 108.0570 - mae: 108.0570 - val_loss: 575.9520 - val_mae: 575.9520\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 113.0542 - mae: 113.0542 - val_loss: 610.0665 - val_mae: 610.0665\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 13ms/step - loss: 107.5941 - mae: 107.5941 - val_loss: 624.9523 - val_mae: 624.9523\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 115.2817 - mae: 115.2817 - val_loss: 579.2303 - val_mae: 579.2303\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 113.5011 - mae: 113.5011 - val_loss: 592.5335 - val_mae: 592.5335\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 114.3766 - mae: 114.3766 - val_loss: 700.0352 - val_mae: 700.0352\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 112.8740 - mae: 112.8740 - val_loss: 592.1710 - val_mae: 592.1710\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 111.1636 - mae: 111.1636 - val_loss: 731.9141 - val_mae: 731.9141\n",
      "Epoch 65/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 119.5208 - mae: 119.5208INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 126ms/step - loss: 117.7030 - mae: 117.7030 - val_loss: 573.5165 - val_mae: 573.5165\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 108.3530 - mae: 108.3530 - val_loss: 574.9173 - val_mae: 574.9173\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 110.8039 - mae: 110.8039 - val_loss: 661.0125 - val_mae: 661.0125\n",
      "Epoch 68/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 111.2903 - mae: 111.2903INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 2s 125ms/step - loss: 111.3048 - mae: 111.3048 - val_loss: 572.4995 - val_mae: 572.4995\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 118.6899 - mae: 118.6899 - val_loss: 616.6113 - val_mae: 616.6113\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 114.1476 - mae: 114.1476 - val_loss: 588.6205 - val_mae: 588.6205\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 116.3503 - mae: 116.3503 - val_loss: 584.5366 - val_mae: 584.5366\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 129.3549 - mae: 129.3549 - val_loss: 724.1111 - val_mae: 724.1111\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 115.0725 - mae: 115.0725 - val_loss: 602.5539 - val_mae: 602.5539\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 115.0649 - mae: 115.0649 - val_loss: 573.0742 - val_mae: 573.0742\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 109.4329 - mae: 109.4329 - val_loss: 602.5897 - val_mae: 602.5897\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 112.6445 - mae: 112.6445 - val_loss: 758.0991 - val_mae: 758.0991\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 124.3680 - mae: 124.3680 - val_loss: 697.3394 - val_mae: 697.3394\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 115.0284 - mae: 115.0284 - val_loss: 629.3743 - val_mae: 629.3743\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 111.5800 - mae: 111.5800 - val_loss: 685.9551 - val_mae: 685.9551\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 125.6633 - mae: 125.6633 - val_loss: 573.5597 - val_mae: 573.5597\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 107.3623 - mae: 107.3623 - val_loss: 575.6964 - val_mae: 575.6964\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 124.2915 - mae: 124.2915 - val_loss: 585.1124 - val_mae: 585.1124\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 120.2311 - mae: 120.2311 - val_loss: 802.0522 - val_mae: 802.0522\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 123.2221 - mae: 123.2221 - val_loss: 586.0029 - val_mae: 586.0029\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 108.6646 - mae: 108.6646 - val_loss: 608.7300 - val_mae: 608.7300\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 111.9685 - mae: 111.9685 - val_loss: 584.6238 - val_mae: 584.6238\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 106.7512 - mae: 106.7512 - val_loss: 589.9123 - val_mae: 589.9123\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 109.6282 - mae: 109.6282 - val_loss: 677.9702 - val_mae: 677.9702\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 112.2347 - mae: 112.2347 - val_loss: 577.5046 - val_mae: 577.5046\n",
      "Epoch 90/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 106.9468 - mae: 106.9468INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: model_experiment\\model_5\\assets\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B6F8FAE80> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n",
      "WARNING:absl:<keras.layers.recurrent.LSTMCell object at 0x0000021B72E81040> has the same name 'LSTMCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.LSTMCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 149ms/step - loss: 106.8417 - mae: 106.8417 - val_loss: 568.2491 - val_mae: 568.2491\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 110.7591 - mae: 110.7591 - val_loss: 635.3989 - val_mae: 635.3989\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 117.5803 - mae: 117.5803 - val_loss: 759.8276 - val_mae: 759.8276\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 118.8411 - mae: 118.8411 - val_loss: 637.5815 - val_mae: 637.5815\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 114.5182 - mae: 114.5182 - val_loss: 630.8237 - val_mae: 630.8237\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 107.5667 - mae: 107.5667 - val_loss: 574.4421 - val_mae: 574.4421\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 108.2801 - mae: 108.2801 - val_loss: 587.1740 - val_mae: 587.1740\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 106.2005 - mae: 106.2005 - val_loss: 600.3242 - val_mae: 600.3242\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 110.4862 - mae: 110.4862 - val_loss: 578.9386 - val_mae: 578.9386\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 115.2062 - mae: 115.2062 - val_loss: 601.1055 - val_mae: 601.1055\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 117.8361 - mae: 117.8361 - val_loss: 575.5864 - val_mae: 575.5864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21b6d4e1a30>"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.fit(train_windows,\n",
    "           train_labels,\n",
    "           batch_size=128,\n",
    "           epochs=100,\n",
    "           validation_data=(test_windows,test_labels),\n",
    "           callbacks=[create_model_checkpoint(model_5.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "8a7026d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 5ms/step - loss: 575.5864 - mae: 575.5864\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[575.5863647460938, 575.5863647460938]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "09f23968",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7ab956df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "model_5 = load_model(\"model_experiment/model_5/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "74af51cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 6ms/step - loss: 568.2491 - mae: 568.2491\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[568.2491455078125, 568.2491455078125]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5.evaluate(test_windows,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "4bbf3251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=array([8858.622, 8773.998, 9020.758, 8797.527, 8731.576], dtype=float32)>"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_preds = make_preds(model_5,test_windows)\n",
    "model_5_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "e74a3b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 568.24915,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.5552742,\n",
       " 'MASE': 0.9982564}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_5_results = evaluate_preds(tf.squeeze(test_labels),model_5_preds)\n",
    "model_5_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "14f5b9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MAE': 567.9802,\n",
       " 'MSE': 1147547.125023896,\n",
       " 'RMSE': 1071.2362601330744,\n",
       " 'MAPE': 2.516525,\n",
       " 'MASE': 0.99957}"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815ba649",
   "metadata": {},
   "source": [
    "## Add data with multivariate time series dataset\n",
    "\n",
    "* misal tweet elon musk untuk menaikan harga bitcoin\n",
    "\n",
    "* memprediksi dengan bitcoin halving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "949f21f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2013-10-01  123.65499\n",
       "2013-10-02  125.45500\n",
       "2013-10-03  108.58483\n",
       "2013-10-04  118.67466\n",
       "2013-10-05  121.33866"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2de44b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4f7f7767",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_reward_1 = 50 #3 january 2009\n",
    "block_reward_2 = 25 #8 Nov 2012\n",
    "block_reward_3 = 12.5 #9 July 2016\n",
    "block_reward_4 = 6.25 #18 May 2020\n",
    "\n",
    "# block reward dates\n",
    "\n",
    "block_reward_2_datetime = np.datetime64(\"2012-11-28\")\n",
    "block_reward_3_datetime = np.datetime64(\"2016-07-09\")\n",
    "block_reward_4_datetime = np.datetime64(\"2020-05-18\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e04dcc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.datetime64('2012-11-28')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_reward_2_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e85e8140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2013-10-01', '2013-10-02', '2013-10-03', '2013-10-04',\n",
       "               '2013-10-05', '2013-10-06', '2013-10-07', '2013-10-08',\n",
       "               '2013-10-09', '2013-10-10',\n",
       "               ...\n",
       "               '2021-05-09', '2021-05-10', '2021-05-11', '2021-05-12',\n",
       "               '2021-05-13', '2021-05-14', '2021-05-15', '2021-05-16',\n",
       "               '2021-05-17', '2021-05-18'],\n",
       "              dtype='datetime64[ns]', name='Date', length=2787, freq=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e93656e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1012, 2421)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data range\n",
    "block_reward_2_days = (block_reward_3_datetime-bitcoin_prices.index[0]).days\n",
    "block_reward_3_days = (block_reward_4_datetime-bitcoin_prices.index[0]).days\n",
    "block_reward_2_days,block_reward_3_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c84b0df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices_block = bitcoin_prices.copy()\n",
    "bitcoin_prices_block['block_reward'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "98c2b026",
   "metadata": {},
   "outputs": [],
   "source": [
    "bitcoin_prices_block.iloc[:block_reward_2_days,-1] = block_reward_2\n",
    "bitcoin_prices_block.iloc[block_reward_2_days:block_reward_3_days,-1] = block_reward_3\n",
    "bitcoin_prices_block.iloc[block_reward_3_days:,-1] = block_reward_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8cacba60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([25, 25, 25, ..., 6.25, 6.25, 6.25], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_block['block_reward'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "912de09a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'block_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-d9d882ea8a86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock_size\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m\u001b[0mbitcoin_prices_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'block_reward'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'block_size' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(np.array(block_size) ==bitcoin_prices_block['block_reward'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "24e9b74b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_block.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c237bd14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1012"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_reward_2_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "afdd5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_size = []\n",
    "for i in bitcoin_prices.index:\n",
    "    if i >= block_reward_2_datetime and i < block_reward_3_datetime:\n",
    "        block_size.append(block_reward_2)\n",
    "    elif i >= block_reward_3_datetime and i < block_reward_4_datetime:\n",
    "        block_size.append(block_reward_3)\n",
    "    elif i >= block_reward_4_datetime :\n",
    "        block_size.append(block_reward_4)\n",
    "    else:\n",
    "        block_size.append(3.12)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "780a61d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 25, 25, 25, 25, 25, 25, 25, 25, 25]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ab4fe9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2787, 2787)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(block_size),len(bitcoin_prices.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42a9eaaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices.index[0] > block_reward_2_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57cc3a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'minmax_scale' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-c1833ee9de63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mminmax_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbitcoin_prices_block\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Price'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"block_reward\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'minmax_scale' is not defined"
     ]
    }
   ],
   "source": [
    "minmax_scale(bitcoin_prices_block[['Price',\"block_reward\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "072cf6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Date'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the block reward vs price over ime\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "scaled_price_block_df = pd.DataFrame(minmax_scale(bitcoin_prices_block[['Price',\"block_reward\"]]),\n",
    "                                                 columns=bitcoin_prices_block.columns,\n",
    "                                                 index = bitcoin_prices_block.index)\n",
    "\n",
    "scaled_price_block_df.plot(figsize=(10,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ca6c85",
   "metadata": {},
   "source": [
    "## making a windowed dataset with pandas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "fa7f5f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup dataset hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff115d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON =1\n",
    "WINDOW_SIZE=7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f0d5a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2465b0e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>block_reward</th>\n",
       "      <th>Price=1</th>\n",
       "      <th>Price=2</th>\n",
       "      <th>Price=3</th>\n",
       "      <th>Price=4</th>\n",
       "      <th>Price=5</th>\n",
       "      <th>Price=6</th>\n",
       "      <th>Price=7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "      <td>25</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "      <td>25</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "      <td>25</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "      <td>25</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-06</th>\n",
       "      <td>120.65533</td>\n",
       "      <td>25</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-07</th>\n",
       "      <td>121.79500</td>\n",
       "      <td>25</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-08</th>\n",
       "      <td>123.03300</td>\n",
       "      <td>25</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-09</th>\n",
       "      <td>124.04900</td>\n",
       "      <td>25</td>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-10</th>\n",
       "      <td>125.96116</td>\n",
       "      <td>25</td>\n",
       "      <td>124.04900</td>\n",
       "      <td>123.03300</td>\n",
       "      <td>121.79500</td>\n",
       "      <td>120.65533</td>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price block_reward    Price=1    Price=2    Price=3  \\\n",
       "Date                                                                  \n",
       "2013-10-01  123.65499           25        NaN        NaN        NaN   \n",
       "2013-10-02  125.45500           25  123.65499        NaN        NaN   \n",
       "2013-10-03  108.58483           25  125.45500  123.65499        NaN   \n",
       "2013-10-04  118.67466           25  108.58483  125.45500  123.65499   \n",
       "2013-10-05  121.33866           25  118.67466  108.58483  125.45500   \n",
       "2013-10-06  120.65533           25  121.33866  118.67466  108.58483   \n",
       "2013-10-07  121.79500           25  120.65533  121.33866  118.67466   \n",
       "2013-10-08  123.03300           25  121.79500  120.65533  121.33866   \n",
       "2013-10-09  124.04900           25  123.03300  121.79500  120.65533   \n",
       "2013-10-10  125.96116           25  124.04900  123.03300  121.79500   \n",
       "\n",
       "              Price=4    Price=5    Price=6    Price=7  \n",
       "Date                                                    \n",
       "2013-10-01        NaN        NaN        NaN        NaN  \n",
       "2013-10-02        NaN        NaN        NaN        NaN  \n",
       "2013-10-03        NaN        NaN        NaN        NaN  \n",
       "2013-10-04        NaN        NaN        NaN        NaN  \n",
       "2013-10-05  123.65499        NaN        NaN        NaN  \n",
       "2013-10-06  125.45500  123.65499        NaN        NaN  \n",
       "2013-10-07  108.58483  125.45500  123.65499        NaN  \n",
       "2013-10-08  118.67466  108.58483  125.45500  123.65499  \n",
       "2013-10-09  121.33866  118.67466  108.58483  125.45500  \n",
       "2013-10-10  120.65533  121.33866  118.67466  108.58483  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_windowed = bitcoin_prices_block.copy()\n",
    "for i in range(WINDOW_SIZE):\n",
    "    bitcoin_prices_windowed[f\"Price={i+1}\"] = bitcoin_prices_windowed[\"Price\"].shift(periods=i+1)\n",
    "bitcoin_prices_windowed[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d68d571",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>block_reward</th>\n",
       "      <th>Price=1</th>\n",
       "      <th>Price=2</th>\n",
       "      <th>Price=3</th>\n",
       "      <th>Price=4</th>\n",
       "      <th>Price=5</th>\n",
       "      <th>Price=6</th>\n",
       "      <th>Price=7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "      <td>25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "      <td>25</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "      <td>25</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "      <td>25</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "      <td>25</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price block_reward    Price=1    Price=2    Price=3  \\\n",
       "Date                                                                  \n",
       "2013-10-01  123.65499           25        NaN        NaN        NaN   \n",
       "2013-10-02  125.45500           25  123.65499        NaN        NaN   \n",
       "2013-10-03  108.58483           25  125.45500  123.65499        NaN   \n",
       "2013-10-04  118.67466           25  108.58483  125.45500  123.65499   \n",
       "2013-10-05  121.33866           25  118.67466  108.58483  125.45500   \n",
       "\n",
       "              Price=4  Price=5  Price=6  Price=7  \n",
       "Date                                              \n",
       "2013-10-01        NaN      NaN      NaN      NaN  \n",
       "2013-10-02        NaN      NaN      NaN      NaN  \n",
       "2013-10-03        NaN      NaN      NaN      NaN  \n",
       "2013-10-04        NaN      NaN      NaN      NaN  \n",
       "2013-10-05  123.65499      NaN      NaN      NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_windowed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4f742a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bitcoin_prices_windowed.dropna().drop(\"Price\",axis=1).astype(np.float32)\n",
    "y = bitcoin_prices_windowed.dropna()[\"Price\"].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4f7cdfe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_reward</th>\n",
       "      <th>Price=1</th>\n",
       "      <th>Price=2</th>\n",
       "      <th>Price=3</th>\n",
       "      <th>Price=4</th>\n",
       "      <th>Price=5</th>\n",
       "      <th>Price=6</th>\n",
       "      <th>Price=7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-08</th>\n",
       "      <td>25.0</td>\n",
       "      <td>121.794998</td>\n",
       "      <td>120.655327</td>\n",
       "      <td>121.338661</td>\n",
       "      <td>118.674660</td>\n",
       "      <td>108.584831</td>\n",
       "      <td>125.455002</td>\n",
       "      <td>123.654991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-09</th>\n",
       "      <td>25.0</td>\n",
       "      <td>123.032997</td>\n",
       "      <td>121.794998</td>\n",
       "      <td>120.655327</td>\n",
       "      <td>121.338661</td>\n",
       "      <td>118.674660</td>\n",
       "      <td>108.584831</td>\n",
       "      <td>125.455002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>124.049004</td>\n",
       "      <td>123.032997</td>\n",
       "      <td>121.794998</td>\n",
       "      <td>120.655327</td>\n",
       "      <td>121.338661</td>\n",
       "      <td>118.674660</td>\n",
       "      <td>108.584831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-11</th>\n",
       "      <td>25.0</td>\n",
       "      <td>125.961159</td>\n",
       "      <td>124.049004</td>\n",
       "      <td>123.032997</td>\n",
       "      <td>121.794998</td>\n",
       "      <td>120.655327</td>\n",
       "      <td>121.338661</td>\n",
       "      <td>118.674660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-12</th>\n",
       "      <td>25.0</td>\n",
       "      <td>125.279663</td>\n",
       "      <td>125.961159</td>\n",
       "      <td>124.049004</td>\n",
       "      <td>123.032997</td>\n",
       "      <td>121.794998</td>\n",
       "      <td>120.655327</td>\n",
       "      <td>121.338661</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            block_reward     Price=1     Price=2     Price=3     Price=4  \\\n",
       "Date                                                                       \n",
       "2013-10-08          25.0  121.794998  120.655327  121.338661  118.674660   \n",
       "2013-10-09          25.0  123.032997  121.794998  120.655327  121.338661   \n",
       "2013-10-10          25.0  124.049004  123.032997  121.794998  120.655327   \n",
       "2013-10-11          25.0  125.961159  124.049004  123.032997  121.794998   \n",
       "2013-10-12          25.0  125.279663  125.961159  124.049004  123.032997   \n",
       "\n",
       "               Price=5     Price=6     Price=7  \n",
       "Date                                            \n",
       "2013-10-08  108.584831  125.455002  123.654991  \n",
       "2013-10-09  118.674660  108.584831  125.455002  \n",
       "2013-10-10  121.338661  118.674660  108.584831  \n",
       "2013-10-11  120.655327  121.338661  118.674660  \n",
       "2013-10-12  121.794998  120.655327  121.338661  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5756d608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2780, 8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8dca8da7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_16776/3273413203.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# mak train test split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0msplit_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msplit_size\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "# mak train test split\n",
    "\n",
    "split_size = int(len(X)*0.8)\n",
    "\n",
    "X_train,y_train = X[:split_size],y[:split_size]\n",
    "X_test,y_test = X[split_size:],y[split_size:]\n",
    "\n",
    "len(X_train),len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ae320d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 25.     , 121.795  , 120.65533, 121.33866, 118.67466, 108.58483,\n",
       "       125.455  , 123.65499], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "611cda31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0626fcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/18 [>.............................] - ETA: 24s - loss: 2853.4023 - mae: 2853.4023INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 2s 33ms/step - loss: 1234.6804 - mae: 1234.6804 - val_loss: 2061.9077 - val_mae: 2061.9077\n",
      "Epoch 2/100\n",
      " 6/18 [=========>....................] - ETA: 0s - loss: 451.5935 - mae: 451.5935INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 351.5053 - mae: 351.5053 - val_loss: 1908.6733 - val_mae: 1908.6733\n",
      "Epoch 3/100\n",
      "11/18 [=================>............] - ETA: 0s - loss: 241.2493 - mae: 241.2493INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 235.4153 - mae: 235.4153 - val_loss: 1329.0585 - val_mae: 1329.0585\n",
      "Epoch 4/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 212.8506 - mae: 212.8506INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 208.6112 - mae: 208.6112 - val_loss: 1102.1342 - val_mae: 1102.1342\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 196.5770 - mae: 196.5770 - val_loss: 1107.8474 - val_mae: 1107.8474\n",
      "Epoch 6/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 185.4590 - mae: 185.4590INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 187.2245 - mae: 187.2245 - val_loss: 1036.1720 - val_mae: 1036.1720\n",
      "Epoch 7/100\n",
      "12/18 [===================>..........] - ETA: 0s - loss: 189.9648 - mae: 189.9648INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 182.0245 - mae: 182.0245 - val_loss: 1019.2928 - val_mae: 1019.2928\n",
      "Epoch 8/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 151.5176 - mae: 151.5176INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 175.7059 - mae: 175.7059 - val_loss: 977.8488 - val_mae: 977.8488\n",
      "Epoch 9/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 142.1689 - mae: 142.1689INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 170.1784 - mae: 170.1784 - val_loss: 954.4037 - val_mae: 954.4037\n",
      "Epoch 10/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 177.8448 - mae: 177.8448INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 164.4430 - mae: 164.4430 - val_loss: 913.5148 - val_mae: 913.5148\n",
      "Epoch 11/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 171.3627 - mae: 171.3627INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 158.6892 - mae: 158.6892 - val_loss: 874.2507 - val_mae: 874.2507\n",
      "Epoch 12/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 147.0429 - mae: 147.0429INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 152.0732 - mae: 152.0732 - val_loss: 861.0418 - val_mae: 861.0418\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 151.1057 - mae: 151.1057 - val_loss: 886.1207 - val_mae: 886.1207\n",
      "Epoch 14/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 152.2400 - mae: 152.2400INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 147.5482 - mae: 147.5482 - val_loss: 837.8616 - val_mae: 837.8616\n",
      "Epoch 15/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 146.6370 - mae: 146.6370INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 142.3497 - mae: 142.3497 - val_loss: 794.4788 - val_mae: 794.4788\n",
      "Epoch 16/100\n",
      "13/18 [====================>.........] - ETA: 0s - loss: 140.2361 - mae: 140.2361INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 137.5206 - mae: 137.5206 - val_loss: 778.4052 - val_mae: 778.4052\n",
      "Epoch 17/100\n",
      " 5/18 [=======>......................] - ETA: 0s - loss: 145.1049 - mae: 145.1049INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 135.8190 - mae: 135.8190 - val_loss: 772.4532 - val_mae: 772.4532\n",
      "Epoch 18/100\n",
      " 5/18 [=======>......................] - ETA: 0s - loss: 153.2008 - mae: 153.2008INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 134.8562 - mae: 134.8562 - val_loss: 747.4802 - val_mae: 747.4802\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 130.3347 - mae: 130.3347 - val_loss: 761.0554 - val_mae: 761.0554\n",
      "Epoch 20/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 129.3624 - mae: 129.3624INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 128.6775 - mae: 128.6775 - val_loss: 701.8977 - val_mae: 701.8977\n",
      "Epoch 21/100\n",
      "15/18 [========================>.....] - ETA: 0s - loss: 128.8097 - mae: 128.8097INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 129.5576 - mae: 129.5576 - val_loss: 691.0128 - val_mae: 691.0128\n",
      "Epoch 22/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 131.2601 - mae: 131.2601INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 125.8060 - mae: 125.8060 - val_loss: 684.4119 - val_mae: 684.4119\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 125.5263 - mae: 125.5263 - val_loss: 692.1298 - val_mae: 692.1298\n",
      "Epoch 24/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 134.1221 - mae: 134.1221INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 122.4765 - mae: 122.4765 - val_loss: 674.2216 - val_mae: 674.2216\n",
      "Epoch 25/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 133.5674 - mae: 133.5674INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 121.1171 - mae: 121.1171 - val_loss: 669.6441 - val_mae: 669.6441\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 127.2623 - mae: 127.2623 - val_loss: 690.0403 - val_mae: 690.0403\n",
      "Epoch 27/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 180.3230 - mae: 180.3230INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 124.6204 - mae: 124.6204 - val_loss: 643.9724 - val_mae: 643.9724\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 118.2544 - mae: 118.2544 - val_loss: 656.2767 - val_mae: 656.2767\n",
      "Epoch 29/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 109.8149 - mae: 109.8149INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 119.6374 - mae: 119.6374 - val_loss: 633.4547 - val_mae: 633.4547\n",
      "Epoch 30/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 130.2605 - mae: 130.2605INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 119.5001 - mae: 119.5001 - val_loss: 625.3953 - val_mae: 625.3953\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 114.5633 - mae: 114.5633 - val_loss: 668.5064 - val_mae: 668.5064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 121.3793 - mae: 121.3793INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 116.9750 - mae: 116.9750 - val_loss: 617.1061 - val_mae: 617.1061\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.2438 - mae: 115.2438 - val_loss: 649.0989 - val_mae: 649.0989\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 114.5187 - mae: 114.5187 - val_loss: 632.1375 - val_mae: 632.1375\n",
      "Epoch 35/100\n",
      "14/18 [======================>.......] - ETA: 0s - loss: 117.1253 - mae: 117.1253INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 113.6357 - mae: 113.6357 - val_loss: 607.4173 - val_mae: 607.4173\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.2605 - mae: 115.2605 - val_loss: 626.4319 - val_mae: 626.4319\n",
      "Epoch 37/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 141.7286 - mae: 141.7286INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 113.7020 - mae: 113.7020 - val_loss: 606.2318 - val_mae: 606.2318\n",
      "Epoch 38/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 111.8183 - mae: 111.8183INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 111.4061 - mae: 111.4061 - val_loss: 603.2919 - val_mae: 603.2919\n",
      "Epoch 39/100\n",
      "17/18 [===========================>..] - ETA: 0s - loss: 112.3874 - mae: 112.3874INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 112.7722 - mae: 112.7722 - val_loss: 596.0060 - val_mae: 596.0060\n",
      "Epoch 40/100\n",
      "16/18 [=========================>....] - ETA: 0s - loss: 110.6383 - mae: 110.6383INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 110.5418 - mae: 110.5418 - val_loss: 593.2170 - val_mae: 593.2170\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.8671 - mae: 110.8671 - val_loss: 609.1062 - val_mae: 609.1062\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.7249 - mae: 115.7249 - val_loss: 607.4877 - val_mae: 607.4877\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 111.3313 - mae: 111.3313 - val_loss: 606.2029 - val_mae: 606.2029\n",
      "Epoch 44/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 65.3244 - mae: 65.3244INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 109.7027 - mae: 109.7027 - val_loss: 586.1215 - val_mae: 586.1215\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 107.8748 - mae: 107.8748 - val_loss: 593.8445 - val_mae: 593.8445\n",
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.8641 - mae: 109.8641 - val_loss: 586.4581 - val_mae: 586.4581\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 112.3587 - mae: 112.3587 - val_loss: 655.4489 - val_mae: 655.4489\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.1614 - mae: 109.1614 - val_loss: 598.7234 - val_mae: 598.7234\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 109.3029 - mae: 109.3029 - val_loss: 589.2489 - val_mae: 589.2489\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 111.1971 - mae: 111.1971 - val_loss: 649.3788 - val_mae: 649.3788\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 110.8514 - mae: 110.8514 - val_loss: 602.7667 - val_mae: 602.7667\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 111.8331 - mae: 111.8331 - val_loss: 599.2957 - val_mae: 599.2957\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.8895 - mae: 110.8895 - val_loss: 652.1644 - val_mae: 652.1644\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 113.8169 - mae: 113.8169 - val_loss: 600.8459 - val_mae: 600.8459\n",
      "Epoch 55/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 129.3818 - mae: 129.3818INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 110.4068 - mae: 110.4068 - val_loss: 575.7752 - val_mae: 575.7752\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 108.6609 - mae: 108.6609 - val_loss: 785.9749 - val_mae: 785.9749\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 124.9823 - mae: 124.9823 - val_loss: 670.3782 - val_mae: 670.3782\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 112.8591 - mae: 112.8591 - val_loss: 580.2877 - val_mae: 580.2877\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 107.2513 - mae: 107.2513 - val_loss: 597.5082 - val_mae: 597.5082\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 109.2322 - mae: 109.2322 - val_loss: 632.2958 - val_mae: 632.2958\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 109.3519 - mae: 109.3519 - val_loss: 591.5412 - val_mae: 591.5412\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 108.4084 - mae: 108.4084 - val_loss: 617.5801 - val_mae: 617.5801\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 113.5326 - mae: 113.5326 - val_loss: 613.1476 - val_mae: 613.1476\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 110.6625 - mae: 110.6625 - val_loss: 689.1802 - val_mae: 689.1802\n",
      "Epoch 65/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 149.2280 - mae: 149.2280INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 112.0475 - mae: 112.0475 - val_loss: 575.5540 - val_mae: 575.5540\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 111.2830 - mae: 111.2830 - val_loss: 590.7802 - val_mae: 590.7802\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 106.7918 - mae: 106.7918 - val_loss: 586.8840 - val_mae: 586.8840\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 112.2987 - mae: 112.2987 - val_loss: 696.5287 - val_mae: 696.5287\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 124.7808 - mae: 124.7808 - val_loss: 698.5261 - val_mae: 698.5261\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.3443 - mae: 119.3443 - val_loss: 581.2100 - val_mae: 581.2100\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.9960 - mae: 109.9960 - val_loss: 607.6742 - val_mae: 607.6742\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - ETA: 0s - loss: 106.7711 - mae: 106.7711INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 106.7711 - mae: 106.7711 - val_loss: 573.6142 - val_mae: 573.6142\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.2485 - mae: 110.2485 - val_loss: 618.8947 - val_mae: 618.8947\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 105.5330 - mae: 105.5330 - val_loss: 574.9452 - val_mae: 574.9452\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 107.3177 - mae: 107.3177 - val_loss: 606.1979 - val_mae: 606.1979\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 107.8084 - mae: 107.8084 - val_loss: 582.2403 - val_mae: 582.2403\n",
      "Epoch 77/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 83.6437 - mae: 83.6437INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 107.2528 - mae: 107.2528 - val_loss: 571.8563 - val_mae: 571.8563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.2309 - mae: 106.2309 - val_loss: 572.2830 - val_mae: 572.2830\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 105.8568 - mae: 105.8568 - val_loss: 596.5461 - val_mae: 596.5461\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 107.8418 - mae: 107.8418 - val_loss: 577.2400 - val_mae: 577.2400\n",
      "Epoch 81/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 95.0620 - mae: 95.0620INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 105.1101 - mae: 105.1101 - val_loss: 568.4897 - val_mae: 568.4897\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 114.1867 - mae: 114.1867 - val_loss: 592.5609 - val_mae: 592.5609\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 107.9631 - mae: 107.9631 - val_loss: 651.6213 - val_mae: 651.6213\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.6690 - mae: 109.6690 - val_loss: 568.9340 - val_mae: 568.9340\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 105.8219 - mae: 105.8219 - val_loss: 571.5334 - val_mae: 571.5334\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 104.8628 - mae: 104.8628 - val_loss: 579.3859 - val_mae: 579.3859\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 104.7148 - mae: 104.7148 - val_loss: 582.9178 - val_mae: 582.9178\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.8899 - mae: 106.8899 - val_loss: 569.0820 - val_mae: 569.0820\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 105.4376 - mae: 105.4376 - val_loss: 569.3439 - val_mae: 569.3439\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 105.1583 - mae: 105.1583 - val_loss: 600.5422 - val_mae: 600.5422\n",
      "Epoch 91/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 111.8188 - mae: 111.8188 - val_loss: 632.4727 - val_mae: 632.4727\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 106.8183 - mae: 106.8183 - val_loss: 601.6358 - val_mae: 601.6358\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 114.4035 - mae: 114.4035 - val_loss: 647.1910 - val_mae: 647.1910\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.5867 - mae: 110.5867 - val_loss: 571.2924 - val_mae: 571.2924\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 105.7926 - mae: 105.7926 - val_loss: 584.9744 - val_mae: 584.9744\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 112.4480 - mae: 112.4480 - val_loss: 624.2061 - val_mae: 624.2061\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 3ms/step - loss: 108.2609 - mae: 108.2609 - val_loss: 581.7926 - val_mae: 581.7926\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 108.0625 - mae: 108.0625 - val_loss: 573.6556 - val_mae: 573.6556\n",
      "Epoch 99/100\n",
      " 1/18 [>.............................] - ETA: 0s - loss: 143.6039 - mae: 143.6039INFO:tensorflow:Assets written to: model_experiment\\model_6_multivariate\\assets\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 107.7017 - mae: 107.7017 - val_loss: 567.8899 - val_mae: 567.8899\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 107.9951 - mae: 107.9951 - val_loss: 626.7441 - val_mae: 626.7441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22fe29ae640>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "model_6 = Sequential(name='model_6_multivariate')\n",
    "model_6.add(layers.Dense(128,activation='relu'))\n",
    "model_6.add(layers.Dense(1))\n",
    "\n",
    "model_6.compile(loss='mae',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "model_6.fit(X_train,y_train,epochs=100,batch_size=128,validation_data=(X_test,y_test),\n",
    "           callbacks=[create_model_checkpoint(model_name=model_6.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e544cbfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step - loss: 626.7440 - mae: 626.7440\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[626.7440185546875, 626.7440185546875]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "model_6.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41f34668",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_6 = load_model(\"model_experiment/model_6_multivariate/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88ab2efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 2ms/step - loss: 567.8899 - mae: 567.8899\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[567.889892578125, 567.889892578125]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_6.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91eede94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([8844.684, 8769.905, 9045.17 , 8747.686, 8728.429, 8772.757,\n",
       "       8667.292, 8503.437, 8470.313, 8527.244], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make pred\n",
    "\n",
    "model_6_preds = tf.squeeze(model_6.predict(X_test))\n",
    "model_6_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cea58ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "691c69c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 567.8899,\n",
       " 'mse': 1164816.6,\n",
       " 'rmse': 1079.2667,\n",
       " 'mape': 2.5460758,\n",
       " 'mase': 0.99762523}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate pred to get eval metrics\n",
    "\n",
    "model_6_results = evaluate_preds(y_test,model_6_preds)\n",
    "model_6_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9717b4f",
   "metadata": {},
   "source": [
    "## Model 7: N-beats algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874baccb",
   "metadata": {},
   "source": [
    "### Build N-Beats block layer\n",
    "* karen block layer tidak ada di layer maka pakai subclassing layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5fc2331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBeatsBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                input_size:int,\n",
    "                theta_size:int,\n",
    "                horizon:int,\n",
    "                n_neurons:int,\n",
    "                n_layers:int,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_size = input_size\n",
    "        self.theta_size = theta_size\n",
    "        self.horizon = horizon\n",
    "        self.n_neurons = n_neurons\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Block contatins stack of 4 full connect layers each relu activation\n",
    "        \n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons,activation='relu') for i in range(n_layers)]\n",
    "        #output of block is theta layer iwht linear activation\n",
    "        self.theta_layer = tf.keras.layers.Dense(theta_size,activation='linear',name='theta')\n",
    "        \n",
    "    def call(self,inputs):\n",
    "        x = inputs\n",
    "        for layer in self.hidden:\n",
    "            x = layer(x)\n",
    "        theta = self.theta_layer(x)\n",
    "        # output the backcast and the forecast from theta\n",
    "        \n",
    "        backcast, forecast = theta[:, :self.input_size], theta[:,-self.horizon:]\n",
    "        \n",
    "        return backcast, forecast\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99c375b",
   "metadata": {},
   "source": [
    "### Test inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2ec48c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dummy NBeatsBlock layer\n",
    "tf.random.set_seed(42)\n",
    "dummy_nbeats_block_layer = NBeatsBlock(input_size=WINDOW_SIZE,\n",
    "                                      theta_size=WINDOW_SIZE+HORIZON,\n",
    "                                      horizon = HORIZON,\n",
    "                                      n_neurons=128,\n",
    "                                      n_layers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdae7089",
   "metadata": {},
   "source": [
    "### Create dummy inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c9d40159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([1, 2, 3, 4, 5, 6, 7])>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.range(WINDOW_SIZE)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0c7b6ac8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1, 7])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs = tf.expand_dims(tf.range(WINDOW_SIZE)+1,axis=0)\n",
    "dummy_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8b7018e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6, 7]])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8f13d070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6, 7]])>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cf314d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backcast:[[ 0.07960171  0.32512033 -0.8428683  -0.6938985  -0.31720552 -0.5698734\n",
      "  -0.6396662 ]]\n",
      "Forecast:[[1.0071648]]\n"
     ]
    }
   ],
   "source": [
    "backcast,forecast = dummy_nbeats_block_layer(dummy_inputs)\n",
    "print(f\"Backcast:{backcast.numpy()}\")\n",
    "print(f\"Forecast:{forecast.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a269c30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backcast:[ 0.07960171  0.32512033 -0.8428683  -0.6938985  -0.31720552 -0.5698734\n",
      " -0.6396662 ]\n",
      "Forecast:1.0071648359298706\n"
     ]
    }
   ],
   "source": [
    "backcast,forecast = dummy_nbeats_block_layer(dummy_inputs)\n",
    "print(f\"Backcast:{tf.squeeze(backcast.numpy())}\")\n",
    "print(f\"Forecast:{tf.squeeze(forecast.numpy())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eae56d5",
   "metadata": {},
   "source": [
    "### Preparing data for the N-beats algorithm using tf.data\n",
    "\n",
    "*pake data pipeline untuk best practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9918cbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1\n",
    "WINDOW_SIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1831d89f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price\n",
       "Date                 \n",
       "2013-10-01  123.65499\n",
       "2013-10-02  125.45500\n",
       "2013-10-03  108.58483\n",
       "2013-10-04  118.67466\n",
       "2013-10-05  121.33866"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create data pipeline inputs\n",
    "bitcoin_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec3e64f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price    Price+1    Price+2    Price+3    Price+4  Price+5  \\\n",
       "Date                                                                         \n",
       "2013-10-01  123.65499        NaN        NaN        NaN        NaN      NaN   \n",
       "2013-10-02  125.45500  123.65499        NaN        NaN        NaN      NaN   \n",
       "2013-10-03  108.58483  125.45500  123.65499        NaN        NaN      NaN   \n",
       "2013-10-04  118.67466  108.58483  125.45500  123.65499        NaN      NaN   \n",
       "2013-10-05  121.33866  118.67466  108.58483  125.45500  123.65499      NaN   \n",
       "\n",
       "            Price+6  Price+7  \n",
       "Date                          \n",
       "2013-10-01      NaN      NaN  \n",
       "2013-10-02      NaN      NaN  \n",
       "2013-10-03      NaN      NaN  \n",
       "2013-10-04      NaN      NaN  \n",
       "2013-10-05      NaN      NaN  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add windowed columns\n",
    "bitcoin_prices_nbeats = bitcoin_prices.copy()\n",
    "for i in range(WINDOW_SIZE):\n",
    "    bitcoin_prices_nbeats[f\"Price+{i+1}\"] = bitcoin_prices_nbeats[\"Price\"].shift(periods=i+1)\n",
    "bitcoin_prices_nbeats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6d80c903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2224, 556)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mak features and labels\n",
    "X = bitcoin_prices_nbeats.dropna().drop(\"Price\",axis=1)\n",
    "y = bitcoin_prices_nbeats.dropna()[\"Price\"]\n",
    "\n",
    "# make train and test sets\n",
    "split_size = int(len(X)*0.8)\n",
    "X_train,y_train = X[:split_size],y[:split_size]\n",
    "X_test,y_test = X[split_size:],y[split_size:]\n",
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6e55f50a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 7), (None,)), types: (tf.float64, tf.float64)>,\n",
       " <PrefetchDataset shapes: ((None, 7), (None,)), types: (tf.float64, tf.float64)>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time to make our dataset performan using tf.data API\n",
    "\n",
    "train_feautres_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "train_labeles_dataset = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "\n",
    "test_feautres_dataset = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "test_labeles_dataset = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "\n",
    "#Combine labels and features by zipping\n",
    "\n",
    "train_dataset = tf.data.Dataset.zip((train_feautres_dataset,train_labeles_dataset))\n",
    "test_dataset = tf.data.Dataset.zip((test_feautres_dataset,test_labeles_dataset))\n",
    "\n",
    "# Batch and prefetch\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "train_dataset= train_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset= test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_dataset,test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e411e67",
   "metadata": {},
   "source": [
    "### Setting up hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0716ccba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_EPOCHS = 5000\n",
    "N_NEURONS = 512\n",
    "N_LAYERS = 4\n",
    "N_STACKS = 30\n",
    "\n",
    "INPUT_SIZE = WINDOW_SIZE*HORIZON\n",
    "THETA_SIZE = INPUT_SIZE +HORIZON\n",
    "\n",
    "INPUT_SIZE, THETA_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192faf11",
   "metadata": {},
   "source": [
    "### membutuhkan 2 layer tambahan untuk residual koneksi (subtract and add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dbf3c511",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_1 = tf.range(10)+10\n",
    "tensor_2 = tf.range(10)\n",
    "\n",
    "# subtract\n",
    "subtacted = layers.subtract([tensor_1,tensor_2])\n",
    "\n",
    "# added\n",
    "added = layers.add([tensor_1,tensor_2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11c74d4",
   "metadata": {},
   "source": [
    "### Building model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "63519827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3/3 [==============================] - 9s 796ms/step - loss: 39965.1328 - mae: 39965.1328 - val_loss: 7229.5254 - val_mae: 7229.5254 - lr: 0.0010\n",
      "Epoch 2/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 7403.0356 - mae: 7403.0356 - val_loss: 6877.1313 - val_mae: 6877.1313 - lr: 0.0010\n",
      "Epoch 3/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 726.6044 - mae: 726.6044 - val_loss: 1638.0896 - val_mae: 1638.0896 - lr: 0.0010\n",
      "Epoch 4/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 895.4393 - mae: 895.4393 - val_loss: 1254.0649 - val_mae: 1254.0649 - lr: 0.0010\n",
      "Epoch 5/5000\n",
      "3/3 [==============================] - 0s 146ms/step - loss: 540.3207 - mae: 540.3207 - val_loss: 1029.8821 - val_mae: 1029.8821 - lr: 0.0010\n",
      "Epoch 6/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 440.8030 - mae: 440.8030 - val_loss: 2337.2297 - val_mae: 2337.2297 - lr: 0.0010\n",
      "Epoch 7/5000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 713.1791 - mae: 713.1791 - val_loss: 1073.3860 - val_mae: 1073.3860 - lr: 0.0010\n",
      "Epoch 8/5000\n",
      "3/3 [==============================] - 0s 111ms/step - loss: 273.9059 - mae: 273.9059 - val_loss: 4744.9600 - val_mae: 4744.9600 - lr: 0.0010\n",
      "Epoch 9/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 1440.5201 - mae: 1440.5201 - val_loss: 2716.8472 - val_mae: 2716.8472 - lr: 0.0010\n",
      "Epoch 10/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 885.3491 - mae: 885.3491 - val_loss: 3063.4487 - val_mae: 3063.4487 - lr: 0.0010\n",
      "Epoch 11/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 334.3727 - mae: 334.3727 - val_loss: 2244.8044 - val_mae: 2244.8044 - lr: 0.0010\n",
      "Epoch 12/5000\n",
      "3/3 [==============================] - 0s 150ms/step - loss: 445.0687 - mae: 445.0687 - val_loss: 850.2482 - val_mae: 850.2482 - lr: 0.0010\n",
      "Epoch 13/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 149.0172 - mae: 149.0172 - val_loss: 1432.5195 - val_mae: 1432.5195 - lr: 0.0010\n",
      "Epoch 14/5000\n",
      "3/3 [==============================] - 0s 149ms/step - loss: 282.6999 - mae: 282.6999 - val_loss: 696.5941 - val_mae: 696.5941 - lr: 0.0010\n",
      "Epoch 15/5000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 124.1610 - mae: 124.1610 - val_loss: 1444.9836 - val_mae: 1444.9836 - lr: 0.0010\n",
      "Epoch 16/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 304.4174 - mae: 304.4174 - val_loss: 3152.6340 - val_mae: 3152.6340 - lr: 0.0010\n",
      "Epoch 17/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 1070.0096 - mae: 1070.0096 - val_loss: 1781.0697 - val_mae: 1781.0697 - lr: 0.0010\n",
      "Epoch 18/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 208.2353 - mae: 208.2353 - val_loss: 980.8828 - val_mae: 980.8828 - lr: 0.0010\n",
      "Epoch 19/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 256.3492 - mae: 256.3492 - val_loss: 2291.5186 - val_mae: 2291.5186 - lr: 0.0010\n",
      "Epoch 20/5000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 544.0620 - mae: 544.0620 - val_loss: 905.2733 - val_mae: 905.2733 - lr: 0.0010\n",
      "Epoch 21/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 391.0331 - mae: 391.0331 - val_loss: 1335.3082 - val_mae: 1335.3082 - lr: 0.0010\n",
      "Epoch 22/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 187.7235 - mae: 187.7234 - val_loss: 1033.9475 - val_mae: 1033.9475 - lr: 0.0010\n",
      "Epoch 23/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 193.2955 - mae: 193.2955 - val_loss: 1286.5708 - val_mae: 1286.5708 - lr: 0.0010\n",
      "Epoch 24/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 306.8769 - mae: 306.8769 - val_loss: 970.2806 - val_mae: 970.2806 - lr: 0.0010\n",
      "Epoch 25/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 359.8948 - mae: 359.8948 - val_loss: 1120.5614 - val_mae: 1120.5614 - lr: 0.0010\n",
      "Epoch 26/5000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 169.2304 - mae: 169.2304 - val_loss: 789.9968 - val_mae: 789.9968 - lr: 0.0010\n",
      "Epoch 27/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 172.8675 - mae: 172.8675 - val_loss: 1712.7948 - val_mae: 1712.7948 - lr: 0.0010\n",
      "Epoch 28/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 438.4444 - mae: 438.4444 - val_loss: 705.4465 - val_mae: 705.4465 - lr: 0.0010\n",
      "Epoch 29/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 338.7339 - mae: 338.7339 - val_loss: 858.1792 - val_mae: 858.1792 - lr: 0.0010\n",
      "Epoch 30/5000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 279.7309 - mae: 279.7309 - val_loss: 1425.7925 - val_mae: 1425.7925 - lr: 0.0010\n",
      "Epoch 31/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 173.6867 - mae: 173.6867 - val_loss: 864.9904 - val_mae: 864.9904 - lr: 0.0010\n",
      "Epoch 32/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 146.3570 - mae: 146.3570 - val_loss: 785.5479 - val_mae: 785.5479 - lr: 0.0010\n",
      "Epoch 33/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 137.9941 - mae: 137.9941 - val_loss: 1027.3453 - val_mae: 1027.3453 - lr: 0.0010\n",
      "Epoch 34/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 242.4478 - mae: 242.4478 - val_loss: 1210.9818 - val_mae: 1210.9818 - lr: 0.0010\n",
      "Epoch 35/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 457.6723 - mae: 457.6723 - val_loss: 1589.9965 - val_mae: 1589.9965 - lr: 0.0010\n",
      "Epoch 36/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 165.5051 - mae: 165.5051 - val_loss: 1166.2454 - val_mae: 1166.2454 - lr: 0.0010\n",
      "Epoch 37/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 188.6732 - mae: 188.6732 - val_loss: 897.3150 - val_mae: 897.3150 - lr: 0.0010\n",
      "Epoch 38/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 245.1331 - mae: 245.1331 - val_loss: 802.4850 - val_mae: 802.4850 - lr: 0.0010\n",
      "Epoch 39/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 194.9196 - mae: 194.9196 - val_loss: 882.9373 - val_mae: 882.9373 - lr: 0.0010\n",
      "Epoch 40/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 156.3790 - mae: 156.3790 - val_loss: 797.8779 - val_mae: 797.8779 - lr: 0.0010\n",
      "Epoch 41/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 132.5749 - mae: 132.5749 - val_loss: 726.8569 - val_mae: 726.8569 - lr: 0.0010\n",
      "Epoch 42/5000\n",
      "3/3 [==============================] - 0s 165ms/step - loss: 124.4634 - mae: 124.4634 - val_loss: 679.9580 - val_mae: 679.9580 - lr: 0.0010\n",
      "Epoch 43/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 138.1503 - mae: 138.1503 - val_loss: 788.1620 - val_mae: 788.1620 - lr: 0.0010\n",
      "Epoch 44/5000\n",
      "3/3 [==============================] - 0s 173ms/step - loss: 222.9060 - mae: 222.9060 - val_loss: 625.4501 - val_mae: 625.4501 - lr: 0.0010\n",
      "Epoch 45/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 224.8990 - mae: 224.8990 - val_loss: 933.3217 - val_mae: 933.3217 - lr: 0.0010\n",
      "Epoch 46/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 138.1661 - mae: 138.1661 - val_loss: 806.7639 - val_mae: 806.7639 - lr: 0.0010\n",
      "Epoch 47/5000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 130.3877 - mae: 130.3877 - val_loss: 824.2864 - val_mae: 824.2864 - lr: 0.0010\n",
      "Epoch 48/5000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 163.3341 - mae: 163.3341 - val_loss: 657.7478 - val_mae: 657.7478 - lr: 0.0010\n",
      "Epoch 49/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 178.5568 - mae: 178.5568 - val_loss: 690.7619 - val_mae: 690.7619 - lr: 0.0010\n",
      "Epoch 50/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 143.6362 - mae: 143.6362 - val_loss: 748.0850 - val_mae: 748.0850 - lr: 0.0010\n",
      "Epoch 51/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 125.1886 - mae: 125.1886 - val_loss: 655.4506 - val_mae: 655.4506 - lr: 0.0010\n",
      "Epoch 52/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 121.3943 - mae: 121.3943 - val_loss: 644.0849 - val_mae: 644.0849 - lr: 0.0010\n",
      "Epoch 53/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 127.4604 - mae: 127.4604 - val_loss: 652.6578 - val_mae: 652.6578 - lr: 0.0010\n",
      "Epoch 54/5000\n",
      "3/3 [==============================] - 0s 151ms/step - loss: 147.7960 - mae: 147.7960 - val_loss: 612.3725 - val_mae: 612.3725 - lr: 0.0010\n",
      "Epoch 55/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 154.5345 - mae: 154.5345 - val_loss: 615.1426 - val_mae: 615.1426 - lr: 0.0010\n",
      "Epoch 56/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 144.9228 - mae: 144.9228 - val_loss: 648.0211 - val_mae: 648.0211 - lr: 0.0010\n",
      "Epoch 57/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 132.5465 - mae: 132.5465 - val_loss: 614.6702 - val_mae: 614.6702 - lr: 0.0010\n",
      "Epoch 58/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 132.6079 - mae: 132.6079 - val_loss: 630.1710 - val_mae: 630.1710 - lr: 0.0010\n",
      "Epoch 59/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 132.2815 - mae: 132.2815 - val_loss: 622.4666 - val_mae: 622.4666 - lr: 0.0010\n",
      "Epoch 60/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 144.2286 - mae: 144.2286 - val_loss: 635.7831 - val_mae: 635.7831 - lr: 0.0010\n",
      "Epoch 61/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 141.6304 - mae: 141.6304 - val_loss: 618.6328 - val_mae: 618.6328 - lr: 0.0010\n",
      "Epoch 62/5000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 140.5760 - mae: 140.5760 - val_loss: 662.3710 - val_mae: 662.3710 - lr: 0.0010\n",
      "Epoch 63/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 131.2871 - mae: 131.2871 - val_loss: 627.3552 - val_mae: 627.3552 - lr: 0.0010\n",
      "Epoch 64/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 128.1579 - mae: 128.1579 - val_loss: 652.3232 - val_mae: 652.3232 - lr: 0.0010\n",
      "Epoch 65/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 120.3566 - mae: 120.3566 - val_loss: 616.2949 - val_mae: 616.2949 - lr: 0.0010\n",
      "Epoch 66/5000\n",
      "3/3 [==============================] - 0s 158ms/step - loss: 128.0517 - mae: 128.0517 - val_loss: 608.2079 - val_mae: 608.2079 - lr: 0.0010\n",
      "Epoch 67/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 129.0240 - mae: 129.0240 - val_loss: 626.4567 - val_mae: 626.4567 - lr: 0.0010\n",
      "Epoch 68/5000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 157.3739 - mae: 157.3739 - val_loss: 636.8206 - val_mae: 636.8206 - lr: 0.0010\n",
      "Epoch 69/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 143.6028 - mae: 143.6028 - val_loss: 632.2822 - val_mae: 632.2822 - lr: 0.0010\n",
      "Epoch 70/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 130.1517 - mae: 130.1517 - val_loss: 666.0176 - val_mae: 666.0176 - lr: 0.0010\n",
      "Epoch 71/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 121.8256 - mae: 121.8256 - val_loss: 626.1979 - val_mae: 626.1979 - lr: 0.0010\n",
      "Epoch 72/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 118.1993 - mae: 118.1993 - val_loss: 618.1436 - val_mae: 618.1436 - lr: 0.0010\n",
      "Epoch 73/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 119.4569 - mae: 119.4569 - val_loss: 637.7909 - val_mae: 637.7909 - lr: 0.0010\n",
      "Epoch 74/5000\n",
      "3/3 [==============================] - 0s 154ms/step - loss: 149.7036 - mae: 149.7036 - val_loss: 604.6997 - val_mae: 604.6997 - lr: 0.0010\n",
      "Epoch 75/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 155.2301 - mae: 155.2301 - val_loss: 613.4810 - val_mae: 613.4810 - lr: 0.0010\n",
      "Epoch 76/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 145.4662 - mae: 145.4662 - val_loss: 711.2293 - val_mae: 711.2293 - lr: 0.0010\n",
      "Epoch 77/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 125.2160 - mae: 125.2160 - val_loss: 658.1572 - val_mae: 658.1572 - lr: 0.0010\n",
      "Epoch 78/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 113.5793 - mae: 113.5793 - val_loss: 647.1178 - val_mae: 647.1178 - lr: 0.0010\n",
      "Epoch 79/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 111.3256 - mae: 111.3256 - val_loss: 629.4971 - val_mae: 629.4971 - lr: 0.0010\n",
      "Epoch 80/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 118.4048 - mae: 118.4048 - val_loss: 613.1133 - val_mae: 613.1133 - lr: 0.0010\n",
      "Epoch 81/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 136.0335 - mae: 136.0335 - val_loss: 617.8605 - val_mae: 617.8605 - lr: 0.0010\n",
      "Epoch 82/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 165.5478 - mae: 165.5478 - val_loss: 634.0537 - val_mae: 634.0537 - lr: 0.0010\n",
      "Epoch 83/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 144.1205 - mae: 144.1205 - val_loss: 627.3460 - val_mae: 627.3460 - lr: 0.0010\n",
      "Epoch 84/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 130.4716 - mae: 130.4716 - val_loss: 675.1162 - val_mae: 675.1162 - lr: 0.0010\n",
      "Epoch 85/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 119.0117 - mae: 119.0117 - val_loss: 628.1384 - val_mae: 628.1384 - lr: 0.0010\n",
      "Epoch 86/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 118.6381 - mae: 118.6381 - val_loss: 636.8201 - val_mae: 636.8201 - lr: 0.0010\n",
      "Epoch 87/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 118.5092 - mae: 118.5092 - val_loss: 622.9928 - val_mae: 622.9928 - lr: 0.0010\n",
      "Epoch 88/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 124.3395 - mae: 124.3395 - val_loss: 613.9252 - val_mae: 613.9252 - lr: 0.0010\n",
      "Epoch 89/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 126.7499 - mae: 126.7499 - val_loss: 610.9008 - val_mae: 610.9008 - lr: 0.0010\n",
      "Epoch 90/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 141.2451 - mae: 141.2451 - val_loss: 625.7866 - val_mae: 625.7866 - lr: 0.0010\n",
      "Epoch 91/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 131.6559 - mae: 131.6559 - val_loss: 607.3901 - val_mae: 607.3901 - lr: 0.0010\n",
      "Epoch 92/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 133.9653 - mae: 133.9653 - val_loss: 649.6838 - val_mae: 649.6838 - lr: 0.0010\n",
      "Epoch 93/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 123.2928 - mae: 123.2928 - val_loss: 614.9291 - val_mae: 614.9291 - lr: 0.0010\n",
      "Epoch 94/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 122.7518 - mae: 122.7518 - val_loss: 628.1685 - val_mae: 628.1685 - lr: 0.0010\n",
      "Epoch 95/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 121.8199 - mae: 121.8199 - val_loss: 614.1572 - val_mae: 614.1572 - lr: 0.0010\n",
      "Epoch 96/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 128.1822 - mae: 128.1822 - val_loss: 630.6202 - val_mae: 630.6202 - lr: 0.0010\n",
      "Epoch 97/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 119.5734 - mae: 119.5734 - val_loss: 609.6875 - val_mae: 609.6875 - lr: 0.0010\n",
      "Epoch 98/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 126.0262 - mae: 126.0262 - val_loss: 627.0678 - val_mae: 627.0678 - lr: 0.0010\n",
      "Epoch 99/5000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 121.8531 - mae: 121.8531 - val_loss: 611.3918 - val_mae: 611.3918 - lr: 0.0010\n",
      "Epoch 100/5000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 126.0020 - mae: 126.0020 - val_loss: 639.9996 - val_mae: 639.9996 - lr: 0.0010\n",
      "Epoch 101/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 115.9133 - mae: 115.9133 - val_loss: 610.7062 - val_mae: 610.7062 - lr: 0.0010\n",
      "Epoch 102/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 120.4196 - mae: 120.4196 - val_loss: 625.0842 - val_mae: 625.0842 - lr: 0.0010\n",
      "Epoch 103/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 113.9141 - mae: 113.9141 - val_loss: 607.4387 - val_mae: 607.4387 - lr: 0.0010\n",
      "Epoch 104/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 124.7789 - mae: 124.7789 - val_loss: 608.2118 - val_mae: 608.2118 - lr: 0.0010\n",
      "Epoch 105/5000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 127.2389 - mae: 127.2389 - val_loss: 617.5670 - val_mae: 617.5670 - lr: 0.0010\n",
      "Epoch 106/5000\n",
      "3/3 [==============================] - 0s 98ms/step - loss: 141.6349 - mae: 141.6349 - val_loss: 677.4125 - val_mae: 677.4125 - lr: 0.0010\n",
      "Epoch 107/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 81ms/step - loss: 120.1055 - mae: 120.1055 - val_loss: 623.0635 - val_mae: 623.0635 - lr: 0.0010\n",
      "Epoch 108/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 116.1826 - mae: 116.1826 - val_loss: 653.3371 - val_mae: 653.3371 - lr: 0.0010\n",
      "Epoch 109/5000\n",
      "3/3 [==============================] - 0s 70ms/step - loss: 108.2681 - mae: 108.2681 - val_loss: 613.2581 - val_mae: 613.2581 - lr: 0.0010\n",
      "Epoch 110/5000\n",
      "3/3 [==============================] - 0s 160ms/step - loss: 105.4800 - mae: 105.4800 - val_loss: 600.5476 - val_mae: 600.5476 - lr: 0.0010\n",
      "Epoch 111/5000\n",
      "3/3 [==============================] - 0s 157ms/step - loss: 105.0348 - mae: 105.0348 - val_loss: 596.6651 - val_mae: 596.6651 - lr: 0.0010\n",
      "Epoch 112/5000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 118.1175 - mae: 118.1175 - val_loss: 609.3514 - val_mae: 609.3514 - lr: 0.0010\n",
      "Epoch 113/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 137.6308 - mae: 137.6308 - val_loss: 638.5224 - val_mae: 638.5224 - lr: 0.0010\n",
      "Epoch 114/5000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 172.2711 - mae: 172.2711 - val_loss: 775.2786 - val_mae: 775.2786 - lr: 0.0010\n",
      "Epoch 115/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 121.9770 - mae: 121.9770 - val_loss: 672.3805 - val_mae: 672.3805 - lr: 0.0010\n",
      "Epoch 116/5000\n",
      "3/3 [==============================] - 0s 180ms/step - loss: 105.2748 - mae: 105.2748 - val_loss: 591.4251 - val_mae: 591.4251 - lr: 0.0010\n",
      "Epoch 117/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 106.6195 - mae: 106.6195 - val_loss: 705.9746 - val_mae: 705.9746 - lr: 0.0010\n",
      "Epoch 118/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 159.3280 - mae: 159.3280 - val_loss: 622.9774 - val_mae: 622.9774 - lr: 0.0010\n",
      "Epoch 119/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 147.2136 - mae: 147.2136 - val_loss: 686.3676 - val_mae: 686.3676 - lr: 0.0010\n",
      "Epoch 120/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 113.4200 - mae: 113.4200 - val_loss: 715.3223 - val_mae: 715.3223 - lr: 0.0010\n",
      "Epoch 121/5000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 104.7250 - mae: 104.7250 - val_loss: 619.5096 - val_mae: 619.5096 - lr: 0.0010\n",
      "Epoch 122/5000\n",
      "3/3 [==============================] - 0s 99ms/step - loss: 98.9318 - mae: 98.9318 - val_loss: 616.5745 - val_mae: 616.5745 - lr: 0.0010\n",
      "Epoch 123/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 98.6407 - mae: 98.6407 - val_loss: 615.7259 - val_mae: 615.7259 - lr: 0.0010\n",
      "Epoch 124/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 102.8311 - mae: 102.8311 - val_loss: 655.7219 - val_mae: 655.7219 - lr: 0.0010\n",
      "Epoch 125/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 141.4739 - mae: 141.4739 - val_loss: 628.0151 - val_mae: 628.0151 - lr: 0.0010\n",
      "Epoch 126/5000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 182.4116 - mae: 182.4116 - val_loss: 632.6960 - val_mae: 632.6960 - lr: 0.0010\n",
      "Epoch 127/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 141.7612 - mae: 141.7612 - val_loss: 761.5012 - val_mae: 761.5012 - lr: 0.0010\n",
      "Epoch 128/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 116.3848 - mae: 116.3848 - val_loss: 640.0383 - val_mae: 640.0383 - lr: 0.0010\n",
      "Epoch 129/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 103.4253 - mae: 103.4253 - val_loss: 616.9666 - val_mae: 616.9666 - lr: 0.0010\n",
      "Epoch 130/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 100.0725 - mae: 100.0725 - val_loss: 593.1357 - val_mae: 593.1357 - lr: 0.0010\n",
      "Epoch 131/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 104.7711 - mae: 104.7711 - val_loss: 680.2235 - val_mae: 680.2235 - lr: 0.0010\n",
      "Epoch 132/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 144.1428 - mae: 144.1428 - val_loss: 864.8360 - val_mae: 864.8360 - lr: 0.0010\n",
      "Epoch 133/5000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 237.6003 - mae: 237.6003 - val_loss: 949.9543 - val_mae: 949.9543 - lr: 0.0010\n",
      "Epoch 134/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 128.0656 - mae: 128.0656 - val_loss: 811.0730 - val_mae: 811.0730 - lr: 0.0010\n",
      "Epoch 135/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 127.3463 - mae: 127.3463 - val_loss: 837.1000 - val_mae: 837.1000 - lr: 0.0010\n",
      "Epoch 136/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 184.8548 - mae: 184.8548 - val_loss: 613.3355 - val_mae: 613.3355 - lr: 0.0010\n",
      "Epoch 137/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 195.0087 - mae: 195.0087 - val_loss: 819.1852 - val_mae: 819.1852 - lr: 0.0010\n",
      "Epoch 138/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 118.7345 - mae: 118.7345 - val_loss: 786.4086 - val_mae: 786.4086 - lr: 0.0010\n",
      "Epoch 139/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 120.5967 - mae: 120.5967 - val_loss: 643.5201 - val_mae: 643.5201 - lr: 0.0010\n",
      "Epoch 140/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 122.5985 - mae: 122.5985 - val_loss: 640.4148 - val_mae: 640.4148 - lr: 0.0010\n",
      "Epoch 141/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 140.2226 - mae: 140.2226 - val_loss: 603.6633 - val_mae: 603.6633 - lr: 0.0010\n",
      "Epoch 142/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 135.7552 - mae: 135.7552 - val_loss: 595.5047 - val_mae: 595.5047 - lr: 0.0010\n",
      "Epoch 143/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 133.1434 - mae: 133.1434 - val_loss: 681.0139 - val_mae: 681.0139 - lr: 0.0010\n",
      "Epoch 144/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 114.5253 - mae: 114.5253 - val_loss: 610.8444 - val_mae: 610.8444 - lr: 0.0010\n",
      "Epoch 145/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 106.8816 - mae: 106.8816 - val_loss: 609.0026 - val_mae: 609.0026 - lr: 0.0010\n",
      "Epoch 146/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 111.4243 - mae: 111.4243 - val_loss: 612.8884 - val_mae: 612.8884 - lr: 0.0010\n",
      "Epoch 147/5000\n",
      "3/3 [==============================] - 0s 159ms/step - loss: 130.0812 - mae: 130.0812 - val_loss: 583.9232 - val_mae: 583.9232 - lr: 0.0010\n",
      "Epoch 148/5000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 132.1445 - mae: 132.1445 - val_loss: 591.5914 - val_mae: 591.5914 - lr: 0.0010\n",
      "Epoch 149/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 126.0425 - mae: 126.0425 - val_loss: 649.3336 - val_mae: 649.3336 - lr: 0.0010\n",
      "Epoch 150/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 105.3980 - mae: 105.3980 - val_loss: 609.5486 - val_mae: 609.5486 - lr: 0.0010\n",
      "Epoch 151/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 100.2798 - mae: 100.2798 - val_loss: 598.0356 - val_mae: 598.0356 - lr: 0.0010\n",
      "Epoch 152/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 99.1059 - mae: 99.1059 - val_loss: 601.1082 - val_mae: 601.1082 - lr: 0.0010\n",
      "Epoch 153/5000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 110.5409 - mae: 110.5409 - val_loss: 605.7071 - val_mae: 605.7071 - lr: 0.0010\n",
      "Epoch 154/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 134.5243 - mae: 134.5243 - val_loss: 600.6010 - val_mae: 600.6010 - lr: 0.0010\n",
      "Epoch 155/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 154.2334 - mae: 154.2334 - val_loss: 720.9116 - val_mae: 720.9116 - lr: 0.0010\n",
      "Epoch 156/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 108.3391 - mae: 108.3391 - val_loss: 633.2339 - val_mae: 633.2339 - lr: 0.0010\n",
      "Epoch 157/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 98.1845 - mae: 98.1845 - val_loss: 605.5792 - val_mae: 605.5792 - lr: 0.0010\n",
      "Epoch 158/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 95.7381 - mae: 95.7381 - val_loss: 602.9825 - val_mae: 602.9825 - lr: 0.0010\n",
      "Epoch 159/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 104.6170 - mae: 104.6170 - val_loss: 624.7252 - val_mae: 624.7252 - lr: 0.0010\n",
      "Epoch 160/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 133.4558 - mae: 133.4558 - val_loss: 592.4393 - val_mae: 592.4393 - lr: 0.0010\n",
      "Epoch 161/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 152.5244 - mae: 152.5244 - val_loss: 741.1505 - val_mae: 741.1505 - lr: 0.0010\n",
      "Epoch 162/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 109.5503 - mae: 109.5503 - val_loss: 656.6835 - val_mae: 656.6835 - lr: 0.0010\n",
      "Epoch 163/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 97.9400 - mae: 97.9400 - val_loss: 655.7742 - val_mae: 655.7742 - lr: 0.0010\n",
      "Epoch 164/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 102.7818 - mae: 102.7818 - val_loss: 634.6478 - val_mae: 634.6478 - lr: 0.0010\n",
      "Epoch 165/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 123.0609 - mae: 123.0609 - val_loss: 639.8599 - val_mae: 639.8599 - lr: 0.0010\n",
      "Epoch 166/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 163.5978 - mae: 163.5978 - val_loss: 731.3569 - val_mae: 731.3569 - lr: 0.0010\n",
      "Epoch 167/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 109.7441 - mae: 109.7441 - val_loss: 630.0448 - val_mae: 630.0448 - lr: 0.0010\n",
      "Epoch 168/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 103.1461 - mae: 103.1461 - val_loss: 596.4363 - val_mae: 596.4363 - lr: 0.0010\n",
      "Epoch 169/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 98.9700 - mae: 98.9700 - val_loss: 589.9572 - val_mae: 589.9572 - lr: 0.0010\n",
      "Epoch 170/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 97.6414 - mae: 97.6414 - val_loss: 599.0228 - val_mae: 599.0228 - lr: 0.0010\n",
      "Epoch 171/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 104.7028 - mae: 104.7028 - val_loss: 633.2844 - val_mae: 633.2844 - lr: 0.0010\n",
      "Epoch 172/5000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 128.8781 - mae: 128.8781 - val_loss: 616.1082 - val_mae: 616.1082 - lr: 0.0010\n",
      "Epoch 173/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 118.1424 - mae: 118.1424 - val_loss: 606.2302 - val_mae: 606.2302 - lr: 0.0010\n",
      "Epoch 174/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 112.9402 - mae: 112.9402 - val_loss: 626.7102 - val_mae: 626.7102 - lr: 0.0010\n",
      "Epoch 175/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 102.9964 - mae: 102.9964 - val_loss: 590.0605 - val_mae: 590.0605 - lr: 0.0010\n",
      "Epoch 176/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 104.0244 - mae: 104.0244 - val_loss: 585.9735 - val_mae: 585.9735 - lr: 0.0010\n",
      "Epoch 177/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 110.9453 - mae: 110.9453 - val_loss: 597.9151 - val_mae: 597.9151 - lr: 0.0010\n",
      "Epoch 178/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 131.4591 - mae: 131.4591 - val_loss: 633.8040 - val_mae: 633.8040 - lr: 0.0010\n",
      "Epoch 179/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 107.4878 - mae: 107.4878 - val_loss: 603.2762 - val_mae: 603.2762 - lr: 0.0010\n",
      "Epoch 180/5000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 103.4220 - mae: 103.4220 - val_loss: 613.1091 - val_mae: 613.1091 - lr: 0.0010\n",
      "Epoch 181/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 99.8346 - mae: 99.8346 - val_loss: 592.4977 - val_mae: 592.4977 - lr: 0.0010\n",
      "Epoch 182/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 100.6761 - mae: 100.6761 - val_loss: 590.5703 - val_mae: 590.5703 - lr: 0.0010\n",
      "Epoch 183/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 105.2242 - mae: 105.2242 - val_loss: 606.9357 - val_mae: 606.9357 - lr: 0.0010\n",
      "Epoch 184/5000\n",
      "3/3 [==============================] - 0s 91ms/step - loss: 124.4348 - mae: 124.4348 - val_loss: 627.4614 - val_mae: 627.4614 - lr: 0.0010\n",
      "Epoch 185/5000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 105.2506 - mae: 105.2506 - val_loss: 603.2062 - val_mae: 603.2062 - lr: 0.0010\n",
      "Epoch 186/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 105.9639 - mae: 105.9639 - val_loss: 620.2673 - val_mae: 620.2673 - lr: 0.0010\n",
      "Epoch 187/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 94.7771 - mae: 94.7771 - val_loss: 599.1430 - val_mae: 599.1430 - lr: 0.0010\n",
      "Epoch 188/5000\n",
      "3/3 [==============================] - 0s 69ms/step - loss: 98.8911 - mae: 98.8911 - val_loss: 597.0067 - val_mae: 597.0067 - lr: 0.0010\n",
      "Epoch 189/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 104.9144 - mae: 104.9144 - val_loss: 613.7418 - val_mae: 613.7418 - lr: 0.0010\n",
      "Epoch 190/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 123.6439 - mae: 123.6439 - val_loss: 626.4614 - val_mae: 626.4614 - lr: 0.0010\n",
      "Epoch 191/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 108.8322 - mae: 108.8322 - val_loss: 604.7034 - val_mae: 604.7034 - lr: 0.0010\n",
      "Epoch 192/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 110.4028 - mae: 110.4028 - val_loss: 635.1136 - val_mae: 635.1136 - lr: 0.0010\n",
      "Epoch 193/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 97.7805 - mae: 97.7805 - val_loss: 608.7405 - val_mae: 608.7405 - lr: 0.0010\n",
      "Epoch 194/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 98.5245 - mae: 98.5245 - val_loss: 599.6547 - val_mae: 599.6547 - lr: 0.0010\n",
      "Epoch 195/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 97.7483 - mae: 97.7483 - val_loss: 608.7889 - val_mae: 608.7889 - lr: 0.0010\n",
      "Epoch 196/5000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 115.7312 - mae: 115.7312 - val_loss: 629.1602 - val_mae: 629.1602 - lr: 0.0010\n",
      "Epoch 197/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 104.1144 - mae: 104.1144 - val_loss: 609.0784 - val_mae: 609.0784 - lr: 0.0010\n",
      "Epoch 198/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 112.0084 - mae: 112.0084 - val_loss: 609.5826 - val_mae: 609.5826 - lr: 0.0010\n",
      "Epoch 199/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 102.4216 - mae: 102.4216 - val_loss: 611.5264 - val_mae: 611.5264 - lr: 0.0010\n",
      "Epoch 200/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 126.8292 - mae: 126.8292 - val_loss: 694.0270 - val_mae: 694.0270 - lr: 0.0010\n",
      "Epoch 201/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 102.9052 - mae: 102.9052 - val_loss: 618.8674 - val_mae: 618.8674 - lr: 0.0010\n",
      "Epoch 202/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 98.9974 - mae: 98.9974 - val_loss: 594.0563 - val_mae: 594.0563 - lr: 0.0010\n",
      "Epoch 203/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 100.3742 - mae: 100.3742 - val_loss: 620.3102 - val_mae: 620.3102 - lr: 0.0010\n",
      "Epoch 204/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 117.9589 - mae: 117.9589 - val_loss: 619.2710 - val_mae: 619.2710 - lr: 0.0010\n",
      "Epoch 205/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 121.3457 - mae: 121.3457 - val_loss: 606.7239 - val_mae: 606.7239 - lr: 0.0010\n",
      "Epoch 206/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 120.8514 - mae: 120.8514 - val_loss: 668.2153 - val_mae: 668.2153 - lr: 0.0010\n",
      "Epoch 207/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 105.2134 - mae: 105.2134 - val_loss: 608.5440 - val_mae: 608.5440 - lr: 0.0010\n",
      "Epoch 208/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 99.8466 - mae: 99.8466 - val_loss: 609.8536 - val_mae: 609.8536 - lr: 0.0010\n",
      "Epoch 209/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 99.6062 - mae: 99.6062 - val_loss: 621.0189 - val_mae: 621.0189 - lr: 0.0010\n",
      "Epoch 210/5000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 129.6704 - mae: 129.6704 - val_loss: 657.2405 - val_mae: 657.2405 - lr: 0.0010\n",
      "Epoch 211/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 103.2523 - mae: 103.2523 - val_loss: 605.4832 - val_mae: 605.4832 - lr: 0.0010\n",
      "Epoch 212/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 103.0691 - mae: 103.0691 - val_loss: 605.1924 - val_mae: 605.1924 - lr: 0.0010\n",
      "Epoch 213/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 78ms/step - loss: 108.5193 - mae: 108.5193 - val_loss: 616.1448 - val_mae: 616.1448 - lr: 0.0010\n",
      "Epoch 214/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 126.0610 - mae: 126.0610 - val_loss: 644.3051 - val_mae: 644.3051 - lr: 0.0010\n",
      "Epoch 215/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 119.4647 - mae: 119.4647 - val_loss: 626.2604 - val_mae: 626.2604 - lr: 0.0010\n",
      "Epoch 216/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 120.8368 - mae: 120.8368 - val_loss: 656.5312 - val_mae: 656.5312 - lr: 0.0010\n",
      "Epoch 217/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 107.8688 - mae: 107.8688 - val_loss: 617.3557 - val_mae: 617.3557 - lr: 0.0010\n",
      "Epoch 218/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 114.0570 - mae: 114.0570 - val_loss: 593.0430 - val_mae: 593.0430 - lr: 0.0010\n",
      "Epoch 219/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 116.4055 - mae: 116.4055 - val_loss: 614.8925 - val_mae: 614.8925 - lr: 0.0010\n",
      "Epoch 220/5000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 137.9004 - mae: 137.9004 - val_loss: 692.8981 - val_mae: 692.8981 - lr: 0.0010\n",
      "Epoch 221/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 117.0289 - mae: 117.0289 - val_loss: 641.0042 - val_mae: 641.0042 - lr: 0.0010\n",
      "Epoch 222/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 98.3811 - mae: 98.3811 - val_loss: 621.1513 - val_mae: 621.1513 - lr: 0.0010\n",
      "Epoch 223/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 100.9420 - mae: 100.9420 - val_loss: 622.7375 - val_mae: 622.7375 - lr: 0.0010\n",
      "Epoch 224/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 99.0866 - mae: 99.0866 - val_loss: 640.9737 - val_mae: 640.9737 - lr: 0.0010\n",
      "Epoch 225/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 99.4210 - mae: 99.4210 - val_loss: 657.3254 - val_mae: 657.3254 - lr: 0.0010\n",
      "Epoch 226/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 121.8704 - mae: 121.8704 - val_loss: 608.7064 - val_mae: 608.7064 - lr: 0.0010\n",
      "Epoch 227/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 138.2496 - mae: 138.2496 - val_loss: 603.7247 - val_mae: 603.7247 - lr: 0.0010\n",
      "Epoch 228/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 124.6954 - mae: 124.6954 - val_loss: 711.8700 - val_mae: 711.8700 - lr: 0.0010\n",
      "Epoch 229/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 107.9215 - mae: 107.9215 - val_loss: 619.9607 - val_mae: 619.9607 - lr: 0.0010\n",
      "Epoch 230/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 101.3092 - mae: 101.3092 - val_loss: 606.8965 - val_mae: 606.8965 - lr: 0.0010\n",
      "Epoch 231/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 99.1259 - mae: 99.1259 - val_loss: 622.4932 - val_mae: 622.4932 - lr: 0.0010\n",
      "Epoch 232/5000\n",
      "3/3 [==============================] - 0s 102ms/step - loss: 116.0111 - mae: 116.0111 - val_loss: 596.7941 - val_mae: 596.7941 - lr: 0.0010\n",
      "Epoch 233/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 119.0748 - mae: 119.0748 - val_loss: 602.0912 - val_mae: 602.0912 - lr: 0.0010\n",
      "Epoch 234/5000\n",
      "3/3 [==============================] - 0s 92ms/step - loss: 113.8733 - mae: 113.8733 - val_loss: 622.9321 - val_mae: 622.9321 - lr: 0.0010\n",
      "Epoch 235/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 97.2767 - mae: 97.2767 - val_loss: 602.6047 - val_mae: 602.6047 - lr: 0.0010\n",
      "Epoch 236/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 100.5076 - mae: 100.5076 - val_loss: 614.0193 - val_mae: 614.0193 - lr: 0.0010\n",
      "Epoch 237/5000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 102.8259 - mae: 102.8259 - val_loss: 643.5553 - val_mae: 643.5553 - lr: 0.0010\n",
      "Epoch 238/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 118.3789 - mae: 118.3789 - val_loss: 637.6434 - val_mae: 637.6434 - lr: 0.0010\n",
      "Epoch 239/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 130.9792 - mae: 130.9792 - val_loss: 598.9166 - val_mae: 598.9166 - lr: 0.0010\n",
      "Epoch 240/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 117.2329 - mae: 117.2329 - val_loss: 621.8008 - val_mae: 621.8008 - lr: 0.0010\n",
      "Epoch 241/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 120.8162 - mae: 120.8162 - val_loss: 599.1204 - val_mae: 599.1204 - lr: 0.0010\n",
      "Epoch 242/5000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 118.8297 - mae: 118.8297 - val_loss: 584.7728 - val_mae: 584.7728 - lr: 0.0010\n",
      "Epoch 243/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 130.0709 - mae: 130.0709 - val_loss: 617.5623 - val_mae: 617.5623 - lr: 0.0010\n",
      "Epoch 244/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 156.3841 - mae: 156.3841 - val_loss: 719.1967 - val_mae: 719.1967 - lr: 0.0010\n",
      "Epoch 245/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 114.1251 - mae: 114.1251 - val_loss: 681.4778 - val_mae: 681.4778 - lr: 0.0010\n",
      "Epoch 246/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 102.2059 - mae: 102.2059 - val_loss: 662.2768 - val_mae: 662.2768 - lr: 0.0010\n",
      "Epoch 247/5000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 99.1681 - mae: 99.1681\n",
      "Epoch 247: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 112.7408 - mae: 112.7408 - val_loss: 634.4069 - val_mae: 634.4069 - lr: 0.0010\n",
      "Epoch 248/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 102.1646 - mae: 102.1646 - val_loss: 643.1404 - val_mae: 643.1404 - lr: 1.0000e-04\n",
      "Epoch 249/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 99.5414 - mae: 99.5414 - val_loss: 622.5222 - val_mae: 622.5222 - lr: 1.0000e-04\n",
      "Epoch 250/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 95.0155 - mae: 95.0155 - val_loss: 617.0999 - val_mae: 617.0999 - lr: 1.0000e-04\n",
      "Epoch 251/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 96.1026 - mae: 96.1026 - val_loss: 621.5380 - val_mae: 621.5380 - lr: 1.0000e-04\n",
      "Epoch 252/5000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 95.8449 - mae: 95.8449 - val_loss: 616.0847 - val_mae: 616.0847 - lr: 1.0000e-04\n",
      "Epoch 253/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 93.2592 - mae: 93.2592 - val_loss: 614.0793 - val_mae: 614.0793 - lr: 1.0000e-04\n",
      "Epoch 254/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 92.2833 - mae: 92.2833 - val_loss: 617.8141 - val_mae: 617.8141 - lr: 1.0000e-04\n",
      "Epoch 255/5000\n",
      "3/3 [==============================] - 0s 100ms/step - loss: 92.1837 - mae: 92.1837 - val_loss: 616.4821 - val_mae: 616.4821 - lr: 1.0000e-04\n",
      "Epoch 256/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 91.1970 - mae: 91.1970 - val_loss: 613.6337 - val_mae: 613.6337 - lr: 1.0000e-04\n",
      "Epoch 257/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 90.8200 - mae: 90.8200 - val_loss: 612.6417 - val_mae: 612.6417 - lr: 1.0000e-04\n",
      "Epoch 258/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 90.4690 - mae: 90.4690 - val_loss: 612.1332 - val_mae: 612.1332 - lr: 1.0000e-04\n",
      "Epoch 259/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 89.8191 - mae: 89.8191 - val_loss: 612.0381 - val_mae: 612.0381 - lr: 1.0000e-04\n",
      "Epoch 260/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 89.5153 - mae: 89.5153 - val_loss: 611.6883 - val_mae: 611.6883 - lr: 1.0000e-04\n",
      "Epoch 261/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 89.0805 - mae: 89.0805 - val_loss: 610.8340 - val_mae: 610.8340 - lr: 1.0000e-04\n",
      "Epoch 262/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 88.8227 - mae: 88.8227 - val_loss: 610.6323 - val_mae: 610.6323 - lr: 1.0000e-04\n",
      "Epoch 263/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 88.3933 - mae: 88.3933 - val_loss: 610.8345 - val_mae: 610.8345 - lr: 1.0000e-04\n",
      "Epoch 264/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 88.1132 - mae: 88.1132 - val_loss: 610.9713 - val_mae: 610.9713 - lr: 1.0000e-04\n",
      "Epoch 265/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 72ms/step - loss: 87.8619 - mae: 87.8619 - val_loss: 610.5778 - val_mae: 610.5778 - lr: 1.0000e-04\n",
      "Epoch 266/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 87.6584 - mae: 87.6584 - val_loss: 610.5273 - val_mae: 610.5273 - lr: 1.0000e-04\n",
      "Epoch 267/5000\n",
      "3/3 [==============================] - 0s 88ms/step - loss: 87.3693 - mae: 87.3693 - val_loss: 610.8731 - val_mae: 610.8731 - lr: 1.0000e-04\n",
      "Epoch 268/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 87.1800 - mae: 87.1800 - val_loss: 610.8865 - val_mae: 610.8865 - lr: 1.0000e-04\n",
      "Epoch 269/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 86.9925 - mae: 86.9925 - val_loss: 610.8139 - val_mae: 610.8139 - lr: 1.0000e-04\n",
      "Epoch 270/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 86.7340 - mae: 86.7340 - val_loss: 610.8435 - val_mae: 610.8435 - lr: 1.0000e-04\n",
      "Epoch 271/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 86.5352 - mae: 86.5352 - val_loss: 610.6134 - val_mae: 610.6134 - lr: 1.0000e-04\n",
      "Epoch 272/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 86.3325 - mae: 86.3325 - val_loss: 610.4147 - val_mae: 610.4147 - lr: 1.0000e-04\n",
      "Epoch 273/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 86.1733 - mae: 86.1733 - val_loss: 610.5356 - val_mae: 610.5356 - lr: 1.0000e-04\n",
      "Epoch 274/5000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 85.9472 - mae: 85.9472 - val_loss: 610.8728 - val_mae: 610.8728 - lr: 1.0000e-04\n",
      "Epoch 275/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 85.7204 - mae: 85.7204 - val_loss: 610.6653 - val_mae: 610.6653 - lr: 1.0000e-04\n",
      "Epoch 276/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 85.5089 - mae: 85.5089 - val_loss: 610.2698 - val_mae: 610.2698 - lr: 1.0000e-04\n",
      "Epoch 277/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 85.6481 - mae: 85.6481 - val_loss: 610.7441 - val_mae: 610.7441 - lr: 1.0000e-04\n",
      "Epoch 278/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 85.3814 - mae: 85.3814 - val_loss: 611.4826 - val_mae: 611.4826 - lr: 1.0000e-04\n",
      "Epoch 279/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 85.1234 - mae: 85.1234 - val_loss: 611.7511 - val_mae: 611.7511 - lr: 1.0000e-04\n",
      "Epoch 280/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 84.8907 - mae: 84.8907 - val_loss: 612.1380 - val_mae: 612.1380 - lr: 1.0000e-04\n",
      "Epoch 281/5000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 84.7654 - mae: 84.7654 - val_loss: 612.5070 - val_mae: 612.5070 - lr: 1.0000e-04\n",
      "Epoch 282/5000\n",
      "3/3 [==============================] - 0s 86ms/step - loss: 84.6348 - mae: 84.6348 - val_loss: 613.1891 - val_mae: 613.1891 - lr: 1.0000e-04\n",
      "Epoch 283/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 84.4341 - mae: 84.4341 - val_loss: 613.4888 - val_mae: 613.4888 - lr: 1.0000e-04\n",
      "Epoch 284/5000\n",
      "3/3 [==============================] - 0s 87ms/step - loss: 84.3766 - mae: 84.3766 - val_loss: 613.7148 - val_mae: 613.7148 - lr: 1.0000e-04\n",
      "Epoch 285/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 84.2375 - mae: 84.2375 - val_loss: 613.9255 - val_mae: 613.9255 - lr: 1.0000e-04\n",
      "Epoch 286/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 84.0885 - mae: 84.0885 - val_loss: 614.7910 - val_mae: 614.7910 - lr: 1.0000e-04\n",
      "Epoch 287/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 83.9038 - mae: 83.9038 - val_loss: 614.7675 - val_mae: 614.7675 - lr: 1.0000e-04\n",
      "Epoch 288/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 83.6761 - mae: 83.6761 - val_loss: 614.8160 - val_mae: 614.8160 - lr: 1.0000e-04\n",
      "Epoch 289/5000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 83.5821 - mae: 83.5821 - val_loss: 615.1669 - val_mae: 615.1669 - lr: 1.0000e-04\n",
      "Epoch 290/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 83.4748 - mae: 83.4748 - val_loss: 615.7508 - val_mae: 615.7508 - lr: 1.0000e-04\n",
      "Epoch 291/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 83.3789 - mae: 83.3789 - val_loss: 616.1025 - val_mae: 616.1025 - lr: 1.0000e-04\n",
      "Epoch 292/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 83.1211 - mae: 83.1211 - val_loss: 616.5596 - val_mae: 616.5596 - lr: 1.0000e-04\n",
      "Epoch 293/5000\n",
      "3/3 [==============================] - 0s 97ms/step - loss: 82.9064 - mae: 82.9064 - val_loss: 616.2615 - val_mae: 616.2615 - lr: 1.0000e-04\n",
      "Epoch 294/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 82.8325 - mae: 82.8325 - val_loss: 617.1232 - val_mae: 617.1232 - lr: 1.0000e-04\n",
      "Epoch 295/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 82.7544 - mae: 82.7544 - val_loss: 618.1978 - val_mae: 618.1978 - lr: 1.0000e-04\n",
      "Epoch 296/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 82.6489 - mae: 82.6489 - val_loss: 618.8173 - val_mae: 618.8173 - lr: 1.0000e-04\n",
      "Epoch 297/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 82.4263 - mae: 82.4263 - val_loss: 618.2877 - val_mae: 618.2877 - lr: 1.0000e-04\n",
      "Epoch 298/5000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 82.3173 - mae: 82.3173 - val_loss: 617.2347 - val_mae: 617.2347 - lr: 1.0000e-04\n",
      "Epoch 299/5000\n",
      "3/3 [==============================] - 0s 93ms/step - loss: 82.1662 - mae: 82.1662 - val_loss: 618.1068 - val_mae: 618.1068 - lr: 1.0000e-04\n",
      "Epoch 300/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 82.1200 - mae: 82.1200 - val_loss: 620.0416 - val_mae: 620.0416 - lr: 1.0000e-04\n",
      "Epoch 301/5000\n",
      "3/3 [==============================] - 0s 90ms/step - loss: 81.8853 - mae: 81.8853 - val_loss: 620.5497 - val_mae: 620.5497 - lr: 1.0000e-04\n",
      "Epoch 302/5000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 81.7833 - mae: 81.7833 - val_loss: 619.9879 - val_mae: 619.9879 - lr: 1.0000e-04\n",
      "Epoch 303/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 81.6208 - mae: 81.6208 - val_loss: 621.0752 - val_mae: 621.0752 - lr: 1.0000e-04\n",
      "Epoch 304/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 81.7531 - mae: 81.7531 - val_loss: 621.2675 - val_mae: 621.2675 - lr: 1.0000e-04\n",
      "Epoch 305/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 81.8144 - mae: 81.8144 - val_loss: 621.1544 - val_mae: 621.1544 - lr: 1.0000e-04\n",
      "Epoch 306/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 81.2331 - mae: 81.2331 - val_loss: 621.4384 - val_mae: 621.4384 - lr: 1.0000e-04\n",
      "Epoch 307/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 81.0615 - mae: 81.0615 - val_loss: 621.6921 - val_mae: 621.6921 - lr: 1.0000e-04\n",
      "Epoch 308/5000\n",
      "3/3 [==============================] - 0s 76ms/step - loss: 81.0377 - mae: 81.0377 - val_loss: 623.7172 - val_mae: 623.7172 - lr: 1.0000e-04\n",
      "Epoch 309/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 80.9090 - mae: 80.9090 - val_loss: 623.7112 - val_mae: 623.7112 - lr: 1.0000e-04\n",
      "Epoch 310/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 80.9831 - mae: 80.9831 - val_loss: 622.7764 - val_mae: 622.7764 - lr: 1.0000e-04\n",
      "Epoch 311/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 80.7426 - mae: 80.7426 - val_loss: 623.0785 - val_mae: 623.0785 - lr: 1.0000e-04\n",
      "Epoch 312/5000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 80.6557 - mae: 80.6557 - val_loss: 623.8577 - val_mae: 623.8577 - lr: 1.0000e-04\n",
      "Epoch 313/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 80.3178 - mae: 80.3178 - val_loss: 625.0273 - val_mae: 625.0273 - lr: 1.0000e-04\n",
      "Epoch 314/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 80.2489 - mae: 80.2489 - val_loss: 625.2585 - val_mae: 625.2585 - lr: 1.0000e-04\n",
      "Epoch 315/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 80.3286 - mae: 80.3286 - val_loss: 626.8558 - val_mae: 626.8558 - lr: 1.0000e-04\n",
      "Epoch 316/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 80.4330 - mae: 80.4330 - val_loss: 626.8887 - val_mae: 626.8887 - lr: 1.0000e-04\n",
      "Epoch 317/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 80.0983 - mae: 80.0983 - val_loss: 625.3886 - val_mae: 625.3886 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 318/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 79.8986 - mae: 79.8986 - val_loss: 626.4229 - val_mae: 626.4229 - lr: 1.0000e-04\n",
      "Epoch 319/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 79.7177 - mae: 79.7177 - val_loss: 627.0131 - val_mae: 627.0131 - lr: 1.0000e-04\n",
      "Epoch 320/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 79.5908 - mae: 79.5908 - val_loss: 627.0596 - val_mae: 627.0596 - lr: 1.0000e-04\n",
      "Epoch 321/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 79.7115 - mae: 79.7115 - val_loss: 628.1502 - val_mae: 628.1502 - lr: 1.0000e-04\n",
      "Epoch 322/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 79.8192 - mae: 79.8192 - val_loss: 629.1234 - val_mae: 629.1234 - lr: 1.0000e-04\n",
      "Epoch 323/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 79.4911 - mae: 79.4911 - val_loss: 628.1175 - val_mae: 628.1175 - lr: 1.0000e-04\n",
      "Epoch 324/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 79.1158 - mae: 79.1158 - val_loss: 629.3869 - val_mae: 629.3869 - lr: 1.0000e-04\n",
      "Epoch 325/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 78.9919 - mae: 78.9919 - val_loss: 630.4696 - val_mae: 630.4696 - lr: 1.0000e-04\n",
      "Epoch 326/5000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 79.0000 - mae: 79.0000 - val_loss: 630.5602 - val_mae: 630.5602 - lr: 1.0000e-04\n",
      "Epoch 327/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 78.9303 - mae: 78.9303 - val_loss: 628.9684 - val_mae: 628.9684 - lr: 1.0000e-04\n",
      "Epoch 328/5000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 78.8676 - mae: 78.8676 - val_loss: 629.6703 - val_mae: 629.6703 - lr: 1.0000e-04\n",
      "Epoch 329/5000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 78.8306 - mae: 78.8306 - val_loss: 631.1394 - val_mae: 631.1394 - lr: 1.0000e-04\n",
      "Epoch 330/5000\n",
      "3/3 [==============================] - 0s 106ms/step - loss: 78.4425 - mae: 78.4425 - val_loss: 632.5258 - val_mae: 632.5258 - lr: 1.0000e-04\n",
      "Epoch 331/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 78.4794 - mae: 78.4794 - val_loss: 632.9643 - val_mae: 632.9643 - lr: 1.0000e-04\n",
      "Epoch 332/5000\n",
      "3/3 [==============================] - 0s 89ms/step - loss: 78.2146 - mae: 78.2146 - val_loss: 633.5324 - val_mae: 633.5324 - lr: 1.0000e-04\n",
      "Epoch 333/5000\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 78.1508 - mae: 78.1508 - val_loss: 632.8571 - val_mae: 632.8571 - lr: 1.0000e-04\n",
      "Epoch 334/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 77.8364 - mae: 77.8364 - val_loss: 634.5552 - val_mae: 634.5552 - lr: 1.0000e-04\n",
      "Epoch 335/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 77.7554 - mae: 77.7554 - val_loss: 634.6692 - val_mae: 634.6692 - lr: 1.0000e-04\n",
      "Epoch 336/5000\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 77.8922 - mae: 77.8922 - val_loss: 635.1599 - val_mae: 635.1599 - lr: 1.0000e-04\n",
      "Epoch 337/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 78.5284 - mae: 78.5284 - val_loss: 636.4211 - val_mae: 636.4211 - lr: 1.0000e-04\n",
      "Epoch 338/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 77.6795 - mae: 77.6795 - val_loss: 635.9485 - val_mae: 635.9485 - lr: 1.0000e-04\n",
      "Epoch 339/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 77.7837 - mae: 77.7837 - val_loss: 635.5730 - val_mae: 635.5730 - lr: 1.0000e-04\n",
      "Epoch 340/5000\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 77.4607 - mae: 77.4607 - val_loss: 637.5172 - val_mae: 637.5172 - lr: 1.0000e-04\n",
      "Epoch 341/5000\n",
      "3/3 [==============================] - 0s 75ms/step - loss: 77.6284 - mae: 77.6284 - val_loss: 637.4136 - val_mae: 637.4136 - lr: 1.0000e-04\n",
      "Epoch 342/5000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 77.1892 - mae: 77.1892 - val_loss: 638.5069 - val_mae: 638.5069 - lr: 1.0000e-04\n",
      "Epoch 343/5000\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 77.3577 - mae: 77.3577 - val_loss: 639.3978 - val_mae: 639.3978 - lr: 1.0000e-04\n",
      "Epoch 344/5000\n",
      "3/3 [==============================] - 0s 85ms/step - loss: 76.9363 - mae: 76.9363 - val_loss: 640.0652 - val_mae: 640.0652 - lr: 1.0000e-04\n",
      "Epoch 345/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 76.9302 - mae: 76.9302 - val_loss: 639.0110 - val_mae: 639.0110 - lr: 1.0000e-04\n",
      "Epoch 346/5000\n",
      "3/3 [==============================] - 0s 72ms/step - loss: 76.9306 - mae: 76.9306 - val_loss: 639.0220 - val_mae: 639.0220 - lr: 1.0000e-04\n",
      "Epoch 347/5000\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 72.6099 - mae: 72.6099\n",
      "Epoch 347: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3/3 [==============================] - 0s 141ms/step - loss: 77.3670 - mae: 77.3670 - val_loss: 639.9692 - val_mae: 639.9692 - lr: 1.0000e-04\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0a9e55580>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(42)\n",
    "#1. setip and instance of NBeatsBlock\n",
    "\n",
    "\n",
    "\n",
    "nbeats_block_layer = NBeatsBlock(input_size = INPUT_SIZE,\n",
    "                                  theta_size = THETA_SIZE,\n",
    "                                  horizon = HORIZON,\n",
    "                                  n_neurons = N_NEURONS,\n",
    "                                  n_layers = N_LAYERS,\n",
    "                                name='initialBlock')\n",
    "\n",
    "# 2. Create input to stack\n",
    "stack_input = tf.keras.layers.Input(shape=(INPUT_SIZE),name='stack_input')\n",
    "\n",
    "# 3. Create initial backcast and forecast input (backc=wards pred + horzion pred)\n",
    "backcast, forecast = nbeats_block_layer(stack_input)\n",
    "\n",
    "#residuals, forecast = nbeats_block_layer(stack_input)\n",
    "residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\") \n",
    "#4. Create stacks of block layers\n",
    "for i, _ in enumerate(range(N_STACKS-1)):\n",
    "    #5 use the n beats block to caclulate \n",
    "    backcast,block_forecast = NBeatsBlock(input_size = INPUT_SIZE,\n",
    "                                      theta_size = THETA_SIZE,\n",
    "                                      horizon = HORIZON,\n",
    "                                      n_neurons = N_NEURONS,\n",
    "                                      n_layers = N_LAYERS,\n",
    "                                    name=f'NBeatsBlock_{i}')(residuals)\n",
    "    residuals = layers.subtract([residuals,backcast],name=f'subtract_{i}')\n",
    "    forecast = layers.add([forecast,block_forecast],name=f\"add_{i}\")\n",
    "\n",
    "#6. Put the stack model together\n",
    "\n",
    "model_7 = tf.keras.Model(inputs=stack_input,outputs=forecast,name='model_7_beats')\n",
    "\n",
    "#7 compile model\n",
    "\n",
    "model_7.compile(loss='mae',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "model_7.fit(train_dataset,\n",
    "           epochs=N_EPOCHS,\n",
    "           validation_data=test_dataset,\n",
    "           callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=200,restore_best_weights=True),\n",
    "                     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=100,verbose=1)])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "434e0681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 148ms/step - loss: 583.9232 - mae: 583.9232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[583.9231567382812, 583.9231567382812]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cab41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_preds = make_preds(model_7,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5326c85b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "100bb6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7_results = evaluate_preds(y_test,model_7_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0506c434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 583.92316,\n",
       " 'mse': 1209093.6,\n",
       " 'rmse': 1099.5879,\n",
       " 'mape': 2.6407816,\n",
       " 'mase': 1.0257913}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_7_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7006ee19",
   "metadata": {},
   "source": [
    "## plotting n-beats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65e09a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0773546",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25ee3a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_custom.save(\"n_beats_custom.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6b7199",
   "metadata": {},
   "source": [
    "## Model 8: Ensemble model(stacking diffrent models togehter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "883e687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON,WINDOW_SIZE = 1,7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb65f67c",
   "metadata": {},
   "source": [
    "### Constructing and fitting ensemble of models (using diffrent loss functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "549dae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_models(horizon=HORIZON,\n",
    "                       train_data=train_dataset,\n",
    "                       test_data = test_dataset,\n",
    "                       num_iter=10,\n",
    "                       num_epochs=1000,\n",
    "                       loss_fns=[\"mae\",\"mse\",\"mape\"]):\n",
    "    ensemble_models = []\n",
    "    \n",
    "    for i in range(num_iter):\n",
    "        # build and fit a new model diffrent loss function\n",
    "        for loss_function in loss_fns:\n",
    "            print(f\"Optimizing model by reducing:{loss_function} for {num_epochs} epochs, model number:{i}\")\n",
    "            \n",
    "            # Construct a simple model (model_1)\n",
    "            model = tf.keras.Sequential([\n",
    "                # initialise dense layer with normal distribution\n",
    "                layers.Dense(128,activation='relu',kernel_initializer='he_normal'),\n",
    "                layers.Dense(128,activation='relu',kernel_initializer='he_normal'),\n",
    "                layers.Dense(HORIZON)\n",
    "            ])\n",
    "            \n",
    "            model.compile(loss=loss_function,metrics=[\"mae\",\"mse\"],optimizer='adam')\n",
    "            \n",
    "            # fit the current model\n",
    "            model.fit(train_data,\n",
    "                      epochs=num_epochs,\n",
    "                     verbose=0,\n",
    "                     validation_data=test_data,\n",
    "                     callbacks=[tf.keras.callbacks.EarlyStopping(patience=200,restore_best_weights=True),\n",
    "                               tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=100,verbose=1)])\n",
    "            \n",
    "            ensemble_models.append(model)\n",
    "            \n",
    "        return ensemble_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4e6e04ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble_models(horizon=HORIZON, \n",
    "                        train_data=train_dataset,\n",
    "                        test_data=test_dataset,\n",
    "                        num_iter=10, \n",
    "                        num_epochs=100, \n",
    "                        loss_fns=[\"mae\", \"mse\", \"mape\"]):\n",
    "  \"\"\"\n",
    "  Returns a list of num_iter models each trained on MAE, MSE and MAPE loss.\n",
    "\n",
    "  For example, if num_iter=10, a list of 30 trained models will be returned:\n",
    "  10 * len([\"mae\", \"mse\", \"mape\"]).\n",
    "  \"\"\"\n",
    "  # Make empty list for trained ensemble models\n",
    "  ensemble_models = []\n",
    "\n",
    "  # Create num_iter number of models per loss function\n",
    "  for i in range(num_iter):\n",
    "    # Build and fit a new model with a different loss function\n",
    "    for loss_function in loss_fns:\n",
    "      print(f\"Optimizing model by reducing: {loss_function} for {num_epochs} epochs, model number: {i}\")\n",
    "\n",
    "      # Construct a simple model (similar to model_1)\n",
    "      model = tf.keras.Sequential([\n",
    "        # Initialize layers with normal (Gaussian) distribution so we can use the models for prediction\n",
    "        # interval estimation later: https://www.tensorflow.org/api_docs/python/tf/keras/initializers/HeNormal\n",
    "        layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"), \n",
    "        layers.Dense(128, kernel_initializer=\"he_normal\", activation=\"relu\"),\n",
    "        layers.Dense(HORIZON)                                 \n",
    "      ])\n",
    "\n",
    "      # Compile simple model with current loss function\n",
    "      model.compile(loss=loss_function,\n",
    "                    optimizer=tf.keras.optimizers.Adam(),\n",
    "                    metrics=[\"mae\", \"mse\"])\n",
    "      \n",
    "      # Fit model\n",
    "      model.fit(train_data,\n",
    "                epochs=num_epochs,\n",
    "                verbose=0,\n",
    "                validation_data=test_data,\n",
    "                # Add callbacks to prevent training from going/stalling for too long\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "                                                            patience=200,\n",
    "                                                            restore_best_weights=True),\n",
    "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
    "                                                                patience=100,\n",
    "                                                                verbose=1)])\n",
    "      \n",
    "      # Append fitted model to list of ensemble models\n",
    "      ensemble_models.append(model)\n",
    "\n",
    "  return ensemble_models # return list of trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1f2ac79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing model by reducing: mae for 1000 epochs, model number: 0\n",
      "\n",
      "Epoch 00911: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Optimizing model by reducing: mse for 1000 epochs, model number: 0\n",
      "\n",
      "Epoch 00266: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00366: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mape for 1000 epochs, model number: 0\n",
      "\n",
      "Epoch 00110: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00425: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00525: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Optimizing model by reducing: mae for 1000 epochs, model number: 1\n",
      "\n",
      "Epoch 00509: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00687: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00787: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Optimizing model by reducing: mse for 1000 epochs, model number: 1\n",
      "\n",
      "Epoch 00661: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00761: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mape for 1000 epochs, model number: 1\n",
      "\n",
      "Epoch 00217: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00317: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mae for 1000 epochs, model number: 2\n",
      "\n",
      "Epoch 00397: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00961: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mse for 1000 epochs, model number: 2\n",
      "\n",
      "Epoch 00332: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00432: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mape for 1000 epochs, model number: 2\n",
      "\n",
      "Epoch 00122: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00863: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00963: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Optimizing model by reducing: mae for 1000 epochs, model number: 3\n",
      "\n",
      "Epoch 00726: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00983: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mse for 1000 epochs, model number: 3\n",
      "\n",
      "Epoch 00443: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00543: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mape for 1000 epochs, model number: 3\n",
      "\n",
      "Epoch 00274: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00385: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00485: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Optimizing model by reducing: mae for 1000 epochs, model number: 4\n",
      "\n",
      "Epoch 00966: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Optimizing model by reducing: mse for 1000 epochs, model number: 4\n",
      "\n",
      "Epoch 00774: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00874: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Optimizing model by reducing: mape for 1000 epochs, model number: 4\n",
      "\n",
      "Epoch 00192: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00347: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00447: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Wall time: 8min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensemble_models=get_ensemble_models(num_iter=5,num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3e3db928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ensemble_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2aef602",
   "metadata": {},
   "source": [
    "### Make predictions with ensemble model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38c3e491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_ensemble_preds(ensemble_models,data):\n",
    "    ensemble_preds = []\n",
    "    \n",
    "    for model in ensemble_models:\n",
    "        preds = model.predict(data)\n",
    "        ensemble_preds.append(preds)\n",
    "    return tf.constant(tf.squeeze(ensemble_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "44f4fafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D719F92040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D719F92700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Wall time: 980 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ensemble_preds = make_ensemble_preds(ensemble_models,test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "de94810a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 568.9462,\n",
       " 'mse': 1143090.0,\n",
       " 'rmse': 1069.1539,\n",
       " 'mape': 2.569465,\n",
       " 'mase': 0.99948096}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate ensemble model(s) predictions\n",
    "ensemble_results = evaluate_preds(y_true=y_test,\n",
    "                                  y_pred=np.mean(ensemble_preds, axis=0)) # take the median across all ensemble predictions\n",
    "ensemble_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511668ea",
   "metadata": {},
   "source": [
    "### Ploting the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "40a40369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(15, 556), dtype=float32, numpy=\n",
       "array([[ 8870.459,  8763.768,  9066.929, ..., 49560.09 , 48140.2  ,\n",
       "        45382.312],\n",
       "       [ 8720.974,  8733.402,  9035.373, ..., 49849.91 , 48443.043,\n",
       "        46787.63 ],\n",
       "       [ 8743.961,  8750.412,  9028.345, ..., 49428.945, 48374.117,\n",
       "        47267.137],\n",
       "       ...,\n",
       "       [ 8778.153,  8767.032,  9076.592, ..., 49762.16 , 48875.082,\n",
       "        46369.434],\n",
       "       [ 8751.562,  8791.237,  9071.208, ..., 50630.902, 48201.07 ,\n",
       "        45861.695],\n",
       "       [ 8762.075,  8796.689,  9061.249, ..., 49906.26 , 48029.05 ,\n",
       "        45856.23 ]], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cec3c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(556,), dtype=float32, numpy=\n",
       "array([ 23.65139  ,  33.722916 ,  46.070866 ,  40.22268  ,  40.456413 ,\n",
       "        43.319244 ,  24.817781 ,  36.262413 ,  33.949547 ,  21.584349 ,\n",
       "        22.312204 ,  31.912865 ,  33.14071  ,  43.757206 ,  54.40727  ,\n",
       "        46.347042 ,  48.44715  ,  57.58317  ,  42.222424 ,  52.72699  ,\n",
       "        41.874233 ,  50.910576 ,  39.53033  ,  35.96361  ,  29.608255 ,\n",
       "        22.278652 ,  28.054306 ,  33.177708 ,  29.905691 ,  22.598442 ,\n",
       "        18.622072 ,  14.473409 ,  22.09645  ,  16.78873  ,  23.49172  ,\n",
       "        24.067537 ,  18.044767 ,  17.628466 ,  13.878993 ,  29.087751 ,\n",
       "        51.62225  ,  64.85775  ,  68.4564   ,  48.119278 ,  38.936947 ,\n",
       "        55.324528 ,  21.98801  ,  13.821814 ,  18.28641  ,  15.141184 ,\n",
       "        18.002317 ,  17.654737 ,  15.9929285,  14.290278 ,  17.925495 ,\n",
       "        11.83382  ,  28.276262 ,  34.593323 ,  32.235855 ,  30.740591 ,\n",
       "        35.7492   ,  36.89234  ,  35.445023 ,  34.52259  ,  45.331394 ,\n",
       "        35.099304 ,  27.639536 ,  53.936222 ,  41.24192  ,  34.041832 ,\n",
       "        37.32485  ,  34.78643  ,  37.253284 ,  25.437693 ,  26.426634 ,\n",
       "        23.783615 ,  27.943365 ,  33.556583 ,  19.839796 ,  34.935028 ,\n",
       "        39.67287  ,  38.598972 ,  30.015514 ,  39.141533 ,  39.958668 ,\n",
       "        36.78749  ,  20.748262 ,  20.444283 ,  20.781763 ,  37.839252 ,\n",
       "        36.090504 ,  39.392563 ,  31.982275 ,  29.977491 ,  43.63334  ,\n",
       "        38.585743 ,  40.5696   ,  35.191746 ,  31.82442  ,  30.910276 ,\n",
       "        45.291218 ,  31.623112 ,  62.50666  ,  64.13651  ,  54.69826  ,\n",
       "        44.17232  ,  39.335133 ,  46.05547  ,  33.524544 ,  31.163849 ,\n",
       "        51.140774 ,  39.81604  ,  54.484547 ,  61.143806 ,  43.739456 ,\n",
       "        57.214466 ,  31.788889 ,  35.68411  ,  34.119164 ,  25.963976 ,\n",
       "        40.368122 ,  52.06693  ,  40.293728 ,  55.05068  ,  66.79796  ,\n",
       "       315.3515   , 363.5048   , 395.05942  , 384.46262  , 494.54617  ,\n",
       "       403.16376  ,  52.48297  , 127.031105 , 103.51343  , 101.11602  ,\n",
       "       102.60861  ,  82.79515  ,  73.65689  ,  32.289646 ,  42.275345 ,\n",
       "        31.291416 ,  22.028936 ,  43.572956 ,  56.616806 ,  48.779514 ,\n",
       "        58.595665 ,  33.95677  ,  27.762924 ,  43.38352  ,  18.213373 ,\n",
       "        43.138348 ,  45.069508 ,  40.97507  ,  31.291456 ,  31.108753 ,\n",
       "        38.32778  ,  42.65868  ,  33.49326  ,  31.131903 ,  28.934967 ,\n",
       "        43.680565 ,  38.49495  ,  44.44298  ,  31.315655 ,  27.88906  ,\n",
       "        31.379927 ,  37.586132 ,  44.96124  ,  29.774553 ,  30.937    ,\n",
       "        32.56687  ,  35.724888 ,  38.172234 ,  76.79401  ,  63.653038 ,\n",
       "        73.89227  ,  72.52941  ,  62.13915  ,  61.8257   ,  18.239578 ,\n",
       "        35.080677 ,  42.889477 ,  28.767155 ,  44.280365 ,  54.15171  ,\n",
       "        53.513176 ,  75.09328  ,  84.58776  ,  48.799385 ,  42.18489  ,\n",
       "        53.582054 ,  58.876373 ,  47.471767 ,  43.97324  ,  30.862726 ,\n",
       "        23.181562 ,  32.154324 ,  36.558937 ,  36.930992 ,  31.184517 ,\n",
       "        38.09513  ,  34.24926  ,  45.915524 ,  31.561047 ,  38.5187   ,\n",
       "        33.23501  ,  70.625275 ,  82.65473  ,  88.90743  ,  73.59372  ,\n",
       "        49.708538 ,  74.00528  ,  44.73643  ,  21.919218 ,  24.398485 ,\n",
       "        23.758041 ,  30.398586 ,  41.472607 ,  41.21403  ,  40.44044  ,\n",
       "        38.60829  ,  40.16614  ,  22.810032 ,  19.454918 ,  14.752826 ,\n",
       "        21.236076 ,  18.243483 ,  41.590168 ,  35.549427 ,  30.424665 ,\n",
       "        28.92539  ,  27.811981 ,  31.43441  ,  28.82499  ,  40.46751  ,\n",
       "        22.628897 ,  24.249641 ,  19.318398 ,  21.509329 ,  21.260166 ,\n",
       "        14.426785 ,  26.16879  ,  26.190538 ,  30.648014 ,  27.916977 ,\n",
       "        29.072733 ,  32.794575 ,  25.61347  ,  24.776148 ,  22.766737 ,\n",
       "        15.346832 ,  14.055505 ,  17.23971  ,  16.479412 ,  18.336826 ,\n",
       "        18.29934  ,  28.324932 ,  26.169073 ,  26.14594  ,  21.50362  ,\n",
       "        21.32652  ,  29.886364 ,  89.94748  ,  89.19267  , 102.19505  ,\n",
       "       106.15419  , 102.34721  ,  95.4023   ,  37.659313 ,  53.710052 ,\n",
       "        46.254692 ,  71.39072  ,  67.8052   ,  41.091694 ,  28.656202 ,\n",
       "        20.883184 ,  35.84509  ,  33.858803 ,  44.46709  ,  50.82676  ,\n",
       "        48.203316 ,  45.46635  ,  31.337723 ,  43.15681  ,  44.927696 ,\n",
       "        45.203693 ,  44.878757 ,  34.191326 ,  45.70873  ,  46.65468  ,\n",
       "        36.595947 ,  31.021305 ,  35.89993  ,  25.241611 ,  40.616436 ,\n",
       "        38.60625  ,  42.79014  ,  27.575174 ,  33.507095 ,  40.17212  ,\n",
       "        61.20181  ,  45.815506 ,  60.168056 ,  95.86751  ,  56.54893  ,\n",
       "        67.639496 ,  38.336994 ,  43.558327 ,  35.495895 ,  33.545765 ,\n",
       "        23.464296 ,  31.383928 ,  36.38597  ,  42.69409  ,  34.06534  ,\n",
       "        27.970795 ,  30.595125 ,  19.414507 ,  32.13157  ,  33.798042 ,\n",
       "        31.133904 ,  46.858673 ,  53.239723 ,  48.261963 ,  33.153297 ,\n",
       "        26.88539  ,  29.31057  ,  22.877455 ,  17.523636 ,  17.264315 ,\n",
       "        17.804823 ,  24.77836  ,  28.793566 ,  24.88792  ,  23.529062 ,\n",
       "        30.185253 ,  32.443584 ,  42.250877 ,  30.678728 ,  40.25982  ,\n",
       "        43.540382 ,  35.462135 ,  35.074554 ,  21.943657 ,  31.44887  ,\n",
       "        29.040283 ,  42.586132 ,  40.150723 ,  82.04686  ,  83.716835 ,\n",
       "        80.61605  ,  71.79584  ,  62.609562 ,  68.40159  ,  53.56694  ,\n",
       "        42.390053 ,  59.87239  ,  47.19923  ,  52.669327 ,  69.312965 ,\n",
       "        39.693592 ,  29.76943  ,  42.605824 ,  86.14922  ,  75.366356 ,\n",
       "        84.50031  ,  82.386    , 103.67956  ,  97.1618   ,  71.63981  ,\n",
       "        71.33281  ,  75.23316  ,  45.562675 ,  35.796505 ,  77.4167   ,\n",
       "        94.01408  ,  57.042133 ,  80.68724  ,  97.24376  ,  85.824394 ,\n",
       "        83.66782  ,  41.884403 ,  55.56391  ,  65.5709   , 114.19101  ,\n",
       "        85.741005 , 140.83592  , 132.7398   , 128.45992  , 114.48838  ,\n",
       "       109.07764  ,  97.38135  ,  56.196735 ,  89.75921  ,  56.456528 ,\n",
       "        61.157948 ,  63.342213 ,  54.298637 ,  34.395115 ,  43.26091  ,\n",
       "        75.24875  ,  82.88274  ,  69.90015  ,  57.04773  , 143.60709  ,\n",
       "       146.6319   , 185.89159  , 219.16156  , 213.20555  , 174.16585  ,\n",
       "       109.5756   ,  49.803303 ,  86.23237  , 103.51137  , 147.30754  ,\n",
       "       126.23029  , 141.6535   , 135.17169  , 206.89006  , 149.53754  ,\n",
       "       106.76218  , 213.5793   , 160.55087  , 223.65752  , 244.31833  ,\n",
       "       261.47238  , 363.99686  , 418.747    , 376.9387   , 496.35068  ,\n",
       "       457.61835  , 418.53223  , 373.88242  , 383.1906   , 347.68286  ,\n",
       "       267.9746   , 157.1557   , 198.45172  , 166.97896  , 113.80545  ,\n",
       "       404.6192   , 329.94095  , 405.9277   , 408.15982  , 319.3512   ,\n",
       "       177.32462  , 264.6751   , 232.80672  , 254.2861   , 196.70049  ,\n",
       "       239.79597  , 222.53165  , 330.35693  , 209.23889  , 125.78702  ,\n",
       "       190.14548  , 212.75334  , 247.83998  , 443.26187  , 582.56506  ,\n",
       "       701.8429   , 540.94745  , 377.6601   , 391.6883   , 175.34343  ,\n",
       "       152.89372  , 256.4188   , 245.38406  , 149.0874   , 316.1426   ,\n",
       "       393.8852   , 403.83755  , 382.45694  , 630.47565  , 407.6848   ,\n",
       "       443.76175  , 560.0225   , 591.2789   , 433.278    , 413.19876  ,\n",
       "       393.74805  , 507.10043  , 340.576    , 388.37463  , 332.72858  ,\n",
       "       297.00964  , 318.82178  , 311.9834   , 294.8017   , 291.44843  ,\n",
       "       295.33292  , 327.0646   , 291.6776   , 336.78537  , 225.99387  ,\n",
       "       383.28055  , 335.25037  , 271.00793  , 242.93965  ,  87.85791  ,\n",
       "       290.46695  , 229.97469  , 300.5769   , 345.0393   , 266.135    ,\n",
       "       362.34747  , 263.7752   , 239.5341   , 233.74194  , 268.1812   ,\n",
       "       204.89993  , 120.869446 , 151.7563   , 162.31628  , 161.12874  ,\n",
       "       133.45747  , 171.50067  , 190.5662   , 196.7344   , 256.8054   ,\n",
       "       223.63387  , 142.1122   , 255.12039  , 224.87628  , 253.9276   ,\n",
       "       201.20364  , 168.75314  , 365.60596  , 270.05695  , 334.10608  ,\n",
       "       355.53763  , 326.56314  , 350.4947   , 288.98123  , 334.79825  ,\n",
       "       468.00882  , 384.20877  , 314.48605  , 338.60736  , 422.11853  ,\n",
       "       386.85974  , 297.4873   , 183.2945   , 248.0579   , 431.3548   ,\n",
       "       361.14633  , 426.54535  , 310.49966  , 174.57451  , 309.69583  ,\n",
       "       192.89713  , 349.5121   , 320.8279   , 364.11542  , 367.09302  ,\n",
       "       379.52316  ], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_std(ensemble_preds,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "25fec6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_upper_lower(preds): #1. take predictions from a number randomly intilized\n",
    "    # Measuure the standard deviation\n",
    "    std = tf.math.reduce_std(preds,axis=0)\n",
    "    \n",
    "    interval = std*1.96\n",
    "    \n",
    "    preds_mean = tf.reduce_mean(preds,axis=0)\n",
    "    \n",
    "    lower, upper = preds_mean - interval, preds_mean +interval\n",
    "    \n",
    "    return lower,upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3744aa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower,upper = get_upper_lower(ensemble_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "51b79b70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d7229fb0a0>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the median/mean values\n",
    "ensemble_median = np.median(ensemble_preds,axis=0)\n",
    "\n",
    "#plot the median\n",
    "offset = 500\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.plot(X_test.index[offset:],y_test[offset:],'g',label='test data')\n",
    "plt.plot(X_test.index[offset:],ensemble_median[offset:],'k',label='ensemble pred')\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"BTC PRice\")\n",
    "\n",
    "plt.fill_between(X_test.index[offset:],\n",
    "                (lower)[offset:],\n",
    "                (upper)[offset:],label='prediction Intervals')\n",
    "plt.legend(loc=\"upper left\",fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8361098a",
   "metadata": {},
   "source": [
    "### analyse plot\n",
    "\n",
    "1. what can my model know?\n",
    "2. what doesn't my model know?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f5dc8b",
   "metadata": {},
   "source": [
    "## Model 9: Futrue prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "481a0b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 1\n",
    "WINDO_SIZE = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b9a9a7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-01</th>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-02</th>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-03</th>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-04</th>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-05</th>\n",
       "      <td>121.33866</td>\n",
       "      <td>118.67466</td>\n",
       "      <td>108.58483</td>\n",
       "      <td>125.45500</td>\n",
       "      <td>123.65499</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price    Price+1    Price+2    Price+3    Price+4  Price+5  \\\n",
       "Date                                                                         \n",
       "2013-10-01  123.65499        NaN        NaN        NaN        NaN      NaN   \n",
       "2013-10-02  125.45500  123.65499        NaN        NaN        NaN      NaN   \n",
       "2013-10-03  108.58483  125.45500  123.65499        NaN        NaN      NaN   \n",
       "2013-10-04  118.67466  108.58483  125.45500  123.65499        NaN      NaN   \n",
       "2013-10-05  121.33866  118.67466  108.58483  125.45500  123.65499      NaN   \n",
       "\n",
       "            Price+6  Price+7  \n",
       "Date                          \n",
       "2013-10-01      NaN      NaN  \n",
       "2013-10-02      NaN      NaN  \n",
       "2013-10-03      NaN      NaN  \n",
       "2013-10-04      NaN      NaN  \n",
       "2013-10-05      NaN      NaN  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_nbeats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ecc2bebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Price+1</th>\n",
       "      <th>Price+2</th>\n",
       "      <th>Price+3</th>\n",
       "      <th>Price+4</th>\n",
       "      <th>Price+5</th>\n",
       "      <th>Price+6</th>\n",
       "      <th>Price+7</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-05-14</th>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "      <td>58788.209679</td>\n",
       "      <td>57107.120672</td>\n",
       "      <td>56583.849879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-15</th>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "      <td>58788.209679</td>\n",
       "      <td>57107.120672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-16</th>\n",
       "      <td>47885.625255</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "      <td>58788.209679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-17</th>\n",
       "      <td>45604.615754</td>\n",
       "      <td>47885.625255</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "      <td>58102.191426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-05-18</th>\n",
       "      <td>43144.471291</td>\n",
       "      <td>45604.615754</td>\n",
       "      <td>47885.625255</td>\n",
       "      <td>50032.693137</td>\n",
       "      <td>49764.132082</td>\n",
       "      <td>52147.821187</td>\n",
       "      <td>56573.555472</td>\n",
       "      <td>55715.546651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Price       Price+1       Price+2       Price+3  \\\n",
       "Date                                                                 \n",
       "2021-05-14  49764.132082  52147.821187  56573.555472  55715.546651   \n",
       "2021-05-15  50032.693137  49764.132082  52147.821187  56573.555472   \n",
       "2021-05-16  47885.625255  50032.693137  49764.132082  52147.821187   \n",
       "2021-05-17  45604.615754  47885.625255  50032.693137  49764.132082   \n",
       "2021-05-18  43144.471291  45604.615754  47885.625255  50032.693137   \n",
       "\n",
       "                 Price+4       Price+5       Price+6       Price+7  \n",
       "Date                                                                \n",
       "2021-05-14  58102.191426  58788.209679  57107.120672  56583.849879  \n",
       "2021-05-15  55715.546651  58102.191426  58788.209679  57107.120672  \n",
       "2021-05-16  56573.555472  55715.546651  58102.191426  58788.209679  \n",
       "2021-05-17  52147.821187  56573.555472  55715.546651  58102.191426  \n",
       "2021-05-18  49764.132082  52147.821187  56573.555472  55715.546651  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_nbeats.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "828b76e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = bitcoin_prices_nbeats.dropna().drop(\"Price\",axis=1).to_numpy()\n",
    "y_all = bitcoin_prices_nbeats.dropna()[\"Price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "444ab062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  121.795     ,   120.65533   ,   121.33866   , ...,\n",
       "          108.58483   ,   125.455     ,   123.65499   ],\n",
       "       [  123.033     ,   121.795     ,   120.65533   , ...,\n",
       "          118.67466   ,   108.58483   ,   125.455     ],\n",
       "       [  124.049     ,   123.033     ,   121.795     , ...,\n",
       "          121.33866   ,   118.67466   ,   108.58483   ],\n",
       "       ...,\n",
       "       [50032.69313676, 49764.1320816 , 52147.82118698, ...,\n",
       "        55715.54665129, 58102.19142623, 58788.20967893],\n",
       "       [47885.62525472, 50032.69313676, 49764.1320816 , ...,\n",
       "        56573.5554719 , 55715.54665129, 58102.19142623],\n",
       "       [45604.61575361, 47885.62525472, 50032.69313676, ...,\n",
       "        52147.82118698, 56573.5554719 , 55715.54665129]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "1f2f2f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices(X_all)\n",
    "label = tf.data.Dataset.from_tensor_slices(y_all)\n",
    "\n",
    "train_dataset_future = tf.data.Dataset.zip((train,label))\n",
    "\n",
    "train_dataset_future = train_dataset_future.batch(1024).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "e5f02343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 7), (None,)), types: (tf.float64, tf.float64)>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "97c78e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_9 =tf.keras.Sequential([\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(1)\n",
    "],name='model_9_futurePredict')\n",
    "model_9.compile(loss='mae',metrics=['mae','mse'],optimizer='adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c9dfad32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 405.6523 - mae: 405.6523 - mse: 195292.0000WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 4789.2661 - mae: 4789.2661 - mse: 80645904.0000 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 249.9811 - mae: 249.9811 - mse: 74818.4531WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 2853.6287 - mae: 2853.6287 - mse: 28402378.0000 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 127.1152 - mae: 127.1152 - mse: 20318.0039WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 947.8903 - mae: 947.8902 - mse: 3196516.5000 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20.5958 - mae: 20.5958 - mse: 1560.6929WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 918.0382 - mae: 918.0383 - mse: 4692064.5000 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 80.8201 - mae: 80.8201 - mse: 9144.8760WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1287.6143 - mae: 1287.6143 - mse: 7205547.5000 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 78.3125 - mae: 78.3125 - mse: 8651.2012WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 850.8937 - mae: 850.8937 - mse: 3221490.0000 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 39.1281 - mae: 39.1281 - mse: 2882.4824WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 377.1281 - mae: 377.1281 - mse: 866807.0000 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 26.1501 - mae: 26.1501 - mse: 1851.1315WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 615.2404 - mae: 615.2404 - mse: 2059246.0000 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 39.4591 - mae: 39.4591 - mse: 2901.6487WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 581.5600 - mae: 581.5600 - mse: 1722783.0000 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27.8684 - mae: 27.8684 - mse: 1957.9034WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 358.4028 - mae: 358.4028 - mse: 820658.9375 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 23.7123 - mae: 23.7123 - mse: 1684.5035WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 453.9425 - mae: 453.9425 - mse: 1295779.3750 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 33.8928 - mae: 33.8928 - mse: 2389.9329WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 447.8247 - mae: 447.8246 - mse: 1187338.1250 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 26.1344 - mae: 26.1344 - mse: 1817.5979WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 349.4255 - mae: 349.4255 - mse: 803091.0625 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20.6015 - mae: 20.6015 - mse: 1533.6483WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 400.5373 - mae: 400.5373 - mse: 974258.4375 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 22.0401 - mae: 22.0401 - mse: 1591.1289WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 355.0482 - mae: 355.0482 - mse: 810210.8125 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20.3800 - mae: 20.3800 - mse: 1492.6237WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 359.4038 - mae: 359.4038 - mse: 865510.5000 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 24.7700 - mae: 24.7700 - mse: 1694.6201WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 361.6545 - mae: 361.6545 - mse: 846603.6875 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21.6074 - mae: 21.6074 - mse: 1506.4724WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 333.9923 - mae: 333.9923 - mse: 743195.9375 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.2131 - mae: 19.2131 - mse: 1375.2556WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 333.5009 - mae: 333.5009 - mse: 722435.2500 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.6105 - mae: 18.6105 - mse: 1315.0771WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 312.1475 - mae: 312.1475 - mse: 669910.5625 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.9436 - mae: 19.9436 - mse: 1331.7240WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 308.1174 - mae: 308.1174 - mse: 643873.6875 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.3463 - mae: 18.3463 - mse: 1230.5385WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 297.8065 - mae: 297.8065 - mse: 596064.6250 - lr: 0.0010\n",
      "Epoch 23/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.2009 - mae: 17.2009 - mse: 1160.3567WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 286.2324 - mae: 286.2324 - mse: 562682.8125 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.6858 - mae: 17.6858 - mse: 1149.6212WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 286.1642 - mae: 286.1642 - mse: 558792.3125 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.1831 - mae: 17.1831 - mse: 1110.2386WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 281.7871 - mae: 281.7871 - mse: 534206.9375 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.3794 - mae: 16.3794 - mse: 1063.9684WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 271.8158 - mae: 271.8158 - mse: 510793.2188 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.8464 - mae: 16.8464 - mse: 1058.5758WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 269.2177 - mae: 269.2177 - mse: 499406.9062 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.1912 - mae: 16.1912 - mse: 1017.5870WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 266.5584 - mae: 266.5584 - mse: 482436.6875 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.7957 - mae: 15.7957 - mse: 986.8303WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 261.1973 - mae: 261.1973 - mse: 472770.4375 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.9400 - mae: 15.9400 - mse: 975.3309WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 257.0648 - mae: 257.0648 - mse: 453436.2812 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.4670 - mae: 15.4670 - mse: 944.5777WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 253.6268 - mae: 253.6268 - mse: 445877.6250 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.4702 - mae: 15.4702 - mse: 930.9413WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 250.4328 - mae: 250.4329 - mse: 431399.3750 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.1531 - mae: 15.1531 - mse: 907.6074WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 247.6676 - mae: 247.6676 - mse: 425275.8125 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.1371 - mae: 15.1371 - mse: 895.7021WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 244.8798 - mae: 244.8798 - mse: 413034.4375 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.8460 - mae: 14.8460 - mse: 874.8585WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 242.1519 - mae: 242.1519 - mse: 406218.6250 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.8391 - mae: 14.8391 - mse: 864.7172WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 239.9705 - mae: 239.9704 - mse: 397443.3125 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.6007 - mae: 14.6007 - mse: 847.4600WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 237.6540 - mae: 237.6540 - mse: 390679.1562 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.6362 - mae: 14.6362 - mse: 840.4733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 235.8504 - mae: 235.8504 - mse: 386343.0312 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.5552 - mae: 14.5552 - mse: 829.8978WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 233.8630 - mae: 233.8630 - mse: 379208.2812 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.4302 - mae: 14.4302 - mse: 817.8301WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.9586 - mae: 231.9586 - mse: 374900.2812 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.4354 - mae: 14.4354 - mse: 811.8121WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 230.5336 - mae: 230.5336 - mse: 370300.5312 - lr: 0.0010\n",
      "Epoch 42/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3673 - mae: 14.3673 - mse: 802.8469WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 229.1343 - mae: 229.1343 - mse: 366233.4688 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3880 - mae: 14.3880 - mse: 798.1229WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.0883 - mae: 228.0883 - mse: 364152.4375 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2674 - mae: 14.2674 - mse: 788.2328WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 227.2321 - mae: 227.2321 - mse: 359256.4375 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3857 - mae: 14.3857 - mse: 788.5134WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.6212 - mae: 228.6212 - mse: 366043.9375 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2735 - mae: 14.2735 - mse: 774.1328WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 253.2639 - mae: 253.2639 - mse: 406575.4375 - lr: 0.0010\n",
      "Epoch 47/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.7062 - mae: 14.7062 - mse: 794.5614WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 320.5806 - mae: 320.5806 - mse: 635602.4375 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.0657 - mae: 15.0657 - mse: 806.3635WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 308.9816 - mae: 308.9816 - mse: 573122.4375 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.1316 - mae: 16.1316 - mse: 816.9741WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 239.6534 - mae: 239.6534 - mse: 397970.4688 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.4273 - mae: 15.4273 - mse: 817.3052WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.0109 - mae: 225.0109 - mse: 351542.7500 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2047 - mae: 14.2047 - mse: 762.4430WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.5739 - mae: 231.5739 - mse: 360589.3438 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2453 - mae: 14.2453 - mse: 768.8542WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 245.9364 - mae: 245.9364 - mse: 410247.2812 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.1483 - mae: 14.1483 - mse: 763.4359WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 260.7838 - mae: 260.7838 - mse: 429320.8438 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.1782 - mae: 14.1782 - mse: 757.3061WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 253.0955 - mae: 253.0955 - mse: 434991.6875 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.8497 - mae: 14.8497 - mse: 788.9624WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 234.1861 - mae: 234.1861 - mse: 370905.7812 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0972 - mae: 14.0972 - mse: 753.6471WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 228.0372 - mae: 228.0372 - mse: 365664.0312 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2222 - mae: 14.2222 - mse: 762.0944WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 225.4194 - mae: 225.4194 - mse: 350867.9688 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0207 - mae: 14.0207 - mse: 751.6886WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 224.3110 - mae: 224.3110 - mse: 355089.7812 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0706 - mae: 14.0706 - mse: 753.4883WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.5528 - mae: 225.5528 - mse: 349941.7500 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0187 - mae: 14.0187 - mse: 750.1451WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.8880 - mae: 226.8880 - mse: 361270.0312 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0195 - mae: 14.0195 - mse: 749.2549WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 232.4194 - mae: 232.4194 - mse: 362802.3438 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0263 - mae: 14.0263 - mse: 748.4401WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 243.7548 - mae: 243.7548 - mse: 403898.0938 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.1335 - mae: 14.1335 - mse: 750.9055WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 250.6585 - mae: 250.6585 - mse: 403288.5312 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.9525 - mae: 13.9525 - mse: 741.3629WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 259.3611 - mae: 259.3611 - mse: 449491.8125 - lr: 0.0010\n",
      "Epoch 65/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.5591 - mae: 14.5591 - mse: 764.9750WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 248.8155 - mae: 248.8155 - mse: 401533.4688 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0411 - mae: 14.0411 - mse: 740.5679WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 240.8884 - mae: 240.8884 - mse: 398317.4375 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3690 - mae: 14.3690 - mse: 756.8430WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 232.5289 - mae: 232.5289 - mse: 364594.0000 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.9311 - mae: 13.9311 - mse: 737.8591WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.1362 - mae: 231.1362 - mse: 371155.3438 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0364 - mae: 14.0364 - mse: 742.6412WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 234.8769 - mae: 234.8769 - mse: 367554.6562 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.9077 - mae: 13.9077 - mse: 736.8690WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 244.5825 - mae: 244.5825 - mse: 405554.7812 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2132 - mae: 14.2132 - mse: 747.7974WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 242.9574 - mae: 242.9574 - mse: 385348.3750 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8977 - mae: 13.8977 - mse: 734.1364WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 245.3352 - mae: 245.3352 - mse: 408968.4688 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3432 - mae: 14.3432 - mse: 751.3076WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 237.6073 - mae: 237.6073 - mse: 373940.2500 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8851 - mae: 13.8851 - mse: 733.0861WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 238.7020 - mae: 238.7020 - mse: 390244.6875 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2476 - mae: 14.2476 - mse: 747.1060WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 232.1568 - mae: 232.1568 - mse: 361989.6250 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8627 - mae: 13.8627 - mse: 732.0339WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 234.0713 - mae: 234.0713 - mse: 377461.1250 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.1101 - mae: 14.1101 - mse: 741.4347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.1794 - mae: 231.1794 - mse: 358862.0938 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8384 - mae: 13.8384 - mse: 730.6857WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 235.4454 - mae: 235.4454 - mse: 380703.7188 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0463 - mae: 14.0463 - mse: 737.8315WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 235.5000 - mae: 235.5000 - mse: 367020.5000 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8066 - mae: 13.8066 - mse: 727.9086WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 244.9118 - mae: 244.9118 - mse: 406346.9688 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.1923 - mae: 14.1923 - mse: 741.0717WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 240.3168 - mae: 240.3168 - mse: 377775.8438 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8317 - mae: 13.8317 - mse: 725.9441WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 239.8711 - mae: 239.8711 - mse: 393450.4062 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3530 - mae: 14.3530 - mse: 745.7811WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 226.5755 - mae: 226.5755 - mse: 349152.8125 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8050 - mae: 13.8050 - mse: 725.1179WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 224.9507 - mae: 224.9507 - mse: 354027.9375 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8484 - mae: 13.8484 - mse: 728.4766WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 229.7346 - mae: 229.7346 - mse: 353267.5625 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7753 - mae: 13.7753 - mse: 725.3589WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 242.2437 - mae: 242.2437 - mse: 397989.3438 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0872 - mae: 14.0872 - mse: 735.4196WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 239.3133 - mae: 239.3133 - mse: 374364.9688 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7798 - mae: 13.7798 - mse: 722.7223WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 240.4263 - mae: 240.4263 - mse: 394619.1250 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2494 - mae: 14.2494 - mse: 740.0107WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 229.6560 - mae: 229.6560 - mse: 354538.2500 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7514 - mae: 13.7514 - mse: 721.3784WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 230.5729 - mae: 230.5729 - mse: 367579.5938 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.9350 - mae: 13.9350 - mse: 728.0937WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.8661 - mae: 228.8661 - mse: 351612.0312 - lr: 0.0010\n",
      "Epoch 92/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7033 - mae: 13.7033 - mse: 719.2761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 237.7332 - mae: 237.7332 - mse: 385411.0000 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0558 - mae: 14.0558 - mse: 730.8973WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 231.7858 - mae: 231.7858 - mse: 358122.8750 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7014 - mae: 13.7014 - mse: 718.2980WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 235.4445 - mae: 235.4445 - mse: 379425.5312 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0481 - mae: 14.0481 - mse: 731.2547WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 228.9786 - mae: 228.9786 - mse: 352421.7812 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6812 - mae: 13.6812 - mse: 717.7913WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 229.9096 - mae: 229.9096 - mse: 365094.9688 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8980 - mae: 13.8980 - mse: 724.7056WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 226.2430 - mae: 226.2429 - mse: 346061.3125 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6265 - mae: 13.6265 - mse: 713.2944WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 228.4335 - mae: 228.4335 - mse: 361080.4062 - lr: 0.0010\n",
      "Epoch 99/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7776 - mae: 13.7776 - mse: 718.9300WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 229.3195 - mae: 229.3195 - mse: 351616.2188 - lr: 0.0010\n",
      "Epoch 100/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6034 - mae: 13.6034 - mse: 711.7886WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 233.5443 - mae: 233.5443 - mse: 374029.0625 - lr: 0.0010\n",
      "Epoch 101/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8839 - mae: 13.8839 - mse: 722.2090WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 229.8090 - mae: 229.8090 - mse: 353068.1250 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6111 - mae: 13.6111 - mse: 712.1745WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.6210 - mae: 231.6210 - mse: 369281.8125 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8822 - mae: 13.8822 - mse: 722.8276WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 227.3258 - mae: 227.3258 - mse: 347776.3750 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5794 - mae: 13.5794 - mse: 710.8406WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 231.3001 - mae: 231.3001 - mse: 367919.7500 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7903 - mae: 13.7903 - mse: 717.7212WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 230.1437 - mae: 230.1437 - mse: 353180.7500 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5571 - mae: 13.5571 - mse: 708.6146WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 234.9417 - mae: 234.9417 - mse: 377437.4062 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.9500 - mae: 13.9500 - mse: 722.4873WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.8631 - mae: 226.8631 - mse: 346983.7500 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5562 - mae: 13.5562 - mse: 709.1782WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 230.1816 - mae: 230.1816 - mse: 365063.5625 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7757 - mae: 13.7757 - mse: 716.7033WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.3185 - mae: 228.3185 - mse: 349145.5000 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5232 - mae: 13.5232 - mse: 705.9952WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.9326 - mae: 231.9326 - mse: 369141.0000 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7749 - mae: 13.7749 - mse: 714.4709WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 229.2729 - mae: 229.2729 - mse: 351088.5312 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5107 - mae: 13.5107 - mse: 704.0952WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 231.6865 - mae: 231.6865 - mse: 368565.4688 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7919 - mae: 13.7919 - mse: 714.5534WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 227.6166 - mae: 227.6166 - mse: 347699.4688 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5023 - mae: 13.5023 - mse: 704.3651WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 230.3985 - mae: 230.3985 - mse: 365221.0312 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7784 - mae: 13.7784 - mse: 715.1816WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.8295 - mae: 226.8295 - mse: 345940.7188 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4951 - mae: 13.4951 - mse: 705.4143WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 230.9824 - mae: 230.9824 - mse: 366424.8125 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7782 - mae: 13.7782 - mse: 714.5004WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 226.9642 - mae: 226.9642 - mse: 346083.1250 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4802 - mae: 13.4802 - mse: 703.5764WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 230.1165 - mae: 230.1165 - mse: 364245.0000 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7526 - mae: 13.7526 - mse: 712.8782WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.4107 - mae: 226.4107 - mse: 344781.2812 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4642 - mae: 13.4642 - mse: 703.0169WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 230.4932 - mae: 230.4932 - mse: 364968.7812 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7481 - mae: 13.7481 - mse: 712.6802WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.8212 - mae: 226.8212 - mse: 345493.1875 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4496 - mae: 13.4496 - mse: 702.0779WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 231.7458 - mae: 231.7458 - mse: 368026.0000 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7554 - mae: 13.7554 - mse: 711.4415WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 227.1219 - mae: 227.1219 - mse: 346039.5312 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4317 - mae: 13.4317 - mse: 700.2836WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 231.8553 - mae: 231.8553 - mse: 368251.1562 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7740 - mae: 13.7740 - mse: 711.6873WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.1908 - mae: 226.1908 - mse: 344191.7812 - lr: 0.0010\n",
      "Epoch 126/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4283 - mae: 13.4283 - mse: 700.5253WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 230.2791 - mae: 230.2791 - mse: 364198.6562 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7287 - mae: 13.7287 - mse: 710.5920WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.0240 - mae: 226.0240 - mse: 343552.1250 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4137 - mae: 13.4137 - mse: 699.7892WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 231.3621 - mae: 231.3621 - mse: 366781.8750 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7446 - mae: 13.7446 - mse: 710.3894WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.1399 - mae: 226.1399 - mse: 343759.1562 - lr: 0.0010\n",
      "Epoch 130/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4024 - mae: 13.4024 - mse: 698.5549WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 230.2011 - mae: 230.2011 - mse: 363771.5938 - lr: 0.0010\n",
      "Epoch 131/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6823 - mae: 13.6823 - mse: 706.8761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.6833 - mae: 226.6833 - mse: 344622.9375 - lr: 0.0010\n",
      "Epoch 132/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3851 - mae: 13.3851 - mse: 696.5602WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 230.4095 - mae: 230.4095 - mse: 364260.6562 - lr: 0.0010\n",
      "Epoch 133/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7059 - mae: 13.7059 - mse: 707.3228WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.2706 - mae: 225.2706 - mse: 341801.0625 - lr: 0.0010\n",
      "Epoch 134/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3772 - mae: 13.3772 - mse: 697.0731WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 230.3591 - mae: 230.3591 - mse: 364015.3438 - lr: 0.0010\n",
      "Epoch 135/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6998 - mae: 13.6998 - mse: 708.1385WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 225.5120 - mae: 225.5120 - mse: 342050.4062 - lr: 0.0010\n",
      "Epoch 136/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3682 - mae: 13.3682 - mse: 696.6477WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 230.7664 - mae: 230.7664 - mse: 364944.7500 - lr: 0.0010\n",
      "Epoch 137/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7081 - mae: 13.7081 - mse: 706.0622WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 224.6341 - mae: 224.6341 - mse: 340492.0312 - lr: 0.0010\n",
      "Epoch 138/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3434 - mae: 13.3434 - mse: 693.8582WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 229.6881 - mae: 229.6880 - mse: 362052.0625 - lr: 0.0010\n",
      "Epoch 139/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6650 - mae: 13.6650 - mse: 704.1586WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.4623 - mae: 224.4623 - mse: 339927.4688 - lr: 0.0010\n",
      "Epoch 140/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3397 - mae: 13.3397 - mse: 693.9288WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.4590 - mae: 228.4590 - mse: 358993.1250 - lr: 0.0010\n",
      "Epoch 141/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6316 - mae: 13.6316 - mse: 704.1575WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.5036 - mae: 224.5036 - mse: 339718.8125 - lr: 0.0010\n",
      "Epoch 142/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3292 - mae: 13.3292 - mse: 693.7794WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 229.2232 - mae: 229.2232 - mse: 360761.5625 - lr: 0.0010\n",
      "Epoch 143/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6405 - mae: 13.6405 - mse: 702.6961WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 224.0160 - mae: 224.0160 - mse: 338857.3438 - lr: 0.0010\n",
      "Epoch 144/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3096 - mae: 13.3096 - mse: 691.6545WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 228.2352 - mae: 228.2352 - mse: 358156.9062 - lr: 0.0010\n",
      "Epoch 145/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5922 - mae: 13.5922 - mse: 700.9843WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 224.6422 - mae: 224.6422 - mse: 339796.1562 - lr: 0.0010\n",
      "Epoch 146/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2993 - mae: 13.2993 - mse: 691.6460WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 230.3564 - mae: 230.3564 - mse: 363411.3125 - lr: 0.0010\n",
      "Epoch 147/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5945 - mae: 13.5945 - mse: 701.5654WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.2527 - mae: 226.2527 - mse: 342299.4062 - lr: 0.0010\n",
      "Epoch 148/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2163 - mae: 13.2163 - mse: 687.9512WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 234.1629 - mae: 234.1629 - mse: 370720.4062 - lr: 0.0010\n",
      "Epoch 149/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3891 - mae: 13.3891 - mse: 692.6658WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 239.1507 - mae: 239.1507 - mse: 369038.2812 - lr: 0.0010\n",
      "Epoch 150/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3958 - mae: 13.3958 - mse: 688.8115WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 233.8742 - mae: 233.8742 - mse: 373327.2500 - lr: 0.0010\n",
      "Epoch 151/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8926 - mae: 13.8926 - mse: 707.5449WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 219.1246 - mae: 219.1246 - mse: 329781.6250 - lr: 0.0010\n",
      "Epoch 152/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2825 - mae: 13.2825 - mse: 686.9863WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.9806 - mae: 217.9806 - mse: 333638.6250 - lr: 0.0010\n",
      "Epoch 153/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3362 - mae: 13.3362 - mse: 690.5520WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 221.7421 - mae: 221.7421 - mse: 332701.2812 - lr: 0.0010\n",
      "Epoch 154/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2478 - mae: 13.2478 - mse: 687.9613WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 232.8791 - mae: 232.8791 - mse: 368491.5312 - lr: 0.0010\n",
      "Epoch 155/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5104 - mae: 13.5104 - mse: 696.7836WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 231.9256 - mae: 231.9256 - mse: 353633.5625 - lr: 0.0010\n",
      "Epoch 156/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2739 - mae: 13.2739 - mse: 686.7219WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 231.4237 - mae: 231.4237 - mse: 365463.3438 - lr: 0.0010\n",
      "Epoch 157/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6118 - mae: 13.6118 - mse: 697.9651WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 224.0980 - mae: 224.0980 - mse: 337293.4062 - lr: 0.0010\n",
      "Epoch 158/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1989 - mae: 13.1989 - mse: 684.2869WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 227.0408 - mae: 227.0408 - mse: 353956.2500 - lr: 0.0010\n",
      "Epoch 159/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4908 - mae: 13.4908 - mse: 693.8702WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 222.8795 - mae: 222.8795 - mse: 335230.5312 - lr: 0.0010\n",
      "Epoch 160/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1897 - mae: 13.1897 - mse: 684.2527WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 226.9831 - mae: 226.9831 - mse: 353713.1875 - lr: 0.0010\n",
      "Epoch 161/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4772 - mae: 13.4772 - mse: 693.9500WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 223.1933 - mae: 223.1933 - mse: 335625.0000 - lr: 0.0010\n",
      "Epoch 162/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1848 - mae: 13.1848 - mse: 684.3574WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 227.3960 - mae: 227.3960 - mse: 354611.5938 - lr: 0.0010\n",
      "Epoch 163/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4177 - mae: 13.4177 - mse: 692.3632WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.9117 - mae: 226.9117 - mse: 342703.1562 - lr: 0.0010\n",
      "Epoch 164/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1939 - mae: 13.1939 - mse: 684.3323WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 229.6598 - mae: 229.6598 - mse: 360361.4062 - lr: 0.0010\n",
      "Epoch 165/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5011 - mae: 13.5011 - mse: 694.7712WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 225.5658 - mae: 225.5658 - mse: 340291.2812 - lr: 0.0010\n",
      "Epoch 166/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1999 - mae: 13.1999 - mse: 684.3008WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.9779 - mae: 226.9779 - mse: 353872.7500 - lr: 0.0010\n",
      "Epoch 167/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4791 - mae: 13.4791 - mse: 693.9655WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 222.6428 - mae: 222.6428 - mse: 334368.5625 - lr: 0.0010\n",
      "Epoch 168/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1748 - mae: 13.1748 - mse: 683.6022WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.7722 - mae: 225.7722 - mse: 350552.8438 - lr: 0.0010\n",
      "Epoch 169/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4079 - mae: 13.4079 - mse: 691.5422WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 223.8894 - mae: 223.8894 - mse: 336374.0625 - lr: 0.0010\n",
      "Epoch 170/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1519 - mae: 13.1519 - mse: 682.7589WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 229.1958 - mae: 229.1958 - mse: 358444.5312 - lr: 0.0010\n",
      "Epoch 171/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4338 - mae: 13.4338 - mse: 691.9819WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.9446 - mae: 226.9446 - mse: 342568.5625 - lr: 0.0010\n",
      "Epoch 172/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1824 - mae: 13.1824 - mse: 682.5618WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.8330 - mae: 226.8330 - mse: 352992.5000 - lr: 0.0010\n",
      "Epoch 173/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4624 - mae: 13.4624 - mse: 692.6707WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.2139 - mae: 222.2139 - mse: 333174.4062 - lr: 0.0010\n",
      "Epoch 174/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1383 - mae: 13.1383 - mse: 682.0947WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.7638 - mae: 226.7638 - mse: 352290.1875 - lr: 0.0010\n",
      "Epoch 175/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3854 - mae: 13.3854 - mse: 690.4493WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 225.3630 - mae: 225.3630 - mse: 338976.2188 - lr: 0.0010\n",
      "Epoch 176/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1433 - mae: 13.1433 - mse: 681.7694WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 228.2606 - mae: 228.2606 - mse: 356002.0312 - lr: 0.0010\n",
      "Epoch 177/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4275 - mae: 13.4275 - mse: 691.4326WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 225.1727 - mae: 225.1727 - mse: 338722.3750 - lr: 0.0010\n",
      "Epoch 178/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1476 - mae: 13.1476 - mse: 681.5427WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.5527 - mae: 226.5527 - mse: 351888.5938 - lr: 0.0010\n",
      "Epoch 179/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4327 - mae: 13.4327 - mse: 690.9733WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 222.2770 - mae: 222.2770 - mse: 333032.7812 - lr: 0.0010\n",
      "Epoch 180/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1192 - mae: 13.1192 - mse: 680.1530WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 225.5567 - mae: 225.5567 - mse: 349080.0938 - lr: 0.0010\n",
      "Epoch 181/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3523 - mae: 13.3523 - mse: 687.8976WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 223.9701 - mae: 223.9701 - mse: 335964.1875 - lr: 0.0010\n",
      "Epoch 182/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1073 - mae: 13.1073 - mse: 679.0416WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 227.5710 - mae: 227.5710 - mse: 353780.9688 - lr: 0.0010\n",
      "Epoch 183/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4082 - mae: 13.4082 - mse: 689.0207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 223.7049 - mae: 223.7049 - mse: 335600.3438 - lr: 0.0010\n",
      "Epoch 184/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1099 - mae: 13.1099 - mse: 678.7236WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.3405 - mae: 225.3405 - mse: 348396.2188 - lr: 0.0010\n",
      "Epoch 185/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3690 - mae: 13.3690 - mse: 688.0034WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.3276 - mae: 222.3276 - mse: 332640.1250 - lr: 0.0010\n",
      "Epoch 186/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0893 - mae: 13.0893 - mse: 678.7483WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.4603 - mae: 226.4603 - mse: 350769.3125 - lr: 0.0010\n",
      "Epoch 187/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3426 - mae: 13.3426 - mse: 687.5336WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.0246 - mae: 225.0246 - mse: 337773.3125 - lr: 0.0010\n",
      "Epoch 188/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1068 - mae: 13.1068 - mse: 679.1584WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.4367 - mae: 226.4366 - mse: 350933.9688 - lr: 0.0010\n",
      "Epoch 189/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3906 - mae: 13.3906 - mse: 689.3071WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 222.8760 - mae: 222.8760 - mse: 333632.2188 - lr: 0.0010\n",
      "Epoch 190/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0959 - mae: 13.0959 - mse: 679.4997WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 225.4321 - mae: 225.4321 - mse: 348411.1562 - lr: 0.0010\n",
      "Epoch 191/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3279 - mae: 13.3279 - mse: 687.2004WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 224.1194 - mae: 224.1194 - mse: 335783.9375 - lr: 0.0010\n",
      "Epoch 192/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0857 - mae: 13.0857 - mse: 677.9606WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 226.5211 - mae: 226.5211 - mse: 350890.3750 - lr: 0.0010\n",
      "Epoch 193/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3712 - mae: 13.3712 - mse: 687.1093WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 222.9296 - mae: 222.9296 - mse: 333665.5625 - lr: 0.0010\n",
      "Epoch 194/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0801 - mae: 13.0801 - mse: 676.6176WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 224.3898 - mae: 224.3898 - mse: 345748.3438 - lr: 0.0010\n",
      "Epoch 195/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3378 - mae: 13.3378 - mse: 685.5179WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 221.3366 - mae: 221.3366 - mse: 330401.4062 - lr: 0.0010\n",
      "Epoch 196/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0553 - mae: 13.0553 - mse: 675.9244WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 224.9647 - mae: 224.9647 - mse: 346807.7500 - lr: 0.0010\n",
      "Epoch 197/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3311 - mae: 13.3311 - mse: 685.4105WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 222.0130 - mae: 222.0130 - mse: 331575.5938 - lr: 0.0010\n",
      "Epoch 198/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0539 - mae: 13.0539 - mse: 676.1566WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 225.2274 - mae: 225.2274 - mse: 347406.7812 - lr: 0.0010\n",
      "Epoch 199/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2862 - mae: 13.2862 - mse: 684.4531WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 224.2036 - mae: 224.2036 - mse: 335515.6875 - lr: 0.0010\n",
      "Epoch 200/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0637 - mae: 13.0637 - mse: 676.1913WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 225.6651 - mae: 225.6651 - mse: 348478.7188 - lr: 0.0010\n",
      "Epoch 201/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3406 - mae: 13.3406 - mse: 685.6883WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.2051 - mae: 222.2050 - mse: 331791.6250 - lr: 0.0010\n",
      "Epoch 202/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0463 - mae: 13.0463 - mse: 675.5211WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 224.3996 - mae: 224.3996 - mse: 345212.7812 - lr: 0.0010\n",
      "Epoch 203/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3317 - mae: 13.3317 - mse: 684.9709WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 220.2790 - mae: 220.2790 - mse: 327898.9375 - lr: 0.0010\n",
      "Epoch 204/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0258 - mae: 13.0258 - mse: 674.8364WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 223.9367 - mae: 223.9367 - mse: 343742.6250 - lr: 0.0010\n",
      "Epoch 205/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2761 - mae: 13.2761 - mse: 682.9524WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 221.8547 - mae: 221.8547 - mse: 330700.4375 - lr: 0.0010\n",
      "Epoch 206/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0217 - mae: 13.0217 - mse: 674.0822WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 225.0956 - mae: 225.0956 - mse: 346283.7188 - lr: 0.0010\n",
      "Epoch 207/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2763 - mae: 13.2763 - mse: 682.5271WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 223.2543 - mae: 223.2543 - mse: 333459.3750 - lr: 0.0010\n",
      "Epoch 208/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0250 - mae: 13.0250 - mse: 673.7216WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 225.3177 - mae: 225.3177 - mse: 346727.2188 - lr: 0.0010\n",
      "Epoch 209/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3066 - mae: 13.3066 - mse: 683.1620WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 221.8964 - mae: 221.8964 - mse: 330809.0000 - lr: 0.0010\n",
      "Epoch 210/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0186 - mae: 13.0186 - mse: 673.6013WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 224.2336 - mae: 224.2337 - mse: 344047.0000 - lr: 0.0010\n",
      "Epoch 211/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2555 - mae: 13.2555 - mse: 681.8264WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.6534 - mae: 222.6534 - mse: 331987.5000 - lr: 0.0010\n",
      "Epoch 212/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0148 - mae: 13.0148 - mse: 673.6607WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 225.6983 - mae: 225.6983 - mse: 347373.9062 - lr: 0.0010\n",
      "Epoch 213/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2585 - mae: 13.2585 - mse: 682.0264WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 224.3429 - mae: 224.3429 - mse: 335316.6562 - lr: 0.0010\n",
      "Epoch 214/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0281 - mae: 13.0281 - mse: 673.8808WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 225.3875 - mae: 225.3875 - mse: 346704.5000 - lr: 0.0010\n",
      "Epoch 215/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2899 - mae: 13.2899 - mse: 682.6910WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 222.5727 - mae: 222.5727 - mse: 331980.3125 - lr: 0.0010\n",
      "Epoch 216/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0197 - mae: 13.0197 - mse: 673.5912WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 223.5203 - mae: 223.5203 - mse: 342115.1875 - lr: 0.0010\n",
      "Epoch 217/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2997 - mae: 13.2997 - mse: 682.8156WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 219.0661 - mae: 219.0661 - mse: 325072.8125 - lr: 0.0010\n",
      "Epoch 218/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9945 - mae: 12.9945 - mse: 673.1277WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.6551 - mae: 222.6551 - mse: 339713.9688 - lr: 0.0010\n",
      "Epoch 219/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2492 - mae: 13.2492 - mse: 681.0804WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 219.9501 - mae: 219.9501 - mse: 326626.5938 - lr: 0.0010\n",
      "Epoch 220/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9835 - mae: 12.9835 - mse: 672.6753WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.8464 - mae: 224.8464 - mse: 344679.8438 - lr: 0.0010\n",
      "Epoch 221/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2255 - mae: 13.2255 - mse: 680.5176WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.1209 - mae: 224.1209 - mse: 334707.7188 - lr: 0.0010\n",
      "Epoch 222/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9992 - mae: 12.9992 - mse: 672.8997WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.5436 - mae: 226.5436 - mse: 348840.2812 - lr: 0.0010\n",
      "Epoch 223/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3366 - mae: 13.3366 - mse: 683.3054WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.2654 - mae: 221.2654 - mse: 329477.0312 - lr: 0.0010\n",
      "Epoch 224/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0055 - mae: 13.0055 - mse: 672.8253WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.2495 - mae: 221.2495 - mse: 336460.3750 - lr: 0.0010\n",
      "Epoch 225/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2839 - mae: 13.2839 - mse: 681.8666WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.3370 - mae: 216.3370 - mse: 319818.5312 - lr: 0.0010\n",
      "Epoch 226/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9727 - mae: 12.9727 - mse: 672.5605WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 219.5072 - mae: 219.5072 - mse: 332082.3750 - lr: 0.0010\n",
      "Epoch 227/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1413 - mae: 13.1413 - mse: 678.1183WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 220.5086 - mae: 220.5085 - mse: 327186.5000 - lr: 0.0010\n",
      "Epoch 228/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9612 - mae: 12.9612 - mse: 672.1285WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 226.1840 - mae: 226.1840 - mse: 347223.4688 - lr: 0.0010\n",
      "Epoch 229/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2945 - mae: 13.2945 - mse: 682.1520WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.2504 - mae: 222.2504 - mse: 331246.5625 - lr: 0.0010\n",
      "Epoch 230/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9809 - mae: 12.9809 - mse: 673.0599WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 224.6147 - mae: 224.6147 - mse: 343694.8438 - lr: 0.0010\n",
      "Epoch 231/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2907 - mae: 13.2907 - mse: 682.5236WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 220.5795 - mae: 220.5795 - mse: 327971.4688 - lr: 0.0010\n",
      "Epoch 232/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9844 - mae: 12.9844 - mse: 673.4225WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.3392 - mae: 221.3392 - mse: 336056.3125 - lr: 0.0010\n",
      "Epoch 233/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2869 - mae: 13.2869 - mse: 681.9890WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 216.1009 - mae: 216.1009 - mse: 319434.8750 - lr: 0.0010\n",
      "Epoch 234/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9544 - mae: 12.9544 - mse: 672.1732WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 219.4889 - mae: 219.4889 - mse: 331474.5000 - lr: 0.0010\n",
      "Epoch 235/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1655 - mae: 13.1655 - mse: 678.3491WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.6176 - mae: 218.6176 - mse: 323694.6562 - lr: 0.0010\n",
      "Epoch 236/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9437 - mae: 12.9437 - mse: 671.8392WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 224.1828 - mae: 224.1828 - mse: 342016.3438 - lr: 0.0010\n",
      "Epoch 237/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2111 - mae: 13.2111 - mse: 679.6465WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 223.1876 - mae: 223.1876 - mse: 332741.5938 - lr: 0.0010\n",
      "Epoch 238/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9578 - mae: 12.9578 - mse: 672.2777WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 226.4236 - mae: 226.4236 - mse: 347398.5938 - lr: 0.0010\n",
      "Epoch 239/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3889 - mae: 13.3889 - mse: 684.1231WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.2204 - mae: 218.2204 - mse: 323729.4062 - lr: 0.0010\n",
      "Epoch 240/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9621 - mae: 12.9621 - mse: 671.9838WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.6641 - mae: 218.6641 - mse: 329553.3438 - lr: 0.0010\n",
      "Epoch 241/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2804 - mae: 13.2804 - mse: 680.7283WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.2664 - mae: 212.2664 - mse: 312251.0000 - lr: 0.0010\n",
      "Epoch 242/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9329 - mae: 12.9329 - mse: 671.2892WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 216.1098 - mae: 216.1098 - mse: 323342.7188 - lr: 0.0010\n",
      "Epoch 243/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0825 - mae: 13.0825 - mse: 676.0178WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 217.2160 - mae: 217.2160 - mse: 320653.4062 - lr: 0.0010\n",
      "Epoch 244/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9239 - mae: 12.9239 - mse: 670.7097WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.3037 - mae: 224.3037 - mse: 341765.1875 - lr: 0.0010\n",
      "Epoch 245/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1927 - mae: 13.1927 - mse: 678.1490WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 223.5356 - mae: 223.5356 - mse: 333176.5625 - lr: 0.0010\n",
      "Epoch 246/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9501 - mae: 12.9501 - mse: 671.2684WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 224.9670 - mae: 224.9670 - mse: 343894.0625 - lr: 0.0010\n",
      "Epoch 247/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3481 - mae: 13.3481 - mse: 682.1146WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.4294 - mae: 217.4294 - mse: 321998.9688 - lr: 0.0010\n",
      "Epoch 248/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9269 - mae: 12.9269 - mse: 669.9883WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.0289 - mae: 221.0289 - mse: 334564.0000 - lr: 0.0010\n",
      "Epoch 249/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1894 - mae: 13.1894 - mse: 677.3246WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 218.6485 - mae: 218.6485 - mse: 323728.0312 - lr: 0.0010\n",
      "Epoch 250/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9191 - mae: 12.9191 - mse: 670.1661WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 224.4777 - mae: 224.4777 - mse: 342230.4688 - lr: 0.0010\n",
      "Epoch 251/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2551 - mae: 13.2551 - mse: 679.4406WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 220.3840 - mae: 220.3840 - mse: 327242.4375 - lr: 0.0010\n",
      "Epoch 252/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9240 - mae: 12.9240 - mse: 669.7524WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.3541 - mae: 224.3541 - mse: 342072.2188 - lr: 0.0010\n",
      "Epoch 253/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2819 - mae: 13.2819 - mse: 679.5897WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 218.8931 - mae: 218.8931 - mse: 324509.8438 - lr: 0.0010\n",
      "Epoch 254/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9312 - mae: 12.9312 - mse: 670.2005WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 220.9348 - mae: 220.9348 - mse: 334369.3438 - lr: 0.0010\n",
      "Epoch 255/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2291 - mae: 13.2291 - mse: 677.5434WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 216.5302 - mae: 216.5302 - mse: 319915.7500 - lr: 0.0010\n",
      "Epoch 256/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9110 - mae: 12.9110 - mse: 669.5549WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.7377 - mae: 221.7377 - mse: 335957.5625 - lr: 0.0010\n",
      "Epoch 257/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2217 - mae: 13.2217 - mse: 677.3035WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 217.6368 - mae: 217.6368 - mse: 321910.0625 - lr: 0.0010\n",
      "Epoch 258/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9080 - mae: 12.9080 - mse: 668.7111WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 221.8878 - mae: 221.8878 - mse: 336399.3125 - lr: 0.0010\n",
      "Epoch 259/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2180 - mae: 13.2180 - mse: 677.5428WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 217.9526 - mae: 217.9526 - mse: 322445.6875 - lr: 0.0010\n",
      "Epoch 260/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9046 - mae: 12.9046 - mse: 668.6558WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 222.2377 - mae: 222.2377 - mse: 337139.4062 - lr: 0.0010\n",
      "Epoch 261/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2052 - mae: 13.2052 - mse: 676.4275WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 218.7750 - mae: 218.7750 - mse: 323917.0938 - lr: 0.0010\n",
      "Epoch 262/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8992 - mae: 12.8992 - mse: 667.8849WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 224.0850 - mae: 224.0850 - mse: 341252.8750 - lr: 0.0010\n",
      "Epoch 263/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2639 - mae: 13.2639 - mse: 678.1343WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 218.7413 - mae: 218.7413 - mse: 324096.4062 - lr: 0.0010\n",
      "Epoch 264/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9075 - mae: 12.9075 - mse: 668.3481WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 221.8962 - mae: 221.8962 - mse: 336389.6562 - lr: 0.0010\n",
      "Epoch 265/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2249 - mae: 13.2249 - mse: 676.4513WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 217.4413 - mae: 217.4413 - mse: 321536.5938 - lr: 0.0010\n",
      "Epoch 266/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9013 - mae: 12.9013 - mse: 667.4581WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 220.4526 - mae: 220.4526 - mse: 333030.6250 - lr: 0.0010\n",
      "Epoch 267/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2097 - mae: 13.2097 - mse: 676.0583WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 9ms/step - loss: 215.8551 - mae: 215.8551 - mse: 318497.9688 - lr: 0.0010\n",
      "Epoch 268/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8915 - mae: 12.8915 - mse: 667.5858WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 220.4575 - mae: 220.4575 - mse: 332918.4062 - lr: 0.0010\n",
      "Epoch 269/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1790 - mae: 13.1790 - mse: 675.1718WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.0811 - mae: 217.0811 - mse: 320647.9062 - lr: 0.0010\n",
      "Epoch 270/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8860 - mae: 12.8860 - mse: 666.2761WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 221.1094 - mae: 221.1094 - mse: 334422.8750 - lr: 0.0010\n",
      "Epoch 271/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1782 - mae: 13.1782 - mse: 673.8657WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 217.7330 - mae: 217.7330 - mse: 321844.4688 - lr: 0.0010\n",
      "Epoch 272/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8789 - mae: 12.8789 - mse: 665.7374WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 223.4685 - mae: 223.4685 - mse: 339661.2500 - lr: 0.0010\n",
      "Epoch 273/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2430 - mae: 13.2430 - mse: 675.6154WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.7685 - mae: 217.7685 - mse: 322086.5312 - lr: 0.0010\n",
      "Epoch 274/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8853 - mae: 12.8853 - mse: 666.0486WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 221.2558 - mae: 221.2558 - mse: 334763.0625 - lr: 0.0010\n",
      "Epoch 275/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2120 - mae: 13.2120 - mse: 674.8775WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.0724 - mae: 216.0724 - mse: 318842.3750 - lr: 0.0010\n",
      "Epoch 276/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8795 - mae: 12.8795 - mse: 665.5460WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 219.9911 - mae: 219.9911 - mse: 331827.0312 - lr: 0.0010\n",
      "Epoch 277/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1960 - mae: 13.1960 - mse: 673.8513WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 214.8106 - mae: 214.8106 - mse: 316466.5000 - lr: 0.0010\n",
      "Epoch 278/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8741 - mae: 12.8741 - mse: 664.7931WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.3463 - mae: 218.3463 - mse: 328052.2188 - lr: 0.0010\n",
      "Epoch 279/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1962 - mae: 13.1962 - mse: 673.6356WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 212.4875 - mae: 212.4875 - mse: 312176.3125 - lr: 0.0010\n",
      "Epoch 280/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8694 - mae: 12.8694 - mse: 664.7751WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.2984 - mae: 215.2984 - mse: 321159.6562 - lr: 0.0010\n",
      "Epoch 281/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1154 - mae: 13.1154 - mse: 671.3160WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 211.4951 - mae: 211.4951 - mse: 310071.9375 - lr: 0.0010\n",
      "Epoch 282/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8583 - mae: 12.8583 - mse: 663.7720WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.4225 - mae: 215.4225 - mse: 321329.3438 - lr: 0.0010\n",
      "Epoch 283/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0903 - mae: 13.0903 - mse: 669.8010WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.3112 - mae: 212.3112 - mse: 311430.4688 - lr: 0.0010\n",
      "Epoch 284/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8509 - mae: 12.8509 - mse: 662.9272WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.2466 - mae: 217.2466 - mse: 325296.2188 - lr: 0.0010\n",
      "Epoch 285/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0811 - mae: 13.0811 - mse: 669.1158WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 215.1916 - mae: 215.1916 - mse: 316656.7188 - lr: 0.0010\n",
      "Epoch 286/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8475 - mae: 12.8475 - mse: 662.5939WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.3148 - mae: 221.3148 - mse: 334375.2188 - lr: 0.0010\n",
      "Epoch 287/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1150 - mae: 13.1150 - mse: 670.1617WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 219.7045 - mae: 219.7045 - mse: 325068.3750 - lr: 0.0010\n",
      "Epoch 288/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8563 - mae: 12.8563 - mse: 663.1213WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 224.0942 - mae: 224.0942 - mse: 340855.0312 - lr: 0.0010\n",
      "Epoch 289/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2665 - mae: 13.2665 - mse: 674.1709WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.4858 - mae: 216.4858 - mse: 319624.2188 - lr: 0.0010\n",
      "Epoch 290/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8592 - mae: 12.8592 - mse: 663.0662WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 219.4496 - mae: 219.4496 - mse: 330423.0312 - lr: 0.0010\n",
      "Epoch 291/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2238 - mae: 13.2238 - mse: 672.7732WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 212.2518 - mae: 212.2518 - mse: 311733.8438 - lr: 0.0010\n",
      "Epoch 292/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8565 - mae: 12.8565 - mse: 662.7693WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 214.2226 - mae: 214.2226 - mse: 318684.8125 - lr: 0.0010\n",
      "Epoch 293/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0746 - mae: 13.0746 - mse: 668.8843WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.3275 - mae: 211.3275 - mse: 309518.6562 - lr: 0.0010\n",
      "Epoch 294/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8470 - mae: 12.8470 - mse: 662.4127WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 213.5901 - mae: 213.5901 - mse: 317253.8125 - lr: 0.0010\n",
      "Epoch 295/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0188 - mae: 13.0188 - mse: 667.0068WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.7179 - mae: 212.7179 - mse: 311736.3438 - lr: 0.0010\n",
      "Epoch 296/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8361 - mae: 12.8361 - mse: 661.5607WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 218.6720 - mae: 218.6720 - mse: 328240.7500 - lr: 0.0010\n",
      "Epoch 297/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0953 - mae: 13.0953 - mse: 668.3353WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.8708 - mae: 215.8708 - mse: 317846.1250 - lr: 0.0010\n",
      "Epoch 298/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8317 - mae: 12.8317 - mse: 661.0548WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 222.4310 - mae: 222.4310 - mse: 336696.0312 - lr: 0.0010\n",
      "Epoch 299/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1214 - mae: 13.1214 - mse: 669.1187WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 220.0760 - mae: 220.0760 - mse: 325683.0625 - lr: 0.0010\n",
      "Epoch 300/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8514 - mae: 12.8514 - mse: 661.7538WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 221.9185 - mae: 221.9185 - mse: 335895.5625 - lr: 0.0010\n",
      "Epoch 301/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.2083 - mae: 13.2083 - mse: 671.5457WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.3478 - mae: 215.3478 - mse: 317275.4062 - lr: 0.0010\n",
      "Epoch 302/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8450 - mae: 12.8450 - mse: 661.9904WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.5902 - mae: 217.5902 - mse: 326110.6250 - lr: 0.0010\n",
      "Epoch 303/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1785 - mae: 13.1785 - mse: 670.9059WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 210.8835 - mae: 210.8835 - mse: 308958.1250 - lr: 0.0010\n",
      "Epoch 304/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8450 - mae: 12.8450 - mse: 661.3818WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.0225 - mae: 211.0226 - mse: 311833.2812 - lr: 0.0010\n",
      "Epoch 305/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9515 - mae: 12.9515 - mse: 664.4014WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 212.5352 - mae: 212.5352 - mse: 311039.6250 - lr: 0.0010\n",
      "Epoch 306/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8284 - mae: 12.8284 - mse: 660.7219WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 219.9909 - mae: 219.9910 - mse: 330993.7500 - lr: 0.0010\n",
      "Epoch 307/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0792 - mae: 13.0792 - mse: 667.0905WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.2910 - mae: 218.2910 - mse: 322179.1250 - lr: 0.0010\n",
      "Epoch 308/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8237 - mae: 12.8237 - mse: 659.8721WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 223.1259 - mae: 223.1259 - mse: 338279.6562 - lr: 0.0010\n",
      "Epoch 309/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1761 - mae: 13.1761 - mse: 669.4622WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 218.0262 - mae: 218.0262 - mse: 322048.1562 - lr: 0.0010\n",
      "Epoch 310/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8366 - mae: 12.8366 - mse: 660.8591WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 220.0532 - mae: 220.0532 - mse: 331581.4375 - lr: 0.0010\n",
      "Epoch 311/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1788 - mae: 13.1788 - mse: 670.0187WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 213.7231 - mae: 213.7231 - mse: 314125.6562 - lr: 0.0010\n",
      "Epoch 312/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8243 - mae: 12.8243 - mse: 659.8446WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 216.7823 - mae: 216.7823 - mse: 324098.2500 - lr: 0.0010\n",
      "Epoch 313/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1206 - mae: 13.1206 - mse: 667.3168WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 211.6184 - mae: 211.6184 - mse: 310102.9375 - lr: 0.0010\n",
      "Epoch 314/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8212 - mae: 12.8212 - mse: 659.4728WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 213.9314 - mae: 213.9314 - mse: 317818.7188 - lr: 0.0010\n",
      "Epoch 315/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0538 - mae: 13.0538 - mse: 665.6630WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 210.5757 - mae: 210.5757 - mse: 307926.7188 - lr: 0.0010\n",
      "Epoch 316/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8139 - mae: 12.8139 - mse: 658.9707WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 212.8715 - mae: 212.8715 - mse: 315520.3438 - lr: 0.0010\n",
      "Epoch 317/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9897 - mae: 12.9897 - mse: 663.3599WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 3ms/step - loss: 211.9301 - mae: 211.9301 - mse: 310065.6250 - lr: 0.0010\n",
      "Epoch 318/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8041 - mae: 12.8041 - mse: 657.9048WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 216.8372 - mae: 216.8372 - mse: 323982.4688 - lr: 0.0010\n",
      "Epoch 319/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0506 - mae: 13.0506 - mse: 663.9775WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 214.0411 - mae: 214.0410 - mse: 314128.0000 - lr: 0.0010\n",
      "Epoch 320/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7992 - mae: 12.7992 - mse: 656.9044WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 218.8706 - mae: 218.8706 - mse: 328547.2500 - lr: 0.0010\n",
      "Epoch 321/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0703 - mae: 13.0703 - mse: 664.4834WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.3339 - mae: 216.3339 - mse: 318456.0938 - lr: 0.0010\n",
      "Epoch 322/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8036 - mae: 12.8036 - mse: 657.6514WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 220.3941 - mae: 220.3941 - mse: 332022.5000 - lr: 0.0010\n",
      "Epoch 323/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1246 - mae: 13.1246 - mse: 665.9602WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 215.9136 - mae: 215.9136 - mse: 317880.2812 - lr: 0.0010\n",
      "Epoch 324/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8059 - mae: 12.8059 - mse: 657.1547WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 219.1166 - mae: 219.1166 - mse: 329268.0000 - lr: 0.0010\n",
      "Epoch 325/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1392 - mae: 13.1392 - mse: 665.6889WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.2300 - mae: 213.2300 - mse: 312967.7812 - lr: 0.0010\n",
      "Epoch 326/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8030 - mae: 12.8030 - mse: 656.7728WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 216.5439 - mae: 216.5439 - mse: 323463.8750 - lr: 0.0010\n",
      "Epoch 327/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0952 - mae: 13.0952 - mse: 664.8621WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.6512 - mae: 211.6512 - mse: 309945.6875 - lr: 0.0010\n",
      "Epoch 328/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8056 - mae: 12.8056 - mse: 657.4913WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 213.6595 - mae: 213.6595 - mse: 317178.8750 - lr: 0.0010\n",
      "Epoch 329/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0435 - mae: 13.0435 - mse: 663.3790WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 209.8834 - mae: 209.8834 - mse: 306471.5938 - lr: 0.0010\n",
      "Epoch 330/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7942 - mae: 12.7942 - mse: 656.1562WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.6913 - mae: 212.6913 - mse: 315027.8750 - lr: 0.0010\n",
      "Epoch 331/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9758 - mae: 12.9758 - mse: 660.1365WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.5388 - mae: 211.5388 - mse: 309177.1875 - lr: 0.0010\n",
      "Epoch 332/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7851 - mae: 12.7851 - mse: 654.8414WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.5260 - mae: 216.5260 - mse: 323216.4375 - lr: 0.0010\n",
      "Epoch 333/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0140 - mae: 13.0140 - mse: 661.2280WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 215.0906 - mae: 215.0906 - mse: 315749.3750 - lr: 0.0010\n",
      "Epoch 334/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7897 - mae: 12.7897 - mse: 655.8123WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 218.2123 - mae: 218.2123 - mse: 327099.6875 - lr: 0.0010\n",
      "Epoch 335/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0720 - mae: 13.0720 - mse: 663.0334WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 214.8320 - mae: 214.8320 - mse: 315493.8438 - lr: 0.0010\n",
      "Epoch 336/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7907 - mae: 12.7907 - mse: 655.1605WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.9831 - mae: 216.9831 - mse: 324405.7500 - lr: 0.0010\n",
      "Epoch 337/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1056 - mae: 13.1056 - mse: 663.3715WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 211.2450 - mae: 211.2450 - mse: 309079.3750 - lr: 0.0010\n",
      "Epoch 338/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7903 - mae: 12.7903 - mse: 655.8976WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.1093 - mae: 213.1093 - mse: 315874.5938 - lr: 0.0010\n",
      "Epoch 339/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0182 - mae: 13.0182 - mse: 661.6964WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 209.9156 - mae: 209.9156 - mse: 306335.7812 - lr: 0.0010\n",
      "Epoch 340/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7810 - mae: 12.7810 - mse: 654.6550WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 212.6193 - mae: 212.6193 - mse: 314760.7812 - lr: 0.0010\n",
      "Epoch 341/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9611 - mae: 12.9611 - mse: 658.8404WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.8993 - mae: 211.8993 - mse: 309670.1875 - lr: 0.0010\n",
      "Epoch 342/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7783 - mae: 12.7783 - mse: 653.9916WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 218.9520 - mae: 218.9520 - mse: 328326.7188 - lr: 0.0010\n",
      "Epoch 343/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0112 - mae: 13.0112 - mse: 660.5530WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 218.4855 - mae: 218.4855 - mse: 321929.9062 - lr: 0.0010\n",
      "Epoch 344/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7874 - mae: 12.7874 - mse: 655.1387WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 221.7843 - mae: 221.7843 - mse: 334961.0625 - lr: 0.0010\n",
      "Epoch 345/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1649 - mae: 13.1649 - mse: 664.5123WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.1761 - mae: 215.1761 - mse: 316383.6875 - lr: 0.0010\n",
      "Epoch 346/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8057 - mae: 12.8057 - mse: 655.5690WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 214.4258 - mae: 214.4258 - mse: 318901.1875 - lr: 0.0010\n",
      "Epoch 347/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1213 - mae: 13.1213 - mse: 663.6182WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 207.6897 - mae: 207.6897 - mse: 302665.4688 - lr: 0.0010\n",
      "Epoch 348/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7844 - mae: 12.7844 - mse: 654.8193WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 208.1438 - mae: 208.1438 - mse: 305510.0625 - lr: 0.0010\n",
      "Epoch 349/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8781 - mae: 12.8781 - mse: 657.3751WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.5935 - mae: 210.5935 - mse: 306892.0312 - lr: 0.0010\n",
      "Epoch 350/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7770 - mae: 12.7770 - mse: 654.7304WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.6869 - mae: 215.6869 - mse: 321190.1875 - lr: 0.0010\n",
      "Epoch 351/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9710 - mae: 12.9710 - mse: 659.4159WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 216.0246 - mae: 216.0245 - mse: 317174.6875 - lr: 0.0010\n",
      "Epoch 352/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7695 - mae: 12.7695 - mse: 654.1041WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 221.8846 - mae: 221.8846 - mse: 334891.5000 - lr: 0.0010\n",
      "Epoch 353/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1244 - mae: 13.1244 - mse: 663.0417WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.6299 - mae: 216.6299 - mse: 318856.8125 - lr: 0.0010\n",
      "Epoch 354/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7898 - mae: 12.7898 - mse: 655.1268WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 217.1169 - mae: 217.1169 - mse: 324770.9375 - lr: 0.0010\n",
      "Epoch 355/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0872 - mae: 13.0872 - mse: 662.8174WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 212.2534 - mae: 212.2534 - mse: 310739.9062 - lr: 0.0010\n",
      "Epoch 356/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7770 - mae: 12.7770 - mse: 654.5975WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 214.9158 - mae: 214.9158 - mse: 319714.4375 - lr: 0.0010\n",
      "Epoch 357/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0795 - mae: 13.0795 - mse: 661.7283WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 209.3045 - mae: 209.3045 - mse: 305387.1562 - lr: 0.0010\n",
      "Epoch 358/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7768 - mae: 12.7768 - mse: 654.1824WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 210.2044 - mae: 210.2044 - mse: 309692.2812 - lr: 0.0010\n",
      "Epoch 359/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9010 - mae: 12.9010 - mse: 657.4725WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 211.8723 - mae: 211.8723 - mse: 309235.8438 - lr: 0.0010\n",
      "Epoch 360/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7757 - mae: 12.7757 - mse: 654.1587WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 220.5717 - mae: 220.5717 - mse: 331551.0938 - lr: 0.0010\n",
      "Epoch 361/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0414 - mae: 13.0414 - mse: 660.6345WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.7104 - mae: 218.7104 - mse: 322474.5312 - lr: 0.0010\n",
      "Epoch 362/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7849 - mae: 12.7849 - mse: 654.0765WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 219.2642 - mae: 219.2642 - mse: 329346.5625 - lr: 0.0010\n",
      "Epoch 363/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1278 - mae: 13.1278 - mse: 662.5157WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 213.1853 - mae: 213.1853 - mse: 312547.6250 - lr: 0.0010\n",
      "Epoch 364/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7734 - mae: 12.7734 - mse: 653.6618WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 215.2310 - mae: 215.2310 - mse: 320411.9062 - lr: 0.0010\n",
      "Epoch 365/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0570 - mae: 13.0570 - mse: 661.1976WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.8473 - mae: 210.8473 - mse: 308137.6250 - lr: 0.0010\n",
      "Epoch 366/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7755 - mae: 12.7755 - mse: 654.4584WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 211.7046 - mae: 211.7046 - mse: 312756.6875 - lr: 0.0010\n",
      "Epoch 367/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9794 - mae: 12.9794 - mse: 659.1762WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 209.4847 - mae: 209.4847 - mse: 305309.4688 - lr: 0.0010\n",
      "Epoch 368/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7627 - mae: 12.7627 - mse: 653.1055WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 212.0354 - mae: 212.0354 - mse: 313400.2500 - lr: 0.0010\n",
      "Epoch 369/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9537 - mae: 12.9537 - mse: 657.3672WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 210.6309 - mae: 210.6309 - mse: 307223.9688 - lr: 0.0010\n",
      "Epoch 370/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7560 - mae: 12.7560 - mse: 652.1315WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 214.2258 - mae: 214.2258 - mse: 318102.8750 - lr: 0.0010\n",
      "Epoch 371/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0127 - mae: 13.0127 - mse: 658.8984WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 210.7516 - mae: 210.7516 - mse: 307688.9062 - lr: 0.0010\n",
      "Epoch 372/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7579 - mae: 12.7579 - mse: 652.9344WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 213.1098 - mae: 213.1098 - mse: 315738.5312 - lr: 0.0010\n",
      "Epoch 373/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9949 - mae: 12.9949 - mse: 658.7636WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 210.0769 - mae: 210.0769 - mse: 306363.0625 - lr: 0.0010\n",
      "Epoch 374/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7550 - mae: 12.7550 - mse: 652.2929WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 212.2885 - mae: 212.2885 - mse: 313979.8438 - lr: 0.0010\n",
      "Epoch 375/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9523 - mae: 12.9523 - mse: 656.7277WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.7002 - mae: 210.7002 - mse: 307261.8750 - lr: 0.0010\n",
      "Epoch 376/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7493 - mae: 12.7493 - mse: 651.2462WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 214.5741 - mae: 214.5741 - mse: 318816.5625 - lr: 0.0010\n",
      "Epoch 377/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9927 - mae: 12.9927 - mse: 657.3871WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 211.7584 - mae: 211.7584 - mse: 309347.9688 - lr: 0.0010\n",
      "Epoch 378/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7509 - mae: 12.7509 - mse: 651.5224WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 214.4412 - mae: 214.4412 - mse: 318615.7500 - lr: 0.0010\n",
      "Epoch 379/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9826 - mae: 12.9826 - mse: 657.5820WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 212.3902 - mae: 212.3902 - mse: 310458.1562 - lr: 0.0010\n",
      "Epoch 380/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7497 - mae: 12.7497 - mse: 651.7828WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 218.2118 - mae: 218.2118 - mse: 326427.1562 - lr: 0.0010\n",
      "Epoch 381/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9787 - mae: 12.9787 - mse: 657.6039WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 218.2669 - mae: 218.2669 - mse: 321306.7500 - lr: 0.0010\n",
      "Epoch 382/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7649 - mae: 12.7649 - mse: 652.8271WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 219.5206 - mae: 219.5206 - mse: 329676.2812 - lr: 0.0010\n",
      "Epoch 383/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.1398 - mae: 13.1398 - mse: 662.2651WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.5723 - mae: 212.5723 - mse: 311377.1875 - lr: 0.0010\n",
      "Epoch 384/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7599 - mae: 12.7599 - mse: 653.0106WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 214.5797 - mae: 214.5797 - mse: 318885.2812 - lr: 0.0010\n",
      "Epoch 385/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0586 - mae: 13.0586 - mse: 659.9329WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 209.5045 - mae: 209.5045 - mse: 305554.6250 - lr: 0.0010\n",
      "Epoch 386/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7555 - mae: 12.7555 - mse: 651.9544WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.6954 - mae: 210.6954 - mse: 310537.9375 - lr: 0.0010\n",
      "Epoch 387/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9185 - mae: 12.9185 - mse: 655.8741WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.5673 - mae: 210.5673 - mse: 306860.5938 - lr: 0.0010\n",
      "Epoch 388/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7508 - mae: 12.7508 - mse: 651.7474WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 214.9069 - mae: 214.9068 - mse: 319383.8125 - lr: 0.0010\n",
      "Epoch 389/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0087 - mae: 13.0087 - mse: 657.9429WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 211.5376 - mae: 211.5376 - mse: 308977.0000 - lr: 0.0010\n",
      "Epoch 390/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7504 - mae: 12.7504 - mse: 651.4917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.6134 - mae: 213.6134 - mse: 316807.6562 - lr: 0.0010\n",
      "Epoch 391/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0394 - mae: 13.0394 - mse: 658.3724WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 208.5423 - mae: 208.5423 - mse: 303699.8750 - lr: 0.0010\n",
      "Epoch 392/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7441 - mae: 12.7441 - mse: 650.8409WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 211.5733 - mae: 211.5733 - mse: 312304.9688 - lr: 0.0010\n",
      "Epoch 393/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9167 - mae: 12.9167 - mse: 655.2656WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 211.4762 - mae: 211.4762 - mse: 308452.3438 - lr: 0.0010\n",
      "Epoch 394/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7432 - mae: 12.7432 - mse: 651.2255WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.0930 - mae: 216.0930 - mse: 321887.3750 - lr: 0.0010\n",
      "Epoch 395/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9510 - mae: 12.9510 - mse: 656.4587WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.2537 - mae: 216.2537 - mse: 317327.7188 - lr: 0.0010\n",
      "Epoch 396/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7494 - mae: 12.7494 - mse: 651.5864WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 218.3529 - mae: 218.3529 - mse: 326916.8438 - lr: 0.0010\n",
      "Epoch 397/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0463 - mae: 13.0463 - mse: 658.7227WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 214.8188 - mae: 214.8188 - mse: 315138.6562 - lr: 0.0010\n",
      "Epoch 398/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7567 - mae: 12.7567 - mse: 651.4625WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 215.1656 - mae: 215.1656 - mse: 320245.8125 - lr: 0.0010\n",
      "Epoch 399/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0882 - mae: 13.0882 - mse: 659.7315WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 208.9304 - mae: 208.9304 - mse: 304551.3750 - lr: 0.0010\n",
      "Epoch 400/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7495 - mae: 12.7495 - mse: 651.6649WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 209.7012 - mae: 209.7012 - mse: 308517.1562 - lr: 0.0010\n",
      "Epoch 401/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9026 - mae: 12.9026 - mse: 654.6564WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 209.6542 - mae: 209.6542 - mse: 305084.0938 - lr: 0.0010\n",
      "Epoch 402/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7390 - mae: 12.7390 - mse: 650.2471WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 214.1459 - mae: 214.1459 - mse: 317741.2500 - lr: 0.0010\n",
      "Epoch 403/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9661 - mae: 12.9661 - mse: 656.0056WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 212.2843 - mae: 212.2843 - mse: 310103.2812 - lr: 0.0010\n",
      "Epoch 404/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7363 - mae: 12.7363 - mse: 650.6523WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.6980 - mae: 215.6980 - mse: 321126.9375 - lr: 0.0010\n",
      "Epoch 405/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9555 - mae: 12.9555 - mse: 655.9928WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 215.4243 - mae: 215.4243 - mse: 315835.6875 - lr: 0.0010\n",
      "Epoch 406/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7425 - mae: 12.7425 - mse: 650.9133WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 217.1163 - mae: 217.1163 - mse: 324225.5000 - lr: 0.0010\n",
      "Epoch 407/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0095 - mae: 13.0095 - mse: 657.4984WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 214.7906 - mae: 214.7906 - mse: 314936.6875 - lr: 0.0010\n",
      "Epoch 408/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7510 - mae: 12.7510 - mse: 651.9501WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 215.7596 - mae: 215.7596 - mse: 321429.7812 - lr: 0.0010\n",
      "Epoch 409/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0490 - mae: 13.0490 - mse: 659.2053WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 211.4259 - mae: 211.4259 - mse: 308969.5625 - lr: 0.0010\n",
      "Epoch 410/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7481 - mae: 12.7481 - mse: 652.0057WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 213.4327 - mae: 213.4327 - mse: 316238.1875 - lr: 0.0010\n",
      "Epoch 411/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0548 - mae: 13.0548 - mse: 659.0294WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 207.9963 - mae: 207.9963 - mse: 302805.6875 - lr: 0.0010\n",
      "Epoch 412/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7439 - mae: 12.7439 - mse: 651.3013WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 210.1202 - mae: 210.1202 - mse: 309208.7188 - lr: 0.0010\n",
      "Epoch 413/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8863 - mae: 12.8863 - mse: 654.4794WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 211.5141 - mae: 211.5141 - mse: 308422.0000 - lr: 0.0010\n",
      "Epoch 414/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7394 - mae: 12.7394 - mse: 650.7168WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.2795 - mae: 216.2795 - mse: 322077.3438 - lr: 0.0010\n",
      "Epoch 415/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9689 - mae: 12.9689 - mse: 656.4199WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.7153 - mae: 215.7153 - mse: 316480.2188 - lr: 0.0010\n",
      "Epoch 416/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7445 - mae: 12.7445 - mse: 651.7959WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 217.2579 - mae: 217.2579 - mse: 324459.8438 - lr: 0.0010\n",
      "Epoch 417/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0252 - mae: 13.0252 - mse: 658.5328WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 6ms/step - loss: 214.3008 - mae: 214.3008 - mse: 314030.7812 - lr: 0.0010\n",
      "Epoch 418/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7459 - mae: 12.7459 - mse: 651.3436WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 214.9492 - mae: 214.9492 - mse: 319655.2500 - lr: 0.0010\n",
      "Epoch 419/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0164 - mae: 13.0164 - mse: 657.1641WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 211.3563 - mae: 211.3563 - mse: 308619.0938 - lr: 0.0010\n",
      "Epoch 420/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7378 - mae: 12.7378 - mse: 650.8303WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 214.3044 - mae: 214.3044 - mse: 318110.5625 - lr: 0.0010\n",
      "Epoch 421/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0167 - mae: 13.0167 - mse: 657.8709WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.3678 - mae: 210.3678 - mse: 306792.9688 - lr: 0.0010\n",
      "Epoch 422/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7412 - mae: 12.7412 - mse: 651.5811WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 211.1955 - mae: 211.1955 - mse: 311539.9062 - lr: 0.0010\n",
      "Epoch 423/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9561 - mae: 12.9561 - mse: 655.7560WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 208.8093 - mae: 208.8093 - mse: 303755.5000 - lr: 0.0010\n",
      "Epoch 424/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7310 - mae: 12.7310 - mse: 649.8478WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.6151 - mae: 211.6151 - mse: 312255.2188 - lr: 0.0010\n",
      "Epoch 425/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9321 - mae: 12.9321 - mse: 654.5449WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.0715 - mae: 210.0715 - mse: 305868.0312 - lr: 0.0010\n",
      "Epoch 426/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7283 - mae: 12.7283 - mse: 649.8542WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.7576 - mae: 212.7576 - mse: 314777.7188 - lr: 0.0010\n",
      "Epoch 427/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9808 - mae: 12.9808 - mse: 655.8459WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 209.2224 - mae: 209.2224 - mse: 304495.4062 - lr: 0.0010\n",
      "Epoch 428/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7273 - mae: 12.7273 - mse: 649.7705WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 211.0852 - mae: 211.0852 - mse: 311299.9062 - lr: 0.0010\n",
      "Epoch 429/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9189 - mae: 12.9189 - mse: 654.1607WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 209.8754 - mae: 209.8754 - mse: 305384.8750 - lr: 0.0010\n",
      "Epoch 430/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7243 - mae: 12.7243 - mse: 649.2929WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 212.6079 - mae: 212.6079 - mse: 314428.8438 - lr: 0.0010\n",
      "Epoch 431/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9355 - mae: 12.9355 - mse: 654.3408WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 211.0766 - mae: 211.0766 - mse: 307619.5312 - lr: 0.0010\n",
      "Epoch 432/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7240 - mae: 12.7240 - mse: 649.2872WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 214.6304 - mae: 214.6304 - mse: 318653.5625 - lr: 0.0010\n",
      "Epoch 433/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9068 - mae: 12.9068 - mse: 653.5845WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.0391 - mae: 216.0391 - mse: 316566.1875 - lr: 0.0010\n",
      "Epoch 434/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7300 - mae: 12.7300 - mse: 649.3333WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 217.2958 - mae: 217.2958 - mse: 324411.2500 - lr: 0.0010\n",
      "Epoch 435/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0183 - mae: 13.0183 - mse: 656.8327WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 214.0169 - mae: 214.0169 - mse: 313334.8125 - lr: 0.0010\n",
      "Epoch 436/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7446 - mae: 12.7446 - mse: 651.5019WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.1127 - mae: 213.1127 - mse: 315778.1562 - lr: 0.0010\n",
      "Epoch 437/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0376 - mae: 13.0376 - mse: 657.7317WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 207.8293 - mae: 207.8293 - mse: 302192.8438 - lr: 0.0010\n",
      "Epoch 438/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7268 - mae: 12.7268 - mse: 649.6611WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 209.7623 - mae: 209.7623 - mse: 308514.9062 - lr: 0.0010\n",
      "Epoch 439/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8687 - mae: 12.8687 - mse: 652.5862WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 211.1727 - mae: 211.1727 - mse: 307521.0938 - lr: 0.0010\n",
      "Epoch 440/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7254 - mae: 12.7254 - mse: 649.6567WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 216.1301 - mae: 216.1301 - mse: 321596.0938 - lr: 0.0010\n",
      "Epoch 441/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9437 - mae: 12.9437 - mse: 655.2837WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.0611 - mae: 216.0611 - mse: 316846.3438 - lr: 0.0010\n",
      "Epoch 442/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7385 - mae: 12.7385 - mse: 650.9045WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.9193 - mae: 215.9193 - mse: 321590.1250 - lr: 0.0010\n",
      "Epoch 443/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0159 - mae: 13.0159 - mse: 656.9025WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 212.4811 - mae: 212.4811 - mse: 310524.3750 - lr: 0.0010\n",
      "Epoch 444/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7315 - mae: 12.7315 - mse: 650.1123WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 212.7865 - mae: 212.7865 - mse: 314837.1562 - lr: 0.0010\n",
      "Epoch 445/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0477 - mae: 13.0477 - mse: 657.5065WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 206.8721 - mae: 206.8721 - mse: 300547.6250 - lr: 0.0010\n",
      "Epoch 446/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7269 - mae: 12.7269 - mse: 650.1768WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 208.4203 - mae: 208.4203 - mse: 305756.6250 - lr: 0.0010\n",
      "Epoch 447/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8557 - mae: 12.8557 - mse: 652.3228WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 209.8542 - mae: 209.8542 - mse: 304999.6250 - lr: 0.0010\n",
      "Epoch 448/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7193 - mae: 12.7193 - mse: 648.7421WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 214.1374 - mae: 214.1374 - mse: 317445.6562 - lr: 0.0010\n",
      "Epoch 449/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8931 - mae: 12.8931 - mse: 653.4643WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 216.1243 - mae: 216.1243 - mse: 316663.7500 - lr: 0.0010\n",
      "Epoch 450/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7277 - mae: 12.7277 - mse: 650.3508WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 216.9568 - mae: 216.9568 - mse: 323651.7188 - lr: 0.0010\n",
      "Epoch 451/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0296 - mae: 13.0296 - mse: 657.0479WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.8664 - mae: 212.8664 - mse: 311186.8438 - lr: 0.0010\n",
      "Epoch 452/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7279 - mae: 12.7279 - mse: 649.7200WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 212.7608 - mae: 212.7608 - mse: 314864.7812 - lr: 0.0010\n",
      "Epoch 453/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0144 - mae: 13.0144 - mse: 656.0247WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 207.9887 - mae: 207.9887 - mse: 302343.4375 - lr: 0.0010\n",
      "Epoch 454/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7217 - mae: 12.7217 - mse: 649.0024WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 209.7500 - mae: 209.7500 - mse: 308406.9375 - lr: 0.0010\n",
      "Epoch 455/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9083 - mae: 12.9083 - mse: 653.1961WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 208.5767 - mae: 208.5767 - mse: 302938.1562 - lr: 0.0010\n",
      "Epoch 456/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7182 - mae: 12.7182 - mse: 648.7596WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 3ms/step - loss: 211.7087 - mae: 211.7087 - mse: 312374.4062 - lr: 0.0010\n",
      "Epoch 457/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9269 - mae: 12.9269 - mse: 653.6921WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 210.1815 - mae: 210.1815 - mse: 305870.6250 - lr: 0.0010\n",
      "Epoch 458/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7151 - mae: 12.7151 - mse: 648.8661WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 212.3283 - mae: 212.3283 - mse: 313797.2500 - lr: 0.0010\n",
      "Epoch 459/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9458 - mae: 12.9458 - mse: 654.2026WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 210.0650 - mae: 210.0650 - mse: 305717.3750 - lr: 0.0010\n",
      "Epoch 460/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7140 - mae: 12.7140 - mse: 648.8596WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 211.8918 - mae: 211.8918 - mse: 312886.7500 - lr: 0.0010\n",
      "Epoch 461/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9544 - mae: 12.9544 - mse: 654.3516WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 4ms/step - loss: 208.9157 - mae: 208.9157 - mse: 303667.5625 - lr: 0.0010\n",
      "Epoch 462/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7136 - mae: 12.7136 - mse: 648.7429WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 210.5096 - mae: 210.5096 - mse: 309993.8438 - lr: 0.0010\n",
      "Epoch 463/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8900 - mae: 12.8900 - mse: 652.6546WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 210.3980 - mae: 210.3980 - mse: 306043.8750 - lr: 0.0010\n",
      "Epoch 464/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7124 - mae: 12.7124 - mse: 648.2882WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 215.1613 - mae: 215.1613 - mse: 319466.3750 - lr: 0.0010\n",
      "Epoch 465/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9234 - mae: 12.9234 - mse: 653.3015WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 215.1952 - mae: 215.1952 - mse: 314976.3125 - lr: 0.0010\n",
      "Epoch 466/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7310 - mae: 12.7310 - mse: 649.6307WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.7335 - mae: 213.7335 - mse: 316933.0312 - lr: 0.0010\n",
      "Epoch 467/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9591 - mae: 12.9591 - mse: 654.9694WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 212.0063 - mae: 212.0063 - mse: 309282.3125 - lr: 0.0010\n",
      "Epoch 468/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7207 - mae: 12.7207 - mse: 649.6841WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 213.8533 - mae: 213.8533 - mse: 316986.9062 - lr: 0.0010\n",
      "Epoch 469/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9404 - mae: 12.9404 - mse: 654.6396WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.4386 - mae: 213.4386 - mse: 311875.9688 - lr: 0.0010\n",
      "Epoch 470/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7253 - mae: 12.7253 - mse: 649.8388WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 214.0483 - mae: 214.0483 - mse: 317453.0625 - lr: 0.0010\n",
      "Epoch 471/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9702 - mae: 12.9702 - mse: 655.0429WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.2068 - mae: 212.2068 - mse: 309746.1562 - lr: 0.0010\n",
      "Epoch 472/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7239 - mae: 12.7239 - mse: 649.4647WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 213.0606 - mae: 213.0605 - mse: 315298.8438 - lr: 0.0010\n",
      "Epoch 473/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0371 - mae: 13.0371 - mse: 656.4144WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 207.7925 - mae: 207.7925 - mse: 301999.0312 - lr: 0.0010\n",
      "Epoch 474/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7228 - mae: 12.7228 - mse: 649.5306WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 207.2905 - mae: 207.2905 - mse: 303509.0312 - lr: 0.0010\n",
      "Epoch 475/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8902 - mae: 12.8902 - mse: 652.5063WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 206.1312 - mae: 206.1312 - mse: 298477.5312 - lr: 0.0010\n",
      "Epoch 476/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7173 - mae: 12.7173 - mse: 648.1840WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 209.8869 - mae: 209.8869 - mse: 308449.5312 - lr: 0.0010\n",
      "Epoch 477/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8386 - mae: 12.8386 - mse: 650.9901WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.9582 - mae: 212.9582 - mse: 310429.4375 - lr: 0.0010\n",
      "Epoch 478/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7101 - mae: 12.7101 - mse: 648.4811WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 216.8859 - mae: 216.8859 - mse: 322935.9375 - lr: 0.0010\n",
      "Epoch 479/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9616 - mae: 12.9616 - mse: 654.3368WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 215.8768 - mae: 215.8768 - mse: 316572.4062 - lr: 0.0010\n",
      "Epoch 480/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7457 - mae: 12.7457 - mse: 649.9068WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.1254 - mae: 212.1254 - mse: 313617.0625 - lr: 0.0010\n",
      "Epoch 481/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0269 - mae: 13.0269 - mse: 656.0147WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 206.8049 - mae: 206.8049 - mse: 300198.5312 - lr: 0.0010\n",
      "Epoch 482/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7137 - mae: 12.7137 - mse: 648.9141WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 207.1345 - mae: 207.1345 - mse: 303197.9375 - lr: 0.0010\n",
      "Epoch 483/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8723 - mae: 12.8723 - mse: 651.5865WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 206.5517 - mae: 206.5517 - mse: 299135.3438 - lr: 0.0010\n",
      "Epoch 484/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7094 - mae: 12.7094 - mse: 647.1449WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 209.7283 - mae: 209.7283 - mse: 308125.0000 - lr: 0.0010\n",
      "Epoch 485/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8329 - mae: 12.8329 - mse: 649.8184WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.6270 - mae: 212.6270 - mse: 309717.6875 - lr: 0.0010\n",
      "Epoch 486/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7029 - mae: 12.7029 - mse: 647.1313WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 217.1111 - mae: 217.1111 - mse: 323360.7188 - lr: 0.0010\n",
      "Epoch 487/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9646 - mae: 12.9646 - mse: 654.0850WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.6082 - mae: 215.6082 - mse: 315933.6250 - lr: 0.0010\n",
      "Epoch 488/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7428 - mae: 12.7428 - mse: 650.6038WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 212.1760 - mae: 212.1760 - mse: 313699.3750 - lr: 0.0010\n",
      "Epoch 489/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.0130 - mae: 13.0130 - mse: 656.1151WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 207.4455 - mae: 207.4455 - mse: 301178.1875 - lr: 0.0010\n",
      "Epoch 490/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7117 - mae: 12.7117 - mse: 648.5873WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 207.1796 - mae: 207.1796 - mse: 303232.5625 - lr: 0.0010\n",
      "Epoch 491/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8767 - mae: 12.8767 - mse: 651.5826WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 206.4069 - mae: 206.4069 - mse: 298793.9688 - lr: 0.0010\n",
      "Epoch 492/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7091 - mae: 12.7091 - mse: 647.7424WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 209.3448 - mae: 209.3448 - mse: 307335.1562 - lr: 0.0010\n",
      "Epoch 493/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.8543 - mae: 12.8543 - mse: 651.1829WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 210.7722 - mae: 210.7722 - mse: 306458.2188 - lr: 0.0010\n",
      "Epoch 494/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7030 - mae: 12.7030 - mse: 647.9435WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 215.1448 - mae: 215.1448 - mse: 319233.9062 - lr: 0.0010\n",
      "Epoch 495/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9071 - mae: 12.9071 - mse: 652.8266WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 216.1562 - mae: 216.1562 - mse: 316701.7812 - lr: 0.0010\n",
      "Epoch 496/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7329 - mae: 12.7329 - mse: 649.4207WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 212.6974 - mae: 212.6974 - mse: 314727.9062 - lr: 0.0010\n",
      "Epoch 497/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9550 - mae: 12.9550 - mse: 653.8198WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 210.7227 - mae: 210.7227 - mse: 306890.6562 - lr: 0.0010\n",
      "Epoch 498/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7076 - mae: 12.7076 - mse: 648.3906WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 211.7280 - mae: 211.7280 - mse: 312377.9688 - lr: 0.0010\n",
      "Epoch 499/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.9957 - mae: 12.9957 - mse: 655.0917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 207.3889 - mae: 207.3889 - mse: 301000.8125 - lr: 0.0010\n",
      "Epoch 500/500\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 12.7118 - mae: 12.7118 - mse: 649.2936WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_loss` which is not available. Available metrics are: loss,mae,mse,lr\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 206.6014 - mae: 206.6014 - mse: 302073.4062 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d722733850>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.fit(train_dataset_future,\n",
    "           epochs=500,\n",
    "           callbacks=[tf.keras.callbacks.EarlyStopping(patience=100,restore_best_weights=True),\n",
    "                     tf.keras.callbacks.ReduceLROnPlateau(patience=100),\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "6dcc4d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2780, 1)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.predict(train_dataset_future).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2043baf",
   "metadata": {},
   "source": [
    "## Make predictions into future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "b9b51bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56573.5554719 , 52147.82118698, 49764.1320816 , 50032.69313676,\n",
       "        47885.62525472, 45604.61575361, 43144.47129086]])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(bitcoin_prices_nbeats[\"Price\"][-7:].to_numpy(),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "a7975ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_future_forecasts(values,model, into_future, window_size = WINDOW_SIZE) -> list:\n",
    "    \n",
    "    future_forecast = []\n",
    "    last_window = values[-WINDOW_SIZE:]\n",
    "    \n",
    "    for _ in range(into_future):\n",
    "        future_pred = model.predict(tf.expand_dims(last_window,axis=0))\n",
    "        print(f\"Predicting on:\\n {last_window}-> Prediction: {tf.squeeze(future_pred).numpy()}\")\n",
    "        \n",
    "        future_forecast.append(tf.squeeze(future_pred).numpy())\n",
    "        \n",
    "        last_window = np.append(last_window,future_pred)[-WINDOW_SIZE:]\n",
    "    return future_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "75ff5930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  123.033     ,   124.049     ,   125.96116   , ...,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "a6921fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on:\n",
      " [56573.5554719  52147.82118698 49764.1320816  50032.69313676\n",
      " 47885.62525472 45604.61575361 43144.47129086]-> Prediction: 56383.26953125\n",
      "Predicting on:\n",
      " [52147.82118698 49764.1320816  50032.69313676 47885.62525472\n",
      " 45604.61575361 43144.47129086 56383.26953125]-> Prediction: 51542.98046875\n",
      "Predicting on:\n",
      " [49764.1320816  50032.69313676 47885.62525472 45604.61575361\n",
      " 43144.47129086 56383.26953125 51542.98046875]-> Prediction: 50366.84765625\n",
      "Predicting on:\n",
      " [50032.69313676 47885.62525472 45604.61575361 43144.47129086\n",
      " 56383.26953125 51542.98046875 50366.84765625]-> Prediction: 49593.6875\n",
      "Predicting on:\n",
      " [47885.62525472 45604.61575361 43144.47129086 56383.26953125\n",
      " 51542.98046875 50366.84765625 49593.6875    ]-> Prediction: 46863.06640625\n",
      "Predicting on:\n",
      " [45604.61575361 43144.47129086 56383.26953125 51542.98046875\n",
      " 50366.84765625 49593.6875     46863.06640625]-> Prediction: 45619.2890625\n",
      "Predicting on:\n",
      " [43144.47129086 56383.26953125 51542.98046875 50366.84765625\n",
      " 49593.6875     46863.06640625 45619.2890625 ]-> Prediction: 45473.23046875\n",
      "Predicting on:\n",
      " [56383.26953125 51542.98046875 50366.84765625 49593.6875\n",
      " 46863.06640625 45619.2890625  45473.23046875]-> Prediction: 56083.078125\n",
      "Predicting on:\n",
      " [51542.98046875 50366.84765625 49593.6875     46863.06640625\n",
      " 45619.2890625  45473.23046875 56083.078125  ]-> Prediction: 51286.24609375\n",
      "Predicting on:\n",
      " [50366.84765625 49593.6875     46863.06640625 45619.2890625\n",
      " 45473.23046875 56083.078125   51286.24609375]-> Prediction: 50778.0703125\n",
      "Predicting on:\n",
      " [49593.6875     46863.06640625 45619.2890625  45473.23046875\n",
      " 56083.078125   51286.24609375 50778.0703125 ]-> Prediction: 48874.22265625\n",
      "Predicting on:\n",
      " [46863.06640625 45619.2890625  45473.23046875 56083.078125\n",
      " 51286.24609375 50778.0703125  48874.22265625]-> Prediction: 46199.14453125\n",
      "Predicting on:\n",
      " [45619.2890625  45473.23046875 56083.078125   51286.24609375\n",
      " 50778.0703125  48874.22265625 46199.14453125]-> Prediction: 45938.5234375\n",
      "Predicting on:\n",
      " [45473.23046875 56083.078125   51286.24609375 50778.0703125\n",
      " 48874.22265625 46199.14453125 45938.5234375 ]-> Prediction: 47372.28515625\n"
     ]
    }
   ],
   "source": [
    "future_forecast=make_future_forecasts(y_all.to_numpy(),\n",
    "                     model_9,\n",
    "                     14,\n",
    "                     WINDOW_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394d2474",
   "metadata": {},
   "source": [
    "### Plot future forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "07581bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_future_dates(start_date,into_future,offset=1):\n",
    "    \n",
    "    start_date = start_date +np.timedelta64(offset,\"D\")\n",
    "    end_date =start_date + np.timedelta64(into_future,\"D\")\n",
    "    \n",
    "    return np.arange(start_date,end_date,dtype='datetime64[D]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "acca07af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2021-05-18 00:00:00')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_timestep = bitcoin_prices.index[-1]\n",
    "last_timestep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "1a034c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2021-05-19', '2021-05-20', '2021-05-21', '2021-05-22',\n",
       "       '2021-05-23', '2021-05-24', '2021-05-25', '2021-05-26',\n",
       "       '2021-05-27', '2021-05-28', '2021-05-29', '2021-05-30',\n",
       "       '2021-05-31', '2021-06-01'], dtype='datetime64[D]')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_time_steps = get_future_dates(start_date=last_timestep,into_future=14)\n",
    "next_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "d16fc7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert last timesteps\n",
    "\n",
    "next_time_steps = np.insert(next_time_steps,0,last_timestep)\n",
    "future_forecast = np.insert(future_forecast,0,btc_price[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "08a50c71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([43144.473, 56383.27 , 51542.98 , 50366.848, 49593.688, 46863.066,\n",
       "        45619.29 , 45473.23 , 56083.08 , 51286.246, 50778.07 , 48874.223,\n",
       "        46199.145, 45938.523, 47372.285], dtype=float32),\n",
       " array(['2021-05-18', '2021-05-19', '2021-05-20', '2021-05-21',\n",
       "        '2021-05-22', '2021-05-23', '2021-05-24', '2021-05-25',\n",
       "        '2021-05-26', '2021-05-27', '2021-05-28', '2021-05-29',\n",
       "        '2021-05-30', '2021-05-31', '2021-06-01'], dtype='datetime64[D]'))"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_forecast,next_time_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "07cd0714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAGpCAYAAADr48CdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAACbaElEQVR4nOzdd3xcV5n4/8+ZGY00M+qSLatYsh07cdxbekIUagihhcAGsiEhIaEsLCwt8CX8FpYFltBZIBBCSahhUyCQQqrS48Q1tuMmV8myei/Tz++Pe+9IskZ9rmaked6vl1+S7rQz1xrNM88553mU1hohhBBCCDG7OZI9ACGEEEIIMX0S1AkhhBBCzAES1AkhhBBCzAES1AkhhBBCzAES1AkhhBBCzAGuZA9gphUXF+tFixYlexhJ19fXh8/nS/YwUpKcG3vIeR2dnJvpk3M4Ojk39pmJc7t169ZWrfW8iVw37YK6RYsWsWXLlmQPI+lqamqorq5O9jBSkpwbe8h5HZ2cm+mTczg6OTf2mYlzq5Q6NtHryvSrEEIIIcQcIEGdEEIIIcQcIEGdEEIIIcQcIEGdEEIIIcQcIEGdEEIIIcQckHa7X4UQQoju7m6am5sJhULJHort8vLy2Lt3b7KHMSdN99xmZGQwf/58cnNzEzIeCeqEEEKkle7ubpqamigvL8fj8aCUSvaQbNXT00NOTk6yhzEnTefcaq0ZGBjgxIkTAAkJ7GT6VQghRFppbm6mvLwcr9c75wM6kbqUUni9XsrLy2lubk7IfUpQJ4QQIq2EQiE8Hk+yhyEEAB6PJ2HLACSoE0IIkXYkQydSRSJ/FyWoE0IIIYSYAySoE0IIIYSYAySoE0IIIcS0ffWrX2XVqlXJHkbC/fa3vyU7OzvZw5gQCeqEEEKIWWT79u04nU4uuOCCSd+2urqaT3ziEzaMamKUUrF/GRkZLFq0iC9+8YuEw+HY+IZe59R/ixYtAqCpqYlPfepTnHbaaWRmZlJeXs5b3/pWHnrooVEf+7e//e2w+yotLeV973sfR44cGXPM//Iv/8Lhw4cTdg7sJHXqhBAixWit6egPUehzJ3soIgX98pe/5OMf/zh33XUXe/fu5cwzz0z2kCbll7/8JZdffjmhUIitW7dy7bXXUlBQwM0338x9991HMBgEoL29nZUrV3Lvvfdy/vnnA+B0Ojl69CgXXHABOTk5fOtb32Lt2rVEo1GeeOIJPvrRj3L8+PFRH9vr9XLo0CG01uzbt4+PfOQjvOMd72DHjh04nc4R17d2Ss+W3dKSqRNCiBTz4ydqOeebj9PU7U/2UESKGRgY4I9//CM33ngjV155Jb/61a9GXOell17i9a9/PT6fj7y8PN7+9rfT0NDAddddx9NPP81Pf/rTWLbq6NGj1NTUoJSitbU1dh9Hjx5FKcWWLVsAiEQi3HDDDSxevBiPx8OyZcu49dZbiUajk34O+fn5LFiwgIULF/Kud72LN73pTWzbtg2AwsJCFixYwIIFC5g/f/6IY/PmzePjH/84Wmu2bNnC+973Ps444wzOPPNMPvGJT7Bz584xH1spxYIFCygtLeWSSy7hP//zP9m9eze1tbWx8/DQQw9x9tln43a7+ec//xl3+vXBBx/knHPOYf78+RQVFfH2t78dv994vQaDQW6++WYqKirw+XycddZZ/POf/5z0eZoKydQJIcQMCkeiuJyjf57eeqyDHz95kEhUs/VYB5etLp3B0aWvr/19D681dM/oY64oy+U/375yUre55557qKqqYs2aNVxzzTW8733v41vf+hYZGRkA7Ny5k0suuYRrrrmG73//+2RmZvLoo48SDof50Y9+xIEDB1i+fDnf/OY3AZg3bx5Hjx4d93Gj0Sjl5eX85S9/Yd68ebz88svcdNNNFBUVccMNN0z6uVtee+01XnjhBT73uc9N6Prt7e088sgj/Pd//3fcdW4FBQWTenwrAze0TtzNN9/M9773PZYuXUpOTg4PPvjgsNs88sgjvPOd7+SLX/wiP/nJT2Ln2ApwP/ShD3Ho0CH++Mc/UlFRwUMPPcTb3/52XnnlFdauXTup8U2WBHVCCDFDfvv8EX7y1CF+d8PZnFk6siVQbyDMf9y9gwW5WbT0BthR1ylBnRjmjjvu4JprrgHg4osvxuv18sADD/Ce97wHgFtvvZW1a9dy++23x25TUVERa2Xldrvxer0sWLBgUo+bkZHBf/3Xf8V+XrRoEdu2beNPf/rTpIO6a665huuuu45wOEwgEODKK6/kU5/61IRuW1tbi9Y6IVPO9fX1fOc736GiooLTTz89lqn86le/ypvf/OZRb/f1r3+dK6+8kv/+7/+OtQlbs2YNAIcOHeJPf/oTR48epbKyEoBPfOITPP744/ziF7/gZz/72bTHPRYJ6oQQYobsPdlDa2+Aq+/YzB9vPIflC4YHdv/19z3Ud/Rz90fO45sP7WXH8c7kDDQNTTZjlgy1tbU8//zz/OlPfwKMqcSrr76aO+64IxbUbd++nXe/+922PP7Pf/5z7rjjDo4dO8bAwAChUIiqqqpJ3893vvMdLr30UiKRCLW1tXzmM5/h2muv5fe///24t9VaT2XoMX19fWRnZ6O1pr+/nw0bNnDffffhdg+uX920adOY97F9+3auu+66uJdt27YNrTUrVqwYdjwQCPD6179+WmOfCAnqhBBihrT1BSjNy0Jr+MAvhwd2j+w+yV+21POJS5Zy1qJC1i3M588v1407XSvSxx133EEkEollgGAwyKmrq2PhwoVTCnocDsew+wJGtK26++67+fSnP813v/tdzj//fHJzc/npT3/K/fffP+nHW7BgAUuXLgXgjDPOoKenh/e///187Wtf47TTThvztsuWLUMpxd69e6cUvHq9Xnbs2IHD4aCkpASfzzfiOvGOTVQ0GkUpxSuvvBKbErfMxGYL+UshhBAzpKU3yNL52fz5pnNxOx184Jeb2dfYTYc/yhfv28Waijw+9cZlAKxbmM9AKML+pp4kj1qkgnA4zJ133sm3vvUtduzYEfu3c+dO1qxZw29+8xsANmzYwJNPPjnq/bjdbiKRyLBj8+bNA+DkyZOxYzt27Bh2neeee45zzjmHT3ziE2zYsIGlS5dy6NChhDw3a9dpf3//uNctLCzkLW95Cz/5yU/o7e0dcXlnZ+eYt1dKsXTpUpYsWTLl4G39+vU88cQTo16mtaaxsZGlS5cO+1deXj6lx5sMCeqEEGKGtPUGKM7OZFGxjz/ddC4ZTsUHfrmZn+4IEAhF+eG/rCPDzMqtX2gs+N5R15nEEYtU8eCDD9La2sqNN97IqlWrhv276qqr+PWvf000GuXzn/8827dv56abbmLnzp3s37+fO++8M1bmY9GiRbz88sscPXqU1tZWotEoS5cuZeHChXz1q1/lwIEDPProo/z3f//3sMc//fTT2bZtGw8//DAHDx7k61//Ok8//fSUnktnZyeNjY00NDTw9NNP81//9V+cfvrpE14n97Of/QytNZs2beL//u//2L9/P/v27eO2226LrW2z05e//GX+7//+j1tuuYV9+/axZ88efvCDH9Df38/pp5/O1VdfzXXXXcc999zD4cOH2bJlC9/97ne57777bB+bBHVCCDEDtNa09gYoMmvPLS728eebziPDqajtjHLL5WeyZN7gbr6FhR4KfW5ZVycA+NWvfsUll1xCUVHRiMve+973cuzYMR5//HHWrVvH448/zr59+zj33HM555xzuPfee2NTgZ/73Odwu92sWLGCefPmcfz4cTIyMvjzn//M4cOHWbt2Lf/5n/8Z2x1r+chHPsL73vc+PvCBD3DWWWdx9OhRPvvZz07pudx4442UlpZSUVHB+9//flauXMnDDz+MyzWxFWGLFy9m27ZtvOlNb+Lmm29mzZo1vP71r+eBBx7gF7/4xZTGNBmXXXYZ999/Pw8//DAXXnghF198MU899VRsGvs3v/kNH/rQh/jCF77A8uXLufzyy3nmmWemtP5wstR0Fx3ONps2bdJW3Z10VlNTQ3V1dbKHkZLk3Ngj3c9rXyDMyv/8J19863I+evHguqG69n5++9Dz3HL1G1FKDbvN9b99hbr2fh77zMUzPdxZZzK/X7OxYO90WDs0ReIl6tyO9TuplNqqtR5794ZJMnVCCDEDWnsDALFMnWVhoZeLKjJGBHRgrKurbemlxx8acZkQQpxKgjohhJgBrb1G66PinMwJ32btwny0hlfru+walhBiDpGgTgghZoCVqSv2TTyoW1eRD8hmCSHExNga1Cml8pVS9yil9iml9iqlzlNKfcf8+VWl1P1KqXzzuouUUgNKqR3mv58PuZ+NSqldSqlapdSPlTlPoZTKVErdbR7frJRaZOfzEUKIqWqLZerc41xzUJ43gyXFPrbLZgkhxATYnan7EfCI1no5sBbYCzwGrNJarwEOAF8acv1DWut15r+PDjl+G3ATsMz8d6l5/AagQ2u9FPgB8G1bn40QQkyRlakr9E08qANjXd2Ous5pV9IXQsx9tgV1Sqlc4HXArwC01kGtdafW+lGtddi82ktAxTj3Uwrkaq1f1MZftbuAd5kXvxO40/z+HuANKt5qYyGESLK23gC5WS4yXc5J3W5dZT6tvQEauvw2jUwIMVfY2SZsCdAC/EYptRbYCnxKa9035DrXA3cP+XmxUmo70A3corV+FigH6odcp948hvm1DkBrHVZKdQFFQOvQgSilbsLI9FFSUkJNTU1CnuBs1tvbK+dhFHJu7JHu5/W1I368jmjcczDWuYl0GdX///DI85y9QDo7jmYyv195eXn09KRPp45IJJJWz3cmJerc+v3+hPx9tPMvhAvYAHxSa71ZKfUj4IvAVwCUUl8GwsAfzOufBCq11m1KqY3AX5VSK4F4mTdrHmKsywYPaH07cDsYderSuVaWJd1rho1Fzo090v283rb/RSqzoLr6vBGXjXVuzg9H+dYr/ySUU0Z19Yq41xGTr1OXTnXbpE6dfRJ1brOysli/fv2078fONXX1QL3WerP58z0YQR5KqWuBy4GrzSlVtNYBrXWb+f1W4BBwunk/Q6doK4CGIY+x0LxPF5AHtNv4nIQQYkpaewMUZU9uPR2A2+VgVVmu7IAVQozLtqBOa90I1CmlzjAPvQF4TSl1KXAz8A6tdax7r1JqnlLKaX6/BGNDxGGt9UmgRyl1rrle7oPA38ybPQBca35/JfCkltXEQogU1NYXpDh74uVMhlq3sIBdJ7oIRaIJHpUQ8V1++eVcd911sZ+rq6v5xCc+MePjaG1tRSmV1ks3JsPuBRqfBP6glHIDh4EPAa8AmcBj5p6Gl8ydrq8D/kspFQYiwEe11lbW7WPAbwEP8LD5D4xNGL9TStViZOiusvn5CCHEpIUiUTr7Q1PK1IGxWeLXzx9hf2MPq8rzEjw6IcZ33333xfrHjqempoZLLrmElpYWiouLbR6ZGMrWoE5rvQM4tV/Z0lGuey9w7yiXbQFWxTnuB947vVEKIYS92vvMGnVTzNStX5gPGEWIJagTExUMBnG7p/ZB4lSFhYUJuR9hL+koIYQQNmvpMbtJTDFTV1HgocjnlnV1aa66upqPfvSjfOpTn6KgoICCggI+//nPE40a0/KLFi3iq1/9Ktdffz35+flcffXVAGzevJmLL74Yr9dLeXk5H/vYx+ju7o7db39/P9dddx3Z2dmUlJTwzW9+M+5jD51+DQaD/L//9/+oqqoiMzOTJUuW8OMf/5ijR49yySWXADBv3jyUUrFpXK01t956K6eddhoej4fVq1fz+9//ftjjvPLKK2zcuDG2cWDz5s2IiZP98UIIYbO2aWbqlFKxIsTCJg9/ERp3zexjLlgNb/2fSd3kD3/4A9dddx0vvvgir776KjfeeCOlpaV85jOfAeD73/8+t9xyC1u2bEFrza5du3jXu97F1772Ne644w7a29v59Kc/zfXXX88999wDwOc+9zkee+wx7r33XsrLy/na177GM888wxVXXDHqOK699lqeffZZfvSjH7F+/XqOHTtGXV0dCxcu5N577+U973kPe/bsobCwEI/HA8Att9zCPffcw09/+lPOOOMMXnzxRW688UYKCgp429veRl9fH29729u4+OKLufPOOzlx4gSf/vSnp3Zu05QEdUIIYbNWM1NXNMWgDozOEk/ub6bbHyI3a2Jrm8TcU1payo9//GOUUixfvpwDBw7w/e9/PxbUXXzxxXzhC1+IXf+DH/wgV1xxBZ/97Gdjx2677TbWr19Pc3MzXq+XX/3qV/z617/mLW95CwC/+c1vqKgYvS/AwYMH+fOf/8zDDz/MpZcaDZ6WLFkSu9yaqp0/f35sTV1fXx/f//73efTRR7nooosAWLx4MS+//DI//elPedvb3sYf/vAHgsEgv/nNb8jOzmbVqlV8+ctf5pprrknEqUsLEtQJIYTN2vqmN/0KxmYJreHVui4uXCaLzxNukhmzZDn33HMZ2jjpvPPO4ytf+UpsOnXTpuHL2Ldu3UptbS333Xdf7JhVJOLQoUN4vV6CwSDnnTdYPzE7O5vVq1ePOobt27fjcDhi06wT8dprr+H3+7n00kuHjT8UCrFo0SLAqB+4Zs0asrOzhz0/MXES1AkhhM1ae4O4XQ6yM6f+J3dNRT4AO+s7JagTo/L5fMN+jkajfPCDH+Tmm28ecd3y8nL2798/6ceYSuUwa93f3//+dyorK4ddZu2qlYpk0ydBnRBC2Ky1N8C87Eym05o6z5PBknk+WVeX5jZv3ozWOva79NJLL1FWVkZubm7c62/YsIF9+/axdGncwhMsXbqUjIwMXnrppdgUal9fH7t37+a0004b9T6j0ShPPfVUbPp1KGvHbSQSiR1bsWIFmZmZHDt2jNe//vVx73fFihXceeed9PX1xYLTl156Ke51RXyy+1UIIWzW2hucco26odZVGJslJKORvhoaGvj0pz/N/v37ueeee/jOd77Df/zHf4x6/ZtvvpmtW7fy0Y9+lO3bt1NbW8s//vEPPvKRjwDGVOsNN9zAzTffzGOPPcaePXu4/vrrhwVkp1q2bBnve9/7+PCHP8y9997LkSNHePbZZ/nd734HQFVVFUopHnzwQVpaWujt7SUnJ4fPfe5zfO5zn+PXv/41tbW17Nixg5///OfcfvvtAHzgAx/A5XJx/fXXs2fPHh577DG+8Y1vJPDszX0S1AkhhM3aegNT3vk61LrKfFp6AjR0+RMwKjEbXX311UQiEc455xxuvPFGbrjhhjGDujVr1vDwww9z9OhRLr74YtauXcuXvvQlSkpKYtf57ne/yyWXXMK73/1uLrnkElatWsXrXve6Mcdx11138YEPfIB///d/Z/ny5Vx33XV0dXUBxHbQfvnLX6akpCRWCuXrX/86X/3qV/nud7/LypUredOb3sS9997L4sWLASPA/Mc//sHBgwfZsGEDn/vc5/j2t7893VOWVmT6VQghbNbaG2BFafzpsclYa62rq+ukPN8z7fsTs4/L5eInP/kJP/nJT0ZcdvTo0bi32bBhA4888sio9+nz+bjrrru46667Rr3OqW26MjMzufXWW7n11lvjXv8rX/kKX/nKV4YdU0rxyU9+kk9+8pOjPs4555zDtm3bhh2TzPTESaZOCCFspLWmrTdIcc70M3VnlubidjpkXZ0QIi4J6oQQwkZdAyHCUU2Rb/pr6twuByvKciWoE0LEJdOvQghho9Zeo5vEvARk6sAoQnz3K3WEI1FcTvlcnk5OnQIV4lTyF0EIIWzU2mt2k/AlLqgbCEU42NybkPsTQswdEtQJIYSN2sxMXXHO9KdfwQjqAJmCnSarGK4QyZbI30UJ6oQQwkaJztRVFXnJ92awU4K6KfP5fJw4cYJgMCg7K0XSaK0JBoOcOHFiRCeQqZI1dUIIYaO23gBKQWECNkqAURZirVmEWExNRUUFra2tHDt2jHA4nOzh2M7v95OVlZXsYcxJ0z23LpeLvLw8iosT0/pPgjohhLBRS2+QQq8bp2PqLcJOtXZhPj958iB9gTC+afSTTVcOh4P58+czf/78ZA9lRtTU1LB+/fpkD2NOSrVzK9OvQghho0R1kxhq/cJ8ohp2nehK6P0KIWY3CeqEEMJGrb2BhPR9HWpNRR6ArKsTQgwjQZ0QQtiorS+Y8ExdUXYmlYVeWVcnhBhGgjohhLBRa0/iM3VgrKuTTJ0QYigJ6oQQwiYDwQh9wUjCM3Vg1Ktr6PLT3O1P+H0LIWYnCeqEEMImVo26YhsydesWGuvqZApWCGGRoE6krSf3NfHMgZZkD0PMYW19ZjcJGzJ1K8vycDmUBHVCiBgJ6kTauvWR/Xzij9vo7A8meyhijmrtMbtJ2BDUZWU4WV6aw876zoTftxBidpKgTqSttr4g3f4wP32qNtlDEXNUW599069grKt7ta6LaFRaXQkhJKgTaSoa1bT3BclwKu584Rh17f3JHpKYg1p77Zt+BVhbkU9PIMyhll5b7l8IMbtIUCfSUudAiEhUc/0Fi1EKvv/YgWQPScxBrb0BsjNdZGU4bbn/00tyADguH0qEEEhQJ9JUm7krcWV5Hh+6YDF/3XGCPQ3SckkkVmtv0JYadZZCn3Hf7X2yLlQIIUGdSFOxaTGfm49Vn0aeJ4P/eXhfkkcl5ho7+r4OJUGdEGIoCepEWrIWsBdlZ5LnyeATlyzl2YOtPHewNckjE3NJa2+AIp99mTqv24nb5aBddnALIZCgTqSpNjNTZ02NXXNeFeX5Hr718F6iWnYSisRo6w1SnGNfpk4pRZHPTXuvBHVCCAnqRJpq6w2gFBR4jaAu0+Xk8285gz0N3Ww+GUny6MRcEI5Eae8PUmxjpg6M3+EOydQJIZCgTqSp1r4ghV43ToeKHXvH2jLOKMnhieOhJI5MzBUd/SG0xtZMHRjr6mRNnRACbA7qlFL5Sql7lFL7lFJ7lVLnKaUKlVKPKaUOml8Lhlz/S0qpWqXUfqXUW4Yc36iU2mVe9mOllDKPZyql7jaPb1ZKLbLz+Yi5o603MGJXosOhWFGWS1dApl/F9Fl9X4t8EtQJIWaG3Zm6HwGPaK2XA2uBvcAXgSe01suAJ8yfUUqtAK4CVgKXAj9TSlnFnW4DbgKWmf8uNY/fAHRorZcCPwC+bfPzEXNEW28w7pttvjeD3pAEdWL62mKFh+2dfpWgTghhsS2oU0rlAq8DfgWgtQ5qrTuBdwJ3mle7E3iX+f07gT9rrQNa6yNALXC2UqoUyNVav6i11sBdp9zGuq97gDdYWTwhxtLWF38Be4HXzUAYQpFoEkYl5hIrUzcT06/d/rD8zgohcNl430uAFuA3Sqm1wFbgU0CJ1vokgNb6pFJqvnn9cuClIbevN4+FzO9PPW7dps68r7BSqgsoAobVpVBK3YSR6aOkpISampoEPcXZq7e3N63PQ2NnH0t9gRHnoPWEsZ7uwcdryM+UJaeJlG6/c5uPGr9L+3a8Ql3G2J81p3Nu5HfWkG6/X5Mh58Y+qXZu7QzqXMAG4JNa681KqR9hTrWOIt5fPT3G8bFuM/yA1rcDtwNs2rRJV1dXjzGM9FBTU0O6nodAOMLAI4+w9owlVFcvG3ZZ76sN3PXadlasOyvWgkkkRjr8zkWjmvb+II1dfvobD5PhPMllb6xmvAmE6ZybvldPctdr2zhz7VmcsSB9f2fT4fdrquTc2CfVzq2dQV09UK+13mz+fA9GUNeklCo1s3SlQPOQ6y8ccvsKoME8XhHn+NDb1CulXEAe0G7HkxFzx2CNupHTYoVeqdAvJu83zx/hl88cprknQDg6+Lly6fzscQO66bK6ShgFtdM3qBNC2BjUaa0blVJ1SqkztNb7gTcAr5n/rgX+x/z6N/MmDwB/VEp9HyjD2BDxstY6opTqUUqdC2wGPgj875DbXAu8CFwJPGmuuxNiVLGgLk79sHwzqOuUul9igo629vHNh/ayujyPd28opyQ3i/k5WZTkZnLa/GzbH98K6jr6pBSPEOnOzkwdwCeBPyil3MBh4EMYmzP+opS6ATgOvBdAa71HKfUXjKAvDPyb1tqqAvsx4LeAB3jY/AfGJozfKaVqMTJ0V9n8fMQc0DqkRdipBntpyhukmJj/eXgfGU4HP79mI/Nzsmb88Qt8GQDSKkwIYW9Qp7XeAWyKc9EbRrn+N4BvxDm+BVgV57gfMygUYqLGKjWR7zXeIKVCv5iIzYfbeGRPI5978+lJCehgsCuKtAoTQqTvVimRttp6R8/UZWU4yXRCh6ypE+OIRjX//eBeyvKy+PBFS5I2jgyng9wsl3wQEUJIUCfST1tfkEyXA5/bGffy7AxFR79Mv4qx/XXHCXad6OILly4nKyP+79JMkQLEQgiQoE6kodbeAMXZmaPuSsx2K8l6iDENBCPc+sh+1lbk8Y61ZckejgR1QghAgjqRhtp6gyP6vg6VnSFr6sTYfvnsYRq7/dxy+QocjuQ3sZGgTggBEtSJNNTWF4hbzsSSnaHolOlXMYqmbj+31RzistULOGtRYbKHAxibJSSoE0JIUCfSjpGpG70fZ7ZbyRukGNWPnjhIOBrl5kuXJ3soMYXZbtr7g0iZTiHSmwR1Iq1orScw/aro9ocIS4N0cYpoVPPI7kYuX1NGVZEv2cOJKfS6CYaj9Acj419ZCDFnSVAn0kpPIEwwEmXeGJm6HLdCa+gakClYMdzexm7a+4JcuLQ42UMZZrBotmSYhUhnEtSJtDLY93XsTB0gZU3ECC/UtgFwgQR1QogUJEGdSCutVuFh39hr6kB2wIqRnqtt5bR5PhbkJad7xGgKrKBOfmeFSGsS1Im0MthNYuySJiBdJezW3O3nTy8fpzcQTvZQJiQYjvLykfaUm3oFYru5pVWYEOnN1t6vQqSa1ljf17HX1IFk6uy0r7GbD/3mFU52+fneowf49BuXcdVZC3E5U/dz5vbjHQyEIpyfgkGdlamT31kh0lvq/gUVwgbWmjqrCXo8sqbOXi/UtvLe214kqjU/umodi4u93PLX3bzlh8/w2GtN0yrLYWdJj+cPteFQcO6SItseY6pyMl1kOKUUjxDpToI6kVba+gLkeTJwu0b/1Xc7we1yyPSrDe7fXs+1v3mZ0vws7v/4BbxzXTl/+ch53H7NRjRw411b+NdfbcYfmnxpjhOdA6z56qM8vOtk4gcOPF/byuqKfPI8Gbbc/3QopaQAcYqLRDXBsJRJEvaSoE6klfFq1IHxBlnodctU1hQFw1H2nuymtrmXuvZ+WnoCdPtDPHAoyH/cvZNNVYX830fPpyzfAxjn+80rF/DPT7+Oz7/lDJ6vbePFQ22TftzfPn+EnkCY3710LNFPiR5/iB11nVxwWupl6SzSKiy1fe7/dnL1HS9JgWhhK1lTJ9JKa2+A4jF2vlryvRky/TpF33tsP794+nDcy961roxbr1wbN1Oa4XTwoQsW8f3HDrD1WAeXLJ8/4cfsDYT588t1ZGU4ePFwGyc6Byg3g8ZEePlIO5GoTslNEhbJ1KW2l4+0c6JzgK3HOtiUIu3lxNwjQZ1IK219QZbNzx73eoU+t0y/TtGTe5tZW5HH9RcuJhCOEghFCISjNNcd5kv/sg6l1Ki39bpdrCzLZeuxjkk95l9eqaMnEOYnH1jPJ/64nb9uP8G/XbJ0uk8l5vnaNjJdDjZUFSTsPhOtMNvN3pPdyR6GiKPbH+JE5wAAv3nhqAR1wjYy/SrSSltvYNzpVzCyHpOdfu0NhHmtYfJvqv5QhD9sPsaNd22hpScw6dunkqZuPwebe7lsdSnvXFfO+zYt5JrzFvHhi5ZwfplrzIDOsqGygB11nRNu0xaJan79/BHOWlTA5WvKOHtxIfduq0/oNNcLh1o5a1EhWRnOhN1nohV65YNIqjrQ2APA8gU5PLK7kQYzwBMi0SSoE2kjHInS0R8as/CwpcA3+enXO549zOX/+yyHWnondP3+YJg7nj3M6259ii/fv5vHXmviL1vqJvWYqea5g63A9DoubKwqYCAUYZ/5RjieR/c0Ut8xwA0XLgHgPRvKOdzSx876rimPYaiWngD7Gns4f2nqrqcDo6xJ50CISFTWbKUa63f5a+9Yidaa39uw7lMIkKBOpBGr2n7xBDN1nf1BopN4g9zf2ENUw4+fODjm9QLhCP/7xEEu+J8n+e8H93LavGz+8OFzOHtRIfduTWyGaaY9X9tKoc/NitLcKd/HRnOKc6JTsHc8d4TKQi9vWlECwFtXl5LpcnDv1vopj2GoFw4ZgWoqr6cDowCx1tApG3xSzv7GHnIyXZy9uJA3rSjhTy8fn9IObyHGI0GdSBuDfV8nkKnzuolqYy3MRB1u6UMpeGBnAwebRs8yfeeR/XzvsQNsqCzg3o+dz59uOpcLlhbzno3lHG7tY3td54QfM5VorXmutpXzTyvC4Rh/mnU0ZfkeSvOy2DKBoG7b8Q62Huvg+gsW4TQfMzcrg7esXMDfX20gEJ7+G+fzta3kZrlYWZY37fuykxQgTl37G3s4Y0EOSik+dMFiOvpD/G3HiWQPS8xBEtSJtNE2gW4SlgKfUYtsolOwkajmSFsfV26owJvh5IejZOt21Xfx6+ePcPU5lfzqurNiWSmAy1aXkpWRuAzTTDvY3EtzT4CLlk0/o7WhqoBtEwjqfvXcEXKyXLx308Jhx6/YUE5nf4in9rVMaxxaa56vbeP804pjQWOqslqFtUmrsJSitWZvYzdnLMgB4JzFhSxfkMNvnj86q7PyIjVJUCfSRusE+r5arI4TEy0RcaJjgGA4yqZFBXzogsU8+OpJ9jUO3zQRjkT54n2vUpydyRcuXT7iPnKsDNPOhlk5NfNsAtbTWTZWFnCic4CTXaMvKK/v6OeR3Y184OxKfJnDN/JfuLSY+TmZ3LttegHysbZ+TnQOcEGKr6eDwd9ZydSllpNdfnr8YZabQZ1SiusvWMy+xh5ePDz5eoxCjEWCOpE2rKBuInXqrDfIia5POtRqbI5YMi+bD1+0mJxMFz98bHi27jfPH2VPQzdfe8fKUbsSvGdDBd3+ME/sbZ7Q46aS52tbWVzso6LAO+37sjKY2451jnqdO184CsC15y8acZnL6eBd68t5al/ztGq3PW+up0vFfq+nKrQydbIDNqXsNzdJnLFgcJ3pO9aVUeDN4LfPH03SqMRcJUGdSBttfUFcDkWuZ/zyjJPN1B1qNoO6Yh/5XjfXX7iYR/Y0sqfB2IFZ197P9x87wBvPnM+lqxaMej8XLC1mQW7WtDNMMy0YjvLS4baEbSZYUZZLVoZj1M0SPf4Qf365jretLo11pjjVFRvKCUc1f9/ZMOVxPL2/hdK8LJYU+6Z8HzMltmRAgrqUYu18PaMkJ3YsK8PJB86p5LG9TdS19ydraGIOkqBOpA2rRt1EaqVZb5CdE1xTd7i1j3xvRixbcv2Fi8nNcvHDxw+iteaWv+7GoeC/3rlqzMd3OhTv3lDO0wdaZlXNuh11nfQHIwmZegWju8Tainy2Ho8f1N1tFhv+8EWLR72P5QtyWVmWO+UA+baaQzz6WhOXrymd0O9MsmW6nGRnumjvk04oqWR/YzeleVnkeYdn5//13CocSnHXi0eTMzAxJ0lQJ9JGW29wQjXqALIzXbgcKlYGZTyHW3pZUuyLvfnneTL48EVLeOy1Jv7n4X08faCFz73ljFGzSkO9Z0MFkaieVbvjnjvYgkPBeQnsjbqxqoA9J7pGrC8MR6L85vmjnL24kDUV+WPexxUbKni1vmvM3cjx/O8TB/n2I/t4x9oybo6z/jFVFfgyaO+bPR8G0sE+c+frqUrzPLxh+Xwe2tWYhFGJuUqCOpE2WvuCE9okAcZi5gKfe+Jr6lr6WDJvePuxD12wiDxPBr945jBrK/L44HmLJnRfS+dns3ZhPvfMol2wz9W2sqYif9S1glOxsaqAcFSz85QSLw/vbuRE5wA3XrRk3Pt457oylIJHdk/sjVNrzQ8eO8D3HjvAFevL+cG/rMPlnD1/Jgt9mbRLz+KUEYpEOdTSy/IF8es2Ll+Qw8muAUIT7J4ixHhmz18rIaaprTcwoXImlgJvBh0TmMrq8Ydo6Qlw2ilBXU5WBp98/VIyXQ6+dcWaSZXEuHJDOfsae2Jr8lJZtz/EzvquhJQyGWp9pVmEeMgUrNaaO549zJJiH29YPn/c+yjOzmRxkY/dEziPWmu+9+gBfvTEQa7cWMF33rs25cuYnKrQmyFr6lLIkdY+QhEd2/l6qooCL1ENjV3+GR6ZmKskqBNpw5h+nVimDozNEhOZfj3c0gfAknkjF9N/+KIlbP3Km1hRNrkOC29fW4bb6ZgV2bqXDrURieqEraezFPrcLJnnG1av7pWjHeys7+L6CxdPuMDxirJcdp8YvyfvDx4/yE+equX9Zy/k1vdMLghPFQU+97R2+4rE2nvS+L2LN/0KUF5gLMeo65DNEiIxJKgTaaE/GGYgFJlQNwmL1SpsPFav19PiBHVgrM+brHyvmzecOZ8HdjSk/NTMc7WteDKcbKgsGP/Kk7SxsoCtxzpiRVp/+exhCrwZvGdDxYTvY1V5Hic6B8b8vwxFovzi6UNctnoB33jX6ml1xEimIgnqUsr+xh5cDjUii2+pMIO6Ex2j12MUYjIkqBNpYbBF2CQydT73hHYSHm7pw+lQVBYmtuzFFRsqaOsL8vKR9oTeb6I9V9vKOUsKcbsS/+dk06ICOvpDHGnt40hrH4/vbeKac6vwuJ0Tvo+VZpZ0T8Po2bp9J3sIhKNctrp01gZ0YPzODoQiDARnX/HquWh/Yw9L5vlGfW2U5nlQCuolqBMJIkGdSAuxwsOTCeq8GXT2B8dt5XO4tZfKQm/CgxqrrlVDZ+r+wW/oHOBwS59tze6tIsRbj3Xwq+cOk+F0cM0EN5xYrJ6tY61P3FFnTPGuW5g/pXGmikKrvqJ0lQBIemcWY+fr6Esv3C4HC3KzJKgTCSNBnZhzdtV30dwzfOFxLFM3wZImYKzpCkc1PYHwmNc71NxnS3FaK6uYyh0Cnqs1Oi5cmOBNEpYlxdnkeTJ4Ym8z92yt593rypmXM/H/QzD+H8vyssZcV7f9eCfF2ZmUT6DkTCqz6iTKZgljx/Oq//wn20apdWi3Hn+IE50Do26SsJTne6iXNXUiQWwN6pRSR5VSu5RSO5RSW8xjd5s/7zAv32EeX6SUGhhy2c+H3M9G835qlVI/VmYxMKVUpnl/tUqpzUqpRXY+H5H6WnsDvOe2F7jiZy8MC+za+ibe99WSb7UKG2MKNhLVHGnr47T58dfMTIfX7SQrw0Fbb+rWHXvlSDtFPvewavmJ5HAoNlTm88ieRvyh6JjFhseysjxvnExdJ+sr82dFkeGxSKswQ21zL5/9yw7CUc3T+1uSMoYDZm3E8YK6igKPZOpEwsxEpu4SrfU6rfUmAK31v5g/rwPuBe4bct1D1mVa648OOX4bcBOwzPx3qXn8BqBDa70U+AHwbZufi0hxf9lSRzASpbU3wHW/foUevxGQtZqZusmWNIGxp7IaOgcIhqO2ZOqUUhT5MmNZxlR0rK2f0+Zl2xoMWVOw1WfMY9kUg8eVZbkcbu2jL07WtbM/yOHWvlk/9QqSqQMjQ3bT77aQleGkqsjLK0eTsyY11h5s3KDOS2O3n3CKb4gSs0PSpl/NbNv7gD+Nc71SIFdr/aI2FjfdBbzLvPidwJ3m9/cAb1Cz/aO2mLJIVPPHzcc5d0kht/3rRvY39fDR328lGDaCvOxMF1kZE19gX2C9QY4R1NVaO19tyNSBsQawNYXfoOs6+qkotHfK8qJl83A6FB+9+LQp38eqsjy0hn2NI6dgd5jFjdfPoaAuXXfARqOaz/5lJ8fa+vnJBzZwyRnz2X68Myk7yPc39pCT6Rp3Sr+iwEMkqmnsllp1YvomX2thcjTwqFJKA7/QWt8+5LKLgCat9cEhxxYrpbYD3cAtWutngXJgaLGuevMY5tc6AK11WCnVBRQBrUMHoZS6CSPTR0lJCTU1NQl6erNXb2/vnDsPO1vC1HcEeEdlFHXyNT60MoM7drXxwZ8+SlSD1xmd0HO2zk1jn/FG8MKWnaiT8TslPHrUyASePLCTmqM2fJ4I+DnWrVPy/yoU1TR2+Yl2N0/qvE7FT17vwX98FzXHp3Rzuv3G/+X9NVvpqRr+f/nX2iAK6Dq6i5r65HwmTNTrMao1DgXbXztITfjY9Ac2i/T29vKF3zzGowdDvH+5m0DdLrz9Rimj3/39KZbkT/wDXSK8tG+AEg88/fTTY16vrdXYzPGPp15keaE9Y5yLf+9TRaqdW7uDugu01g1KqfnAY0qpfVrrZ8zL3s/wLN1JoFJr3aaU2gj8VSm1Eoj3V9bajjjWZYMHjGDydoBNmzbp6urqqT2bOaSmpoa5dh5+99tXKM7u4tPvfT1ul4NqoOCpWr7zz/1kOBWry/Oorr5g3Puxzk1Xf4gvPvsoC6qWUn1h/LVcj92/izzPSd7+pmpbpiD/0bKT5w62puT/1eGWXvSjT3PR+hVUbxy/blwyf+e01nzjlccJ+uZTXb122GW/PfIyp5f4eesbX5eUsUFiz03h84+RM28B1dWrE3J/s8VP7nmce2sDvH1tGd+8ah1KKVZ0+/nZjieIFC6m+nXjt5VLFK01/17zKJevLRv3/6GqtY/vbKmhuOqMCb2OpmIu/r1PFal2bm2dftVaN5hfm4H7gbMBlFIu4Arg7iHXDWit28zvtwKHgNMxMnNDf9MrgAbz+3pg4ZD7zANSu6iXsEV9Rz9P7m/mqrMWDist8vHq07j2vCpCET2pwsMAOVkuHGrs9UmHWno5bZ7PtjVlRdlGMdnxyqokQ525uHthoTfJIxmfUipuZwmtNTvqOufEejpLgdeddmvqmrv93LYzwBklOXz7Patjr8f5uVlJWVfX2O2n2x8ed5MEQFl+FoDsgBUJYVtQp5TyKaVyrO+BNwO7zYvfCOzTWtcPuf48pZTT/H4JxoaIw1rrk0CPUupcc73cB4G/mTd7ALjW/P5K4Emdiu9+wnZ/evk4Cnj/OZXDjiul+P/evpIbL1rMu9aVx7/xKBwOZbxBjrGm7nBLH0tGqRafCMW+TIKR6LhlVZKhrt14E1po85q6RFlVnsfB5h4C4cHaZUfb+unsD7G+Mj95A0uwAp877Xa/vnK0g74QfOPdq/G6h09AnbWokC1DupKcaiAY4YO/fpmtx8YvfXLLX3fxj1cbxr1ebJPEBDb2ZLqclORmSlcJkRB2ZupKgOeUUjuBl4EHtdaPmJddxcgNEq8DXjWvfw/wUa219fHqY8AdQC1GBu9h8/ivgCKlVC3wGeCLdj0ZkbqC4Sh3v1LH65fPj7so2elQfPltK3jbmtJJ33e+N4PO/vglTXr8IZp7AnF7viZKrFZdCu6Arevox+10UJKTleyhTMjKslxCEc3Bpt7YsVjR4TkU1BX50i9TZ33wstpuDXXWogLa+4Kxdn6nemxvE88caOGlw21jPobWmj+/XMc3H9w77k7V/Y1WOZOJ9XyuKPBKWRORELatqdNaHwbWjnLZdXGO3YtR4iTe9bcAq+Ic9wPvndZAZ0BvIMy3H97H5y89g9ys+AvuxdT9c08jrb1Brj63KuH3XThGL83DLX0Ao/Z1TARryritN8BiG8qmTEddez8VBZ5Z01Zr1ZDOEqvKje93HO/E53aybL49dfaSoSAN+792DRgfvPI8I/++nrWoEDCyeUvj/D//dfsJYPwPTt0DYcJRTUOXn4d3N/L2tWWjXnd/Yw+leVnkeSf2976iwJO0IslibpGOEjPgxUNt/O6lY7x0aOxPgmJqfv/SMRYWerh42byE33f+GNOvh1vNciZ2ZurMEhWtqZipax+gYhasp7NUFnrJznQNW1e3va6T1RV5OGdJYDoRhebvbDSaPitROvqCuJ3ELVm0uNhHcbabV+L0UG7rDfD0AaM4cXvf2EW+24ZcfsdzR0adzu0LhHn2YGusPd1ElOd7ONnpJ5JG/2fCHhLUzQBr7VFTT+p2BpitDjb1sPlIOx84u8qWjFGBN2P0oK6lD6dDUVloX1BnFUtuG+cNJxnqOvpZGGe6K1U5HMZmCauzhD8UYe/JbtZXFiR5ZIlV6HMT1dDtH70TylzT0R8iOyP+618pxaaqQl6Os1niwV0niUQ1Bd6McdchWtnPNyyfz866zlEzaz9/+hCtvQE+fsnE6ypWFHgJRzVNUqtOTJMEdTOgztzV1Cwv2IT7w+bjuJ0O3rfJnlIABT43Hf2huJ/KD7X0UlnoHbbbNtFibZ9SLFPX4w/R2R+aFTtfh1pZlsvekz1Eopo9Dd2EInpO7XyF9GwV1tkfHDWoAzhrcSH1HQOc7Bq+bu3+7SdYviCH9ZUF477GrPN50+uWkJvl4lfPHRlxnROdA9z+zGHesbaMDZP4sGCtBZR1dWK6JKibAdYLtbk79bIts1k0qrl3Wz2Xrlow6XIlE1XgdRMMR+kPRkZcdrilz5b2YEO5XQ5ys1wpt0aqrt34na6cZUHdqrI8BkIRjrT2st3MtMyFThJDFaRhq7CO/iC+MZavnbXICLBeOTqYXTvW1sf24528a335mGtnLdblFYVe3n9OJY/sbozNwlhufWQfADe/dfmkxj8Y1ElZEzE9EtTNgMHpV8nUJVJzT4Aef5izFxfa9hiF3vitwiJRzZHWPlt3vlqKsjNp7U2tDwTHrXImBbMrqFtZbuxG3H2imx11nZTne5ifOzt2706UtQ6zoSt9/t50DoTIdo+eqVtRmovP7Ry2ru6v2xtQCt6xtowi3/j1IK2grsjn5rrzF+FQit++cDR2+fbjHfxtRwM3XrRk3NZgpyrLl0ydSAwJ6mymtY7VH2qSTF1Cneg0AovJ/gGdjHxz91pH3/D1SQ2dAwTCUVt3vlqKfO6Um361MgqzpUadZem8bDJdDvY0dM25osOWZSXZlORm8qfNU+ypNgt1jrGmDsDldLChqiBWhFhrzd92nOCcxYWU5Xso9LkJRqL0jlEPsq03iM/tJCvDSWmeh8tWl3L3K3X0+I3lGV//x2vMy8nko9WT71GcleFkXk6mZOrEtElQZ7OugRA9gTAOJWvqEs36VFtu42J9a33SqZk6q+aVnYWHLUXZ7pTbKFHX3k9OpituCYlU5nI6WL4gh5r9LdR3DMzJoC7T5eTDFy7hxcNtsSnmuSwa1eOuqQPYVFXI/qYeugZCvFrfxeHWPt693ihIbi3fGGsKtr0vQKFZNxLghgsX0xsIc/crdfzj1ZNsO97J5958OtmZU6sUVlHg4USnZOrE9EhQZzMr8DhjQS5tfUFC4xStFBNn/QG0N1MXP6izatTN1PRrqmXq6jqMciZ2tUez08ryPA42G0H5XOokMdT7z6kkz5PBz2oOJXsotuvxh4lq8I0T1J21uACtYeuxdv664wRup4NLVxkFyYsmsLmkrS9IoW9w7e7ahfmctaiA3zx/lP95eB8rSnO5cuPCKT8PKUAsEkGCOptZ6+k2VuUD0CJlTRLmRMcA+d4MfFP8ZDwRhXEWnXf7Q/z5lePMz8mMvRnYqdjnpr0/mFI1rI6391M5y6ZeLSvLjHV1LoeKFSGea7IzXVx7/iIee62JA009ca/THwzzyT9t5+U49dtmk84B47WZPc5Lcf3CAlwOxUuH2/n7zgbecOb8WKbZep23j/Hhqa03OOL1fsOFiznROcCJzgFuufzMadU7rCjw0NA5EPd1HonqlNssJVKTBHU2s8qZbKwydl9JHaLEOdE5YGuWDowK9UpBu9kqLBiO8rHfb+VwSx8/+Jd1M5KpKsrOROuR2cJk0VpT39E/6zZJWKzOEstLc+IWq50rPnT+IjwZTn4eJ1unteb/3beLv+9s4LHXGpMwusTpMF+b402/etxOVpXn8cfNx2ntDfLOIb2gY0HdmNOvwdj1LG9asYDT5vm4bPUCzj+teKpPATCCulBE0xxnQ91Pn6rlku/WpNQHO5GaJKizWX3HALlZrlgbombJ1CVMwwwEdU6HIs+TQWe/sTPui/e9yvO1bXz7PWu4YOn0/ohPVKr1f23pDeAPRWddjTrLGQtycDsdk6ojNhsV+Ny8/+xK/razYUTpjd9vPs5fdxi7P2f7Oi7rw854QR3A2YsL6Q2Eyc1yccnywQ40sdfYKEGd1kam7NRMndOhePDfL+JHV62f6vBjykfZAau15p6t9cb67DQqKC2mRoI6mxn9Mb3MzzXWYshmicSwdhXbuUnCUuA1ChD/8PGD3LftBP/xxtN5z0Z7ih3HU+RLra4SVo262bbz1ZKV4eSPN57Dp96wLNlDsd2Nr1uMQ8Evnz0cO7ajrpOv//01LjljHhecVhzbnT9bdZpB3Xhr6gA2mTMmb1tTRqZrMEvrdbvIynCM2iqsNxAmGImOyNSB8fuU4Zz+W2mFmfk+9f9jZ31XrISQ1eNWiNFIUGez+o4BFhZ6KPJl4lBS1iRRugZC9AUjtmfqwChr8vT+Zn70xEHeu7GCf3/DUtsfc6jiFMvUxcqZzNLpV4BNiwptK1idSkrzPLx7fTl3v1JHS0+Ajr4g//aHbczPzeQH/7JuTuy47LSmX8eoU2c5f2kxbzxzPtdfsGjEZUW+zFEzdda0bLygLlFGK0D8950Nse9TJqj7/ZWw9+/JHoWIQ4I6GxlrjwaoKPDidCjm5WTKmroEiZUzmYGgrtDrptsf5qJlxXzzitUzvuNzsFVYanwgON5mvOlUzOKgLp185OLTCEai/Oq5I3z67h209AT42dUbyPe6Kc/30NobxB8a2TFltujoD6EUY3aUsGRnurjj2rNYVpIz4rLCMepBWsFesY0fBLIynBRnZw6bfo1ENf94tYF5OcbjpkRQpzXUPgbHXkj2SEQcEtTZqK0vyEAoEmt6XpKbJWvqEiRWzmQGpl83VBWwsaqAn129ISHTLJOV73XjUDPby/NwSy9HW/viXlbX0c+8nEw87rm7yWAuOW1eNm9dtYCfP32Ipw+08J/vWMGainxg8PXTMIuzdZ39QXKzMnBM88PWWK3CrF2xdmbqwMjWDQ3qXjnaTlN3gPefZZRKsbKSSRUxx+DvSu44RFwS1NnIWpxsLSifn5MlmboEOTGDmbp/u2Qp937sfHKyklNo1+lQFPrctM7g9Ot//GUnH/391riX1bUPxD6oiNnh49VLUQquWF/OB86ujB23Xj+zeQq2oz8U6/wyHUVjBXUzMP0KRpA9dPr17zsb8GQ4uWKDsYY3JTJ1EfMcSVCXkuwr8CWoMwMPa5pqfm4m29KgwvtMONE5QFaGw/Y/sqmiyJc5Y9Ovkahm38luAuEoh1p6R7RCq+voj5XoEbPDqvI8nvpsNRUFnmHLB6xM3WzeLNHZHzSLhE8v4Cn0jd65xcqSF41XDG+aKgo8PLaniWhUE9Gah3ad5I0rSliQZ/QnlqBOjEcydTayPnFZC2BLcrJo7wsSDEtXiemyypnMxo4GU2G0CpuZTF1dez8B83f0oVdPDrssFInS0DlA5SwtZ5LOFhX7cJ2yfKAkNwvHLC9r0tkfoiARmbrsTPyhKP3Bkf1f23oDZGU48LrtzYNUFHgJRqK09AZ4vraVjv4Qb19TSlaGk0yXg+6UCOpSbPq1fgs88O/GWj8hQZ2d6toHKPS5Yx0PSsyyJi0psuB9NjvROUB5Gi3UN1qFzczvjdWBIN+bwYO7hgd1Jzv9RPXs3vkqBmU4HSzIzZrVmbqO/iAF3uln0GKtwuIsczBq1Nm/W3roDtgHdjaQk+Xi4jOMenp5nozUyNRFzTEEupM7Dkvt47DtztQZT5JJUGcjo+r+4NqjklwjhS7r6qbvRIf9hYdTSZFv5jJ1Vl/UD1+4mH2NPRxq6Y1dZnVIqZilNerESOWzvKxJZ38o1u5rOsbqKtEWp5uEHaz3i0PNfTy6p4lLVy6I1dNLmaAu1aZfw+aH3VQZT5JJUGcjq5yJxdqWLgWIp2cgGKGtL0h5flayhzJjirPd9PjDBML2l57Y39hDeb4nVmB56BRsbPOPZOrmjPL82RvUhSJRegPhhGTqCrNHD+ritQizQ5n5QfX3m4/RGwjz9rVlsctSJ6izpl+7U2PKM9WCzCSToM4m0ajR8WBoRmMwUyfTr9Mxk+VMUkWhOfUzE029DzT1cHpJNqV5HjZWFQybgq3r6MfpUJTmpU9APdeVF3ho7PLPyr6iVomPgokUqRtHbPp1lKDu1BZhdvC6XRT53Lxa30WRz835pxXFLjPaFaZQUKcjEIxf9mhGxTJ1Mv0KEtTZprknQDASHZapK/K5cTpU3IbNYuJiQV1++mSLZqr/azgS5XBLH6ebxVnftrqUfY09HDanYI+3G9Pepy64F7NXWb6HcFTPymUhVouw/ERk6mLTryM/dLf1BWzf+Wqx1tVdtrp02Ossz5sqmbohf4NSITsWNn9vU2EsKUD+MtukLtZKaTCb5HAo5udkSqZummI16tIoU2e1Cmu1ebPE0bZ+gpFoLKh76+oFADxkZuvq2vtnbc9XEd9srlXXYWXqErD7NTvThdvpGJGp6w+G8YeisWy53axEwDvWlQ07nufJSK3dr5AagZRMvw4jQZ1NYv0xTyn9MF9ahU3biU5jCrAkZ+737rRYO+/sztQdNHe+WkHd4BRsI2Bt/kmfDGk6qJjFXSVimTrP9LNoShlFvttPeY1Zr7mZmH4FOPe0IjZU5rOxcngtyDxPBj2BcPKnyYdm6lJhx6lslBhGgjqb1LXH73gwPzeLFmkVNi0NnX4W5Gal1RRgbPp1lOKoiXKgqRelYOn8wYLDl60uZe/JbvY0dNHaGxzxQUXMbtbi/PpZWNbEWmOWiI4SEL9VWNsMdZOwXHNuFfd9/AIcjuE1OK0dvknP1kUlU5fK0uddcYbVd/QzPyeTrIzh/TFLciVTN10nOgbSauoVzKkh18ipoUQ70NRDZaF3WF/Xy8wp2F88fRgYzOyIucHrdlHgzZil06/G66EgQQFXUbab1lNeY9Yau8IZWlM3GiuoS/q6ulSbfrUydamQNUwBEtTZpK59IO6bX0lOFh39oRkpTTFXnehMrxp1YEwNFfvctk+/HmjqYdn8nGHHSvM8bKjMj+2ClW4Sc095gWdWFiDu6A+R4VT43M7xrzwBRv/X4dnwmZ5+HU3qBHUptlEilqnrTOowUoUEdTap7+yPO001P9eqVSdTsFMRjkRp7PanXVAH9neVCIajHGnt4/SS7BGXXba6NLaWR6Zf557yfM+sXFPXNRAkz+NOWLvAQl/miDV17TM8/ToaK6jrlKBuOFlTN4wEdTYIR6I0dPrjZurmm7XqmmVd3ZQ0dhv1tNJt+hXs7/96pLWPcFRzxoKcEZddtroUAE+GM+kZC5F45fleTnQOoFOhmOwkdPQlpu+rpSjbTV8wgj80OJPS3hfE7XSQnWlv39fxpE6mbkhv3FQIpKSkyTAS1NngpFnIM94uwZIcM6iTdXVTEitnkoaZukKbp1+tnq+nTr+CsZh+Y1UBS+b5EpYVEamjvMBDfzCSGsVtJyFRfV8t8VqFWS3Ckv17n+dNlaAuxXa/ykaJYZL70WOOsnaRxZumKjGnX2WzxNSkYzcJS3F2Jq29AbTWtrzBHGzqwaFgyTxf3Mv/9/3rCYSjCX9ckXxWy70TnQMJ23QwEzr7Q1QVJW45wNCgztoVPFMtwsaTMrtfrSAqMy81AimZfh1GMnU2iDU9jxN4FHjduByKJpl+nZKGzvTN1BX53ATCUfqC9myy2d/Uw6Ji34gd25ayfA+Li+MHfGJ2s7qzzLayJp0DwYSVM4H4rcLa+oIz1k1iLJkuJ1kZjhTI1JmP7ytKjUAqlqlLgaxhCrA1qFNKHVVK7VJK7VBKbTGPfVUpdcI8tkMpddmQ639JKVWrlNqvlHrLkOMbzfupVUr9WJlpCqVUplLqbvP4ZqXUIjufz0TVdwzgUMauwVNZXSVko8TUnOgcoDjbPWrgMZcVZVsFiO353TnY1MvpcaZexdxXngIFiLv6Q+yo65zw9bXWdPSHbJp+HXyNtfcFUmYdaZ4ng65kT5Fbdeq8xakRSA3N1M2yNaF2mIlM3SVa63Va601Djv3APLZOa/0QgFJqBXAVsBK4FPiZUsp6574NuAlYZv671Dx+A9ChtV4K/AD4tv1PZ3z17f0syM3C7Yp/eufnZkn/1ymq7xiITYukm8ECxIlfV+cPRTjaFn/nq5j7CrwZeDKcSa1V97OaWq742fPsPTmxQGEgFCEYjiak76slXueWtt7gjLUIG0+eJ4POAXvLGo3Lyoz55qVWpk5HINiX3LGkgFSafn0n8GetdUBrfQSoBc5WSpUCuVrrF7WxNesu4F1DbnOn+f09wBtUslezYgQeFWOUfZACxFOXjjXqLMU2tgo71NJLVMPpcXa+irlPKUVZflZSa9W9Wt9FVMO3Ht43oesnsu+rJdfjwuVQsY0S/lCE/mAkJaZfwczUpcr0q7cwNYK6cACy8o3vU2E8SWb3RgkNPKqU0sAvtNa3m8c/oZT6ILAF+KzWugMoB14actt681jI/P7U45hf6wC01mGlVBdQBLQOHYRS6iaMTB8lJSXU1NQk7AnGU9vYz5mFzlEfJ9QT4ER72PZxjKW3tzepjz8VWmvq2/pZ5gvYOvZUPTdtA8YmhRe2vkpGc+LeyABeaDDKFHQd20dN+4GE3rclVc9rKkiFc+PRfvbVDSRlHFprXq3rx5cBzxxo4X//73FWzxv77elYt7G2tP7wAWr6DyfsHPoyYHftMWpqGmOvuZb6I9TU1I9zS/uF+vw0+vWkn2cif78WH66lEgd1rb2UD3TybDJ/b7WmOhKgL3MePjp55dnH6cuumtEhpMJrdyi7g7oLtNYNSqn5wGNKqX0YU6lfxwj4vg58D7geiJdh02McZ5zLBg8YweTtAJs2bdLV1dWTfBoTFwhH6PjnI2w6czHV1afHvc7u6EGePH6Acy+4KGlrw2pqarDzPNihtTdA8J+Pc+7q06m+YLFtj5Oq58YfivDZpx+huGIx1dVLE3rfLz+yD5fjMO99a/WoywamK1XPaypIhXPzz/Zd/HNPY1LGUd/RT98/n+L/u3wFv33hKP+od/Lx91yE0zH6xMvzta3wwmYuPHs95y4pStg5LN3xDJm5XqqrN7Grvguefo7zNqymeuWCad/3dD3QvIOWw+2Tfp4J/f0KPgENmVQuWwV191N9wbmQkZWY+56scACeBt+8RXCsnrPWnAGV587oEFLhtTuUrdOvWusG82szcD9wtta6SWsd0VpHgV8CZ5tXrwcWDrl5BdBgHq+Ic3zYbZRSLiAPaLfn2UzMyU4/Wo/dH9MqQNwiO2AnJZ1r1AFkZTjJyXTRasNGiQNNPSyZ57MtoBOpr6LAQ3tfkAGbdleP5bUGYx3dusp8br50Ofuberhna92Yt4n1fU3gmjowi3ybr7E2c8NEqmyUyPe4U2P61emGrDzj52TWqrM2SWTPM77K9Kt9QZ1SyqeUyrG+B94M7DbXyFneDew2v38AuMrc0boYY0PEy1rrk0CPUupcc73cB4G/DbnNteb3VwJP6iSXRLfKmYzVSqnEDOpkXd3kpHONOkth9sgCxIFwhC/fvyv2xjgVB5p6WVYi6+nSmfVhKRmbJfY0dKMULF+Qw2WrF7ChMp/vPnqAvkB41NvYsaYOzFZh5pq6VGkRZsnzZNAbCBOOJLFeZCQITtdgUJfMHbBDN22ABHXYm6krAZ5TSu0EXgYe1Fo/Atxqlid5FbgE+A8ArfUe4C/Aa8AjwL9pra2PjB8D7sDYPHEIeNg8/iugSClVC3wG+KKNz2dCcrIyeNua0jHrec3PMfu/SqZuUqxyCxX56dt7tMjnjmUPLD996hB/2HycB3c1jHKrsfUHw9R19Es5kzRXlsSg7rWT3Swp9uF1u1BK8eW3raClJ8Dtzxwe9TadZsCVl+CgzniNDQ/qilJm96uxYqrbP3qwa7voKZm6ZAZSsUzd/OSPJUXYtqZOa30YWBvn+DVj3OYbwDfiHN8CrIpz3A+8d3ojTax1C/P56Qc2jHkdydRNTX3HAD63k1xP+jZCKcrOpK69P/bzgaYebqupBYzerVNR29yL1nDGAilnks6sDHgydsC+1tDNhqqC2M8bqwp425pSbn/mMB84pzL2N3OozoEQXreTTFdi1yUX+tz0+MMEw1Ha+oK4HCpl/uZYAWxnfxK7XERC4MyAzFzjZ39ncsYBEDGDOp8V1HUmbSipQhbQJEGBN4MMp6JJChBPyonOAcoLPEnvwZhMxdmDWYRoVPOl+3aRnelifWU+R1r7x7l1fAeaegFk+jXNleRk4nQoTnRO7fdoqjr7g5zoHGBFae6w4ze/ZTmRqOZ7j+6Pe7tE9321WMFSR3+Qtt5ASvR9tVitwpK6ri4STKE1dVbLsmxweVKjGHKSSVCXBEop5udk0SyZukk50ZG+NeosReZ6n2hU84fNx9h6rINb3raCDZUFHG3tIxqd/JLSg009uJ0OqsZYByrmPpfTwYLcLBo6Z/bv0mtmseGVZcODusoiL9ecV8X/ba2P20Wlsz+U0BZhllirsN5gyvR9taRMUOfISJHpV/N31ZkJWbky/YoEdUkzPzdT1tRNkpWpS2dF2W4iUc2+xh6+/ch+LlpWzBUbyllc7GMgFKFpCp1K9jf1cNr8bFxO+XOQ7srzPTM+/Wpt8FlxSlAH8JaVC9Aath3vHHFZR39i+75aBluFBVOm76slNYK6sDH9mmVNvyYxkLI2SrgyjSBTgrqJBXVKKY9S6gy7B5NOSnKyZE3dJPQGwnQNhGKNx9OV1f/1M3/ZQTga5RvvWo1SiiXmxpwjLZNfV3eopZel82U9nTDW1c30RonXGropyc2kOHvkZoQ1FXm4HIrtxztGXNbVH0poizDLYDu+gJmpS41NEgC5ZlDXnexMndMN7mxQjuROeVobJazpYAnqxg/qlFJvB3Zg7EhFKbVOKfWAzeOa86RV2ORY56o0L0lFLlNEsZlF2NfYw3+88XQqi4wgd/E8I6g7PMnNEuFIlIZOP5WF6Z0BFYbyfA+N3f4ZLZmxp6F7xHo6S1aGkxVluWyLE9QZa+rsyNQZQVx7X5D23mDK1KiDVMnUBY1MnVLJD6SsjRKSqYuZSKbuqxgFgjsBtNY7gEV2DShdzM/Notsfxh+a+UKfs5EV1FnlYNJVoZlFWFmWyw0XDnbVKMnJwpPh5Ogkg7qTXX4iUc3CgvTOgApDeYGHSFTTNENLQ/yhCLUtvawsyxv1OhsqC9hZ1zUs0IxGNV0DIVs2SuR7MnAoaOz20xMIp9SaukyXE0+GM7lBXdScfgVjB2xS19TJ9OupJhLUhbXWcqYSLFarTnbAToh1nubHKW2QTpYUZ/O+TRX84F/WDVsD53Aoqoq8ky5rMpFi2SJ9xAoQz9C6uoNNvUSiOu56Osv6ynwGQhH2NfbEjnX7Q0T1YOYqkRwORYHXzaFmY1d4KgV1YDznzv5kZ+rMc5KVl9zdr1amzplpBJjJHEuKmEhQt1sp9QHAqZRappT6X+AFm8c158Vq1U1hYXs6ajbPU0luemfq3C4Ht165ltPjlB9ZMs836aCuvt1485ZMnYChBYhnpqzJngYjX3DqztehNlQa9euGrqvrjHWTsCfgKsp2x0r9pNL0KxhBXfKnX4cEdalQfHhopi65TaWSbiJB3SeBlUAA+CPQBXzaxjGlhXlmpk76v05MU3cAT4aT7MzUKAKaihYX+zje3k9oEuuh6jv6cSgozU/vDKgwzHSm7rWT3WRnusb8UFFR4GFeTuawHbCxvq++xGfqwMjOWVnsojgbOJIp+UFdCBzm3+FUCeqsjRKR4GCZkzQ17juk1rof+LL5TyRITpZx6nuT2e5lFmnq9lOSm5kyRUBT0eLibMJRTX3HwJht6oaq6xigNM9DhpQzEYDH7aQ4201d+8wEddYmCYdj9Ne1UooNlfnDNktYmTo7dr+CUQ/SSvik2vRrrieD+o6ZLRA9TCR0SqYuBXq/Wpk6MILMjPTd+DWR3a+PKaXyh/xcoJT6p62jSgNWxql3jIbVYlBzTyDt19ONxwrkjrT2Tvg2de39VKR57T8xXGWhl+Pt9gcN0ahm78nuMdfTWTZUFnCsrZ9WswixlanLt2FNHQwP5FJx+jW5JU1ODepSKFMHab9ZYiIfz4u11p3WD1rrDmC+bSNKE163EdT1ByWom4jmbn/a73wdz2BQN/E35LqOftkkIYapKvLNSFB3tK2P/mBkYkFdlbWurhOwf02dFdQ5HcqWzRjTke9N9vRrcPju12APRJNUxeHUkiaQ9q3CJhLURZVSldYPSqkqIL1XIiaA2+XA7XTQG5CSJuPRWtPUHYjb1FsMKvBmkOfJmHCmzh+K0NQdkE0SYpiFhV4augYIhO3922S1BxutRt1Qq8uNIsTWFGxnfxClBovxJppVgLjAmzHm1HAy5Hky6AtGJrV2NqGGBnXJ7v9qlTRxZkqmzjSRVedfBp5TSj1t/vw64Cb7hpQ+vJlO+mT6dVy9gTADoUja73wdj1KKxcUT3wFrdQ5YKIWHxRBVhV60hvqOAU6bZ1+nkdcauslwqrg7uU+VleFkZVku244ZQV1Hf4g8TwZOmwIuK1OXauvpYHgB4nhdOGwXDQ+ffgUjkPIUzPxYIgGjD63DMWQsnTM/jhQybqZOa/0IsAG4G/gLsFFrLWvqEsDndtEn06/jarJq1OVIpm48S4p9E24VVt9hBXWSqRODqswuJXZPwe5p6Gbp/Bzcrolt0llfWcCr9UYR4o7+oG3r6WD2BHVJMSxTl+T+r+GAMfUKkqkzjfpqUkotN79uACqBBuAEUGkeE9OUnemSTN0ENFvdJCRTN65FxT4auvwMBMefOqsz37Rlo4QYymo9d7zN3qDutZPdY9anO9WGqoJYEeKuAXv6vlqKzFZhRSnU99WSEkGd45Tp12StYwsH4mcN09hY06+fwZhm/V6cyzTweltGlEa8mU76J/Dmm+6azVp+sqZufNZmiWPtfSxfMPYbZl1HP26ngxLJgIoh5mVn4slwcszGoK65x09LT2BC6+ksGyrzAdh2vIOO/iDzbJx6TOVMXW4yg7poBHQ0dQKpyJBMnSvLCDbTvKvEqEGd1vompZQDuEVr/fwMjiltZGe6pKTJBFh9XyWoG19sB2zL+EFdffsA5QWelFsILpJLKWWWNZlcd5LJeK3B3CQxiUxdeb6H+TmZbDvWQUdfiNPnj78Wb6qsTUcTrfc4k6xMXVLKmkTMxxy6+xWSOP06pLuFUskvsZICxtwoobWOKqW+C5w3Q+NJKz63KxawiNE1dQfwuqWbxERYb0KHJ7BZoq5DatSJ+CqLvBydZMu5ydgzhaDOKEJcwLbjnXT2B22dfnU5HTz52Ytt2107HUmdfrWK/Z6aqUtWdmxops4aT5oHdRNZofqoUuo9Skr5J5yx+1WmX8fT3OOXLN0E+TJdlORmTmgHbF271KgT8VWZBYi1TX0069r7mZeTSW7W5IKmDVX5HG/vpy8YId9rb8BVlJ2Zkp1WYkFdv2TqCAclqDvFRFIfnwF8QFgp5QcUoLXWE/+IJeLKzpTdrxPR3B2QwsOTsKho/LImvYEwHf0hqVEn4qoq8hIIR2nusac+ZLc/NKWivhsqB8tmFNgc1KUqt8uB1+2kMylr6k4J6pwucGcnd02dU4K6oSZS0iRHa+3QWru11rnmzxLQJYDXLbtfJ6Kpxy8twiZhybzxgzqrd6RMv4p4KovMDTc2bZbo8Ydj/a8nY1V5HhlOY9LIzunXVJfnSVJXiVOnXyG5/V/Dp06/5kpQN9oFSqllSqm/KaV2K6X+qJQqn8mBpYPsTCehiCYYTlJl8FlAa01zd4ASydRN2OJiH+19wTGnZ6yG7TL9KuKpNH8vjrXZs66u2x8mZ5JTr2AUIV5RZqzjsqtF2GyQvKDOytSdGtR1zvxYYHhJk9hY0nv361iZul8D/wDeA2wH/ndGRpRGfObCf8nWja4n1k1CMnUTtbjY6AJwZIw3ZKtG3ULJ1Ik4yvM9ONTg70mi9fhDU8rUwWBpE7vX1KWy3GRn6hxD/u8yk5gdk40SI4wV1OVorX+ptd6vtf4OsGiGxpQ2fG4zqJN1daOSwsOTFytrMkYP2LqOfrxuZ0rW4RLJ53Y5KMv3cMy2oC5M7hSDujetKKE4OzOt14PmeTKSXNLklOxYMnu/njqW8ICRwUtTY72qspRS6zE2RgB4hv6std5m9+DmusFMneyAHU2ztAibtMpCLw7FmO3C6jsGWFjgRTa1i9FUFXltXFMXmtL0K8D5pxWz5ZY3JnhEs0ueJ4PdqRTUte6f+bGAmakb8t6QlW989XdD9rykDCnZxgrqTgLfH/Jz45CfpaNEAvgynQBSgHgMTT1W4WHJ1E2U2+WgosA7Zq06o5yJTL2K0VUW+vjnnsaE328oEsUfipIjdSenLPkbJYb83yVzc0I4CK4hAebQEisS1A2ntb5kJgeSjqxMXb9Mv46qycrUyZq6SVlc7OPoKGvqtNbUdwxw7pKiGR6VmE0qC7209wWnlVWLp8dv/L2b6po6AfmeDPqDEYLhKG7XDNbSi462UaIbtDa6OsykeCVNAALpu64u9SorppHYmjrJ1I2quTuAT7pJTNriYh9HWvriFo/t7A/RGwhLORMxpqoiY83a8QSvq7PWgqVit4bZIs+bpK4So5U00REI2teBZFQjSpokuRdtCpCgLoms6VdZUze6JukmMSWLi330BSO09IxcMFxn1qiTciZiLFZZk+MJXlc3mKmToG6qktYq7NSOEpDcrhLxSpokaywpQoK6JIptlJDp11E1d/uZJzXqJm2sHrCxGnVpvHtQjM/K1CV6B2yP3wgMZPp16nKTFtRZJU2GBHXJ6v8ajRrTwZKpG2as4sNvUUpdGef41UqpN9k7rPRgTSnKRonR2dWmaK4bLGsyMqirj2XqZPpVjC4nK4NCnzvhO2C7ZU3dtFmZuhkvazLa7leY+UBqtKngZIwlhYyVqfsa8HSc408A/2XPcNJLpsuBQ0G/TL/GpbWmqdsvO1+noCzfQ06mi+cOto64rK6jn3xvhkx/iXEtLPRyvD2xa6WsTF2u/P5NWUpNvyYtqDOXlgwtaeL2gXKmdVeJsYI6r9a65dSDWutGwGffkNKHUgpfpksydaPo9ofxh6JSo24KnA7F1edW8dDukxxqGV6EuK59QKZexYRUFXoTvlFCdr9OX/KCurGyYzMcSIXNsQydflUq7fu/jhXUZSmlRrzqlFIZwITmbZRSR5VSu5RSO5RSW8xj31FK7VNKvaqUul8plW8eX6SUGjCvu0Mp9fMh97PRvJ9apdSPlVkxVSmVqZS62zy+WSm1aOJPPTX43C7Z/TqKlh7pJjEdH75oMZkuB7fVHBp2vK6jX3a+igmpKvLS0OknFElcf2orqJMd7VNnBXWdY/R3tkUsqIuXqeuc4bGYmTrnKV1x0rxV2FhB3X3AL5VSsayc+f3Pzcsm6hKt9Tqt9Sbz58eAVVrrNcAB4EtDrnvIvO46rfVHhxy/DbgJWGb+u9Q8fgPQobVeCvwA+PYkxpUSfJlO+oMy/RqPVaNO1tRNTXF2JledVcn920/EenhGo0aNOtn5KiaistBLJKo50TGQsPvs8Yfwup24nLJPb6oynA58bufMZ+qiZgIiFXa/Wq3AXKd86JegblS3AE3AMaXUVqXUVuAo0GJeNiVa60e11lZq6iWgYqzrK6VKgVyt9YvaKLp1F/Au8+J3Anea398DvMHK4s0W2TL9Oqomq++r7H6dso9cvASHgl88Y2TrWnoDBMNRFkqmTkxAVZHxmT6RO2C7/SGZek2ApHSViDf9mpFlFACe6d2vYcnUxTPWK+shrfWblVJfA5aax2q11pP5yKaBR5VSGviF1vr2Uy6/Hrh7yM+LlVLbgW7gFq31s0A5UD/kOvXmMcyvdQBa67BSqgsoAoatDldK3YSR6aOkpISamppJPAV7BfsHONnHjI+pt7c3pc5DPC8dNv6A7N/5CsddMxerz4ZzMxkXlDr58+bjbMxqoXXAKEbcUV9LTc3RGR3HXDuviZSq56bDb0y7Pv7SDnRDYjY2HK7z44xGE/58U/Uc2sUZDXK4/iQ1NR3jXjdR56by2H6WAE8/9wJ6SFmT8x0eWg/v48AMnv/snlo2Abv2HaStdfBxV/YE8fY38MoMjSXVfu/GCurmAZhB3K4p3v8FWusGpdR84DGl1D6t9TMASqkvA2HgD+Z1TwKVWus2pdRG4K9KqZVAvHdzq0z+WJcNHjCCydsBNm3apKurq6f4dBLv98e2cKJzgOrqi2b0cWtqakil8xDP0z17yD5Wz1vfOLMd62bDuZmMJav7ueR7NewOL2D1ojzYvIPLLj6XpfOzZ3Qcc+28JlKqnptoVPPF5x4hq6ic6uoVCbnPO2o3syAzTHX1BQm5P0uqnkO7lO1/Ea2huvq8ca+bsHPz1AtwBC6+5I3DW4LtKqas0EvZTJ7/4x7YCqvXboRlQx638//gcN2M/S6k2u/dWEFdnlLqitEu1FqPu65Oa91gfm1WSt0PnA08o5S6FrgceIM5pYrWOgAEzO+3KqUOAadjZOaGTtFWAA3m9/XAQqDe3NSRB7SPN65Ukp3plI0So2juDsjUawJUFnl559oy/rj5OFedvRBANkqICXE4FJWF3oTWquvxh8j3use/ohhTnicj4TUExxUJGYWHT13lZPV/ndGxyJq6eMZaU5eHEXi9Pc6/y8e7Y6WUTymVY30PvBnYrZS6FLgZeIfWun/I9ecppZzm90swNkQc1lqfBHqUUuea6+U+CPzNvNkDwLXm91cCT1pB4mzhzXTRLx0l4mru8cvO1wT5+CWn4Q9H+P1Lx5iXk0lWhjPZQxKzRFVRYsua9PjDsqYuAfI8GXQOBGf2QSPBkWvYIDmBVLySJtZYgr0QSc/31bFeWce01tdP475LgPvNfQsu4I9a60eUUrVAJsZ0LMBL5k7X1wH/pZQKAxHgo1prK+v2MeC3GKVUHjb/AfwK+J15n+3AVdMYb1LIRonRNXUHWF+Zn+xhzAlL5+fw1lULeGhXo2ySEJNSWejjhUNtaK1JxD60bn9YCl8nQHI2SoTAGSdsyMyFrvqRx+0UNjbSxd0oAcbGDW/hzI4pBYwV1E3r1au1PgysjXN8aZyro7W+F7h3lMu2AKviHPcD753OOJPN63biD0UJR6KyxX8Iq5uETL8mzserlxpBnZQzEZNQWeihPxihpTeQkELgPf4QuZKpm7Y8Twb+UJRAOEKma4Yy79FQ6mTqRp1+tUqsdKZlUDdWFHHNqQeUUsWzrWRIqrMKcPaHpFbdUN3+MIFwVGrUJdCq8jy+9o6VXHv+omQPRcwiVlmTugRMwQbDUQLhqEy/JkCBzwiu2vtmcAo2FadfR8vUpWmrsLGCumylVI1S6j6l1Hql1G5gN9BkrosTCeAzgzrZLDFcs1WjToK6hLr2/EVsqCxI9jDELFJZZGR2E7Eo3+r7KtOv01duLqNIZGHocUVCwwsPW7LyjOlQq3bcjIxljI0SkLabJcYK6n4CfBP4E/Ak8GGt9QKMtW/fmoGxpQWv20ib9wUkUzdUrJuETL8KkVQVBR6USkxQ1y19XxPGWhtbP6NBXdDY/XqqZGTHYpk6CeqGGiuoc5ndH/4PaNRavwSgtd43M0NLD9mSqYuruUcydUKkgkyXk/J8D7UtvdO+L8nUJU55vpFBPdE505m6UaZfYWYDKcnUxTVWUDe0g/OpvzWzqmxIKvO6JaiLx8rUyUYJIZJv7cJ8dhzvnPb99JiZOtkoMX0et5PibDf1HTNYq26s6VeAwAwGUqP1fk1WL9oUMVZQt1Yp1a2U6gHWmN9bP6+eofHNebFMXVCmX4dq6vaTk+mKrTkUQiTPxsoCTnQOcLJrelkhydQlVnm+Z+anX+MFdckIpEbr/ZqZC6iZ70WbIkYN6rTWTq11rtY6R2vtMr+3fpZXZIL4Mq01dZKpG6q5x888KTwsRErYtMjYXLP12Ph9Rscia+oSq6LAO8NBXYpNvzrdI7tbOBxGYCeZOpEMViZKChAP19wdoCQBNbGEENN3ZmkungwnW45OL6gbnH6VvEAiVBR4ONExQDQ6QyuiouNMv870RolTN0kMHY8EdSIZrKBOWoUN19Tjp0QydUKkhAyng7UL89h2fLpBnTH9mi2ZuoSoKPAQjERp6Z2hUiKj1qlLwvRrJACuUXoIS1AnksVr9uDslZImMUY3iYDsfBUihWysKmBPQ/e0PoD2+MP43E6cDqlhnwgVBcYO2Bmbgo2E4pc0cWeDcszwmroguEZ5j8iS6VeRJA6Hwut20i/TrzHdA2GC4ajsfBUihWyqKiQS1eysm/qbZfdASDZJJFB5rFbdDO2AHW33q1KQlQ/9bTMzDhhcUxePZOpEMvkyXfTJ9GvM/qYewJhaEEKkhvWV+QBsPdY+5fvo8Ydlk0QClefPcAHi0aZfARashvotMzMOMHa/nlrOxJKVJ23CRPL43E6Zfh3ikd2NuJ0OLlhanOyhCCFM+V43y+ZnT2sHbE8gJEFdAvkyXRT63DM7/TpaULf4ImjaBf1TD/onJSyZungkqEsBvkyXTL+atNY8svskFy0rlmkaIVLMxqoCth7rmPJuyx5/mFyPvK4TqaLAM4PTr0FwjhKUL7rI+Hrs+RkayziZukA3RKPxL5/DJKhLAb5Ml5Q0Me2s76Khy89bV5cmeyhCiFNsrCqg2x/m0BRbhhnTrxLUJVJFgWfmWoVFx8jUlW2ADC8ceXZmxjJWSZPMXECDv3NmxpJCJKhLAT63U9bUmR7efRKXQ/GmM0uSPRQhxCk2VhlFiLdMcQq2xy/Tr4lWnm/UqtN6BmrVjTX96nLDwnPg6HP2jwPGLmlSusb4uv33MzOWFCJBXQowpl9lTZ3Wmod3NXL+0mLyvPJpXohUs7jYR6HPPeV1dd2yUSLhKgq8BMIzVKsuEgTHGP9/iy+C5j3Q12r/WMYqabL4dbDsLfD0rdDTZP9YUogEdSkgW6ZfAXjtZDfH2/t566oFyR6KECIOpRQbKgumFNT5QxGC4ah0k0iwioIZ2gGr9di7X2Fm19WNVdIE4NJvQdgPT3zN/rGkEAnqUoDX7aI/KJm6R3Y34lDw5hUy9SpEqtq0qIAjrX20TTIz1CN9X20xYwWIo+Z71FiBVNl6yPDNzLq6sUqaABSdBud+DHb8Aeq32j+eFCFBXQrIzjTW1M3ImogU9tCuk5yzuIiibCk6LESqstbVTTZbZ7UIk6AusawCxCfsDuoiQeNrvOLDFmcGVJ47M+vqxippYnnd5yG7BB7+fNrshJWgLgV4M11oTVpn6w429XCopY/LVsvUqxCpbHV5HhlOxdZJ9oGNZeoyZfo1kbIzXeR7M+wvazKRoA5g0YXQshd6W2wezziZOjDahb3xq3BiK7z6Z3vHkyIkqEsBvkzjk2s674B9aFcjSsFbVkpQJ0Qqy8pwsqo8j61HpxjUSaYu4YxadXZPv5rvT+Nlxxa/zvh6zOZs3VglTYZacxWUb4THvwqBHnvHlAIkqEsB2ZlOAPpmwQ7Y+o5+/vFqQ8Lv9+HdJ9lUVcD83FF2MwkhUsamqgJePdFFIDzxv1nW9KsUH068inxv6mTqSteCO9v+dXVjlTQZyuGAt94KvU3wzHfsHVMKkKAuBXjdZqZuFuyAvevFY3zyT9vxhxIXgB5p7WNfYw9vXSUFh4WYDTZWFRAMR9l9Ynh/zaZu/6g7+SVTZx+rALGt67JjQd04gZQzAyrPs3ddXTRqZA5HK2lyqopNsO5qePFn0NNo37hSgLy6UkB25uwJ6hq7/GhtfF1U7EvIfT68+yQAl0opEyFmhQ3mZon7t9ez9Vg72493sv14J43dfi5aVszvbjhnxG26YxslJFOXaBUFHvyhKG19QYrt2mgWMf7/cEzg/2/RhfD4fxo14nJsqGYQMXdejxdgDrX+GmMnbOMuyJm77zWSqUsBXrc5/ToL1tQ1dfsBaEhgW5qHdzWybmE+ZfmehN2nEMI+83OyWFTk5fcvHeebD+1jd0MXZy8uZG1FHntPxl+3ZGXqrA+xInFmpKyJFdSNN/0KRhFisG9dXdgM6sbbKDFU8enG19YDiR9PCpFXVwoYzNSl/pq65h7jxZSoXoP1Hf3sOtHFl966PCH3J4SYGbf960bqOwZYtzCfeTnGm+tPn6rlO//cT18gHNsAZun2h8jOdOF0qGQMd04rjxUg7mfdwnx7HmSi068AC9aCO8dYV7fqPYkfS3gKmTpfEXgKJagT9vPNkulXrfWQTJ0/Ife5s64LgAuWFifk/oQQM+PM0lzOLM0ddqyy0MgY1XX0s3zB8Mt6pEWYbcpnoqvEZDJ1ThdUnW/furrIFDJ1YGTrWg8mfjwpRKZfU4DP3CiR6q3CegPhWC29k12J+eOxv7Ebh4Kl87MTcn9CiOSpKjKCumNtI3di9vhDEtTZJDcrgzyPzbXqJrr71bLoQmg7CN0nEz+WsDWWyQZ1y+Z8pk6CuhTgM0uapHrx4abuwbZAiZp+3d/Uw6JiH1kZzoTcnxAieaxM3fG4QV1YNknYqKLAY29XiaiVqZvglOdiG/vAxjJ1k5h+BSNT19cC/e2JH1OKkKAuBbicDjJdjpSffm02p14LvBkJ2yhxoKmXM0pyEnJfQojkyve6yc1ycbx9tKBOMnV2sb0AcWSSQd2CNZCZC4efSvxYYhslJlnX1Nos0Vab2PGkEAnqUoQv05Xy069NPUZQt76ygJNd/mnXRPKHIhxt6+N0CeqEmDMqi7wcixvUhciVTJ1tyvO91HfYWKvOmn51TDAwdzjhjLfCa3+HUIKDzcls2hiqeJnxdQ6vq5OgLkX4Mp2zZvp13cJ8+oMRugZC07q/2uZetIYzFkhQJ8RcUVXoo04ydTOuosDDQChCe1/QngeYbKYOYP2/QqAL9v4jsWOZSkkTgPwqo87eHF5XJ0FdivC5Z0GmrttPdqaLZeamhumuq9vXaNSzkqBOiLmjsshoWRWJDmaMtNayps5mFXbvgJ1KUFd1oRFIbf9dYscSK2kyyaDO6YKi0yRTN1VKqaNKqV1KqR1KqS3msUKl1GNKqYPm14Ih1/+SUqpWKbVfKfWWIcc3mvdTq5T6sVJKmcczlVJ3m8c3K6UW2fl87OTLdNGf4sWHm7sDzM/NjBUJnm5ZkwNNPbhdDqrMxdVCiNmvstBLKKKHrbsNhKMEI1HJ1NnIKkCcqE1sI0x29ysYfVfX/ysceRo6jiVwLFPcKAFzfgfsTGTqLtFar9NabzJ//iLwhNZ6GfCE+TNKqRXAVcBK4FLgZ0opa0vkbcBNwDLz36Xm8RuADq31UuAHwLdn4PnYwlhTl9rTr43dfkpysmJB3XTLmuxv7GHpvGxcTkkYCzFXWB/Shk7BWi3CciWos83QAsRDaa3p8Een/wBTCeoA1r4fULDjj9Mfg2WqmTowNkt0HBnMPM4xyXg3fSdwp/n9ncC7hhz/s9Y6oLU+AtQCZyulSoFcrfWL2lgBetcpt7Hu6x7gDVYWb7bxuZ0pv/u1qdtPSW4mRT43bqdj2p8IDzT1yNSrEHNMpVWrbkhQZ7UIk+lX++R5MsjJcg2bfo1ENV99YA//UTPAaw3d03uAqPn+NNnNCfkL4bRLjL6r0QQElzAYYE4pU3e68VzajyRmLCnG7o9NGnhUKaWBX2itbwdKtNYnAbTWJ5VS883rlgMvDbltvXksZH5/6nHrNnXmfYWVUl1AEdA6dBBKqZswMn2UlJRQU1OTsCeYKD0dAdq7IzM2tt7e3kk9ltaaxs4BAvlhnnnmafIzNTv2H6PG0zSlx+8LaU52+cnoa065/4/JnhsxMXJeRzeXzk1Ua5wKntu+j9L+wwAc7jRmIY4e3EtNlz3rmebSOZyq/IwoO2vrqalpJRTV/PLVAC83Guf+/qc201w+9aC6ou41lgLPvriZiMs3qdvOy9zAyq4n2fnXH9NRuG7KY7CUNuziDOCFV7YTzDw+qdvmdPewEdhdcx+t886d9lhS7ffO7qDuAq11gxm4PaaU2jfGdeNl2PQYx8e6zfADRjB5O8CmTZt0dXX1mINOhqe6dvNq2wlmamw1NTWTeqyOviDhfz7GppXLqL5wMacdeIlQJEp19flTevxXjrbDEy/y1vPXUb18/vg3mEGTPTdiYuS8jm6unZvKrTWQnUt19QYAnAdb4KWXOf+sDZy9uNCWx5xr53Aqlh/fwrG2Pjaeez4f+d1WXm7s5/NvOYPv/nM/3vlVVFefPvU7f247HIKLXncJuCe5Djp0Lhy+g7XRXVD96amPwbJ5PxyA8y+sNnq6ToZ/A2z7HKtKM+HC6mkPJdV+72ydftVaN5hfm4H7gbOBJnNKFfNrs3n1emDhkJtXAA3m8Yo4x4fdRinlAvKAWVkq2pfpoi8Ysa/G0DRZNepKco01DKX5WdMqQLzf3Pl6uky/CjHnLCz0cqy9L/bz4PSrrKmzU0WBh7r2Aa66/SVePtLO99+3ln+7ZCmFWSpuQehJmcruV0tGFqx5H+z9Owx0TG8cAGFzk95Upl+zciF7wZzdAWtbUKeU8imlcqzvgTcDu4EHgGvNq10L/M38/gHgKnNH62KMDREvm1O1PUqpc831ch885TbWfV0JPKlTNSoahy/TRSSqCYQTtOYgwawadQtyjQre5fkeGrv9hCNTG++Bph6yM12U5U2yIrgQIuVVFXqHtQrrsTZKeGRNnZ0qCrwMhCIcbunjl9du4ooNRj5kvldxtK1vnFuPIxIClFFUeCrWX2PsWt11z/TGAVPv/WqZwztg7czUlQDPKaV2Ai8DD2qtHwH+B3iTUuog8CbzZ7TWe4C/AK8BjwD/prW2toN+DLgDY/PEIeBh8/ivgCKlVC3wGcydtLORz228UFJ1s0RTt5WpM4KwsnwPUQ1NPYGxbjaq/Y09nF6SzSzd1yKEGENVkZduf5jOfuPNVzJ1M+OcxYWsLMvljzeewyVnDC5rmed1xO3HOymRoJGlm+rf7NI1RuuwRNSss0qaTHYnrqX4dCOom505oDHZ9grTWh8G1sY53ga8YZTbfAP4RpzjW4BVcY77gfdOe7ApwJdp/Ff0ByNMcoXAjLD6vs7LMadfzQzbyc4Bys0SJxOltWZ/Uw9vXVWa2EEKIVLCQrOsyfH2fvK9brr9YZSCbLcEdXZaVZ7Hg/9+0YjjJV7FM/VBevyhqe9AjoSmHkRZ1l8DD38eTr5qBHlTFQ4YWbqpBpjFp4O/C/paIDu11nRPlxQISxHZZlCXql0lmroD5HszyMowMopWIDeVsiYtPQE6+0OcUZKd0DEKIVJDlVXWxMwOdQ+EyHa7cDgkM58M873GW/2x6WTrogkI6lZfaWT7dvxhevcTCYJrGkt3Yj1g594UrAR1KcJrBnWpPP1akjP4IiqdRleJ/U2ySUKIuaxySKYOpO9rss33GsH0tDZLWNOv0+EthMrzoP6V6d1PODC1TRKWYnMXsAR1wi7ZmeaaumBqdpVo6jFahFmyM13keTKm1FXC2vl6RokEdULMRV63i+LszNg6rmlN+4lpS0imLhKaflAHkLcQuk9O7z4iwalvkgDILQeXB1prpzeOFCRBXYrwulM7U9fc7Y9tkrCU5k2trMmBph6Ks90UZU/jRSmESGlVRYNlTSRTl1wel6LI5+bYdHbARoLgSMD/YW4Z9DZCZBrvdWH/9DJ1DgcUL5VMnbBPKq+pi0Y1zT2BWI06S3m+hxNTmX5tlPZgQsx1lYVe6tqND309gZAEdUlWWeRNjUxdbhnoKPROrRsRMLhRYjqsHbBzjAR1KSK2+zUFg7q2viCRqB6RqSvL90w6UxeNag409XK6TL0KMadVFnpp6BogEI6YmTqZfk2mRUW+aa6pS2BQB9DdMPb1xhxLcHqZOjCCus7jEJpeD/NUI0FdivC6k7um7h+vNvDTp+KvL7Bq1M3POWX6NT+LroHQpKaM6zsGGAhFZD2dEHNcVZEXrY3XfI8/TK5HMnXJNDTInpJIcPq7X2FIUHdi6veRkEzdMkBD26Hp3U+KkaAuRWS6HLgcKmlr6u7fdoL/ffJg3A4Rzae0CLNYZU1G2ywRjY4s7Cg7X4VID7EdsG39slEiBVhBtjUlPmkJC+rKja8909gsEQmCKwHTrzDnpmAlqEsRSim8bmfSgrrOgRD+UJR95s7UoawWYfGmX4G46+qe2tfMmq89yj9eHZ5iP2AFdZKpE2JOqzRr1R1o6iEU0bKmLsmqinwAHG+f4maJaDgx06+eAqPG3HQzddMN6gpPM77OsR6wEtSlkOxMF72B5Ey/dpjtfLYfH9lsuemUbhIWK6g7GWdd3Z9ePk5vIMwn/7Sd3710LHZ8X2MPFQWe2MYQIcTcNC87E0+Gk90N3QCSqUsyqyD00dYprqtLVKZOKWMKdrpr6qY7/er2Ql4ltElQJ2ziy3TRH0xOpq6r32i4vf1454jLmroDFGe7yXAO/3UpycnEoRixWaLHH6LmQAvvP3shrz9jPl/5625++PgBtNYcaOyR9XRCpAGlFJWFXvY0dAGQK5m6pCryufG5nVPfLBEJgiNBgXnONIO66ZY0sRQvm3PTr/IqSyHeTFdSSpporekcMIO6us4Rl8erUQfgcjooyc0aMf365L5mguEoV2yoYN3CfL547y5++PhBWnoCHG7t5fVnzq1ee0KI+CqLvDy+1yhdIdOvyaWUoqrIN/VadYno/WrJLYO6zVO/fTgBmTow1tVtexGiUaN23Rwgr7IUkp3ppD8Ju197A2EiUU1xdiZHWvto7wtS6Bv8FNTUEz+og/hlTR589SQluZlsrCzA4VB8971rKM5284tnDgPSSUKIdFFZaCzOB5l+TQVVRd5YR59JS1RJEzCCup6TUw+mItNsE2YpXgahfuhpgLyK6d9fCpgboekc4XO7krJRotOceq0+Yx4AO+qGr6tr6h5ZeNhSmpc1bPdrbyBMzYEW3rqqNNa8WynFly47k/932XKKfG42VhXY8TSEECnGWscFkqlLBZVFXuo6+onEqUwwrkT0frXklhv31982tdsnoqQJQNFS42vb3GkXJkFdCvGNMv1q9zo7K6i7aFkxTocatq4uFInS2hsYUaPOUp7voaHLHytf8sTeJoLhKG9bUzriuje97jS23PJGFhZ6R1wmhJh7KguHBnWSqUu2RUU+QhE9pZ7dRqYuQYF5rvn+MNUdsIkoaQKD2bnprO9LMRLUpRBfnOnXxi4/537zCb750F7bHrdzwNj5WpbvYfmCnGFBXWtvAK1HljOxlOV7CIajtPUZ9/HQrsGp13iUUokdvBAiZQ0N6mSjRPJVmf8fU2oXFk3w9CtMvVZdIkqaDB3HdMqrpBgJ6lKIzz0yU/eTpw7S7Q/zy2cPs/VYuy2Pa2Xq8j0ZrK/MZ0ddZyw9P1ijbvTpVzAKEPcGwtTsHz71KoRIXxUFXhzKqGLhc0tQl2xW7cApBXWJnn6FqQVTkTDoSGKmXzM84C2CLgnqhA18mS6C4Sghs6tDXXs/d79SxxXryynL8/CFe17FH0r8RopOs0ZdnjeDDZUF9AbC1Db3AoM16sbK1IFR1uSJvU0EwlEuWz1y6lUIkX7cLgeleUZdSvmgl3yleR7cTgfHplKAOJG7X33zwOGa2rRnxEg0JGSjBEy/Zl6KkaAuhfjMgrz9ZgHiHz1xEKUUX7h0Od+8YjWHWvr43ycTXyhxMFPnZr05bWoVIW62+r6OkqkrH9JV4qFdJ5mfk8km2QghhDBVFnrJlfV0KcHpUFQUejg2lQLEiaxT53BCTunUgqmwGdQlIlMHRtZQgjphB5/bCUBvMMyhll7u21bPNedWsSAvi4tPn8d7NlTw86cPs/tEV0Ift3MghM/txO1ysKjIS743g21mUNfUHcDpUBT54r+A8r0ZeDKc1Db3ULO/hctWy9SrEGLQezdV8L5NC5M9DGGqKvRybLIFiLVOXJswS07pFKdfjZmlxGXqyqG7PjH3lQIkqEshg5m6MD98/CBZGU4+Vn1a7PKvXH4mhT43X7jn1dgUbSJ09ofI9xovEKUU6xfmxzZLNHX7mZediXOUQE0pRWl+Fg/saJCpVyHECFdsqOBTb1yW7GEIU1WRj+NtfWg9ibImEWM2J2HTr2BOe05ho0TCM3VlMNABwSl22kgxEtSlEKsf6pZjHfx9ZwMfumARxdmDv7j5Xjdff+cqXjvZze1mId9E6OwPkucZfLFuqCzgYHMvXQMhmnpGr1FnKc/30BeMyNSrEEKkuKoiL33BCK29wYnfyMqOJTSoM6c9JxNcDh2LK/467ymNA6a+EzfFSFCXQrzm9Ov3Hj1ATpaLmy46bcR1Ll21gLetLuVHjx+ktnmKlcFP0TkQIt87+GK11tW9Wt9Jc7ef+aNskrCU5Rnr6t66aoFMvQohRAqzCkIfn8xmiVhQl8Dp19wyCPWBf5LLicIJ3iiRZwZ1XXNjClaCuhRiTb+29ga46aIl5Hnjfyr66jtW4nDAHzYfT8jjdvYHKfAOvkDWLMxDKdh2rJOmbv+4mbrSfCPok6lXIYRIbVVFPmCSZU2iZqmthGbqrALEk9ykELFho8RUxpGipHBQCrGCukKfmw9duHjU683LyaSq0Ed9xxSqgsfRNRAaFkDmZmWwbH42m4+00dEfYsE4mbp3risnEtVsWlSYkPEIIYSwR0WBB6Xg6GSCOlsydda0ZwOUrJj47RKdqcuZZneLFCOZuhRSnO0mK8PBv79+aWx93WjK8rNo6Jx+UKe1NjZKeIZ/AttQWcDmI0ax4/GmXxcX+/jsm88YdTOFEEKI1JDpclKW5+F42xSmXxNV0gSGdHOYZIYs0Rsl3F7wFEpQJxIvJyuDV778Rq67YPQsnaUs35OQoK43ECYc1cPW1AGsr8yPdZUYrfCwEEKI2aeqaJJlTSI2TL9mLwDUFKZfrY0SCQrqYE7VqpOgLsVMtOl1Wb6Hjv4QA8HpdZiIFR72Dk9lrx/Su3W8NXVCCCFmj6oi7+TW1Nkx/epyG50lJpshi02/JjKoK5NMnUguq5NDQ9f0snVdA4N9X4daOi+bHHMKuCRHMnVCCDFXVBb6aO8L0uMPTewGdgR1MLVadbGxJDCoyyufM/1fJaibpYb2XJ2ODrPv66mZOodDsa4yH7fTMWJqVgghxOy1yCxrMuFsXaz4cIL3Vk5l2jPRGyXALEDcDqHEbD5MJgnqZqnSPCN7Nt2gbnD6dWTgdvU5VXzwvCqUkg0QQggxV1TGatVNMKiLWkGdHZm6yU6/+s2xJHhNHcyJdXVS0mSWWpCXhVJwotM/rfvpHGX6FYxCx5euWjCt+xdCCJFaFhYaQV3dRIM6O6df/Z1Giy63d3JjSfRGCTACzKKRRf9nE8nUzVIZTgclOdMva9JlTr+OVuhYCCHE3JKblUGeJ2PimTpr+jWRJU1gsKzJZFp0xUqa2FAzbw5k6iSom8USUauuoz+E1+0k0+VM0KiEEEKkuspCL3UTLWBvR+9XGFKrbhJTsLZk6sxxzIFWYbYHdUopp1Jqu1LqH+bPdyuldpj/jiqldpjHFymlBoZc9vMh97FRKbVLKVWrlPqxMhd5KaUyzfurVUptVkotsvv5pJJE1KqLV3hYCCHE3Law0EP9ZDN1CZ9+nUKGLBwA5QBHAlePub3gKZBM3QR9Cthr/aC1/het9Tqt9TrgXuC+Idc9ZF2mtf7okOO3ATcBy8x/l5rHbwA6tNZLgR8A37bvaaSe8nwPDV1+tNZTvo+ugSB53gS/UIUQQqS0hQVe6jsGiEYn8P4RC+oSnACYSouuSMDYJJHoDXxzpACxrUGdUqoCeBtwR5zLFPA+4E/j3EcpkKu1flEb0ctdwLvMi98J3Gl+fw/wBpVGWzXL8j0Ew1Ha+oJTvo/O/hAFsp5OCCHSSkWhl2AkSlPPBDbb2TX96vZCVv4kM3XBxJYzseSWQ/fsn361e/frD4EvADlxLrsIaNJaHxxybLFSajvQDdyitX4WKAeGnul68xjm1zoArXVYKdUFFAGtQx9IKXUTRqaPkpISampqpvesUkRbk9G65e9PPMfivMmtievt7aWmpoaG1n7Ksh1z5pwkgnVuRGLJeR2dnJvpk3M4unjnpqPFeP944IkXOKNw7PeP0oY9nAG8sHkLwczDCR3bJmce/sO72D3B/7vT645QHFG8kOD/69N7objt2KTvN9V+72wL6pRSlwPNWuutSqnqOFd5P8OzdCeBSq11m1JqI/BXpdRKIF7mzcoXj3XZ4AGtbwduB9i0aZOuro43nNmn+EQXP97+HKWnraB6VemkbltTU0N1dTXB5x5jWdUCqqtX2zTK2cc6NyKx5LyOTs7N9Mk5HF28c1PZ0sv3tz5NcdUZVG+sGPsONu+HA3D+RdXgLUzs4OpPJ7uvZeL/dx1/hv6cxP9fq1fgqX9SfcG5kDGBLkpawz0fYpdayerLP5/YsUyDndOvFwDvUEodBf4MvF4p9XsApZQLuAK427qy1jqgtW4zv98KHAJOx8jMDf2NqwCsXG09sHDIfeYB7fY9pdRitQqbaq06rbWxUUKmX4UQIq2UF3hQCuo6JrBZwq7pVzALEE9yo0SiN2yA0SoMJr6+r/0w7LkfdzC1Qg7bgjqt9Ze01hVa60XAVcCTWut/NS9+I7BPax2bVlVKzVNKOc3vl2BsiDistT4J9CilzjXXy30Q+Jt5sweAa83vrzQfY+q7BmaZfG8GngznlHfA9gUjhKNa1tQJIUSayXQ5KcnJoq59Au8fVlCX6Dp1YKxl62s21spNRCSY2HImsXFY5VUmGGA2bAegJ2dZ4scyDcnqKHEVIzdIvA74L6VUGIgAH9VaWyHwx4DfAh7gYfMfwK+A3ymlajEydFfZPO6UopSaVq26Tqvvq0d2vwohRLpZWOiZWFeJiLH+zp5Mnbl0qLcR8ivHv344YFNQN8nyKg3bwZVFn28CY55BMxLUaa1rgJohP18X5zr3YpQ4iXf7LcCqOMf9wHsTNMxZaTq16qy+r9JNQggh0s/CQi8vHmob/4qRICgnOGwoUj80QzaRoM4qaWLbOCa4A/bENliwGp3IenkJIB0lZrnyfM+U19RZQZ0UHxZCiPSzsMBLY7efQDgy9hUjQXuydDC87+pE2FXSxO2beHmVaARO7oSyDYkfxzRJUDfLleZ5aO0NjP+ijKNzwJh+LfDJ9KsQQqSbhYVetIaG8RIDkZA9mxNg8mvZwn57MnUw8QLELfsh1AflEtSJBCvLN7ZeN3ZNPlsnmTohhEhfCwuMCgrHx1tXFw3Zl6nLzIUMH3SfnNj17dooAcYO2In0f23YZnyVTJ1ItMGyJpNfV2dtlMiVoE4IIdJOZZEXYPzNEpGgfZk6pcyyJhOdfrWppAlMvLzKiW1GMFq01J5xTIMEdbNcmRnUjZs+j6OzP4Qnw0lWhg2LX4UQQqS0kpws3E7H+LXqIiF7yplYcssmliEDezN1ueXQ3wqhcd5PG7ZB6VpwpF4IlXojEpOyIM+Yfp3KDtjOAen7KoQQ6crhUJQXeKgfr1ZdxMbpV4CSldC028jCjceukiYwuGmjZ4xsXTgAjbuhbL09Y5gmCepmuawMJ8XZmVML6vpD5Hllk4QQQqSrigLP+Gvq7Jx+Bag8z9gA0bBj/OvaVdIEJrZpo2m3scYwBTdJgAR1c0J5ftaoa+r8oQjBcDTuZZ39QdkkIYQQaayy0Dux6Vc7M3WV5xlfj78w/nXtKmkCg5m6rjHW951I3U0SIEHdnFCaN3oB4qvv2MwX73017mWdA9L3VQgh0tnCQi+d/SF6/KHRr2RnnTqA7HlQtAyOvTj29bS2uaSJlakbI6hr2AHeookVSk4CCermgLJ8Dye7/Jza9vZIax9bj3Xw0uH4FcM7+0Pky/SrEEKkrYUF1g7YMZbwRG2sU2epOg/qXoJo/JklYxxhQNu3pi4zG7Lyxp5+bdhmZOmUsmcM0yRB3RxQlp9FfzBC18DwT1oP7TLq/jR0+enoG94sWWtN10BQMnVCCJHGFhYaFRTGnIK1e/oVoPJ88HdB82ujX8faSGFngJlbPnqmLtgHLftSdj0dSFA3J4xWq+4fr57E6zbKlexp6B52mT8CoYiWNXVCCJHGBjN1YwV1QXtLmoCRqQM4PsYUbMRMTriy7BvHWEHdyZ2goym7ng4kqJsT4tWqO9Lax96T3Vx/wWIAXjvZNew2fSFjqlYydUIIkb7yvRnkZLrGD+rsnn7Nr4KcsrGDOitTZ9dGCRi7AHFsk0RqljMBCermhMGgbjBTZ029fuCcSsryskZk6gaDOllTJ4QQ6UopRUWhl7qOMdbURcL2T78qZWTrjr1obIiIOw5r+tWmNXVgZOr6WuLXzGvYZlyeU2Lf40+TBHVzQJHPjdvlGBbUPfjqSTZU5lOW72FFWW6coM74KtOvQgiR3hYWeJKfqQOjtElPA3Qei3952Jp+tTGoyzPLmsTL1p3YltJZOpCgbk5wOBSleYO16o629vHayW4uW10KwIqyPA639DIQjMRu0xuUTJ0QQgijrEldR/+ICgoxM7FRAqDqfOPraKVNwuYSI1s3SphlTU4NLPvboeNISm+SAAnq5oyyIbXqHjSnXq2gbmVZLlENexsHs3W9sqZOCCEERgFifyhKS+8obbrsrlNnmXcmZOWPXoQ4MgOZupLV4M6Gv30CmvcOHm/YbnxN4U0SIEHdnGHVqgNjPd16c+oVjKAOhu+AtdbU5cn0qxBCpLVYWZPRatXNRJ06AIcDKs8dI1M3AyVNsufBhx4yAshfvQWOPGscb0j9TRIgQd2cUZ6fRVO3n9rmXvY0dPM2M0tnXOYhz5PBaw2DO2D7QhpPhpOsDGcyhiuEECJFWGVN6kerVReZoaAOjHV1bQehtyXOOKzdrzaWNAEoXQsffhxyFsDvr4Bd9xidJApPA0++vY89TRLUzRFl+R6iGn7z/BEA3jokqFNKsfKUzRK9IZl6FUIIARXj1aqLBMHhmpnBWOvq4pU2iW2UmIEAM78SbvgnVJwF994ABx9L+fV0IEHdnGFNtd6ztZ51C/NjBYktK8ty2dfYQyhitGDpC2mZehVCCIHH7WReTibHRw3qZjBTV7rOyMTFC+pmoqTJUJ4CuOZ+WPUe47HLN83M407DDIXewm5WUBcIR7l8TemIy1eW5REMRznU0svyBbn0hTRFBbLzVQghhFXWJM6aumgEdGTmgjqX2wiejsXZLDETJU1GjCcTrrgD1n0AFl00c487RZKpmyPK8gfXGAyderXENkucMKZge0Napl+FEEIAg2VNRoiYRU2dM5gDqjoPGl+FQM/w4zNR0iQehwOWvnFmg8kpkqBujvC6XeR7M+JOvQIsmZdNVoYjtq6uNyhr6oQQQhgWFng52eWPLdGJscqIzGQgVXme0WO17uVTxmJtlEj94CpZZPp1DvnaO1bGFryeyulQLF+Qy56GLrTW5po6mX4VQghh1KqLRDUnO/1UFg15H4mGja8zGdQtPBuUw1hXt/QNg8fDSQgwZxnJ1M0h71xXzsaqglEvX1mWy2snu+kLRohoKJBMnRBCCKDCqlV36hRsLFM3g+8XmTmwYA0ceAT6WoeMZYZKmsxiEtSlkZVlefT4w+yqN+rVyfSrEEIIGKxVN6KsiRXUOWb4/WLDB6FxN/xwNTx6C/Q2J2ejxCwj069pxNos8cIh45OPTL8KIYQAWJCXhUMRazcZE9soMcPvF2fdAIsuhGe/By/+FF6+A/IqQDnBIUXzRyOZujRyxoIcnA7Fc7VGUCeZOiGEEAAZTgcLcrOoHzWoS8L7xbwz4Irb4d9egZXvhvbDkJU38+OYRSRTl0ayMpwsnZfNqzL9KoQQ4hRl+R5OdJwa1KXA5oTipfDu2+DiL4wscyKGkUxdmllZlkskqgEo8Mr0qxBCCEN5gYcTqZSpO1XhYihdk+xRpDQJ6tLMCnNdHSBtwoQQQsSU53to7PLHPvgDEE2hoE6MS4K6NLOyzFiP4HYY07FCCCEEGJm6cFTT1O0fPJgK069iwiSoSzNWps6XoZI8EiGEEKnE6kY0bAdsskqaiCmxPahTSjmVUtuVUv8wf/6qUuqEUmqH+e+yIdf9klKqVim1Xyn1liHHNyqldpmX/VgppczjmUqpu83jm5VSi+x+PrNdnieDhYUest0S1AkhhBhUUWAEdcPW1aXSmjoxrpnI1H0K2HvKsR9ordeZ/x4CUEqtAK4CVgKXAj9TSlnzg7cBNwHLzH+XmsdvADq01kuBHwDftvWZzBH/smkhG+bL1KsQQohBZWamrr4jXlAn06+zga1BnVKqAngbcMcErv5O4M9a64DW+ghQC5ytlCoFcrXWL2qtNXAX8K4ht7nT/P4e4A1WFk+M7hOvX8a7l8kLVAghxCCv20WBN+OUTJ2sqZtN7K5T90PgC0DOKcc/oZT6ILAF+KzWugMoB14acp1681jI/P7U45hf6wC01mGlVBdQBAxpFgdKqZswMn2UlJRQU1Mz3ec16/X29sp5GIWcG3vIeR2dnJvpk3M4usmcm1xXhF2HTlBT0wZASeOrnAm8tGUrfk+DfYOcpVLt9862oE4pdTnQrLXeqpSqHnLRbcDXAW1+/R5wPRAvw6bHOM44lw0e0Pp24HaATZs26erq6lOvknZqamqQ8xCfnBt7yHkdnZyb6ZNzOLrJnJvldVs41NJHdfXFxoGtx2AfnHv+RUabLjFMqv3e2Tn9egHwDqXUUeDPwOuVUr/XWjdprSNa6yjwS+Bs8/r1wMIht68AGszjFXGOD7uNUsoF5AHt9jwdIYQQYm4rz/fS0DmAsdqJIXXqZPp1NrAtqNNaf0lrXaG1XoSxAeJJrfW/mmvkLO8GdpvfPwBcZe5oXYyxIeJlrfVJoEcpda65Xu6DwN+G3OZa8/srzccYkakTQgghxPjKCzz0ByN09pvBnOx+nVWS0fv1VqXUOoxp0qPARwC01nuUUn8BXgPCwL9prSPmbT4G/BbwAA+b/wB+BfxOKVWLkaG7amaeghBCCDH3WLXqTnQOUOBzS526WWZGgjqtdQ1QY35/zRjX+wbwjTjHtwCr4hz3A+9N1DiFEEKIdFY+pKzJqvI8KWkyy0hHCSGEEEIAxvQrDClALNOvs4oEdUIIIYQAoMCbgSfDyQmrAHEkCA4XSAnYWUGCOiGEEEIAoJSivMAz2P81EpSp11lEgjohhBBCxJTnewanX6NhmXqdRSSoE0IIIURMecGQoE4ydbOKBHVCCCGEiCnP99DeF6Q/GDbX1EmmbraQoE4IIYQQMVZZk4bOAWP3q0y/zhoS1AkhhBAixiprUt9hBXUy/TpbSFAnhBBCiJjBTJ1f1tTNMhLUCSGEECKmJDcLl0NxorPfzNQlo6OomAoJ6oQQQggR43QoFuRlGQWIozL9OptIUCeEEEKIYcqsWnWypm5WkaBOCCGEEMNU5HuMTJ3VJkzMChLUCSGEEGKY8gIPjd1+omHZKDGbSFAnhBBCiGHK8z1ENYRDEtTNJhLUCSGEEGIYq1ZdJBSQ4sOziAR1QgghhBjGqlUnQd3sIkGdEEIIIYYpM4M6LcWHZxUJ6oQQQggxTFaGk+JsN1p6v84qEtQJIYQQYoTyfA9Kig/PKhLUCSGEEGKE8gIPzmgIHJKpmy0kqBNCCCHECOX5Hpw6gpbp11lDgjohhBBCjFCel0UGYQYiEirMFvI/JYQQQogRKvIzcShNVzDZIxETJUGdEEIIIUYoy3UC0BVUSR6JmCgJ6oQQQggxQnmOsZauw5/kgYgJcyV7AEIIIYRIPbk5Oex4/e9ZetqKZA9FTJAEdUIIIYQYQbncrHvd25M9DDEJMv0qhBBCCDEHSFAnhBBCCDEHSFAnhBBCCDEHSFAnhBBCCDEHSFAnhBBCCDEH2B7UKaWcSqntSql/mD9/Rym1Tyn1qlLqfqVUvnl8kVJqQCm1w/z38yH3sVEptUspVauU+rFSSpnHM5VSd5vHNyulFtn9fIQQQgghUtFMZOo+Bewd8vNjwCqt9RrgAPClIZcd0lqvM/99dMjx24CbgGXmv0vN4zcAHVrrpcAPgG/b9ByEEEIIIVKarUGdUqoCeBtwh3VMa/2o1jps/vgSUDHOfZQCuVrrF7XWGrgLeJd58TuBO83v7wHeYGXxhBBCCCHSid2Zuh8CXwCio1x+PfDwkJ8Xm1O1TyulLjKPlQP1Q65Tbx6zLqsDMAPFLqAoMUMXQgghhJg9bOsooZS6HGjWWm9VSlXHufzLQBj4g3noJFCptW5TSm0E/qqUWgnEy7xp627GuGzoY92EMX1LSUkJNTU1k3syc1Bvb6+ch1HIubGHnNfRybmZPjmHo5NzY59UO7d2tgm7AHiHUuoyIAvIVUr9Xmv9r0qpa4HLgTeYU6porQNAwPx+q1LqEHA6RmZu6BRtBdBgfl8PLATqlVIuIA9oP3UgWuvbgdsBNm3apKurqxP9XGedmpoa5DzEJ+fGHnJeRyfnZvrkHI5Ozo19Uu3c2jb9qrX+kta6Qmu9CLgKeNIM6C4FbgbeobXut66vlJqnlHKa3y/B2BBxWGt9EuhRSp1rrpf7IPA382YP8P+3d38xdpR1GMe/jywpJqKWAma11QYtkraa1NbEEkMaDIogirKawoWQyEWVRL3kgouGpDGtRlGL8U80rf9RKwGbUGywq0hStMCWtWilVUyXolYMmhKtLf15Me+W6XLm7Jnunp05M88nOTmz8+c97z797dm3M++egRvT8kh6jZecqTMzMzNrun6eqSuyGZgH7Ex/07A7/aXrZcDtkk4ALwDrImLyrNvHgS3Ay8nm4E3Ow/sm8B1JB8jO0K2dq2/CzMzMrE7mZFAXEaPAaFp+U8E+24BtBdv2AMs7rP8v8OHZ6qeZmZnZoPIdJczMzMwaQG2bgibpCPCXqvtRA+cD/6i6EzXlbPrDuRZzNjPnDIs5m/6Zi2zfEBEX9LJj6wZ1lpG0JyJWVd2POnI2/eFcizmbmXOGxZxN/9QtW19+NTMzM2sAD+rMzMzMGsCDuvb6etUdqDFn0x/OtZizmTlnWMzZ9E+tsvWcOjMzM7MG8Jk6MzMzswbwoM7MzMysATyoqwlJiyTtkvR7SfskfSqtP0/STklPpuf5af0Vkh6RNJ6eL8+1tUHSIUlHp3nNlen4A5K+lO6ti6R1af2YpF9LWlpw/DxJd6XjH5a0OLdth6TnJG1vaTaXSXpU0glJI1O2vZCOH5N070zzOVN1yjW3fURSSOr4EQFtrLnc9umyqVXN1SlDSTdJOpLL4OaC41tXXyWyqVV9FfSxNrmmbR+R9ETqy/cLjp/dmosIP2rwAIaBt6Xlc4E/AkuBTcCtaf2twMa0vAJ4bVpeDjyda+sdqb2j07zmb4DVgMjup/vetP6VuX3eD+woOP4TwFfT8lrgrty2dwHXANtbms1i4K3At4GRKdu6vnYbay7Xh18Bu4FVrrnS2dSq5uqUIXATsLmHPreuvkpkU6v6GoBclwCPAfPT1xfORc1V/o/gR2Gh3ANcAewHhtO6YWB/h30FPAvMm7K+sBhTW3/IfX098LUO+10P3FfQxv3A6rQ8RPap2sptXzMbb4CDmE1uny11fQOsW67AHcD7yO4TXTRwaWXN9ZJN3WuuygzpfeDSuvrqNZu611cNc90E3DzXNefLrzWUTr+uAB4GXhMRzwCk5ws7HHId8FhEHCvxMq8DJnJfT6R1k324RdJBssL8ZJc2DqW+nQD+BSwo0YfSBiibbs6RtEfSbknXnsHxs67qXCWtABZFxHSXGVpXcyWy6abSmqs6w8k2JT0u6SeSFnVpo1X1NdlmD9l04/e0TD7Xi4GLJT2UcrmySxuzVnNDZ3qg9YekVwDbgE9HxL91+rSaTvsvAzYC7y77Uh3WxamFiDuBOyXdANwG3Fi2jdk2YNl08/qIOCzpIuAXksYj4mDJNmZN1blKehnwBbIzBmfURsl+9GzAsummspqrOsP0/DPgBxFxTNI6YCtweYf9W1Vf6bnXbLrxe9qLJnMdIrsEuwZYCDwoaXlEPFeijdJ8pq5GJJ1NVojfi4ifptV/kzSctg8Df8/tvxC4G/jodD9Aks7KTWS9nex/FAtzuywEDnc49IfAtamNDZNtpG0TwKK0bQh4FfDP3r/j3g1gNoUi4nB6/hPZ5bQV0x3TLzXJ9Vyy+Syjkp4im8tyr6RVrrlS2RSqquZqkiER8WzuDMw3gJWpjbbXV5lsCvk97ZT874oJ4J6IOB4Rfya7BLyk7zVX9hq1H3279i+yCah3TFn/WU6f4LkpLb8a2Atc16XN6SZ4/pbsl8TkBM+r0voluX2uAfYUHH8Lp0/w/NGU7WuYnUnFA5dNbp8t5OafAPNJczaA84EngaVtr7kp+4xSPKeudTXXazZ1q7k6ZUiaT5WWPwjsdn2Vy6Zu9TUAuV4JbM3lcghY0O+am/PQ/SgsjHeSnXJ9HBhLj6vIrq0/kH5QHgDOS/vfBjyf23eM9Nc1ZHO9JoCT6Xl9wWuuAn4HHAQ2w6k7jHwR2Jfa3AUsKzj+HODHwAGyvwC6KLftQeAI8J/Uh/e0LJu3p/afJ5t8uy+tvxQYJ3sjGQc+5pp7yT6jFA/qWldzJbKpVc3VKUPgM2Q/t3vJfm4vcX2VzqZW9TUAuQr4PPBEymXtXNScbxNmZmZm1gCeU2dmZmbWAB7UmZmZmTWAB3VmZmZmDeBBnZmZmVkDeFBnZmZm1gAe1JmZdSBpQe6DRv8q6em0fFTSV6run5nZVP5IEzOzaUhaT/YhpJ+rui9mZkV8ps7MrARJayRtT8vrJW2V9HNJT0n6kKRNksYl7Ui3LELSSkm/lPSIpPsnb1lkZjabPKgzM5uZNwJXAx8Avgvsioi3kH0K/NVpYPdlslsrrQS+BWyoqrNm1lxDVXfAzGzA3RcRxyWNA2cBO9L6cWAx8GZgObBTEmmfZyrop5k1nAd1ZmYzcwwgIk5KOh4vTlQ+SfYeK7L7ZK6uqoNm1g6+/Gpm1l/7gQskrQaQdLakZRX3ycwayIM6M7M+ioj/ASPARkl7gTHg0ko7ZWaN5I80MTMzM2sAn6kzMzMzawAP6szMzMwawIM6MzMzswbwoM7MzMysATyoMzMzM2sAD+rMzMzMGsCDOjMzM7MG+D8gq5UKa0SwDwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot future prices predictions of Bitcoin\n",
    "\n",
    "plt.figure(figsize=(10,7))\n",
    "plot_time_series(bitcoin_prices.index,btc_price,start=2700,format=\"-\",label='Actual BTC Price')\n",
    "plot_time_series(next_time_steps,future_forecast,format='-',label=\"predicted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec85386",
   "metadata": {},
   "source": [
    "## MOdel 10: Why forecasting is BS (turkey problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "04021c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "btc_price_turkey = btc_price.copy()\n",
    "btc_price_turkey[-1] = btc_price_turkey[-1]/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "7da7894e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58788.2096789273,\n",
       " 58102.1914262342,\n",
       " 55715.5466512869,\n",
       " 56573.5554719043,\n",
       " 52147.8211869823,\n",
       " 49764.1320815975,\n",
       " 50032.6931367648,\n",
       " 47885.6252547166,\n",
       " 45604.6157536131,\n",
       " 431.44471290860304]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_price_turkey[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5b0e702d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2021-05-09T00:00:00.000000000', '2021-05-10T00:00:00.000000000',\n",
       "       '2021-05-11T00:00:00.000000000', '2021-05-12T00:00:00.000000000',\n",
       "       '2021-05-13T00:00:00.000000000', '2021-05-14T00:00:00.000000000',\n",
       "       '2021-05-15T00:00:00.000000000', '2021-05-16T00:00:00.000000000',\n",
       "       '2021-05-17T00:00:00.000000000', '2021-05-18T00:00:00.000000000'],\n",
       "      dtype='datetime64[ns]')"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_timesteps_turkey = np.array(bitcoin_prices.index)\n",
    "btc_timesteps_turkey[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "eb254793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,7))\n",
    "plot_time_series(timesteps=btc_timesteps_turkey,\n",
    "         values=btc_price_turkey,\n",
    "         format='-',\n",
    "         label='BTC Price + Turkey Problem',\n",
    "         start=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8d6932b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON=1\n",
    "WINDOW_SIZE =7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "3e0c5311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and test sets for turkey probleum data\n",
    "full_windows,full_labels = make_windows(np.array(btc_price_turkey),WINDOW_SIZE,HORIZON)\n",
    "\n",
    "X_train,X_test,y_train,y_test = make_train_test_splits(full_windows,full_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "f5806302",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "y_train = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "X_test = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "y_test = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "\n",
    "train_model_10 = tf.data.Dataset.zip((X_train,y_train))\n",
    "test_model_10 = tf.data.Dataset.zip((X_test,y_test))\n",
    "\n",
    "train_model_10 = train_model_10.batch(1024).prefetch(tf.data.AUTOTUNE)\n",
    "test_model_10= test_model_10.batch(1024).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "dc01a75e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([123.65499, 125.455  , 108.58483, 118.67466, 121.33866, 120.65533,\n",
       "       121.795  ])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "id": "b61b382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = tf.keras.models.clone_model(model_1)\n",
    "model_10._name = \"model_10_turkey\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "58e66f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10 = tf.keras.Sequential([\n",
    "    layers.Input(shape=(7),name = \"input_shape\"),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(128,activation='relu'),\n",
    "    layers.Dense(1)\n",
    "],name='model_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "id": "d6f1d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10.compile(loss='mae',metrics=['mae','mse'],optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "8fef4e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_10.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "a192354b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10_turkey\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1024      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 129       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,153\n",
      "Trainable params: 1,153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_10.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "19dc20a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7*128+128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "67266cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 443.3746 - mae: 443.3746 - mse: 233274.9688INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 351ms/step - loss: 2677.4521 - mae: 2677.4521 - mse: 16742433.0000 - val_loss: 11949.3467 - val_mae: 11949.3467 - val_mse: 252681856.0000\n",
      "Epoch 2/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 252.2037 - mae: 252.2037 - mse: 76382.2734INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 315ms/step - loss: 1406.3638 - mae: 1406.3638 - mse: 4669995.5000 - val_loss: 4201.8496 - val_mae: 4201.8496 - val_mse: 35913688.0000\n",
      "Epoch 3/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 85.2889 - mae: 85.2889 - mse: 9981.8008INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 318ms/step - loss: 303.8629 - mae: 303.8629 - mse: 313344.5625 - val_loss: 2348.2649 - val_mae: 2348.2649 - val_mse: 18863852.0000\n",
      "Epoch 4/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 570.1611 - mae: 570.1611 - mse: 1060337.6250 - val_loss: 3545.1990 - val_mae: 3545.1990 - val_mse: 32601542.0000\n",
      "Epoch 5/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 81.1340 - mae: 81.1340 - mse: 9479.3721INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 322ms/step - loss: 515.6251 - mae: 515.6251 - mse: 843743.7500 - val_loss: 1745.3623 - val_mae: 1745.3623 - val_mse: 13410370.0000\n",
      "Epoch 6/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 42.1180 - mae: 42.1180 - mse: 3387.3279INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 362ms/step - loss: 219.5259 - mae: 219.5259 - mse: 230689.2031 - val_loss: 1727.4198 - val_mae: 1727.4198 - val_mse: 10879564.0000\n",
      "Epoch 7/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 333.5434 - mae: 333.5434 - mse: 408076.5625 - val_loss: 2370.6443 - val_mae: 2370.6443 - val_mse: 15709471.0000\n",
      "Epoch 8/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 47.0552 - mae: 47.0552 - mse: 3862.0586INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 324ms/step - loss: 323.3797 - mae: 323.3797 - mse: 371915.6562 - val_loss: 1507.3137 - val_mae: 1507.3137 - val_mse: 9688310.0000\n",
      "Epoch 9/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 27.1207 - mae: 27.1207 - mse: 2085.2253INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 568ms/step - loss: 205.1832 - mae: 205.1832 - mse: 210720.7656 - val_loss: 1340.8153 - val_mae: 1340.8153 - val_mse: 10069352.0000\n",
      "Epoch 10/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 261.8531 - mae: 261.8531 - mse: 302183.6562 - val_loss: 1381.5258 - val_mae: 1381.5258 - val_mse: 10378777.0000\n",
      "Epoch 11/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 32.0271 - mae: 32.0271 - mse: 2409.5481INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 219.2757 - mae: 219.2757 - mse: 230854.6406 - val_loss: 1222.9406 - val_mae: 1222.9406 - val_mse: 8591093.0000\n",
      "Epoch 12/100\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 219.1255 - mae: 219.1255 - mse: 225802.2344 - val_loss: 1580.1998 - val_mae: 1580.1998 - val_mse: 9930095.0000\n",
      "Epoch 13/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 225.4578 - mae: 225.4578 - mse: 226225.4531 - val_loss: 1223.4600 - val_mae: 1223.4600 - val_mse: 8443843.0000\n",
      "Epoch 14/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 21.9003 - mae: 21.9003 - mse: 1731.9226INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 195.0417 - mae: 195.0417 - mse: 196831.1406 - val_loss: 1173.3278 - val_mae: 1173.3278 - val_mse: 8783943.0000\n",
      "Epoch 15/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 25.3070 - mae: 25.3070 - mse: 1878.8438INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 203.9411 - mae: 203.9411 - mse: 207026.1719 - val_loss: 1135.7000 - val_mae: 1135.7000 - val_mse: 8251494.0000\n",
      "Epoch 16/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 190.5209 - mae: 190.5209 - mse: 188859.1406 - val_loss: 1302.0416 - val_mae: 1302.0416 - val_mse: 8567748.0000\n",
      "Epoch 17/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 197.5230 - mae: 197.5230 - mse: 192214.0938 - val_loss: 1162.0378 - val_mae: 1162.0378 - val_mse: 8142853.5000\n",
      "Epoch 18/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20.9951 - mae: 20.9951 - mse: 1637.8591INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 186.4048 - mae: 186.4048 - mse: 183118.5625 - val_loss: 1108.4066 - val_mae: 1108.4066 - val_mse: 8145732.0000\n",
      "Epoch 19/100\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 183.3364 - mae: 183.3364 - mse: 179334.5469 - val_loss: 1145.6575 - val_mae: 1145.6575 - val_mse: 8008217.0000\n",
      "Epoch 20/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 186.4459 - mae: 186.4459 - mse: 178971.2812 - val_loss: 1176.2988 - val_mae: 1176.2988 - val_mse: 8013520.0000\n",
      "Epoch 21/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20.9237 - mae: 20.9237 - mse: 1586.4509INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 295ms/step - loss: 180.2979 - mae: 180.2979 - mse: 171769.1094 - val_loss: 1088.3352 - val_mae: 1088.3352 - val_mse: 7847548.5000\n",
      "Epoch 22/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 178.1940 - mae: 178.1940 - mse: 170172.1719 - val_loss: 1096.1058 - val_mae: 1096.1058 - val_mse: 7761653.0000\n",
      "Epoch 23/100\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 178.1335 - mae: 178.1335 - mse: 167284.5938 - val_loss: 1124.8336 - val_mae: 1124.8336 - val_mse: 7736088.0000\n",
      "Epoch 24/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 20.0846 - mae: 20.0846 - mse: 1498.7515INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 273ms/step - loss: 174.7405 - mae: 174.7405 - mse: 162630.0625 - val_loss: 1065.2443 - val_mae: 1065.2443 - val_mse: 7604994.0000\n",
      "Epoch 25/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 171.8936 - mae: 171.8936 - mse: 159648.4531 - val_loss: 1084.8627 - val_mae: 1084.8627 - val_mse: 7544423.5000\n",
      "Epoch 26/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 174.2577 - mae: 174.2577 - mse: 158770.4219 - val_loss: 1072.8427 - val_mae: 1072.8427 - val_mse: 7461991.5000\n",
      "Epoch 27/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 19.3153 - mae: 19.3153 - mse: 1411.9333INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 169.2750 - mae: 169.2750 - mse: 153991.8281 - val_loss: 1030.1042 - val_mae: 1030.1042 - val_mse: 7368740.0000\n",
      "Epoch 28/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 166.4288 - mae: 166.4288 - mse: 150212.3125 - val_loss: 1059.5718 - val_mae: 1059.5718 - val_mse: 7310363.5000\n",
      "Epoch 29/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.9761 - mae: 18.9761 - mse: 1360.3776INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 166.6292 - mae: 166.6292 - mse: 147747.1094 - val_loss: 1021.9685 - val_mae: 1021.9685 - val_mse: 7199923.5000\n",
      "Epoch 30/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.6107 - mae: 18.6107 - mse: 1327.7443INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 163.0307 - mae: 163.0307 - mse: 144285.3281 - val_loss: 1008.3126 - val_mae: 1008.3126 - val_mse: 7112433.0000\n",
      "Epoch 31/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.3754 - mae: 18.3754 - mse: 1298.6814INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 162.4196 - mae: 162.4196 - mse: 141168.9688 - val_loss: 1006.7846 - val_mae: 1006.7846 - val_mse: 7026536.0000\n",
      "Epoch 32/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 18.1558 - mae: 18.1558 - mse: 1267.3135INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 158.5718 - mae: 158.5718 - mse: 136761.3438 - val_loss: 967.4116 - val_mae: 967.4116 - val_mse: 6899028.5000\n",
      "Epoch 33/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.7830 - mae: 17.7830 - mse: 1226.8678INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 155.2727 - mae: 155.2727 - mse: 131232.8125 - val_loss: 954.6343 - val_mae: 954.6343 - val_mse: 6726868.0000\n",
      "Epoch 34/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.3582 - mae: 17.3582 - mse: 1176.3115INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 297ms/step - loss: 151.8342 - mae: 151.8342 - mse: 126477.1484 - val_loss: 936.4812 - val_mae: 936.4812 - val_mse: 6584894.5000\n",
      "Epoch 35/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 17.0510 - mae: 17.0510 - mse: 1140.0844INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 293ms/step - loss: 150.3237 - mae: 150.3237 - mse: 122560.7656 - val_loss: 910.5187 - val_mae: 910.5187 - val_mse: 6461247.5000\n",
      "Epoch 36/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.6940 - mae: 16.6940 - mse: 1102.6071INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 145.9160 - mae: 145.9160 - mse: 118535.4062 - val_loss: 904.6865 - val_mae: 904.6865 - val_mse: 6335188.5000\n",
      "Epoch 37/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.4057 - mae: 16.4057 - mse: 1065.7839INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 304ms/step - loss: 148.1575 - mae: 148.1575 - mse: 115950.3984 - val_loss: 869.8256 - val_mae: 869.8256 - val_mse: 6234518.0000\n",
      "Epoch 38/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 16.0979 - mae: 16.0979 - mse: 1033.2067INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 319ms/step - loss: 143.6731 - mae: 143.6731 - mse: 114251.1797 - val_loss: 869.7043 - val_mae: 869.7043 - val_mse: 6139064.0000\n",
      "Epoch 39/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.8454 - mae: 15.8454 - mse: 1002.3112INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 292ms/step - loss: 151.3773 - mae: 151.3773 - mse: 114425.4922 - val_loss: 842.2814 - val_mae: 842.2814 - val_mse: 6079374.5000\n",
      "Epoch 40/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.7320 - mae: 15.7320 - mse: 982.6031INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 291ms/step - loss: 154.0092 - mae: 154.0092 - mse: 122247.8438 - val_loss: 831.0420 - val_mae: 831.0420 - val_mse: 6027688.0000\n",
      "Epoch 41/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 152.9330 - mae: 152.9330 - mse: 113817.2578 - val_loss: 869.7219 - val_mae: 869.7219 - val_mse: 5969944.0000\n",
      "Epoch 42/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.6996 - mae: 15.6996 - mse: 951.1650INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 140.3841 - mae: 140.3841 - mse: 107441.1953 - val_loss: 816.2886 - val_mae: 816.2886 - val_mse: 5935093.0000\n",
      "Epoch 43/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 140.5617 - mae: 140.5617 - mse: 102974.3281 - val_loss: 816.4722 - val_mae: 816.4722 - val_mse: 5854513.0000\n",
      "Epoch 44/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 15.1276 - mae: 15.1276 - mse: 914.9808INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 141.0555 - mae: 141.0555 - mse: 107180.4297 - val_loss: 808.3019 - val_mae: 808.3019 - val_mse: 5814974.5000\n",
      "Epoch 45/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 148.3655 - mae: 148.3655 - mse: 107071.0625 - val_loss: 815.9313 - val_mae: 815.9313 - val_mse: 5770253.0000\n",
      "Epoch 46/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.9837 - mae: 14.9837 - mse: 892.1098INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 141.8983 - mae: 141.8983 - mse: 107153.4375 - val_loss: 792.3846 - val_mae: 792.3846 - val_mse: 5801691.5000\n",
      "Epoch 47/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 138.7070 - mae: 138.7070 - mse: 99007.3125 - val_loss: 804.8356 - val_mae: 804.8356 - val_mse: 5701361.5000\n",
      "Epoch 48/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.8227 - mae: 14.8227 - mse: 873.0910INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 282ms/step - loss: 134.7963 - mae: 134.7963 - mse: 99585.7656 - val_loss: 782.8826 - val_mae: 782.8826 - val_mse: 5694977.5000\n",
      "Epoch 49/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.8083 - mae: 14.8083 - mse: 869.1797INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 136.6467 - mae: 136.6467 - mse: 96441.7266 - val_loss: 781.1788 - val_mae: 781.1788 - val_mse: 5646331.0000\n",
      "Epoch 50/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.6458 - mae: 14.6458 - mse: 856.4065INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 138.6608 - mae: 138.6608 - mse: 102607.3984 - val_loss: 773.6599 - val_mae: 773.6599 - val_mse: 5630776.5000\n",
      "Epoch 51/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 142.5967 - mae: 142.5967 - mse: 99796.7734 - val_loss: 792.0907 - val_mae: 792.0907 - val_mse: 5583300.5000\n",
      "Epoch 52/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.6416 - mae: 14.6416 - mse: 842.0594INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 280ms/step - loss: 135.3655 - mae: 135.3655 - mse: 98846.8672 - val_loss: 764.1191 - val_mae: 764.1191 - val_mse: 5609051.5000\n",
      "Epoch 53/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 135.0494 - mae: 135.0494 - mse: 93673.5625 - val_loss: 771.4147 - val_mae: 771.4147 - val_mse: 5531351.5000\n",
      "Epoch 54/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.4095 - mae: 14.4095 - mse: 826.7324INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 286ms/step - loss: 133.3292 - mae: 133.3292 - mse: 96519.0234 - val_loss: 757.0052 - val_mae: 757.0052 - val_mse: 5543077.0000\n",
      "Epoch 55/100\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 134.9348 - mae: 134.9348 - mse: 92828.0469 - val_loss: 761.1682 - val_mae: 761.1682 - val_mse: 5488312.5000\n",
      "Epoch 56/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.3023 - mae: 14.3023 - mse: 815.1108INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 134.0248 - mae: 134.0248 - mse: 96769.5938 - val_loss: 749.6147 - val_mae: 749.6147 - val_mse: 5507306.5000\n",
      "Epoch 57/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 134.8547 - mae: 134.8547 - mse: 92179.0859 - val_loss: 752.4930 - val_mae: 752.4930 - val_mse: 5450819.0000\n",
      "Epoch 58/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.2128 - mae: 14.2128 - mse: 805.0266INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 136.3428 - mae: 136.3428 - mse: 98625.2500 - val_loss: 744.5856 - val_mae: 744.5856 - val_mse: 5497273.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 133.2626 - mae: 133.2626 - mse: 90623.3672 - val_loss: 747.9884 - val_mae: 747.9884 - val_mse: 5413082.0000\n",
      "Epoch 60/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.1427 - mae: 14.1427 - mse: 795.6970INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 0s 234ms/step - loss: 133.8974 - mae: 133.8974 - mse: 96024.1797 - val_loss: 738.8049 - val_mae: 738.8049 - val_mse: 5459252.0000\n",
      "Epoch 61/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 131.6306 - mae: 131.6306 - mse: 89038.8594 - val_loss: 741.0934 - val_mae: 741.0934 - val_mse: 5383302.5000\n",
      "Epoch 62/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0734 - mae: 14.0734 - mse: 787.6783INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 132.7445 - mae: 132.7445 - mse: 94680.9141 - val_loss: 733.2375 - val_mae: 733.2375 - val_mse: 5421162.0000\n",
      "Epoch 63/100\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 131.4271 - mae: 131.4271 - mse: 88453.4141 - val_loss: 736.2660 - val_mae: 736.2660 - val_mse: 5353540.0000\n",
      "Epoch 64/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 14.0135 - mae: 14.0135 - mse: 780.2424INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 271ms/step - loss: 131.8719 - mae: 131.8719 - mse: 93655.7500 - val_loss: 729.3036 - val_mae: 729.3036 - val_mse: 5405750.5000\n",
      "Epoch 65/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 128.8416 - mae: 128.8416 - mse: 86441.9453 - val_loss: 734.0674 - val_mae: 734.0674 - val_mse: 5323574.0000\n",
      "Epoch 66/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.9738 - mae: 13.9738 - mse: 773.3414INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 259ms/step - loss: 127.1612 - mae: 127.1612 - mse: 89124.2344 - val_loss: 722.8107 - val_mae: 722.8107 - val_mse: 5347218.0000\n",
      "Epoch 67/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 128.7705 - mae: 128.7705 - mse: 85919.5391 - val_loss: 726.2546 - val_mae: 726.2546 - val_mse: 5300800.0000\n",
      "Epoch 68/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8970 - mae: 13.8970 - mse: 766.7620INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 527ms/step - loss: 127.4917 - mae: 127.4917 - mse: 89246.6016 - val_loss: 718.2731 - val_mae: 718.2731 - val_mse: 5318924.0000\n",
      "Epoch 69/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 129.5318 - mae: 129.5318 - mse: 86056.0156 - val_loss: 720.8102 - val_mae: 720.8102 - val_mse: 5278410.0000\n",
      "Epoch 70/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8416 - mae: 13.8416 - mse: 761.0411INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 258ms/step - loss: 129.2560 - mae: 129.2560 - mse: 90657.9531 - val_loss: 715.3737 - val_mae: 715.3737 - val_mse: 5320162.5000\n",
      "Epoch 71/100\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 127.6629 - mae: 127.6629 - mse: 84607.8672 - val_loss: 720.4113 - val_mae: 720.4113 - val_mse: 5251929.0000\n",
      "Epoch 72/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.8160 - mae: 13.8160 - mse: 755.8285INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 266ms/step - loss: 125.0737 - mae: 125.0737 - mse: 86792.9531 - val_loss: 710.2650 - val_mae: 710.2650 - val_mse: 5280104.5000\n",
      "Epoch 73/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 126.5592 - mae: 126.5592 - mse: 83539.2266 - val_loss: 712.1292 - val_mae: 712.1292 - val_mse: 5236989.0000\n",
      "Epoch 74/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.7464 - mae: 13.7464 - mse: 750.7277INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 279ms/step - loss: 125.8900 - mae: 125.8900 - mse: 87346.8438 - val_loss: 706.5333 - val_mae: 706.5333 - val_mse: 5247048.5000\n",
      "Epoch 75/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 130.1003 - mae: 130.1003 - mse: 85549.6016 - val_loss: 709.8989 - val_mae: 709.8989 - val_mse: 5214642.0000\n",
      "Epoch 76/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 128.2265 - mae: 128.2265 - mse: 89347.3750 - val_loss: 707.0581 - val_mae: 707.0581 - val_mse: 5280545.0000\n",
      "Epoch 77/100\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 124.5503 - mae: 124.5503 - mse: 81885.2109 - val_loss: 707.3202 - val_mae: 707.3202 - val_mse: 5195941.0000\n",
      "Epoch 78/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6764 - mae: 13.6764 - mse: 741.9462INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 298ms/step - loss: 123.0441 - mae: 123.0441 - mse: 84621.2422 - val_loss: 699.7189 - val_mae: 699.7189 - val_mse: 5210513.5000\n",
      "Epoch 79/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 127.6174 - mae: 127.6174 - mse: 83406.5938 - val_loss: 700.5125 - val_mae: 700.5125 - val_mse: 5185233.5000\n",
      "Epoch 80/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6271 - mae: 13.6271 - mse: 738.4435INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 277ms/step - loss: 127.4197 - mae: 127.4197 - mse: 88338.4297 - val_loss: 699.3488 - val_mae: 699.3488 - val_mse: 5229889.5000\n",
      "Epoch 81/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 125.8687 - mae: 125.8687 - mse: 82139.7578 - val_loss: 702.3017 - val_mae: 702.3017 - val_mse: 5162894.5000\n",
      "Epoch 82/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.6165 - mae: 13.6165 - mse: 734.8146INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 310ms/step - loss: 123.0003 - mae: 123.0003 - mse: 84352.1328 - val_loss: 694.1417 - val_mae: 694.1417 - val_mse: 5190314.5000\n",
      "Epoch 83/100\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 126.1838 - mae: 126.1838 - mse: 82013.2266 - val_loss: 695.9291 - val_mae: 695.9291 - val_mse: 5152428.0000\n",
      "Epoch 84/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5561 - mae: 13.5561 - mse: 732.1413INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 275ms/step - loss: 124.5570 - mae: 124.5570 - mse: 85552.1406 - val_loss: 692.5468 - val_mae: 692.5468 - val_mse: 5187807.0000\n",
      "Epoch 85/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 125.5646 - mae: 125.5646 - mse: 81405.2422 - val_loss: 694.7219 - val_mae: 694.7219 - val_mse: 5138253.0000\n",
      "Epoch 86/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.5368 - mae: 13.5368 - mse: 729.8524INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 283ms/step - loss: 123.0993 - mae: 123.0993 - mse: 84187.2422 - val_loss: 689.4774 - val_mae: 689.4774 - val_mse: 5168022.5000\n",
      "Epoch 87/100\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 125.8075 - mae: 125.8075 - mse: 81373.2109 - val_loss: 691.9525 - val_mae: 691.9525 - val_mse: 5127304.5000\n",
      "Epoch 88/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4976 - mae: 13.4976 - mse: 725.4094INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 123.2041 - mae: 123.2041 - mse: 84277.7500 - val_loss: 687.6232 - val_mae: 687.6232 - val_mse: 5161381.5000\n",
      "Epoch 89/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 125.2001 - mae: 125.2001 - mse: 80912.1875 - val_loss: 689.0856 - val_mae: 689.0856 - val_mse: 5118184.0000\n",
      "Epoch 90/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4639 - mae: 13.4639 - mse: 722.9186INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 262ms/step - loss: 123.0808 - mae: 123.0808 - mse: 84119.4766 - val_loss: 685.7241 - val_mae: 685.7241 - val_mse: 5153008.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 124.8759 - mae: 124.8759 - mse: 80520.8672 - val_loss: 687.5594 - val_mae: 687.5594 - val_mse: 5108008.5000\n",
      "Epoch 92/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4405 - mae: 13.4405 - mse: 720.5295INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 288ms/step - loss: 122.4024 - mae: 122.4024 - mse: 83421.7109 - val_loss: 683.3237 - val_mae: 683.3237 - val_mse: 5138367.0000\n",
      "Epoch 93/100\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 125.1917 - mae: 125.1917 - mse: 80413.0469 - val_loss: 686.3359 - val_mae: 686.3359 - val_mse: 5098152.0000\n",
      "Epoch 94/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4342 - mae: 13.4342 - mse: 720.0449INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 278ms/step - loss: 122.1066 - mae: 122.1066 - mse: 82958.7891 - val_loss: 682.0236 - val_mae: 682.0236 - val_mse: 5133956.0000\n",
      "Epoch 95/100\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 124.2282 - mae: 124.2282 - mse: 79697.1641 - val_loss: 685.0081 - val_mae: 685.0081 - val_mse: 5088953.5000\n",
      "Epoch 96/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.4069 - mae: 13.4069 - mse: 715.3699INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 285ms/step - loss: 120.9733 - mae: 120.9733 - mse: 82146.9766 - val_loss: 679.6873 - val_mae: 679.6873 - val_mse: 5119828.5000\n",
      "Epoch 97/100\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 124.0197 - mae: 124.0197 - mse: 79679.7422 - val_loss: 681.2233 - val_mae: 681.2233 - val_mse: 5082441.5000\n",
      "Epoch 98/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3748 - mae: 13.3748 - mse: 714.1464INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 284ms/step - loss: 121.5699 - mae: 121.5699 - mse: 82656.9609 - val_loss: 677.7649 - val_mae: 677.7649 - val_mse: 5109294.0000\n",
      "Epoch 99/100\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 124.6193 - mae: 124.6193 - mse: 79918.4453 - val_loss: 679.6297 - val_mae: 679.6297 - val_mse: 5073620.5000\n",
      "Epoch 100/100\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 13.3517 - mae: 13.3517 - mse: 712.0610INFO:tensorflow:Assets written to: model_experiment\\model_10\\assets\n",
      "3/3 [==============================] - 1s 269ms/step - loss: 122.0671 - mae: 122.0671 - mse: 83039.8047 - val_loss: 677.4432 - val_mae: 677.4432 - val_mse: 5111628.0000\n",
      "Wall time: 38.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d72efecfd0>"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_10.fit(train_model_10,\n",
    "            validation_data=test_model_10,\n",
    "            epochs=100,\n",
    "            callbacks=[create_model_checkpoint(model_10.name)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "id": "f942b9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(\"model_experiment/model_10/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "id": "36e9f4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 167ms/step - loss: 677.4432 - mae: 677.4432 - mse: 5111628.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[677.4432373046875, 677.4432373046875, 5111628.0]"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "aa911681",
   "metadata": {},
   "outputs": [],
   "source": [
    "turkey_preds = make_preds(model_10,test_model_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "c23121e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (1,), types: tf.float64>"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "67a951f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(556,), dtype=float32, numpy=\n",
       "array([ 8778.385 ,  8668.549 ,  8946.971 ,  8719.741 ,  8623.909 ,\n",
       "        8658.228 ,  8619.049 ,  8408.3955,  8386.47  ,  8441.518 ,\n",
       "        8183.819 ,  8021.747 ,  7986.3022,  7620.771 ,  7188.68  ,\n",
       "        7187.3696,  7025.5615,  7085.9097,  7078.0713,  7411.5786,\n",
       "        7349.4893,  7620.182 ,  7502.6094,  7355.9907,  7225.855 ,\n",
       "        7268.2686,  7148.4526,  7287.779 ,  7437.5913,  7476.184 ,\n",
       "        7468.024 ,  7305.2144,  7169.412 ,  7120.8345,  7126.412 ,\n",
       "        7152.7188,  7046.416 ,  7029.047 ,  6848.858 ,  6555.9287,\n",
       "        7186.051 ,  7198.648 ,  7070.881 ,  7141.07  ,  7249.9165,\n",
       "        7080.887 ,  7147.2236,  7161.9575,  7117.596 ,  7143.2124,\n",
       "        7238.395 ,  7311.63  ,  7208.1846,  7112.304 ,  7098.668 ,\n",
       "        6927.9155,  7147.138 ,  7282.694 ,  7298.8125,  7562.7803,\n",
       "        7966.554 ,  8021.74  ,  7769.594 ,  7954.7236,  8032.3574,\n",
       "        8074.9204,  8024.9395,  8578.604 ,  8788.543 ,  8679.846 ,\n",
       "        8772.643 ,  8898.066 ,  8610.115 ,  8525.224 ,  8624.057 ,\n",
       "        8578.809 ,  8319.824 ,  8340.557 ,  8288.667 ,  8446.879 ,\n",
       "        8750.523 ,  9052.376 ,  9219.003 ,  9444.705 ,  9351.6875,\n",
       "        9271.982 ,  9284.398 ,  9215.757 ,  9084.034 ,  9456.365 ,\n",
       "        9623.605 ,  9699.144 ,  9804.074 , 10044.034 ,  9802.122 ,\n",
       "       10060.15  , 10271.194 , 10185.545 , 10202.4   ,  9928.158 ,\n",
       "        9762.907 ,  9548.771 , 10016.545 ,  9699.011 ,  9536.608 ,\n",
       "        9519.715 ,  9649.327 ,  9761.004 ,  9613.34  ,  9325.161 ,\n",
       "        8757.271 ,  8667.137 ,  8670.706 ,  8592.62  ,  8440.123 ,\n",
       "        8780.488 ,  8762.538 ,  8673.646 ,  8920.209 ,  9086.827 ,\n",
       "        8871.618 ,  8174.4253,  7790.39  ,  7832.5454,  7898.3184,\n",
       "        6060.143 ,  5488.7856,  5334.9   ,  5359.106 ,  4898.741 ,\n",
       "        5367.514 ,  5342.134 ,  6131.4023,  6178.388 ,  6184.9087,\n",
       "        5820.379 ,  6341.398 ,  6691.889 ,  6712.6255,  6618.371 ,\n",
       "        6647.3013,  6248.2617,  5862.464 ,  6303.6064,  6446.9326,\n",
       "        6461.636 ,  6713.67  ,  6789.6196,  6766.773 ,  6746.311 ,\n",
       "        7155.1797,  7150.356 ,  7280.058 ,  7250.1274,  6901.1777,\n",
       "        6746.99  ,  6953.8193,  6874.955 ,  6789.3564,  6676.723 ,\n",
       "        7032.361 ,  7036.5073,  7188.6187,  7119.9453,  6869.2036,\n",
       "        6780.41  ,  7031.12  ,  7448.6753,  7461.9434,  7469.687 ,\n",
       "        7535.646 ,  7712.2993,  7693.407 ,  8541.751 ,  8770.194 ,\n",
       "        8791.025 ,  8825.491 ,  8897.152 ,  8785.125 ,  8876.865 ,\n",
       "        9238.303 ,  9759.972 ,  9873.299 ,  9576.089 ,  8801.334 ,\n",
       "        8497.245 ,  8668.871 ,  9195.027 ,  9617.688 ,  9383.245 ,\n",
       "        9291.87  ,  9556.357 ,  9681.538 ,  9607.85  ,  9476.306 ,\n",
       "        9110.6875,  9057.15  ,  9128.52  ,  8998.372 ,  8807.391 ,\n",
       "        8753.335 ,  8982.672 ,  9376.395 ,  9387.331 ,  9547.87  ,\n",
       "        9398.152 , 10051.006 ,  9582.808 ,  9536.104 ,  9638.025 ,\n",
       "        9687.05  ,  9513.053 ,  9647.7   ,  9708.059 ,  9689.182 ,\n",
       "        9769.811 ,  9272.9795,  9295.644 ,  9366.148 ,  9313.446 ,\n",
       "        9286.323 ,  9435.933 ,  9384.871 ,  9306.146 ,  9206.699 ,\n",
       "        9245.912 ,  9211.999 ,  9529.292 ,  9552.81  ,  9280.027 ,\n",
       "        9125.511 ,  9109.238 ,  8952.22  ,  8975.575 ,  9095.562 ,\n",
       "        9079.559 ,  9124.3125,  9041.905 ,  9003.885 ,  9022.468 ,\n",
       "        8993.283 ,  9143.386 ,  9180.038 ,  9355.347 ,  9189.246 ,\n",
       "        9154.682 ,  9124.164 ,  9211.429 ,  9146.271 ,  9171.332 ,\n",
       "        9128.432 ,  9060.095 ,  9057.095 ,  9091.254 ,  9103.149 ,\n",
       "        9085.248 ,  9273.49  ,  9438.751 ,  9532.027 ,  9486.432 ,\n",
       "        9600.993 ,  9821.526 , 10923.263 , 10977.537 , 11136.979 ,\n",
       "       11021.98  , 11298.123 , 11568.042 , 11197.177 , 11068.137 ,\n",
       "       11121.159 , 11522.268 , 11653.992 , 11594.478 , 11587.225 ,\n",
       "       11595.931 , 11700.306 , 11303.138 , 11381.378 , 11603.327 ,\n",
       "       11719.24  , 11736.344 , 11805.341 , 12216.02  , 12043.513 ,\n",
       "       11676.962 , 11650.904 , 11549.948 , 11517.702 , 11542.257 ,\n",
       "       11642.232 , 11313.046 , 11317.721 , 11210.3545, 11353.762 ,\n",
       "       11387.84  , 11549.085 , 11560.45  , 11824.514 , 11417.895 ,\n",
       "       10685.461 , 10398.1   , 10030.526 , 10031.6875, 10232.8545,\n",
       "       10041.692 , 10080.009 , 10252.64  , 10308.775 , 10304.111 ,\n",
       "       10254.135 , 10513.711 , 10731.674 , 10928.24  , 10847.031 ,\n",
       "       10843.704 , 10918.574 , 10801.579 , 10452.798 , 10393.63  ,\n",
       "       10208.888 , 10487.121 , 10632.348 , 10669.711 , 10619.866 ,\n",
       "       10769.178 , 10682.824 , 10636.728 , 10534.224 , 10475.062 ,\n",
       "       10442.192 , 10545.84  , 10645.203 , 10524.135 , 10520.444 ,\n",
       "       10759.031 , 10957.837 , 11214.207 , 11256.88  , 11518.434 ,\n",
       "       11388.512 , 11299.6   , 11349.526 , 11305.163 , 11224.848 ,\n",
       "       11338.111 , 11641.581 , 11818.598 , 12824.371 , 13109.3955,\n",
       "       12884.876 , 12876.326 , 12964.165 , 12896.744 , 13470.694 ,\n",
       "       13296.072 , 13285.175 , 13408.365 , 13780.6045, 13612.008 ,\n",
       "       13525.912 , 13649.385 , 14016.727 , 15113.857 , 15482.945 ,\n",
       "       14799.458 , 15149.354 , 15273.397 , 15232.381 , 15533.91  ,\n",
       "       16134.891 , 16200.508 , 15903.146 , 15755.596 , 16466.326 ,\n",
       "       17383.383 , 17706.432 , 17778.014 , 18367.77  , 18502.691 ,\n",
       "       18458.338 , 18296.996 , 18800.957 , 18646.027 , 17255.277 ,\n",
       "       16712.021 , 17518.826 , 17998.42  , 18982.092 , 18962.361 ,\n",
       "       19005.07  , 19199.346 , 18842.562 , 18731.408 , 18930.916 ,\n",
       "       18977.129 , 18520.521 , 18370.734 , 18189.355 , 17994.004 ,\n",
       "       18549.904 , 18917.486 , 19076.135 , 19212.373 , 20888.137 ,\n",
       "       22598.936 , 22960.463 , 23517.373 , 23482.78  , 23060.209 ,\n",
       "       23080.857 , 23108.33  , 23309.662 , 24209.11  , 25983.309 ,\n",
       "       26287.393 , 26450.795 , 26684.477 , 28344.055 , 28904.904 ,\n",
       "       29106.8   , 31393.271 , 32892.438 , 31498.025 , 33439.633 ,\n",
       "       35992.145 , 39077.97  , 40142.305 , 40191.85  , 38494.24  ,\n",
       "       34718.094 , 33515.895 , 36152.957 , 38186.895 , 36648.965 ,\n",
       "       35664.918 , 35971.93  , 36122.324 , 36117.508 , 34897.8   ,\n",
       "       30896.773 , 32204.287 , 32156.197 , 31993.852 , 31817.867 ,\n",
       "       32347.346 , 30380.363 , 32525.533 , 34513.387 , 34585.52  ,\n",
       "       32811.984 , 33205.867 , 35045.28  , 36994.04  , 37028.73  ,\n",
       "       37410.15  , 39635.027 , 38670.08  , 43204.95  , 46141.1   ,\n",
       "       45556.63  , 46251.266 , 47825.133 , 46857.07  , 48098.3   ,\n",
       "       48114.47  , 48258.805 , 51067.87  , 51780.55  , 54526.723 ,\n",
       "       54674.016 , 56453.15  , 54049.656 , 48709.723 , 47403.832 ,\n",
       "       48051.914 , 45714.3   , 45529.695 , 45057.242 , 48117.164 ,\n",
       "       47798.12  , 50038.69  , 48133.625 , 48711.734 , 48213.22  ,\n",
       "       50139.473 , 50798.863 , 53723.004 , 56190.26  , 57334.445 ,\n",
       "       56843.82  , 59695.258 , 60057.094 , 56405.652 , 55534.8   ,\n",
       "       57867.42  , 57766.56  , 57609.34  , 58043.016 , 57513.793 ,\n",
       "       54184.38  , 53912.387 , 52565.805 , 51700.47  , 53318.188 ,\n",
       "       55781.316 , 55071.758 , 56614.492 , 58250.473 , 58419.477 ,\n",
       "       58246.684 , 58403.31  , 57185.45  , 57380.355 , 58227.594 ,\n",
       "       57722.51  , 56053.61  , 57001.457 , 57711.11  , 58632.918 ,\n",
       "       59154.895 , 59442.473 , 62085.75  , 62701.008 , 62756.047 ,\n",
       "       61470.273 , 60295.844 , 56627.41  , 55507.76  , 55832.59  ,\n",
       "       54108.066 , 51436.83  , 50134.984 , 50200.11  , 48325.703 ,\n",
       "       52083.97  , 54702.613 , 54532.754 , 52628.082 , 56274.004 ,\n",
       "       57420.742 , 56217.367 , 56263.633 , 53951.664 , 55896.29  ,\n",
       "       56253.48  , 56732.266 , 57653.29  , 58090.742 , 55414.64  ,\n",
       "       55654.58  , 52435.652 , 49319.574 , 49038.348 , 47970.785 ,\n",
       "       45172.85  ], dtype=float32)>"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "ff1139b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 691.45496,\n",
       " 'mse': 4852130.5,\n",
       " 'rmse': 2202.7551,\n",
       " 'mape': 21.390478,\n",
       " 'mase': 1.0700288}"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turkey_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "e41ab118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 7))\n",
    "# plot_time_series(timesteps=btc_timesteps_turkey[:split_size], values=btc_price_turkey[:split_size], label=\"Train Data\")\n",
    "offset=300\n",
    "plot_time_series(timesteps=btc_timesteps_turkey[-len(X_test):], \n",
    "                 values=btc_price_turkey[-len(y_test):], \n",
    "                 format=\"-\", \n",
    "                 label=\"Turkey Test Data\", start=offset)\n",
    "plot_time_series(timesteps=btc_timesteps_turkey[-len(X_test):],\n",
    "                 values=turkey_preds, \n",
    "                 label=\"Turkey Preds\", \n",
    "                 start=offset);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "id": "2d630cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "turkey_preds =evaluate_preds(y_test.flatten(),\n",
    "                     turkey_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "id": "1fd45599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[58788.2096789273,\n",
       " 58102.1914262342,\n",
       " 55715.5466512869,\n",
       " 56573.5554719043,\n",
       " 52147.8211869823,\n",
       " 49764.1320815975,\n",
       " 50032.6931367648,\n",
       " 47885.6252547166,\n",
       " 45604.6157536131,\n",
       " 431.44471290860304]"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btc_price_turkey[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "id": "8927ea85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 691.45496,\n",
       " 'mse': 4852130.5,\n",
       " 'rmse': 2202.7551,\n",
       " 'mape': 21.390478,\n",
       " 'mase': 1.0700288}"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "869b50d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mae': 677.44324,\n",
       " 'mse': 5111628.0,\n",
       " 'rmse': 2260.8909,\n",
       " 'mape': 21.993103,\n",
       " 'mase': 1.0483456}"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "73ac42f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/18 [==============================] - 1s 19ms/step - loss: 910.6824 - mae: 910.6824 - mse: 3137916.0000 - val_loss: 2776.4536 - val_mae: 2776.4536 - val_mse: 23987940.0000\n",
      "Epoch 2/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 297.1787 - mae: 297.1787 - mse: 409419.7188 - val_loss: 1352.5813 - val_mae: 1352.5813 - val_mse: 10314437.0000\n",
      "Epoch 3/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 232.3934 - mae: 232.3934 - mse: 258413.5781 - val_loss: 1293.6466 - val_mae: 1293.6466 - val_mse: 9488863.0000\n",
      "Epoch 4/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 218.3065 - mae: 218.3065 - mse: 245975.4531 - val_loss: 1247.4363 - val_mae: 1247.4363 - val_mse: 9231879.0000\n",
      "Epoch 5/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 210.6752 - mae: 210.6752 - mse: 231823.9688 - val_loss: 1267.1111 - val_mae: 1267.1111 - val_mse: 8889160.0000\n",
      "Epoch 6/100\n",
      "18/18 [==============================] - 0s 10ms/step - loss: 206.0157 - mae: 206.0157 - mse: 218819.6250 - val_loss: 1236.4786 - val_mae: 1236.4786 - val_mse: 9223942.0000\n",
      "Epoch 7/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 198.3103 - mae: 198.3103 - mse: 205845.7188 - val_loss: 1166.7772 - val_mae: 1166.7772 - val_mse: 8264824.5000\n",
      "Epoch 8/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 190.0773 - mae: 190.0773 - mse: 190351.8281 - val_loss: 1111.6124 - val_mae: 1111.6124 - val_mse: 8012672.0000\n",
      "Epoch 9/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 184.3965 - mae: 184.3965 - mse: 182475.0938 - val_loss: 1116.5083 - val_mae: 1116.5083 - val_mse: 7674858.5000\n",
      "Epoch 10/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 176.4091 - mae: 176.4091 - mse: 168735.1250 - val_loss: 1036.6383 - val_mae: 1036.6383 - val_mse: 7406129.5000\n",
      "Epoch 11/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 168.8605 - mae: 168.8605 - mse: 155864.8438 - val_loss: 1013.7426 - val_mae: 1013.7426 - val_mse: 7092045.5000\n",
      "Epoch 12/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 162.2441 - mae: 162.2441 - mse: 145350.0938 - val_loss: 1019.4166 - val_mae: 1019.4166 - val_mse: 6866012.0000\n",
      "Epoch 13/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 160.2905 - mae: 160.2905 - mse: 142115.1562 - val_loss: 1061.8560 - val_mae: 1061.8560 - val_mse: 6795425.0000\n",
      "Epoch 14/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 156.3292 - mae: 156.3292 - mse: 131884.4375 - val_loss: 1009.4957 - val_mae: 1009.4957 - val_mse: 6534370.5000\n",
      "Epoch 15/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 151.7147 - mae: 151.7147 - mse: 127677.1953 - val_loss: 938.3816 - val_mae: 938.3816 - val_mse: 6271646.5000\n",
      "Epoch 16/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 145.0758 - mae: 145.0758 - mse: 116960.2109 - val_loss: 921.7419 - val_mae: 921.7419 - val_mse: 6115406.0000\n",
      "Epoch 17/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 140.8877 - mae: 140.8877 - mse: 113297.2734 - val_loss: 886.8993 - val_mae: 886.8993 - val_mse: 5948467.5000\n",
      "Epoch 18/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 139.8127 - mae: 139.8127 - mse: 111032.0781 - val_loss: 854.4940 - val_mae: 854.4940 - val_mse: 5810081.0000\n",
      "Epoch 19/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 135.3759 - mae: 135.3759 - mse: 106104.7734 - val_loss: 839.4468 - val_mae: 839.4468 - val_mse: 5705379.0000\n",
      "Epoch 20/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 135.8172 - mae: 135.8172 - mse: 105934.7500 - val_loss: 863.1379 - val_mae: 863.1379 - val_mse: 5666240.5000\n",
      "Epoch 21/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 135.8043 - mae: 135.8043 - mse: 102343.9062 - val_loss: 794.5225 - val_mae: 794.5225 - val_mse: 5617963.5000\n",
      "Epoch 22/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 131.1851 - mae: 131.1851 - mse: 99599.0312 - val_loss: 817.9620 - val_mae: 817.9619 - val_mse: 5481805.0000\n",
      "Epoch 23/100\n",
      "18/18 [==============================] - 0s 11ms/step - loss: 131.9278 - mae: 131.9278 - mse: 97613.9609 - val_loss: 780.7481 - val_mae: 780.7481 - val_mse: 5417798.0000\n",
      "Epoch 24/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 128.9233 - mae: 128.9233 - mse: 96465.7812 - val_loss: 783.4708 - val_mae: 783.4708 - val_mse: 5579904.0000\n",
      "Epoch 25/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 127.3350 - mae: 127.3350 - mse: 92478.5547 - val_loss: 763.2529 - val_mae: 763.2529 - val_mse: 5443616.5000\n",
      "Epoch 26/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 127.7757 - mae: 127.7757 - mse: 93673.4688 - val_loss: 761.2580 - val_mae: 761.2580 - val_mse: 5266104.0000\n",
      "Epoch 27/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 126.8738 - mae: 126.8738 - mse: 90025.3516 - val_loss: 745.3154 - val_mae: 745.3154 - val_mse: 5243336.5000\n",
      "Epoch 28/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 122.3441 - mae: 122.3441 - mse: 87175.2266 - val_loss: 751.9295 - val_mae: 751.9295 - val_mse: 5199246.5000\n",
      "Epoch 29/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 123.2677 - mae: 123.2677 - mse: 88441.5000 - val_loss: 742.2153 - val_mae: 742.2153 - val_mse: 5175101.0000\n",
      "Epoch 30/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 127.0995 - mae: 127.0995 - mse: 90295.7734 - val_loss: 732.9399 - val_mae: 732.9399 - val_mse: 5157666.0000\n",
      "Epoch 31/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 120.1186 - mae: 120.1186 - mse: 83461.7578 - val_loss: 722.4172 - val_mae: 722.4172 - val_mse: 5164799.0000\n",
      "Epoch 32/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 118.5979 - mae: 118.5979 - mse: 84569.3828 - val_loss: 758.2532 - val_mae: 758.2532 - val_mse: 5129675.5000\n",
      "Epoch 33/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 119.1896 - mae: 119.1896 - mse: 82906.9844 - val_loss: 732.8185 - val_mae: 732.8185 - val_mse: 5092183.0000\n",
      "Epoch 34/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 118.9559 - mae: 118.9559 - mse: 84816.7734 - val_loss: 709.7493 - val_mae: 709.7493 - val_mse: 5110785.0000\n",
      "Epoch 35/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 119.9886 - mae: 119.9886 - mse: 85835.5000 - val_loss: 706.8917 - val_mae: 706.8917 - val_mse: 5073267.5000\n",
      "Epoch 36/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 121.6335 - mae: 121.6335 - mse: 83174.4062 - val_loss: 708.4401 - val_mae: 708.4401 - val_mse: 5138092.5000\n",
      "Epoch 37/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 119.9638 - mae: 119.9638 - mse: 85104.0000 - val_loss: 699.3072 - val_mae: 699.3072 - val_mse: 5061000.5000\n",
      "Epoch 38/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.1073 - mae: 116.1073 - mse: 81056.7109 - val_loss: 700.7713 - val_mae: 700.7713 - val_mse: 5020141.5000\n",
      "Epoch 39/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.7868 - mae: 116.7868 - mse: 81999.0625 - val_loss: 694.9230 - val_mae: 694.9230 - val_mse: 5060376.0000\n",
      "Epoch 40/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.7297 - mae: 115.7297 - mse: 78397.7266 - val_loss: 729.2144 - val_mae: 729.2144 - val_mse: 5245728.5000\n",
      "Epoch 41/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 115.7179 - mae: 115.7179 - mse: 80151.2812 - val_loss: 690.2816 - val_mae: 690.2816 - val_mse: 5052696.0000\n",
      "Epoch 42/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 123.5384 - mae: 123.5384 - mse: 85416.9531 - val_loss: 686.4817 - val_mae: 686.4817 - val_mse: 5009661.0000\n",
      "Epoch 43/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.6975 - mae: 114.6975 - mse: 77927.4219 - val_loss: 720.4423 - val_mae: 720.4423 - val_mse: 5200439.5000\n",
      "Epoch 44/100\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 115.2838 - mae: 115.2838 - mse: 78029.4766 - val_loss: 683.9165 - val_mae: 683.9165 - val_mse: 5027638.0000\n",
      "Epoch 45/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.9140 - mae: 112.9140 - mse: 78127.7734 - val_loss: 684.7210 - val_mae: 684.7210 - val_mse: 5045208.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.9509 - mae: 113.9509 - mse: 76578.1953 - val_loss: 687.9102 - val_mae: 687.9102 - val_mse: 4960832.5000\n",
      "Epoch 47/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 113.4702 - mae: 113.4702 - mse: 77825.2812 - val_loss: 738.5416 - val_mae: 738.5416 - val_mse: 4984560.5000\n",
      "Epoch 48/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.3943 - mae: 112.3943 - mse: 76340.1797 - val_loss: 715.2219 - val_mae: 715.2219 - val_mse: 4946004.0000\n",
      "Epoch 49/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 113.9316 - mae: 113.9316 - mse: 77226.8672 - val_loss: 731.7644 - val_mae: 731.7644 - val_mse: 4965111.5000\n",
      "Epoch 50/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 118.9512 - mae: 118.9512 - mse: 79947.6562 - val_loss: 751.3452 - val_mae: 751.3452 - val_mse: 5303964.5000\n",
      "Epoch 51/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.0778 - mae: 116.0778 - mse: 77634.7266 - val_loss: 677.5536 - val_mae: 677.5536 - val_mse: 4932898.0000\n",
      "Epoch 52/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 116.9659 - mae: 116.9659 - mse: 79260.0781 - val_loss: 755.7087 - val_mae: 755.7087 - val_mse: 5314809.0000\n",
      "Epoch 53/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 114.1033 - mae: 114.1033 - mse: 76535.4766 - val_loss: 698.4045 - val_mae: 698.4045 - val_mse: 4915066.5000\n",
      "Epoch 54/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 111.7807 - mae: 111.7807 - mse: 75114.7344 - val_loss: 668.7816 - val_mae: 668.7816 - val_mse: 4938238.0000\n",
      "Epoch 55/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.2144 - mae: 112.2144 - mse: 76724.2109 - val_loss: 683.2570 - val_mae: 683.2570 - val_mse: 4909182.0000\n",
      "Epoch 56/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.8749 - mae: 109.8749 - mse: 74096.8828 - val_loss: 886.1785 - val_mae: 886.1785 - val_mse: 5823752.5000\n",
      "Epoch 57/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 123.6319 - mae: 123.6319 - mse: 84611.6719 - val_loss: 667.1531 - val_mae: 667.1531 - val_mse: 4968034.0000\n",
      "Epoch 58/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.7959 - mae: 114.7959 - mse: 75339.1953 - val_loss: 676.1812 - val_mae: 676.1812 - val_mse: 4899215.0000\n",
      "Epoch 59/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.2444 - mae: 110.2444 - mse: 74432.6406 - val_loss: 695.7468 - val_mae: 695.7468 - val_mse: 5080363.0000\n",
      "Epoch 60/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 112.4460 - mae: 112.4460 - mse: 76201.0938 - val_loss: 698.1436 - val_mae: 698.1436 - val_mse: 4899723.0000\n",
      "Epoch 61/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 110.9536 - mae: 110.9536 - mse: 74753.6094 - val_loss: 663.3470 - val_mae: 663.3470 - val_mse: 4905839.5000\n",
      "Epoch 62/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.0299 - mae: 109.0299 - mse: 72875.6797 - val_loss: 663.7130 - val_mae: 663.7130 - val_mse: 4950512.5000\n",
      "Epoch 63/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 110.5041 - mae: 110.5041 - mse: 74021.5781 - val_loss: 673.3375 - val_mae: 673.3375 - val_mse: 4887244.5000\n",
      "Epoch 64/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 109.6684 - mae: 109.6684 - mse: 73172.7734 - val_loss: 694.5554 - val_mae: 694.5554 - val_mse: 4894707.0000\n",
      "Epoch 65/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 110.1538 - mae: 110.1538 - mse: 74146.5859 - val_loss: 666.4135 - val_mae: 666.4135 - val_mse: 4888583.5000\n",
      "Epoch 66/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.2730 - mae: 109.2730 - mse: 73038.9609 - val_loss: 670.9163 - val_mae: 670.9163 - val_mse: 4883211.5000\n",
      "Epoch 67/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 109.3796 - mae: 109.3796 - mse: 72717.4531 - val_loss: 710.8259 - val_mae: 710.8259 - val_mse: 5135105.0000\n",
      "Epoch 68/100\n",
      "18/18 [==============================] - 0s 4ms/step - loss: 111.5883 - mae: 111.5883 - mse: 72473.4062 - val_loss: 661.1478 - val_mae: 661.1478 - val_mse: 4952065.0000\n",
      "Epoch 69/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 116.9270 - mae: 116.9270 - mse: 75298.8281 - val_loss: 807.3711 - val_mae: 807.3711 - val_mse: 5072754.0000\n",
      "Epoch 70/100\n",
      "18/18 [==============================] - 0s 5ms/step - loss: 124.5775 - mae: 124.5775 - mse: 79777.6406 - val_loss: 684.9165 - val_mae: 684.9165 - val_mse: 4892255.5000\n",
      "Epoch 71/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 109.7607 - mae: 109.7607 - mse: 72084.8047 - val_loss: 666.9169 - val_mae: 666.9169 - val_mse: 4983686.5000\n",
      "Epoch 72/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 111.9087 - mae: 111.9087 - mse: 74138.6406 - val_loss: 658.1334 - val_mae: 658.1334 - val_mse: 4935735.5000\n",
      "Epoch 73/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 111.7452 - mae: 111.7452 - mse: 73440.6953 - val_loss: 656.0873 - val_mae: 656.0873 - val_mse: 4917179.5000\n",
      "Epoch 74/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 113.3013 - mae: 113.3013 - mse: 75687.0781 - val_loss: 669.6256 - val_mae: 669.6256 - val_mse: 4986247.5000\n",
      "Epoch 75/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 112.0791 - mae: 112.0791 - mse: 73375.0391 - val_loss: 680.1508 - val_mae: 680.1508 - val_mse: 4866679.0000\n",
      "Epoch 76/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 114.2171 - mae: 114.2171 - mse: 76224.7266 - val_loss: 690.0253 - val_mae: 690.0253 - val_mse: 5047295.5000\n",
      "Epoch 77/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 108.9265 - mae: 108.9265 - mse: 71389.7656 - val_loss: 660.9926 - val_mae: 660.9926 - val_mse: 4863447.0000\n",
      "Epoch 78/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 113.4908 - mae: 113.4908 - mse: 72301.5703 - val_loss: 702.5338 - val_mae: 702.5338 - val_mse: 5090421.0000\n",
      "Epoch 79/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 113.7240 - mae: 113.7240 - mse: 76889.0938 - val_loss: 655.6396 - val_mae: 655.6396 - val_mse: 4912998.5000\n",
      "Epoch 80/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.6579 - mae: 108.6579 - mse: 72702.9531 - val_loss: 671.7449 - val_mae: 671.7449 - val_mse: 4851728.0000\n",
      "Epoch 81/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.0989 - mae: 109.0989 - mse: 72456.0234 - val_loss: 658.9921 - val_mae: 658.9921 - val_mse: 4853260.5000\n",
      "Epoch 82/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 119.3973 - mae: 119.3973 - mse: 80247.8906 - val_loss: 652.6486 - val_mae: 652.6486 - val_mse: 4894741.0000\n",
      "Epoch 83/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 114.3968 - mae: 114.3968 - mse: 75845.8906 - val_loss: 799.4191 - val_mae: 799.4191 - val_mse: 5430473.0000\n",
      "Epoch 84/100\n",
      "18/18 [==============================] - 0s 9ms/step - loss: 116.6947 - mae: 116.6947 - mse: 75681.2812 - val_loss: 676.0466 - val_mae: 676.0466 - val_mse: 5002510.0000\n",
      "Epoch 85/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.4331 - mae: 109.4331 - mse: 72368.5781 - val_loss: 661.9835 - val_mae: 661.9835 - val_mse: 4852441.0000\n",
      "Epoch 86/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 107.9836 - mae: 107.9836 - mse: 70896.0703 - val_loss: 672.5440 - val_mae: 672.5440 - val_mse: 4849198.0000\n",
      "Epoch 87/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 106.7076 - mae: 106.7076 - mse: 69672.2500 - val_loss: 674.9368 - val_mae: 674.9368 - val_mse: 4991440.5000\n",
      "Epoch 88/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 111.0564 - mae: 111.0564 - mse: 72850.4844 - val_loss: 660.0588 - val_mae: 660.0588 - val_mse: 4845709.5000\n",
      "Epoch 89/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 108.4222 - mae: 108.4222 - mse: 70065.4219 - val_loss: 653.8290 - val_mae: 653.8290 - val_mse: 4847693.5000\n",
      "Epoch 90/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 108.1306 - mae: 108.1306 - mse: 68231.3672 - val_loss: 650.9099 - val_mae: 650.9099 - val_mse: 4856329.5000\n",
      "Epoch 91/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 8ms/step - loss: 112.3989 - mae: 112.3989 - mse: 72970.2578 - val_loss: 650.5928 - val_mae: 650.5928 - val_mse: 4883779.0000\n",
      "Epoch 92/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 109.6363 - mae: 109.6363 - mse: 72420.8203 - val_loss: 680.1230 - val_mae: 680.1231 - val_mse: 5001032.5000\n",
      "Epoch 93/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 115.1294 - mae: 115.1294 - mse: 73536.8594 - val_loss: 681.7811 - val_mae: 681.7811 - val_mse: 5007527.0000\n",
      "Epoch 94/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 115.5698 - mae: 115.5698 - mse: 75846.0000 - val_loss: 724.5936 - val_mae: 724.5937 - val_mse: 4891506.0000\n",
      "Epoch 95/100\n",
      "18/18 [==============================] - 0s 7ms/step - loss: 109.8529 - mae: 109.8529 - mse: 69962.7734 - val_loss: 648.0812 - val_mae: 648.0812 - val_mse: 4865130.5000\n",
      "Epoch 96/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 117.5845 - mae: 117.5845 - mse: 75650.0234 - val_loss: 794.1907 - val_mae: 794.1907 - val_mse: 5398478.0000\n",
      "Epoch 97/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.4868 - mae: 112.4868 - mse: 75097.3828 - val_loss: 652.2084 - val_mae: 652.2084 - val_mse: 4837578.5000\n",
      "Epoch 98/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 107.6283 - mae: 107.6283 - mse: 71172.9531 - val_loss: 659.7683 - val_mae: 659.7683 - val_mse: 4935878.0000\n",
      "Epoch 99/100\n",
      "18/18 [==============================] - 0s 8ms/step - loss: 107.2824 - mae: 107.2824 - mse: 70892.9375 - val_loss: 652.7236 - val_mae: 652.7236 - val_mse: 4833385.5000\n",
      "Epoch 100/100\n",
      "18/18 [==============================] - 0s 6ms/step - loss: 112.5064 - mae: 112.5064 - mse: 71247.1328 - val_loss: 691.4550 - val_mae: 691.4550 - val_mse: 4852131.0000\n",
      "Wall time: 12.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d72dac9070>"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_10.fit(x=X_train,\n",
    "            y=y_train,\n",
    "             batch_size=128,\n",
    "            validation_data=(X_test,y_test),\n",
    "            epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b188e39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a11c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "2bf73da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.random.randint(1,10,(1,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "df575037",
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.array([[5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "833b1cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10,), array([[5]]))"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4d823e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 7, 1, 1, 9, 7, 8, 7, 1, 5, 5])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.append(t,d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "cf04a456",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 7 and the array at index 1 has size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-2dfbd227b572>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbitcoin_prices_nbeats\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Price\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda4\\lib\\site-packages\\numpy\\core\\overrides.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 7 and the array at index 1 has size 1"
     ]
    }
   ],
   "source": [
    "np.concatenate((np.expand_dims(bitcoin_prices_nbeats[\"Price\"][-7:].to_numpy(),axis=0),[[5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4efd1e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56573.5554719 , 52147.82118698, 49764.1320816 , 50032.69313676,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_nbeats[\"Price\"][-7:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "87bd383a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56573.5554719043,\n",
       " 52147.8211869823,\n",
       " 49764.1320815975,\n",
       " 50032.6931367648,\n",
       " 47885.6252547166,\n",
       " 45604.6157536131,\n",
       " 43144.4712908603]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_nbeats[\"Price\"][-7:].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "027eb95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = bitcoin_prices_nbeats[\"Price\"][-7:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "06b91ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56573.5554719 , 52147.82118698, 49764.1320816 , 50032.69313676,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "35ecd0f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       "array([[56573.555, 52147.82 , 49764.133, 50032.69 , 47885.625, 45604.617,\n",
       "        43144.473]], dtype=float32)>"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.expand_dims(np.array(future,dtype='float32'),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8606287f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56573.5554719 , 52147.82118698, 49764.1320816 , 50032.69313676,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "a96e784e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[50441.51]], dtype=float32)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_9.predict(tf.expand_dims(future,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f8acb33e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.65735555e+04, 5.21478212e+04, 4.97641321e+04, 5.00326931e+04,\n",
       "       4.78856253e+04, 4.56046158e+04, 4.31444713e+04, 5.00000000e+00])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7ee22ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56383.27,\n",
       " 51542.98,\n",
       " 50366.848,\n",
       " 49593.688,\n",
       " 46863.066,\n",
       " 45619.29,\n",
       " 45473.23,\n",
       " 56083.08,\n",
       " 51286.246,\n",
       " 50778.07,\n",
       " 48874.223,\n",
       " 46199.145,\n",
       " 45938.523,\n",
       " 47372.285]"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "2436f5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56573.5554719043,\n",
       " 52147.8211869823,\n",
       " 49764.1320815975,\n",
       " 50032.6931367648,\n",
       " 47885.6252547166,\n",
       " 45604.6157536131,\n",
       " 43144.4712908603,\n",
       " 5]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "64f4eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "future = bitcoin_prices_nbeats[\"Price\"][-7:].to_list()\n",
    "hasil = []\n",
    "for index,i in enumerate(range(30)):  \n",
    "\n",
    "    pred= model_9.predict(tf.expand_dims(np.array(future,dtype='float32'),axis=0))\n",
    "    future.append(pred.flatten()[0])\n",
    "    hasil.append(pred.flatten()[0])\n",
    "   # print(future)\n",
    "    future = future[-7:]\n",
    "  #  print(f\"bag 2:{future}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "265c00f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56573.5554719 , 52147.82118698, 49764.1320816 , 50032.69313676,\n",
       "       47885.62525472, 45604.61575361, 43144.47129086])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin_prices_nbeats[\"Price\"][-7:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "408e1d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56383.27,\n",
       " 51542.98,\n",
       " 50366.848,\n",
       " 49593.688,\n",
       " 46863.066,\n",
       " 45619.29,\n",
       " 45473.23,\n",
       " 56083.08,\n",
       " 51286.246,\n",
       " 50778.07,\n",
       " 48874.223,\n",
       " 46199.145,\n",
       " 45938.523,\n",
       " 47372.285]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future_forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "cc5bd689",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56383.27,\n",
       " 51542.98,\n",
       " 50366.848,\n",
       " 49593.688,\n",
       " 46863.066,\n",
       " 45619.29,\n",
       " 45473.23,\n",
       " 56083.08,\n",
       " 51286.246,\n",
       " 50778.07,\n",
       " 48874.223,\n",
       " 46199.145,\n",
       " 45938.523,\n",
       " 47372.285,\n",
       " 55701.46,\n",
       " 51206.2,\n",
       " 50937.137,\n",
       " 48067.402,\n",
       " 45906.25,\n",
       " 46431.477,\n",
       " 48991.45,\n",
       " 55292.043,\n",
       " 51229.91,\n",
       " 50805.996,\n",
       " 47302.207,\n",
       " 45916.824,\n",
       " 47059.477,\n",
       " 50372.91,\n",
       " 54884.777,\n",
       " 51275.86]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "98c7015f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[56383.27, 51542.98, 50366.848, 49593.688, 46863.066, 45619.29, 45473.23]"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0574ce5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'median'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10840/3310819541.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mensemble_preds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy_ops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m         np_config.enable_numpy_behavior()\"\"\".format(type(self).__name__, name))\n\u001b[1;32m--> 513\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    514\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    515\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'median'"
     ]
    }
   ],
   "source": [
    "ensemble_preds.median(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd95fef5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032e6d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c75ffd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c070c49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "26c81d77",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int32, numpy=array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10])>,\n",
       " <tf.Tensor: shape=(10,), dtype=int32, numpy=array([10, 12, 14, 16, 18, 20, 22, 24, 26, 28])>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subtacted,added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "abebf9f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "048519ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros(shape=(7)) +np.ones((7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74db2b0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=array([[0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((1,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "5dccb39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tets=tf.keras.layers.Input(shape=(INPUT_SIZE),name=f'block_input_{i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "85560441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6, 7]])>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fd3ad28b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7) dtype=float32 (created by layer 'block_input_28')>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "34236078",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input tensor cannot be reached given provided output tensors. Please make sure the tensor KerasTensor(type_spec=TensorSpec(shape=(None, 7), dtype=tf.float32, name='stack_input_0_block_3'), name='stack_input_0_block_3', description=\"created by layer 'stack_input_0_block_3'\") is included in the model inputs when building functional model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    627\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    628\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 629\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    630\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\envs\\tf-latest3\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    143\u001b[0m       if not all([functional_utils.is_input_keras_tensor(t)\n\u001b[0;32m    144\u001b[0m                   for t in tf.nest.flatten(inputs)]):\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone_graph_nodes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\envs\\tf-latest3\\lib\\site-packages\\keras\\engine\\functional_utils.py\u001b[0m in \u001b[0;36mclone_graph_nodes\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m   \"\"\"\n\u001b[1;32m--> 146\u001b[1;33m   \u001b[0mnodes_to_clone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_nodes_by_inputs_and_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m   \u001b[0mcloned_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m   \u001b[0mcloned_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda4\\envs\\tf-latest3\\lib\\site-packages\\keras\\engine\\functional_utils.py\u001b[0m in \u001b[0;36mfind_nodes_by_inputs_and_outputs\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    111\u001b[0m       \u001b[1;31m# input in the user-specified inputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0minbound_node\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         raise ValueError('Found input tensor cannot be reached given provided '\n\u001b[0m\u001b[0;32m    114\u001b[0m                          \u001b[1;34m'output tensors. Please make sure the tensor {} is '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m                          \u001b[1;34m'included in the model inputs when building '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input tensor cannot be reached given provided output tensors. Please make sure the tensor KerasTensor(type_spec=TensorSpec(shape=(None, 7), dtype=tf.float32, name='stack_input_0_block_3'), name='stack_input_0_block_3', description=\"created by layer 'stack_input_0_block_3'\") is included in the model inputs when building functional model."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tf.random.set_seed(42)\n",
    "#1. setip and instance of NBeatsBlock\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2. Create input to stack\n",
    "\n",
    "for j,_ in enumerate(range(N_STACKS-1)):\n",
    "    if j==0:\n",
    "        stack_input = tf.keras.layers.Input(shape=(INPUT_SIZE),name=f'stack_input_{j}_block_{i}')\n",
    "    else:\n",
    "        stack_input = residuals\n",
    "        \n",
    "    #4. Create stacks of block layers\n",
    "    for i, _ in enumerate(range(4)):\n",
    "        #5 use the n beats block to caclulate \n",
    "        if i==0 and j==0 :\n",
    "            nbeats_block_layer = NBeatsBlock(input_size = INPUT_SIZE,\n",
    "                                  theta_size = THETA_SIZE,\n",
    "                                  horizon = HORIZON,\n",
    "                                  n_neurons = N_NEURONS,\n",
    "                                  n_layers = N_LAYERS,\n",
    "                                name='initialBlock')\n",
    "\n",
    "            # 2. Create input to stack\n",
    "            \n",
    "\n",
    "            # 3. Create initial backcast and forecast input (backc=wards pred + horzion pred)\n",
    "            backcast, forecast = nbeats_block_layer(stack_input)\n",
    "            \n",
    "            #residuals, forecast = nbeats_block_layer(stack_input)\n",
    "            residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\") \n",
    "#         elif i==0 and j!=0:\n",
    "#             nbeats_block_layer = NBeatsBlock(input_size = INPUT_SIZE,\n",
    "#                                   theta_size = THETA_SIZE,\n",
    "#                                   horizon = HORIZON,\n",
    "#                                   n_neurons = N_NEURONS,\n",
    "#                                   n_layers = N_LAYERS,\n",
    "#                                 name='initialBlock')\n",
    "\n",
    "#             # 2. Create input to stack\n",
    "#             stack_input = tf.keras.layers.Input(shape=(INPUT_SIZE),name=f'stack_input_{j}_block_{i}')\n",
    "\n",
    "#             # 3. Create initial backcast and forecast input (backc=wards pred + horzion pred)\n",
    "#             backcast, forecast = nbeats_block_layer(residuals)\n",
    "            \n",
    "#             #residuals, forecast = nbeats_block_layer(stack_input)\n",
    "#             residuals = layers.subtract([stack_input, backcast], name=f\"subtract_00\") \n",
    "        else:\n",
    "            \n",
    "       \n",
    "            backcast,block_forecast = NBeatsBlock(input_size = INPUT_SIZE,\n",
    "                                              theta_size = THETA_SIZE,\n",
    "                                              horizon = HORIZON,\n",
    "                                              n_neurons = N_NEURONS,\n",
    "                                              n_layers = N_LAYERS,\n",
    "                                            name=f'NBeatsBlock_{i}')(residuals)\n",
    "            residuals = layers.subtract([residuals,backcast],name=f'subtract_{i}')\n",
    "            forecast = layers.add([forecast,block_forecast],name=f\"add_{i}\")\n",
    "    \n",
    "    forecast_global = layers.add([forecast,forecast_global],name='forecast_global')\n",
    "\n",
    "#6. Put the stack model together\n",
    "\n",
    "model_custom_1 = tf.keras.Model(inputs=stack_input,outputs=forecast_global,name='model_7_beats')\n",
    "\n",
    "#7 compile model\n",
    "\n",
    "model_custom_1.compile(loss='mae',optimizer='adam',metrics=['mae'])\n",
    "\n",
    "model_custom_1.fit(train_dataset,\n",
    "           epochs=N_EPOCHS,\n",
    "           validation_data=test_dataset,\n",
    "           callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=200,restore_best_weights=True),\n",
    "                     tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',patience=100,verbose=1)])\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df8571b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NBeatsBlock(tf.keras.layers.Layer):\n",
    "    def __init__(self,\n",
    "                input_size:int,\n",
    "                theta_size:int,\n",
    "                horizon:int,\n",
    "                n_neurons:int,\n",
    "                n_layers:int,\n",
    "                **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.input_size = input_size\n",
    "        self.theta_size = theta_size\n",
    "        self.horizon = horizon\n",
    "        self.n_neurons = n_neurons\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Block contatins stack of 4 full connect layers each relu activation\n",
    "        \n",
    "        self.hidden = [tf.keras.layers.Dense(n_neurons,activation='relu') for i in range(n_layers)]\n",
    "        #output of block is theta layer iwht linear activation\n",
    "        self.theta_layer = tf.keras.layers.Dense(theta_size,activation='linear',name='theta')\n",
    "        \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"arg1\": self.arg1,\n",
    "            \"arg2\": self.arg2,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def call(self,inputs):\n",
    "        x = inputs\n",
    "  \n",
    "        for _ in range(N_STACKS):\n",
    "            inputs = x\n",
    "        \n",
    "            for _ in range(4):\n",
    "              #  inputs = x\n",
    "                for layer in self.hidden:\n",
    "                    x = layer(x)\n",
    "                theta = self.theta_layer(x)\n",
    "                # output the backcast and the forecast from theta\n",
    "\n",
    "                backcast, forecast = theta[:, :self.input_size], theta[:,-self.horizon:]\n",
    "                \n",
    "                x = tf.keras.layers.subtract([tf.cast(inputs[:,:WINDOW_SIZE],dtype=tf.float32),backcast])\n",
    "               \n",
    "                forecast = tf.keras.layers.add([forecast,tf.zeros((1,HORIZON),dtype=tf.float32)])\n",
    "            \n",
    "            global_forecast = tf.keras.layers.add([forecast,tf.zeros((1,HORIZON),dtype=tf.float32)])\n",
    "            \n",
    "        return global_forecast\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d1511e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n",
      "3/3 [==============================] - 21s 2s/step - loss: 17687.0371 - mae: 17687.0371 - mse: 994774848.0000 - val_loss: 7590.6626 - val_mae: 7590.6626 - val_mse: 104831224.0000 - lr: 0.0010\n",
      "Epoch 2/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 8041.6763 - mae: 8041.6763 - mse: 786662208.0000 - val_loss: 9993.0186 - val_mae: 9993.0186 - val_mse: 176168848.0000 - lr: 0.0010\n",
      "Epoch 3/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 2821.2029 - mae: 2821.2029 - mse: 20461996.0000 - val_loss: 17931.6738 - val_mae: 17931.6738 - val_mse: 566318144.0000 - lr: 0.0010\n",
      "Epoch 4/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 1871.4103 - mae: 1871.4103 - mse: 9342614.0000 - val_loss: 10376.2939 - val_mae: 10376.2939 - val_mse: 191614320.0000 - lr: 0.0010\n",
      "Epoch 5/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 2202.4814 - mae: 2202.4814 - mse: 12167376.0000 - val_loss: 5795.1167 - val_mae: 5795.1167 - val_mse: 62684992.0000 - lr: 0.0010\n",
      "Epoch 6/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 1676.1917 - mae: 1676.1917 - mse: 8004678.0000 - val_loss: 2889.5686 - val_mae: 2889.5686 - val_mse: 18509966.0000 - lr: 0.0010\n",
      "Epoch 7/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 384.6613 - mae: 384.6613 - mse: 590035.3750 - val_loss: 8446.9375 - val_mae: 8446.9375 - val_mse: 136775168.0000 - lr: 0.0010\n",
      "Epoch 8/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 2655.1873 - mae: 2655.1873 - mse: 21043366.0000 - val_loss: 11857.4941 - val_mae: 11857.4941 - val_mse: 248901728.0000 - lr: 0.0010\n",
      "Epoch 9/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 2590.6929 - mae: 2590.6929 - mse: 17094034.0000 - val_loss: 18718.5723 - val_mae: 18718.5723 - val_mse: 617008384.0000 - lr: 0.0010\n",
      "Epoch 10/5000\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 3002.0820 - mae: 3002.0820 - mse: 21924840.0000 - val_loss: 19347.4668 - val_mae: 19347.4668 - val_mse: 659121280.0000 - lr: 0.0010\n",
      "Epoch 11/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 3045.3167 - mae: 3045.3167 - mse: 22481876.0000 - val_loss: 19256.8828 - val_mae: 19256.8828 - val_mse: 653002496.0000 - lr: 0.0010\n",
      "Epoch 12/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 2991.5781 - mae: 2991.5781 - mse: 21633664.0000 - val_loss: 18172.1289 - val_mae: 18172.1289 - val_mse: 581649792.0000 - lr: 0.0010\n",
      "Epoch 13/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 2619.1450 - mae: 2619.1450 - mse: 16312134.0000 - val_loss: 8171.4121 - val_mae: 8171.4121 - val_mse: 120117936.0000 - lr: 0.0010\n",
      "Epoch 14/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 1406.8481 - mae: 1406.8481 - mse: 5368695.0000 - val_loss: 2567.4971 - val_mae: 2567.4971 - val_mse: 14993711.0000 - lr: 0.0010\n",
      "Epoch 15/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 353.9519 - mae: 353.9519 - mse: 497866.4688 - val_loss: 7416.0991 - val_mae: 7416.0991 - val_mse: 105870600.0000 - lr: 0.0010\n",
      "Epoch 16/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 2261.6660 - mae: 2261.6660 - mse: 15001670.0000 - val_loss: 10405.3252 - val_mae: 10405.3252 - val_mse: 192104464.0000 - lr: 0.0010\n",
      "Epoch 17/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 2386.7109 - mae: 2386.7109 - mse: 14632827.0000 - val_loss: 17688.5020 - val_mae: 17688.5020 - val_mse: 551114944.0000 - lr: 0.0010\n",
      "Epoch 18/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 2855.6733 - mae: 2855.6733 - mse: 19878316.0000 - val_loss: 18520.2832 - val_mae: 18520.2832 - val_mse: 604072192.0000 - lr: 0.0010\n",
      "Epoch 19/5000\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 2913.8748 - mae: 2913.8748 - mse: 20588744.0000 - val_loss: 18260.5664 - val_mae: 18260.5664 - val_mse: 587317504.0000 - lr: 0.0010\n",
      "Epoch 20/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 2791.0034 - mae: 2791.0032 - mse: 18772616.0000 - val_loss: 15607.8486 - val_mae: 15607.8486 - val_mse: 429696448.0000 - lr: 0.0010\n",
      "Epoch 21/5000\n",
      "3/3 [==============================] - 1s 178ms/step - loss: 1643.9716 - mae: 1643.9716 - mse: 6937934.0000 - val_loss: 78930.7891 - val_mae: 78930.7891 - val_mse: 11211194368.0000 - lr: 0.0010\n",
      "Epoch 22/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 25018.8887 - mae: 25018.8887 - mse: 2041989760.0000 - val_loss: 15485.6797 - val_mae: 15485.6797 - val_mse: 423010496.0000 - lr: 0.0010\n",
      "Epoch 23/5000\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 2936.0664 - mae: 2936.0664 - mse: 21463030.0000 - val_loss: 19696.8848 - val_mae: 19696.8848 - val_mse: 683115520.0000 - lr: 0.0010\n",
      "Epoch 24/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 3109.0232 - mae: 3109.0234 - mse: 23442244.0000 - val_loss: 19790.5000 - val_mae: 19790.5000 - val_mse: 689628864.0000 - lr: 0.0010\n",
      "Epoch 25/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 3094.1646 - mae: 3094.1646 - mse: 23166970.0000 - val_loss: 19169.5410 - val_mae: 19169.5410 - val_mse: 647077376.0000 - lr: 0.0010\n",
      "Epoch 26/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 2885.2769 - mae: 2885.2769 - mse: 19958496.0000 - val_loss: 14302.3369 - val_mae: 14302.3369 - val_mse: 360476192.0000 - lr: 0.0010\n",
      "Epoch 27/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 1909.2599 - mae: 1909.2599 - mse: 13932990.0000 - val_loss: 10060.6289 - val_mae: 10060.6289 - val_mse: 178829328.0000 - lr: 0.0010\n",
      "Epoch 28/5000\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 2608.3337 - mae: 2608.3337 - mse: 17568058.0000 - val_loss: 19063.8477 - val_mae: 19063.8477 - val_mse: 639873792.0000 - lr: 0.0010\n",
      "Epoch 29/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 3052.4390 - mae: 3052.4390 - mse: 22649450.0000 - val_loss: 19642.5332 - val_mae: 19642.5332 - val_mse: 679308800.0000 - lr: 0.0010\n",
      "Epoch 30/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 3092.4590 - mae: 3092.4590 - mse: 23178770.0000 - val_loss: 19651.6074 - val_mae: 19651.6074 - val_mse: 679973568.0000 - lr: 0.0010\n",
      "Epoch 31/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 3081.1084 - mae: 3081.1084 - mse: 22994174.0000 - val_loss: 19474.3535 - val_mae: 19474.3535 - val_mse: 667779008.0000 - lr: 0.0010\n",
      "Epoch 32/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 3041.7056 - mae: 3041.7056 - mse: 22393898.0000 - val_loss: 19052.8438 - val_mae: 19052.8438 - val_mse: 639209728.0000 - lr: 0.0010\n",
      "Epoch 33/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 2944.7288 - mae: 2944.7288 - mse: 20939632.0000 - val_loss: 17821.6934 - val_mae: 17821.6934 - val_mse: 559364160.0000 - lr: 0.0010\n",
      "Epoch 34/5000\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 2608.9504 - mae: 2608.9504 - mse: 16237209.0000 - val_loss: 11276.2754 - val_mae: 11276.2754 - val_mse: 224615600.0000 - lr: 0.0010\n",
      "Epoch 35/5000\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 1797.5304 - mae: 1797.5304 - mse: 25187900.0000 - val_loss: 5612.1914 - val_mae: 5612.1914 - val_mse: 56961804.0000 - lr: 0.0010\n",
      "Epoch 36/5000\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 2204.9980 - mae: 2204.9980 - mse: 13078673.0000 - val_loss: 17631.6602 - val_mae: 17631.6602 - val_mse: 547459264.0000 - lr: 0.0010\n",
      "Epoch 37/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 2877.2556 - mae: 2877.2556 - mse: 20215074.0000 - val_loss: 18828.4805 - val_mae: 18828.4805 - val_mse: 624212672.0000 - lr: 0.0010\n",
      "Epoch 38/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 2975.0735 - mae: 2975.0735 - mse: 21473264.0000 - val_loss: 18878.2773 - val_mae: 18878.2773 - val_mse: 627526208.0000 - lr: 0.0010\n",
      "Epoch 39/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 2947.0845 - mae: 2947.0845 - mse: 21021870.0000 - val_loss: 18353.9648 - val_mae: 18353.9648 - val_mse: 593216256.0000 - lr: 0.0010\n",
      "Epoch 40/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 2825.2041 - mae: 2825.2041 - mse: 19269436.0000 - val_loss: 17022.9199 - val_mae: 17022.9199 - val_mse: 510404672.0000 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 2522.9102 - mae: 2522.9102 - mse: 15248395.0000 - val_loss: 12916.8779 - val_mae: 12916.8779 - val_mse: 294250208.0000 - lr: 0.0010\n",
      "Epoch 42/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 1263.4303 - mae: 1263.4303 - mse: 4024796.5000 - val_loss: 26547.1621 - val_mae: 26547.1621 - val_mse: 1250869632.0000 - lr: 0.0010\n",
      "Epoch 43/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 10892.8008 - mae: 10892.8008 - mse: 355258208.0000 - val_loss: 9804.1260 - val_mae: 9804.1260 - val_mse: 169858176.0000 - lr: 0.0010\n",
      "Epoch 44/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 2487.4028 - mae: 2487.4028 - mse: 15981406.0000 - val_loss: 18543.1719 - val_mae: 18543.1719 - val_mse: 605420608.0000 - lr: 0.0010\n",
      "Epoch 45/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 3004.8994 - mae: 3004.8994 - mse: 22007910.0000 - val_loss: 19580.4297 - val_mae: 19580.4297 - val_mse: 675012352.0000 - lr: 0.0010\n",
      "Epoch 46/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 3097.8867 - mae: 3097.8867 - mse: 23285568.0000 - val_loss: 19799.7109 - val_mae: 19799.7109 - val_mse: 690216384.0000 - lr: 0.0010\n",
      "Epoch 47/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 3111.6602 - mae: 3111.6602 - mse: 23459984.0000 - val_loss: 19726.1016 - val_mae: 19726.1016 - val_mse: 685103168.0000 - lr: 0.0010\n",
      "Epoch 48/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 3087.3125 - mae: 3087.3125 - mse: 23075552.0000 - val_loss: 19401.2090 - val_mae: 19401.2090 - val_mse: 662746816.0000 - lr: 0.0010\n",
      "Epoch 49/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 3018.1724 - mae: 3018.1724 - mse: 22028722.0000 - val_loss: 18722.1367 - val_mae: 18722.1367 - val_mse: 617193536.0000 - lr: 0.0010\n",
      "Epoch 50/5000\n",
      "3/3 [==============================] - 1s 179ms/step - loss: 2871.4475 - mae: 2871.4475 - mse: 19882020.0000 - val_loss: 17094.2500 - val_mae: 17094.2500 - val_mse: 514647264.0000 - lr: 0.0010\n",
      "Epoch 51/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 2302.4275 - mae: 2302.4275 - mse: 12487054.0000 - val_loss: 11097.6992 - val_mae: 11097.6992 - val_mse: 232132176.0000 - lr: 0.0010\n",
      "Epoch 52/5000\n",
      "3/3 [==============================] - 1s 180ms/step - loss: 7018.8906 - mae: 7018.8906 - mse: 159590048.0000 - val_loss: 10435.9678 - val_mae: 10435.9678 - val_mse: 192954816.0000 - lr: 0.0010\n",
      "Epoch 53/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 2030.2653 - mae: 2030.2653 - mse: 10389808.0000 - val_loss: 13871.3008 - val_mae: 13871.3008 - val_mse: 339385664.0000 - lr: 0.0010\n",
      "Epoch 54/5000\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 2144.9111 - mae: 2144.9111 - mse: 11148338.0000 - val_loss: 11334.7969 - val_mae: 11334.7969 - val_mse: 227201792.0000 - lr: 0.0010\n",
      "Epoch 55/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1228.1349 - mae: 1228.1349 - mse: 3656150.5000 - val_loss: 11687.1045 - val_mae: 11687.1045 - val_mse: 248259792.0000 - lr: 0.0010\n",
      "Epoch 56/5000\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 5055.6343 - mae: 5055.6343 - mse: 69257992.0000 - val_loss: 5396.2466 - val_mae: 5396.2466 - val_mse: 53043224.0000 - lr: 0.0010\n",
      "Epoch 57/5000\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 1918.4865 - mae: 1918.4865 - mse: 9905012.0000 - val_loss: 15744.6543 - val_mae: 15744.6543 - val_mse: 436705568.0000 - lr: 0.0010\n",
      "Epoch 58/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 2602.4187 - mae: 2602.4187 - mse: 16594338.0000 - val_loss: 17317.0898 - val_mae: 17317.0898 - val_mse: 528148192.0000 - lr: 0.0010\n",
      "Epoch 59/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 2766.4534 - mae: 2766.4534 - mse: 18625198.0000 - val_loss: 17867.8047 - val_mae: 17867.8047 - val_mse: 562200704.0000 - lr: 0.0010\n",
      "Epoch 60/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 2819.3074 - mae: 2819.3074 - mse: 19293678.0000 - val_loss: 17920.3379 - val_mae: 17920.3379 - val_mse: 565535232.0000 - lr: 0.0010\n",
      "Epoch 61/5000\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 2804.5151 - mae: 2804.5151 - mse: 19064026.0000 - val_loss: 17672.1660 - val_mae: 17672.1660 - val_mse: 550034688.0000 - lr: 0.0010\n",
      "Epoch 62/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 2755.4402 - mae: 2755.4402 - mse: 18397470.0000 - val_loss: 17298.1973 - val_mae: 17298.1973 - val_mse: 527069984.0000 - lr: 0.0010\n",
      "Epoch 63/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 2689.9568 - mae: 2689.9568 - mse: 17527588.0000 - val_loss: 16790.6055 - val_mae: 16790.6055 - val_mse: 496647136.0000 - lr: 0.0010\n",
      "Epoch 64/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 2594.5076 - mae: 2594.5076 - mse: 16287562.0000 - val_loss: 15921.9717 - val_mae: 15921.9717 - val_mse: 446716288.0000 - lr: 0.0010\n",
      "Epoch 65/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 2417.8386 - mae: 2417.8386 - mse: 14106833.0000 - val_loss: 14255.8936 - val_mae: 14255.8936 - val_mse: 358396256.0000 - lr: 0.0010\n",
      "Epoch 66/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 2074.2737 - mae: 2074.2737 - mse: 10319713.0000 - val_loss: 10645.9316 - val_mae: 10645.9316 - val_mse: 200607088.0000 - lr: 0.0010\n",
      "Epoch 67/5000\n",
      "3/3 [==============================] - 1s 191ms/step - loss: 1234.7792 - mae: 1234.7792 - mse: 3632053.7500 - val_loss: 2636.4446 - val_mae: 2636.4446 - val_mse: 16141841.0000 - lr: 0.0010\n",
      "Epoch 68/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 2121.0664 - mae: 2121.0664 - mse: 12220300.0000 - val_loss: 1043.9360 - val_mae: 1043.9360 - val_mse: 3525960.2500 - lr: 0.0010\n",
      "Epoch 69/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1204.5032 - mae: 1204.5032 - mse: 4235450.5000 - val_loss: 9014.0117 - val_mae: 9014.0117 - val_mse: 144369840.0000 - lr: 0.0010\n",
      "Epoch 70/5000\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 1572.8948 - mae: 1572.8948 - mse: 6238790.5000 - val_loss: 10997.2295 - val_mae: 10997.2295 - val_mse: 213893344.0000 - lr: 0.0010\n",
      "Epoch 71/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1706.2043 - mae: 1706.2043 - mse: 7094938.0000 - val_loss: 9184.4531 - val_mae: 9184.4531 - val_mse: 149804576.0000 - lr: 0.0010\n",
      "Epoch 72/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 1214.9402 - mae: 1214.9402 - mse: 3570287.5000 - val_loss: 5013.9546 - val_mae: 5013.9546 - val_mse: 46454480.0000 - lr: 0.0010\n",
      "Epoch 73/5000\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 446.1790 - mae: 446.1790 - mse: 600263.6875 - val_loss: 2443.0918 - val_mae: 2443.0918 - val_mse: 14316420.0000 - lr: 0.0010\n",
      "Epoch 74/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 580.6885 - mae: 580.6885 - mse: 1111658.0000 - val_loss: 10676.0254 - val_mae: 10676.0254 - val_mse: 201716528.0000 - lr: 0.0010\n",
      "Epoch 75/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 2462.4050 - mae: 2462.4050 - mse: 15419974.0000 - val_loss: 15081.2227 - val_mae: 15081.2227 - val_mse: 400731872.0000 - lr: 0.0010\n",
      "Epoch 76/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 1851.2500 - mae: 1851.2500 - mse: 8121914.0000 - val_loss: 6141.9937 - val_mae: 6141.9937 - val_mse: 71991680.0000 - lr: 0.0010\n",
      "Epoch 77/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 1876.1882 - mae: 1876.1882 - mse: 9214687.0000 - val_loss: 4262.2734 - val_mae: 4262.2734 - val_mse: 34358640.0000 - lr: 0.0010\n",
      "Epoch 78/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 1830.3824 - mae: 1830.3824 - mse: 9162347.0000 - val_loss: 14822.6309 - val_mae: 14822.6309 - val_mse: 387321664.0000 - lr: 0.0010\n",
      "Epoch 79/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 2351.8606 - mae: 2351.8606 - mse: 13429688.0000 - val_loss: 12826.4092 - val_mae: 12826.4092 - val_mse: 290319584.0000 - lr: 0.0010\n",
      "Epoch 80/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 1404.5616 - mae: 1404.5616 - mse: 4788863.0000 - val_loss: 24403.2031 - val_mae: 24403.2031 - val_mse: 1059582720.0000 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 10479.9180 - mae: 10479.9180 - mse: 339201824.0000 - val_loss: 11655.8828 - val_mae: 11655.8828 - val_mse: 239959664.0000 - lr: 0.0010\n",
      "Epoch 82/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 2427.2893 - mae: 2427.2893 - mse: 14844294.0000 - val_loss: 16132.8594 - val_mae: 16132.8594 - val_mse: 458642848.0000 - lr: 0.0010\n",
      "Epoch 83/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 2528.6960 - mae: 2528.6960 - mse: 15550534.0000 - val_loss: 16286.9717 - val_mae: 16286.9717 - val_mse: 467367392.0000 - lr: 0.0010\n",
      "Epoch 84/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 2558.0876 - mae: 2558.0876 - mse: 15889180.0000 - val_loss: 16071.2119 - val_mae: 16071.2119 - val_mse: 455119040.0000 - lr: 0.0010\n",
      "Epoch 85/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 2469.0029 - mae: 2469.0029 - mse: 14736947.0000 - val_loss: 14625.8438 - val_mae: 14625.8438 - val_mse: 377203648.0000 - lr: 0.0010\n",
      "Epoch 86/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 2149.2871 - mae: 2149.2871 - mse: 11082115.0000 - val_loss: 10034.5098 - val_mae: 10034.5098 - val_mse: 178380832.0000 - lr: 0.0010\n",
      "Epoch 87/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 1132.4240 - mae: 1132.4240 - mse: 3984755.5000 - val_loss: 6347.5781 - val_mae: 6347.5781 - val_mse: 72559208.0000 - lr: 0.0010\n",
      "Epoch 88/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 1857.0161 - mae: 1857.0161 - mse: 9223122.0000 - val_loss: 14804.8467 - val_mae: 14804.8467 - val_mse: 386128928.0000 - lr: 0.0010\n",
      "Epoch 89/5000\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 2370.0193 - mae: 2370.0193 - mse: 13668269.0000 - val_loss: 14214.4297 - val_mae: 14214.4297 - val_mse: 356053920.0000 - lr: 0.0010\n",
      "Epoch 90/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 2154.0034 - mae: 2154.0034 - mse: 11242662.0000 - val_loss: 13468.2676 - val_mae: 13468.2676 - val_mse: 320106048.0000 - lr: 0.0010\n",
      "Epoch 91/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 2074.8506 - mae: 2074.8506 - mse: 10428178.0000 - val_loss: 11511.3271 - val_mae: 11511.3271 - val_mse: 234246192.0000 - lr: 0.0010\n",
      "Epoch 92/5000\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 1707.7882 - mae: 1707.7882 - mse: 7064255.5000 - val_loss: 8440.7617 - val_mae: 8440.7617 - val_mse: 126686256.0000 - lr: 0.0010\n",
      "Epoch 93/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 897.8112 - mae: 897.8112 - mse: 1986282.6250 - val_loss: 2452.5752 - val_mae: 2452.5752 - val_mse: 14163171.0000 - lr: 0.0010\n",
      "Epoch 94/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 1047.2249 - mae: 1047.2249 - mse: 3552926.2500 - val_loss: 3499.9165 - val_mae: 3499.9165 - val_mse: 23868848.0000 - lr: 0.0010\n",
      "Epoch 95/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 841.8270 - mae: 841.8270 - mse: 2918234.2500 - val_loss: 7294.0396 - val_mae: 7294.0396 - val_mse: 95381272.0000 - lr: 0.0010\n",
      "Epoch 96/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 2156.0144 - mae: 2156.0144 - mse: 12148858.0000 - val_loss: 14756.0020 - val_mae: 14756.0020 - val_mse: 383834784.0000 - lr: 0.0010\n",
      "Epoch 97/5000\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 2222.2358 - mae: 2222.2358 - mse: 11888544.0000 - val_loss: 10759.9717 - val_mae: 10759.9717 - val_mse: 204828576.0000 - lr: 0.0010\n",
      "Epoch 98/5000\n",
      "3/3 [==============================] - 1s 181ms/step - loss: 1055.7794 - mae: 1055.7794 - mse: 2614367.2500 - val_loss: 6878.2583 - val_mae: 6878.2583 - val_mse: 85011080.0000 - lr: 0.0010\n",
      "Epoch 99/5000\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 1788.0051 - mae: 1788.0051 - mse: 8348644.5000 - val_loss: 12568.7568 - val_mae: 12568.7568 - val_mse: 279061184.0000 - lr: 0.0010\n",
      "Epoch 100/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 1796.6284 - mae: 1796.6284 - mse: 7742531.0000 - val_loss: 8294.4082 - val_mae: 8294.4082 - val_mse: 122354944.0000 - lr: 0.0010\n",
      "Epoch 101/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 1884.3232 - mae: 1884.3232 - mse: 9045255.0000 - val_loss: 6631.6792 - val_mae: 6631.6792 - val_mse: 78827776.0000 - lr: 0.0010\n",
      "Epoch 102/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 427.0139 - mae: 427.0139 - mse: 517318.5625 - val_loss: 2127.1975 - val_mae: 2127.1975 - val_mse: 11935377.0000 - lr: 0.0010\n",
      "Epoch 103/5000\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 741.1808 - mae: 741.1808 - mse: 1665282.0000 - val_loss: 5599.6919 - val_mae: 5599.6919 - val_mse: 57518796.0000 - lr: 0.0010\n",
      "Epoch 104/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 1606.0081 - mae: 1606.0081 - mse: 6832859.0000 - val_loss: 10344.5117 - val_mae: 10344.5117 - val_mse: 189613296.0000 - lr: 0.0010\n",
      "Epoch 105/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 1162.3408 - mae: 1162.3408 - mse: 3337303.0000 - val_loss: 19610.6387 - val_mae: 19610.6387 - val_mse: 688271168.0000 - lr: 0.0010\n",
      "Epoch 106/5000\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 7944.6304 - mae: 7944.6304 - mse: 188554096.0000 - val_loss: 9854.1211 - val_mae: 9854.1211 - val_mse: 172223296.0000 - lr: 0.0010\n",
      "Epoch 107/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 2251.2024 - mae: 2251.2024 - mse: 12954960.0000 - val_loss: 15409.6436 - val_mae: 15409.6436 - val_mse: 418416320.0000 - lr: 0.0010\n",
      "Epoch 108/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 2213.5464 - mae: 2213.5464 - mse: 11704274.0000 - val_loss: 12247.4248 - val_mae: 12247.4248 - val_mse: 265536144.0000 - lr: 0.0010\n",
      "Epoch 109/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 1959.3505 - mae: 1959.3505 - mse: 9465105.0000 - val_loss: 13280.0400 - val_mae: 13280.0400 - val_mse: 311243200.0000 - lr: 0.0010\n",
      "Epoch 110/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 2144.8396 - mae: 2144.8396 - mse: 11265130.0000 - val_loss: 13209.9082 - val_mae: 13209.9082 - val_mse: 307871424.0000 - lr: 0.0010\n",
      "Epoch 111/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 1958.0956 - mae: 1958.0956 - mse: 9247097.0000 - val_loss: 10623.7949 - val_mae: 10623.7949 - val_mse: 199757168.0000 - lr: 0.0010\n",
      "Epoch 112/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 1458.0814 - mae: 1458.0814 - mse: 5121445.5000 - val_loss: 6914.8291 - val_mae: 6914.8291 - val_mse: 86063048.0000 - lr: 0.0010\n",
      "Epoch 113/5000\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 823.3539 - mae: 823.3539 - mse: 1713602.7500 - val_loss: 1127.5820 - val_mae: 1127.5820 - val_mse: 4188796.2500 - lr: 0.0010\n",
      "Epoch 114/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 901.0114 - mae: 901.0114 - mse: 2561858.2500 - val_loss: 3077.0149 - val_mae: 3077.0149 - val_mse: 21311188.0000 - lr: 0.0010\n",
      "Epoch 115/5000\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 290.8843 - mae: 290.8843 - mse: 337133.1250 - val_loss: 1605.3685 - val_mae: 1605.3685 - val_mse: 6419101.5000 - lr: 0.0010\n",
      "Epoch 116/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 211.7703 - mae: 211.7703 - mse: 215364.3438 - val_loss: 1076.3552 - val_mae: 1076.3552 - val_mse: 3707183.0000 - lr: 0.0010\n",
      "Epoch 117/5000\n",
      "3/3 [==============================] - 1s 183ms/step - loss: 236.3704 - mae: 236.3704 - mse: 246787.3594 - val_loss: 1015.8690 - val_mae: 1015.8690 - val_mse: 3444892.5000 - lr: 0.0010\n",
      "Epoch 118/5000\n",
      "3/3 [==============================] - 1s 182ms/step - loss: 272.5124 - mae: 272.5124 - mse: 312020.8438 - val_loss: 1103.6599 - val_mae: 1103.6599 - val_mse: 3588329.2500 - lr: 0.0010\n",
      "Epoch 119/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 333.1062 - mae: 333.1063 - mse: 406653.8125 - val_loss: 1648.7209 - val_mae: 1648.7209 - val_mse: 6517491.0000 - lr: 0.0010\n",
      "Epoch 120/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 199.0258 - mae: 199.0258 - mse: 188909.8281 - val_loss: 995.6556 - val_mae: 995.6556 - val_mse: 3306647.7500 - lr: 0.0010\n",
      "Epoch 121/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 214ms/step - loss: 175.0635 - mae: 175.0635 - mse: 157704.5000 - val_loss: 935.7474 - val_mae: 935.7474 - val_mse: 2897631.7500 - lr: 0.0010\n",
      "Epoch 122/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 190.1648 - mae: 190.1648 - mse: 176091.6094 - val_loss: 1310.2467 - val_mae: 1310.2467 - val_mse: 4355669.5000 - lr: 0.0010\n",
      "Epoch 123/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 325.0880 - mae: 325.0880 - mse: 371227.2188 - val_loss: 940.6659 - val_mae: 940.6659 - val_mse: 2879480.5000 - lr: 0.0010\n",
      "Epoch 124/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 319.5946 - mae: 319.5946 - mse: 396543.5312 - val_loss: 948.0037 - val_mae: 948.0037 - val_mse: 3014263.2500 - lr: 0.0010\n",
      "Epoch 125/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 302.3202 - mae: 302.3202 - mse: 349078.7812 - val_loss: 1852.6848 - val_mae: 1852.6848 - val_mse: 8002006.5000 - lr: 0.0010\n",
      "Epoch 126/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 209.0622 - mae: 209.0622 - mse: 189188.6094 - val_loss: 1051.0985 - val_mae: 1051.0985 - val_mse: 3620275.0000 - lr: 0.0010\n",
      "Epoch 127/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 203.9020 - mae: 203.9020 - mse: 193685.3281 - val_loss: 1231.1775 - val_mae: 1231.1775 - val_mse: 4027801.2500 - lr: 0.0010\n",
      "Epoch 128/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 285.7261 - mae: 285.7261 - mse: 307975.4062 - val_loss: 1203.2930 - val_mae: 1203.2930 - val_mse: 3903963.7500 - lr: 0.0010\n",
      "Epoch 129/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 203.0355 - mae: 203.0355 - mse: 197241.9531 - val_loss: 936.7986 - val_mae: 936.7986 - val_mse: 2957795.7500 - lr: 0.0010\n",
      "Epoch 130/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 187.7340 - mae: 187.7340 - mse: 168831.7812 - val_loss: 941.5903 - val_mae: 941.5903 - val_mse: 2856755.0000 - lr: 0.0010\n",
      "Epoch 131/5000\n",
      "3/3 [==============================] - 1s 170ms/step - loss: 197.2771 - mae: 197.2771 - mse: 185608.4531 - val_loss: 982.8796 - val_mae: 982.8796 - val_mse: 2949502.2500 - lr: 0.0010\n",
      "Epoch 132/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 236.2078 - mae: 236.2078 - mse: 229683.2656 - val_loss: 958.1616 - val_mae: 958.1616 - val_mse: 2885234.2500 - lr: 0.0010\n",
      "Epoch 133/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 233.0666 - mae: 233.0666 - mse: 241514.3594 - val_loss: 953.3741 - val_mae: 953.3741 - val_mse: 3056533.7500 - lr: 0.0010\n",
      "Epoch 134/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 196.6374 - mae: 196.6374 - mse: 181370.1719 - val_loss: 1081.9268 - val_mae: 1081.9268 - val_mse: 3353711.5000 - lr: 0.0010\n",
      "Epoch 135/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 178.2405 - mae: 178.2405 - mse: 162661.1875 - val_loss: 935.0517 - val_mae: 935.0517 - val_mse: 2906289.2500 - lr: 0.0010\n",
      "Epoch 136/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 179.0111 - mae: 179.0111 - mse: 161071.7656 - val_loss: 941.2452 - val_mae: 941.2452 - val_mse: 2880709.2500 - lr: 0.0010\n",
      "Epoch 137/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 185.9661 - mae: 185.9661 - mse: 170609.9844 - val_loss: 958.7136 - val_mae: 958.7136 - val_mse: 2882639.5000 - lr: 0.0010\n",
      "Epoch 138/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 206.9181 - mae: 206.9181 - mse: 190981.7344 - val_loss: 950.4228 - val_mae: 950.4228 - val_mse: 2831355.7500 - lr: 0.0010\n",
      "Epoch 139/5000\n",
      "3/3 [==============================] - 1s 386ms/step - loss: 202.1431 - mae: 202.1431 - mse: 192089.7188 - val_loss: 894.5004 - val_mae: 894.5004 - val_mse: 2700165.7500 - lr: 0.0010\n",
      "Epoch 140/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 195.5089 - mae: 195.5089 - mse: 175439.9062 - val_loss: 982.8538 - val_mae: 982.8538 - val_mse: 2888465.0000 - lr: 0.0010\n",
      "Epoch 141/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 182.3311 - mae: 182.3311 - mse: 164514.9062 - val_loss: 891.3336 - val_mae: 891.3336 - val_mse: 2640445.0000 - lr: 0.0010\n",
      "Epoch 142/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 188.9802 - mae: 188.9802 - mse: 166568.9688 - val_loss: 927.2675 - val_mae: 927.2675 - val_mse: 2705196.2500 - lr: 0.0010\n",
      "Epoch 143/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 187.2977 - mae: 187.2977 - mse: 170138.3281 - val_loss: 891.5958 - val_mae: 891.5958 - val_mse: 2625542.7500 - lr: 0.0010\n",
      "Epoch 144/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 196.8282 - mae: 196.8282 - mse: 175756.1406 - val_loss: 954.7776 - val_mae: 954.7776 - val_mse: 2774112.2500 - lr: 0.0010\n",
      "Epoch 145/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 186.3577 - mae: 186.3577 - mse: 168991.4062 - val_loss: 876.5814 - val_mae: 876.5814 - val_mse: 2594638.5000 - lr: 0.0010\n",
      "Epoch 146/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 186.1046 - mae: 186.1046 - mse: 162751.1094 - val_loss: 953.3500 - val_mae: 953.3500 - val_mse: 2753647.2500 - lr: 0.0010\n",
      "Epoch 147/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 174.8777 - mae: 174.8777 - mse: 153735.1875 - val_loss: 880.3029 - val_mae: 880.3029 - val_mse: 2552111.2500 - lr: 0.0010\n",
      "Epoch 148/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 185.4060 - mae: 185.4060 - mse: 160799.7188 - val_loss: 901.1960 - val_mae: 901.1960 - val_mse: 2581290.0000 - lr: 0.0010\n",
      "Epoch 149/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 185.0805 - mae: 185.0805 - mse: 165447.1875 - val_loss: 872.0272 - val_mae: 872.0272 - val_mse: 2519222.2500 - lr: 0.0010\n",
      "Epoch 150/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 193.8775 - mae: 193.8774 - mse: 170341.9531 - val_loss: 939.1740 - val_mae: 939.1740 - val_mse: 2676134.7500 - lr: 0.0010\n",
      "Epoch 151/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 181.3565 - mae: 181.3565 - mse: 160981.0000 - val_loss: 859.3243 - val_mae: 859.3243 - val_mse: 2502885.0000 - lr: 0.0010\n",
      "Epoch 152/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 180.0294 - mae: 180.0294 - mse: 154254.2969 - val_loss: 922.7841 - val_mae: 922.7841 - val_mse: 2618763.7500 - lr: 0.0010\n",
      "Epoch 153/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 171.2295 - mae: 171.2295 - mse: 148020.4531 - val_loss: 866.5851 - val_mae: 866.5851 - val_mse: 2462970.7500 - lr: 0.0010\n",
      "Epoch 154/5000\n",
      "3/3 [==============================] - 1s 301ms/step - loss: 183.1871 - mae: 183.1871 - mse: 156514.2500 - val_loss: 872.0419 - val_mae: 872.0419 - val_mse: 2468341.2500 - lr: 0.0010\n",
      "Epoch 155/5000\n",
      "3/3 [==============================] - 1s 306ms/step - loss: 188.2634 - mae: 188.2634 - mse: 168264.2812 - val_loss: 856.8497 - val_mae: 856.8497 - val_mse: 2450300.7500 - lr: 0.0010\n",
      "Epoch 156/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 195.2991 - mae: 195.2991 - mse: 170714.2031 - val_loss: 945.9784 - val_mae: 945.9784 - val_mse: 2663753.5000 - lr: 0.0010\n",
      "Epoch 157/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 177.4624 - mae: 177.4624 - mse: 155530.3438 - val_loss: 844.9088 - val_mae: 844.9088 - val_mse: 2420503.0000 - lr: 0.0010\n",
      "Epoch 158/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 180.2012 - mae: 180.2012 - mse: 152785.8125 - val_loss: 906.1877 - val_mae: 906.1877 - val_mse: 2531713.2500 - lr: 0.0010\n",
      "Epoch 159/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 171.4474 - mae: 171.4474 - mse: 147492.0781 - val_loss: 853.1719 - val_mae: 853.1719 - val_mse: 2390900.2500 - lr: 0.0010\n",
      "Epoch 160/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 185.4059 - mae: 185.4059 - mse: 157479.8281 - val_loss: 875.6928 - val_mae: 875.6928 - val_mse: 2424064.5000 - lr: 0.0010\n",
      "Epoch 161/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 181.2054 - mae: 181.2054 - mse: 158006.8125 - val_loss: 833.4781 - val_mae: 833.4781 - val_mse: 2330859.0000 - lr: 0.0010\n",
      "Epoch 162/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 186.3069 - mae: 186.3069 - mse: 158094.5625 - val_loss: 877.9882 - val_mae: 877.9882 - val_mse: 2418585.7500 - lr: 0.0010\n",
      "Epoch 163/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 182.3338 - mae: 182.3338 - mse: 159555.3125 - val_loss: 831.2953 - val_mae: 831.2953 - val_mse: 2349051.7500 - lr: 0.0010\n",
      "Epoch 164/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 182.8771 - mae: 182.8771 - mse: 154469.9219 - val_loss: 908.8428 - val_mae: 908.8428 - val_mse: 2511199.2500 - lr: 0.0010\n",
      "Epoch 165/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 170.9044 - mae: 170.9044 - mse: 146256.6562 - val_loss: 836.9296 - val_mae: 836.9296 - val_mse: 2338841.5000 - lr: 0.0010\n",
      "Epoch 166/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 180.8863 - mae: 180.8863 - mse: 151877.9219 - val_loss: 882.6712 - val_mae: 882.6712 - val_mse: 2427643.0000 - lr: 0.0010\n",
      "Epoch 167/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 172.2579 - mae: 172.2579 - mse: 147018.0938 - val_loss: 834.5725 - val_mae: 834.5725 - val_mse: 2304292.5000 - lr: 0.0010\n",
      "Epoch 168/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 185.2311 - mae: 185.2311 - mse: 156090.0000 - val_loss: 876.8987 - val_mae: 876.8987 - val_mse: 2390407.2500 - lr: 0.0010\n",
      "Epoch 169/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 175.3299 - mae: 175.3299 - mse: 150060.7188 - val_loss: 822.0164 - val_mae: 822.0164 - val_mse: 2280503.5000 - lr: 0.0010\n",
      "Epoch 170/5000\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 180.4655 - mae: 180.4655 - mse: 150444.1406 - val_loss: 884.3695 - val_mae: 884.3695 - val_mse: 2404989.7500 - lr: 0.0010\n",
      "Epoch 171/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 169.4031 - mae: 169.4031 - mse: 143024.5312 - val_loss: 820.9183 - val_mae: 820.9183 - val_mse: 2252622.7500 - lr: 0.0010\n",
      "Epoch 172/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 178.5969 - mae: 178.5969 - mse: 147946.2656 - val_loss: 859.3092 - val_mae: 859.3092 - val_mse: 2320584.5000 - lr: 0.0010\n",
      "Epoch 173/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 171.1377 - mae: 171.1377 - mse: 144146.2656 - val_loss: 818.7614 - val_mae: 818.7614 - val_mse: 2222799.7500 - lr: 0.0010\n",
      "Epoch 174/5000\n",
      "3/3 [==============================] - 1s 251ms/step - loss: 182.6015 - mae: 182.6015 - mse: 151970.1406 - val_loss: 842.3636 - val_mae: 842.3636 - val_mse: 2272912.0000 - lr: 0.0010\n",
      "Epoch 175/5000\n",
      "3/3 [==============================] - 1s 276ms/step - loss: 181.8985 - mae: 181.8985 - mse: 157128.4375 - val_loss: 808.8472 - val_mae: 808.8472 - val_mse: 2247139.0000 - lr: 0.0010\n",
      "Epoch 176/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 177.3347 - mae: 177.3347 - mse: 146383.8438 - val_loss: 889.2859 - val_mae: 889.2859 - val_mse: 2403097.2500 - lr: 0.0010\n",
      "Epoch 177/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 164.4491 - mae: 164.4491 - mse: 137059.8906 - val_loss: 820.5453 - val_mae: 820.5453 - val_mse: 2228888.7500 - lr: 0.0010\n",
      "Epoch 178/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 179.0008 - mae: 179.0008 - mse: 147584.6562 - val_loss: 849.4307 - val_mae: 849.4307 - val_mse: 2279272.0000 - lr: 0.0010\n",
      "Epoch 179/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 170.9507 - mae: 170.9507 - mse: 143211.2031 - val_loss: 803.1230 - val_mae: 803.1230 - val_mse: 2152287.5000 - lr: 0.0010\n",
      "Epoch 180/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 181.5493 - mae: 181.5493 - mse: 149942.2969 - val_loss: 817.7909 - val_mae: 817.7909 - val_mse: 2199002.5000 - lr: 0.0010\n",
      "Epoch 181/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 188.5805 - mae: 188.5805 - mse: 165510.9688 - val_loss: 827.6530 - val_mae: 827.6530 - val_mse: 2329773.0000 - lr: 0.0010\n",
      "Epoch 182/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 194.1473 - mae: 194.1473 - mse: 169117.8438 - val_loss: 878.0204 - val_mae: 878.0204 - val_mse: 2398452.0000 - lr: 0.0010\n",
      "Epoch 183/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 180.5092 - mae: 180.5092 - mse: 155887.2188 - val_loss: 798.7205 - val_mae: 798.7205 - val_mse: 2176026.0000 - lr: 0.0010\n",
      "Epoch 184/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 181.3987 - mae: 181.3987 - mse: 149216.8438 - val_loss: 852.9473 - val_mae: 852.9473 - val_mse: 2258183.7500 - lr: 0.0010\n",
      "Epoch 185/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 171.1137 - mae: 171.1137 - mse: 142819.5625 - val_loss: 786.8649 - val_mae: 786.8649 - val_mse: 2063245.1250 - lr: 0.0010\n",
      "Epoch 186/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 187.0199 - mae: 187.0199 - mse: 153581.5469 - val_loss: 788.6523 - val_mae: 788.6523 - val_mse: 2127757.5000 - lr: 0.0010\n",
      "Epoch 187/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 221.1014 - mae: 221.1014 - mse: 209204.8906 - val_loss: 806.2844 - val_mae: 806.2844 - val_mse: 2212256.2500 - lr: 0.0010\n",
      "Epoch 188/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 225.2950 - mae: 225.2950 - mse: 206285.1562 - val_loss: 1137.1710 - val_mae: 1137.1710 - val_mse: 3349118.2500 - lr: 0.0010\n",
      "Epoch 189/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 162.1791 - mae: 162.1791 - mse: 134314.5312 - val_loss: 826.2106 - val_mae: 826.2106 - val_mse: 2327626.7500 - lr: 0.0010\n",
      "Epoch 190/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 154.2201 - mae: 154.2201 - mse: 125042.1016 - val_loss: 836.3378 - val_mae: 836.3378 - val_mse: 2278434.0000 - lr: 0.0010\n",
      "Epoch 191/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 155.4608 - mae: 155.4608 - mse: 127528.0156 - val_loss: 899.6287 - val_mae: 899.6287 - val_mse: 2425031.0000 - lr: 0.0010\n",
      "Epoch 192/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 191.0337 - mae: 191.0337 - mse: 160374.5625 - val_loss: 800.4716 - val_mae: 800.4716 - val_mse: 2183662.2500 - lr: 0.0010\n",
      "Epoch 193/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 214.2676 - mae: 214.2676 - mse: 200123.9688 - val_loss: 799.2205 - val_mae: 799.2205 - val_mse: 2193173.7500 - lr: 0.0010\n",
      "Epoch 194/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 197.0037 - mae: 197.0037 - mse: 167387.6719 - val_loss: 983.3882 - val_mae: 983.3882 - val_mse: 2684208.7500 - lr: 0.0010\n",
      "Epoch 195/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 160.0927 - mae: 160.0927 - mse: 131680.0781 - val_loss: 799.1305 - val_mae: 799.1305 - val_mse: 2189492.2500 - lr: 0.0010\n",
      "Epoch 196/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 158.2452 - mae: 158.2452 - mse: 125846.4453 - val_loss: 829.7053 - val_mae: 829.7053 - val_mse: 2214316.5000 - lr: 0.0010\n",
      "Epoch 197/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 155.6207 - mae: 155.6207 - mse: 126278.0469 - val_loss: 838.2395 - val_mae: 838.2395 - val_mse: 2221581.7500 - lr: 0.0010\n",
      "Epoch 198/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 179.9644 - mae: 179.9644 - mse: 146835.2812 - val_loss: 807.6310 - val_mae: 807.6310 - val_mse: 2136261.2500 - lr: 0.0010\n",
      "Epoch 199/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 179.1361 - mae: 179.1361 - mse: 151658.0156 - val_loss: 786.0210 - val_mae: 786.0210 - val_mse: 2088014.0000 - lr: 0.0010\n",
      "Epoch 200/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 182.7756 - mae: 182.7756 - mse: 149318.3906 - val_loss: 870.1569 - val_mae: 870.1569 - val_mse: 2276175.0000 - lr: 0.0010\n",
      "Epoch 201/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 163.6840 - mae: 163.6840 - mse: 134163.1562 - val_loss: 777.2152 - val_mae: 777.2152 - val_mse: 2070834.1250 - lr: 0.0010\n",
      "Epoch 202/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 164.3015 - mae: 164.3015 - mse: 129514.7734 - val_loss: 813.9700 - val_mae: 813.9700 - val_mse: 2117444.0000 - lr: 0.0010\n",
      "Epoch 203/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 203ms/step - loss: 159.4868 - mae: 159.4868 - mse: 128633.5547 - val_loss: 794.8537 - val_mae: 794.8537 - val_mse: 2062189.3750 - lr: 0.0010\n",
      "Epoch 204/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 178.6042 - mae: 178.6042 - mse: 143669.8594 - val_loss: 797.1608 - val_mae: 797.1608 - val_mse: 2058502.8750 - lr: 0.0010\n",
      "Epoch 205/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 176.9668 - mae: 176.9668 - mse: 147936.6562 - val_loss: 766.9047 - val_mae: 766.9047 - val_mse: 2015630.2500 - lr: 0.0010\n",
      "Epoch 206/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 173.8750 - mae: 173.8750 - mse: 138807.5156 - val_loss: 836.3880 - val_mae: 836.3880 - val_mse: 2154522.2500 - lr: 0.0010\n",
      "Epoch 207/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 160.4527 - mae: 160.4527 - mse: 129282.2031 - val_loss: 767.1729 - val_mae: 767.1729 - val_mse: 2008843.0000 - lr: 0.0010\n",
      "Epoch 208/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 163.7009 - mae: 163.7009 - mse: 128041.1484 - val_loss: 802.0681 - val_mae: 802.0681 - val_mse: 2062232.8750 - lr: 0.0010\n",
      "Epoch 209/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 157.7527 - mae: 157.7527 - mse: 125825.5391 - val_loss: 777.1281 - val_mae: 777.1281 - val_mse: 1996776.0000 - lr: 0.0010\n",
      "Epoch 210/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 174.1460 - mae: 174.1460 - mse: 138627.7344 - val_loss: 796.1087 - val_mae: 796.1087 - val_mse: 2033958.0000 - lr: 0.0010\n",
      "Epoch 211/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 166.6253 - mae: 166.6253 - mse: 135320.0156 - val_loss: 761.5084 - val_mae: 761.5084 - val_mse: 1983003.1250 - lr: 0.0010\n",
      "Epoch 212/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 168.3387 - mae: 168.3387 - mse: 132143.0469 - val_loss: 810.0806 - val_mae: 810.0806 - val_mse: 2072731.6250 - lr: 0.0010\n",
      "Epoch 213/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 160.0155 - mae: 160.0155 - mse: 128262.8516 - val_loss: 764.9584 - val_mae: 764.9584 - val_mse: 1972970.8750 - lr: 0.0010\n",
      "Epoch 214/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 170.3221 - mae: 170.3221 - mse: 134192.7188 - val_loss: 808.8691 - val_mae: 808.8691 - val_mse: 2060990.8750 - lr: 0.0010\n",
      "Epoch 215/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 158.7535 - mae: 158.7535 - mse: 126616.4453 - val_loss: 758.4175 - val_mae: 758.4175 - val_mse: 1944454.6250 - lr: 0.0010\n",
      "Epoch 216/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 168.1986 - mae: 168.1986 - mse: 132004.0469 - val_loss: 788.5430 - val_mae: 788.5430 - val_mse: 2002512.6250 - lr: 0.0010\n",
      "Epoch 217/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 161.9256 - mae: 161.9256 - mse: 129796.0859 - val_loss: 760.8655 - val_mae: 760.8655 - val_mse: 1954644.2500 - lr: 0.0010\n",
      "Epoch 218/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 171.6658 - mae: 171.6658 - mse: 134925.4062 - val_loss: 803.6861 - val_mae: 803.6861 - val_mse: 2039381.8750 - lr: 0.0010\n",
      "Epoch 219/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 161.5971 - mae: 161.5971 - mse: 129663.9141 - val_loss: 754.1238 - val_mae: 754.1238 - val_mse: 1935058.8750 - lr: 0.0010\n",
      "Epoch 220/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 167.3082 - mae: 167.3082 - mse: 129985.7969 - val_loss: 797.2599 - val_mae: 797.2599 - val_mse: 2013343.5000 - lr: 0.0010\n",
      "Epoch 221/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 157.4069 - mae: 157.4069 - mse: 124527.5391 - val_loss: 751.6332 - val_mae: 751.6332 - val_mse: 1899246.0000 - lr: 0.0010\n",
      "Epoch 222/5000\n",
      "3/3 [==============================] - 1s 195ms/step - loss: 171.2759 - mae: 171.2759 - mse: 134644.5000 - val_loss: 773.7153 - val_mae: 773.7153 - val_mse: 1945138.1250 - lr: 0.0010\n",
      "Epoch 223/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 166.5546 - mae: 166.5546 - mse: 134395.3438 - val_loss: 748.4300 - val_mae: 748.4300 - val_mse: 1913470.2500 - lr: 0.0010\n",
      "Epoch 224/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 170.9296 - mae: 170.9296 - mse: 133492.9844 - val_loss: 786.7685 - val_mae: 786.7685 - val_mse: 1983215.8750 - lr: 0.0010\n",
      "Epoch 225/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 165.4701 - mae: 165.4701 - mse: 133696.7500 - val_loss: 748.5568 - val_mae: 748.5568 - val_mse: 1913372.3750 - lr: 0.0010\n",
      "Epoch 226/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 168.2133 - mae: 168.2133 - mse: 130420.1328 - val_loss: 806.6950 - val_mae: 806.6950 - val_mse: 2029097.8750 - lr: 0.0010\n",
      "Epoch 227/5000\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 154.4659 - mae: 154.4659 - mse: 121686.4453 - val_loss: 748.7969 - val_mae: 748.7969 - val_mse: 1889950.3750 - lr: 0.0010\n",
      "Epoch 228/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 167.0202 - mae: 167.0202 - mse: 129682.7891 - val_loss: 769.0375 - val_mae: 769.0375 - val_mse: 1924475.3750 - lr: 0.0010\n",
      "Epoch 229/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 160.6487 - mae: 160.6487 - mse: 127604.1406 - val_loss: 754.9029 - val_mae: 754.9029 - val_mse: 1899371.0000 - lr: 0.0010\n",
      "Epoch 230/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 176.4324 - mae: 176.4324 - mse: 138669.9219 - val_loss: 794.0696 - val_mae: 794.0696 - val_mse: 1987332.8750 - lr: 0.0010\n",
      "Epoch 231/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 164.2659 - mae: 164.2659 - mse: 132401.4688 - val_loss: 743.5977 - val_mae: 743.5977 - val_mse: 1894068.5000 - lr: 0.0010\n",
      "Epoch 232/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 161.1752 - mae: 161.1752 - mse: 122709.5078 - val_loss: 787.8101 - val_mae: 787.8101 - val_mse: 1967523.8750 - lr: 0.0010\n",
      "Epoch 233/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 151.9976 - mae: 151.9976 - mse: 118566.8203 - val_loss: 751.3908 - val_mae: 751.3908 - val_mse: 1875854.3750 - lr: 0.0010\n",
      "Epoch 234/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 169.2281 - mae: 169.2281 - mse: 130854.5312 - val_loss: 764.9716 - val_mae: 764.9716 - val_mse: 1897741.2500 - lr: 0.0010\n",
      "Epoch 235/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 163.2398 - mae: 163.2398 - mse: 129769.8672 - val_loss: 735.6808 - val_mae: 735.6808 - val_mse: 1848374.6250 - lr: 0.0010\n",
      "Epoch 236/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 163.2891 - mae: 163.2891 - mse: 124815.7812 - val_loss: 779.1855 - val_mae: 779.1855 - val_mse: 1929869.2500 - lr: 0.0010\n",
      "Epoch 237/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 152.8118 - mae: 152.8118 - mse: 118631.4844 - val_loss: 739.1695 - val_mae: 739.1695 - val_mse: 1842881.1250 - lr: 0.0010\n",
      "Epoch 238/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 164.5677 - mae: 164.5677 - mse: 125592.5469 - val_loss: 761.4532 - val_mae: 761.4532 - val_mse: 1881308.3750 - lr: 0.0010\n",
      "Epoch 239/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 158.4954 - mae: 158.4954 - mse: 124173.3359 - val_loss: 730.4506 - val_mae: 730.4506 - val_mse: 1811549.0000 - lr: 0.0010\n",
      "Epoch 240/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 166.0617 - mae: 166.0617 - mse: 127498.9062 - val_loss: 765.5188 - val_mae: 765.5188 - val_mse: 1880333.2500 - lr: 0.0010\n",
      "Epoch 241/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 155.7408 - mae: 155.7408 - mse: 121095.8125 - val_loss: 728.6815 - val_mae: 728.6815 - val_mse: 1805512.8750 - lr: 0.0010\n",
      "Epoch 242/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 163.1231 - mae: 163.1231 - mse: 123838.5469 - val_loss: 760.7461 - val_mae: 760.7461 - val_mse: 1865067.2500 - lr: 0.0010\n",
      "Epoch 243/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 154.5145 - mae: 154.5145 - mse: 119507.4062 - val_loss: 722.7801 - val_mae: 722.7801 - val_mse: 1776952.1250 - lr: 0.0010\n",
      "Epoch 244/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 161.5367 - mae: 161.5367 - mse: 122891.0781 - val_loss: 744.3180 - val_mae: 744.3180 - val_mse: 1817911.7500 - lr: 0.0010\n",
      "Epoch 245/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 156.6348 - mae: 156.6348 - mse: 121583.5000 - val_loss: 736.8105 - val_mae: 736.8105 - val_mse: 1801687.2500 - lr: 0.0010\n",
      "Epoch 246/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 176.6478 - mae: 176.6478 - mse: 136892.6094 - val_loss: 737.4777 - val_mae: 737.4777 - val_mse: 1801602.7500 - lr: 0.0010\n",
      "Epoch 247/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 179.7902 - mae: 179.7902 - mse: 148854.3281 - val_loss: 732.4233 - val_mae: 732.4233 - val_mse: 1830581.0000 - lr: 0.0010\n",
      "Epoch 248/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 165.5659 - mae: 165.5659 - mse: 126287.1953 - val_loss: 808.2374 - val_mae: 808.2374 - val_mse: 1988114.6250 - lr: 0.0010\n",
      "Epoch 249/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 147.9019 - mae: 147.9019 - mse: 113441.4062 - val_loss: 729.9017 - val_mae: 729.9017 - val_mse: 1810682.8750 - lr: 0.0010\n",
      "Epoch 250/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 156.1650 - mae: 156.1650 - mse: 116778.1719 - val_loss: 748.0464 - val_mae: 748.0464 - val_mse: 1837589.6250 - lr: 0.0010\n",
      "Epoch 251/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 153.3687 - mae: 153.3687 - mse: 118622.3594 - val_loss: 739.1568 - val_mae: 739.1568 - val_mse: 1813856.7500 - lr: 0.0010\n",
      "Epoch 252/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 171.3091 - mae: 171.3091 - mse: 131811.9219 - val_loss: 767.0920 - val_mae: 767.0920 - val_mse: 1873105.0000 - lr: 0.0010\n",
      "Epoch 253/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 157.3314 - mae: 157.3314 - mse: 122925.2109 - val_loss: 723.2079 - val_mae: 723.2079 - val_mse: 1789553.2500 - lr: 0.0010\n",
      "Epoch 254/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 155.0596 - mae: 155.0596 - mse: 115569.8984 - val_loss: 753.4805 - val_mae: 753.4805 - val_mse: 1833886.8750 - lr: 0.0010\n",
      "Epoch 255/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 147.5454 - mae: 147.5454 - mse: 112107.6797 - val_loss: 726.8146 - val_mae: 726.8146 - val_mse: 1767695.3750 - lr: 0.0010\n",
      "Epoch 256/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 163.7903 - mae: 163.7903 - mse: 123511.0938 - val_loss: 737.4727 - val_mae: 737.4727 - val_mse: 1783581.7500 - lr: 0.0010\n",
      "Epoch 257/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 157.7486 - mae: 157.7486 - mse: 122265.8984 - val_loss: 713.6981 - val_mae: 713.6981 - val_mse: 1732467.3750 - lr: 0.0010\n",
      "Epoch 258/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 164.4201 - mae: 164.4201 - mse: 124478.3906 - val_loss: 748.0381 - val_mae: 748.0381 - val_mse: 1803981.8750 - lr: 0.0010\n",
      "Epoch 259/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 154.5926 - mae: 154.5926 - mse: 119245.2422 - val_loss: 714.1417 - val_mae: 714.1417 - val_mse: 1736374.8750 - lr: 0.0010\n",
      "Epoch 260/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 160.2133 - mae: 160.2133 - mse: 119047.1875 - val_loss: 741.1727 - val_mae: 741.1727 - val_mse: 1782050.2500 - lr: 0.0010\n",
      "Epoch 261/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 153.4342 - mae: 153.4342 - mse: 117883.9531 - val_loss: 711.6391 - val_mae: 711.6391 - val_mse: 1716559.0000 - lr: 0.0010\n",
      "Epoch 262/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 162.9433 - mae: 162.9433 - mse: 122536.5469 - val_loss: 739.6435 - val_mae: 739.6435 - val_mse: 1770957.7500 - lr: 0.0010\n",
      "Epoch 263/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 152.6947 - mae: 152.6947 - mse: 116897.2500 - val_loss: 709.5676 - val_mae: 709.5676 - val_mse: 1706305.1250 - lr: 0.0010\n",
      "Epoch 264/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 160.9564 - mae: 160.9564 - mse: 119237.5000 - val_loss: 731.1470 - val_mae: 731.1470 - val_mse: 1744832.0000 - lr: 0.0010\n",
      "Epoch 265/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 155.1506 - mae: 155.1506 - mse: 119330.9531 - val_loss: 705.6524 - val_mae: 705.6524 - val_mse: 1690929.6250 - lr: 0.0010\n",
      "Epoch 266/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 163.4794 - mae: 163.4794 - mse: 122633.6562 - val_loss: 733.1232 - val_mae: 733.1232 - val_mse: 1744893.0000 - lr: 0.0010\n",
      "Epoch 267/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 154.8727 - mae: 154.8727 - mse: 119019.8438 - val_loss: 705.8583 - val_mae: 705.8583 - val_mse: 1689599.2500 - lr: 0.0010\n",
      "Epoch 268/5000\n",
      "3/3 [==============================] - 1s 193ms/step - loss: 162.8902 - mae: 162.8902 - mse: 120964.6875 - val_loss: 740.1658 - val_mae: 740.1658 - val_mse: 1760820.5000 - lr: 0.0010\n",
      "Epoch 269/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 152.3091 - mae: 152.3091 - mse: 116401.6875 - val_loss: 702.2682 - val_mae: 702.2682 - val_mse: 1686044.2500 - lr: 0.0010\n",
      "Epoch 270/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 155.7383 - mae: 155.7383 - mse: 114693.4062 - val_loss: 723.6107 - val_mae: 723.6107 - val_mse: 1716573.8750 - lr: 0.0010\n",
      "Epoch 271/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 150.8157 - mae: 150.8157 - mse: 114511.4531 - val_loss: 705.5162 - val_mae: 705.5162 - val_mse: 1676379.6250 - lr: 0.0010\n",
      "Epoch 272/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 163.2029 - mae: 163.2029 - mse: 120893.0938 - val_loss: 725.0582 - val_mae: 725.0582 - val_mse: 1713880.8750 - lr: 0.0010\n",
      "Epoch 273/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 155.6109 - mae: 155.6109 - mse: 119343.7578 - val_loss: 698.8914 - val_mae: 698.8914 - val_mse: 1663545.6250 - lr: 0.0010\n",
      "Epoch 274/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 162.6330 - mae: 162.6330 - mse: 121547.0625 - val_loss: 733.9922 - val_mae: 733.9922 - val_mse: 1736079.6250 - lr: 0.0010\n",
      "Epoch 275/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 151.9486 - mae: 151.9486 - mse: 115960.3906 - val_loss: 702.2919 - val_mae: 702.2919 - val_mse: 1672984.7500 - lr: 0.0010\n",
      "Epoch 276/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 160.4884 - mae: 160.4884 - mse: 118020.2891 - val_loss: 724.6381 - val_mae: 724.6381 - val_mse: 1712092.5000 - lr: 0.0010\n",
      "Epoch 277/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 154.0738 - mae: 154.0738 - mse: 117970.2266 - val_loss: 698.4828 - val_mae: 698.4828 - val_mse: 1666902.0000 - lr: 0.0010\n",
      "Epoch 278/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 158.6608 - mae: 158.6608 - mse: 117747.5234 - val_loss: 733.6509 - val_mae: 733.6509 - val_mse: 1729178.1250 - lr: 0.0010\n",
      "Epoch 279/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 146.2625 - mae: 146.2625 - mse: 110047.5391 - val_loss: 705.1485 - val_mae: 705.1485 - val_mse: 1663062.3750 - lr: 0.0010\n",
      "Epoch 280/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 164.3762 - mae: 164.3762 - mse: 121067.0391 - val_loss: 709.0587 - val_mae: 709.0587 - val_mse: 1664419.7500 - lr: 0.0010\n",
      "Epoch 281/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 161.9499 - mae: 161.9499 - mse: 126127.9141 - val_loss: 694.6486 - val_mae: 694.6486 - val_mse: 1643122.8750 - lr: 0.0010\n",
      "Epoch 282/5000\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 169.0395 - mae: 169.0395 - mse: 128182.1875 - val_loss: 739.5402 - val_mae: 739.5402 - val_mse: 1739258.0000 - lr: 0.0010\n",
      "Epoch 283/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 154.5716 - mae: 154.5716 - mse: 119066.7109 - val_loss: 703.7225 - val_mae: 703.7225 - val_mse: 1677818.5000 - lr: 0.0010\n",
      "Epoch 284/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 169.4587 - mae: 169.4587 - mse: 127697.7969 - val_loss: 706.7809 - val_mae: 706.7809 - val_mse: 1680724.1250 - lr: 0.0010\n",
      "Epoch 285/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 231ms/step - loss: 177.4473 - mae: 177.4473 - mse: 144664.9375 - val_loss: 703.6241 - val_mae: 703.6241 - val_mse: 1683218.0000 - lr: 0.0010\n",
      "Epoch 286/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 180.2899 - mae: 180.2899 - mse: 140004.1562 - val_loss: 862.1907 - val_mae: 862.1907 - val_mse: 2118978.0000 - lr: 0.0010\n",
      "Epoch 287/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 143.0010 - mae: 143.0010 - mse: 107673.3984 - val_loss: 729.3196 - val_mae: 729.3196 - val_mse: 1814768.7500 - lr: 0.0010\n",
      "Epoch 288/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 133.3146 - mae: 133.3146 - mse: 96474.9766 - val_loss: 721.4387 - val_mae: 721.4387 - val_mse: 1724353.8750 - lr: 0.0010\n",
      "Epoch 289/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 132.6633 - mae: 132.6633 - mse: 98120.4375 - val_loss: 744.0687 - val_mae: 744.0687 - val_mse: 1757902.3750 - lr: 0.0010\n",
      "Epoch 290/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 156.2533 - mae: 156.2533 - mse: 112251.5156 - val_loss: 689.1873 - val_mae: 689.1873 - val_mse: 1635185.6250 - lr: 0.0010\n",
      "Epoch 291/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 175.9428 - mae: 175.9428 - mse: 140186.0312 - val_loss: 700.2529 - val_mae: 700.2529 - val_mse: 1631624.5000 - lr: 0.0010\n",
      "Epoch 292/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 195.3244 - mae: 195.3244 - mse: 156059.5156 - val_loss: 918.4010 - val_mae: 918.4010 - val_mse: 2298780.0000 - lr: 0.0010\n",
      "Epoch 293/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 139.7678 - mae: 139.7678 - mse: 103022.1328 - val_loss: 724.8677 - val_mae: 724.8677 - val_mse: 1789894.0000 - lr: 0.0010\n",
      "Epoch 294/5000\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 128.4961 - mae: 128.4961 - mse: 92443.9688 - val_loss: 712.9475 - val_mae: 712.9475 - val_mse: 1668440.8750 - lr: 0.0010\n",
      "Epoch 295/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 126.8738 - mae: 126.8738 - mse: 91888.9688 - val_loss: 727.7756 - val_mae: 727.7756 - val_mse: 1687515.8750 - lr: 0.0010\n",
      "Epoch 296/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 145.2773 - mae: 145.2773 - mse: 101376.6016 - val_loss: 716.4058 - val_mae: 716.4058 - val_mse: 1731567.2500 - lr: 0.0010\n",
      "Epoch 297/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 198.2165 - mae: 198.2165 - mse: 162532.9688 - val_loss: 744.7877 - val_mae: 744.7877 - val_mse: 1716445.6250 - lr: 0.0010\n",
      "Epoch 298/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 234.3089 - mae: 234.3089 - mse: 204883.7344 - val_loss: 1209.2107 - val_mae: 1209.2107 - val_mse: 3535384.7500 - lr: 0.0010\n",
      "Epoch 299/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 153.1814 - mae: 153.1814 - mse: 111486.6953 - val_loss: 847.0367 - val_mae: 847.0367 - val_mse: 2256851.7500 - lr: 0.0010\n",
      "Epoch 300/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 151.0822 - mae: 151.0822 - mse: 111141.9453 - val_loss: 987.9390 - val_mae: 987.9390 - val_mse: 2691387.0000 - lr: 0.0010\n",
      "Epoch 301/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 230.9709 - mae: 230.9709 - mse: 204611.3438 - val_loss: 777.6489 - val_mae: 777.6489 - val_mse: 1853856.1250 - lr: 0.0010\n",
      "Epoch 302/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 163.2721 - mae: 163.2721 - mse: 127424.1562 - val_loss: 1565.4060 - val_mae: 1565.4060 - val_mse: 5595961.0000 - lr: 0.0010\n",
      "Epoch 303/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 507.4394 - mae: 507.4394 - mse: 742907.0000 - val_loss: 1582.6271 - val_mae: 1582.6271 - val_mse: 6076892.5000 - lr: 0.0010\n",
      "Epoch 304/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 510.4207 - mae: 510.4207 - mse: 936676.2500 - val_loss: 5118.4482 - val_mae: 5118.4482 - val_mse: 48898992.0000 - lr: 0.0010\n",
      "Epoch 305/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1157.5562 - mae: 1157.5562 - mse: 3464740.0000 - val_loss: 3670.2646 - val_mae: 3670.2646 - val_mse: 25564610.0000 - lr: 0.0010\n",
      "Epoch 306/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 1619.9709 - mae: 1619.9709 - mse: 7137189.5000 - val_loss: 10950.4883 - val_mae: 10950.4883 - val_mse: 211905824.0000 - lr: 0.0010\n",
      "Epoch 307/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 1524.7698 - mae: 1524.7698 - mse: 5559165.0000 - val_loss: 3258.5913 - val_mae: 3258.5913 - val_mse: 20416030.0000 - lr: 0.0010\n",
      "Epoch 308/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 544.4764 - mae: 544.4764 - mse: 870832.5000 - val_loss: 4104.8198 - val_mae: 4104.8198 - val_mse: 31274950.0000 - lr: 0.0010\n",
      "Epoch 309/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 1260.2267 - mae: 1260.2267 - mse: 4305170.0000 - val_loss: 9796.0938 - val_mae: 9796.0938 - val_mse: 169894448.0000 - lr: 0.0010\n",
      "Epoch 310/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 1536.3698 - mae: 1536.3698 - mse: 5786103.5000 - val_loss: 8457.4033 - val_mae: 8457.4033 - val_mse: 127048800.0000 - lr: 0.0010\n",
      "Epoch 311/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 1050.4928 - mae: 1050.4928 - mse: 2661532.2500 - val_loss: 984.5697 - val_mae: 984.5697 - val_mse: 2949254.0000 - lr: 0.0010\n",
      "Epoch 312/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 911.1531 - mae: 911.1531 - mse: 2534916.5000 - val_loss: 1105.5857 - val_mae: 1105.5857 - val_mse: 3873916.2500 - lr: 0.0010\n",
      "Epoch 313/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 597.6984 - mae: 597.6984 - mse: 1138812.5000 - val_loss: 5179.1475 - val_mae: 5179.1475 - val_mse: 48950796.0000 - lr: 0.0010\n",
      "Epoch 314/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 706.0482 - mae: 706.0482 - mse: 1290275.2500 - val_loss: 939.1613 - val_mae: 939.1613 - val_mse: 2950808.2500 - lr: 0.0010\n",
      "Epoch 315/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 706.7165 - mae: 706.7165 - mse: 1578262.5000 - val_loss: 1344.8903 - val_mae: 1344.8903 - val_mse: 5325031.0000 - lr: 0.0010\n",
      "Epoch 316/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 388.1971 - mae: 388.1971 - mse: 532170.5625 - val_loss: 3052.1721 - val_mae: 3052.1721 - val_mse: 18597722.0000 - lr: 0.0010\n",
      "Epoch 317/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 336.5068 - mae: 336.5068 - mse: 375151.9375 - val_loss: 2013.4285 - val_mae: 2013.4285 - val_mse: 10105670.0000 - lr: 0.0010\n",
      "Epoch 318/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 769.3839 - mae: 769.3839 - mse: 1721751.2500 - val_loss: 1105.3412 - val_mae: 1105.3412 - val_mse: 3880788.2500 - lr: 0.0010\n",
      "Epoch 319/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 434.8746 - mae: 434.8746 - mse: 648817.3125 - val_loss: 3615.8647 - val_mae: 3615.8647 - val_mse: 25033082.0000 - lr: 0.0010\n",
      "Epoch 320/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 426.2079 - mae: 426.2079 - mse: 543286.4375 - val_loss: 2214.2605 - val_mae: 2214.2605 - val_mse: 11774121.0000 - lr: 0.0010\n",
      "Epoch 321/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 1013.9614 - mae: 1013.9614 - mse: 2895868.0000 - val_loss: 1483.5828 - val_mae: 1483.5828 - val_mse: 6278663.5000 - lr: 0.0010\n",
      "Epoch 322/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 413.5896 - mae: 413.5896 - mse: 595773.3125 - val_loss: 3390.3899 - val_mae: 3390.3899 - val_mse: 22446666.0000 - lr: 0.0010\n",
      "Epoch 323/5000\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 423.0144 - mae: 423.0144 - mse: 537609.8125 - val_loss: 998.4410 - val_mae: 998.4410 - val_mse: 3322055.5000 - lr: 0.0010\n",
      "Epoch 324/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 478.6330 - mae: 478.6330 - mse: 786717.0000 - val_loss: 1458.8473 - val_mae: 1458.8473 - val_mse: 6039376.0000 - lr: 0.0010\n",
      "Epoch 325/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 224.3631 - mae: 224.3631 - mse: 217642.7656 - val_loss: 1559.8845 - val_mae: 1559.8845 - val_mse: 5866679.0000 - lr: 0.0010\n",
      "Epoch 326/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 204ms/step - loss: 193.1801 - mae: 193.1801 - mse: 169553.1875 - val_loss: 936.0861 - val_mae: 936.0861 - val_mse: 2950981.0000 - lr: 0.0010\n",
      "Epoch 327/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 171.3128 - mae: 171.3128 - mse: 153204.0938 - val_loss: 1199.2577 - val_mae: 1199.2577 - val_mse: 3797189.0000 - lr: 0.0010\n",
      "Epoch 328/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 238.1579 - mae: 238.1579 - mse: 229015.8750 - val_loss: 929.4086 - val_mae: 929.4086 - val_mse: 2906521.7500 - lr: 0.0010\n",
      "Epoch 329/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 314.8619 - mae: 314.8619 - mse: 377831.9375 - val_loss: 921.9610 - val_mae: 921.9610 - val_mse: 2745171.2500 - lr: 0.0010\n",
      "Epoch 330/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 330.4099 - mae: 330.4099 - mse: 391913.8438 - val_loss: 1846.8772 - val_mae: 1846.8772 - val_mse: 7784392.5000 - lr: 0.0010\n",
      "Epoch 331/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 198.8539 - mae: 198.8539 - mse: 168070.6406 - val_loss: 1038.6415 - val_mae: 1038.6415 - val_mse: 3480288.2500 - lr: 0.0010\n",
      "Epoch 332/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 189.6654 - mae: 189.6654 - mse: 171148.4844 - val_loss: 1303.6243 - val_mae: 1303.6243 - val_mse: 4307594.0000 - lr: 0.0010\n",
      "Epoch 333/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 296.8650 - mae: 296.8650 - mse: 320059.0625 - val_loss: 1196.2913 - val_mae: 1196.2913 - val_mse: 3794831.5000 - lr: 0.0010\n",
      "Epoch 334/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 201.1861 - mae: 201.1861 - mse: 193950.8750 - val_loss: 969.8149 - val_mae: 969.8149 - val_mse: 3131517.2500 - lr: 0.0010\n",
      "Epoch 335/5000\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 176.3300 - mae: 176.3300 - mse: 157537.7812 - val_loss: 1025.3099 - val_mae: 1025.3099 - val_mse: 3102254.0000 - lr: 0.0010\n",
      "Epoch 336/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 167.1382 - mae: 167.1382 - mse: 148428.5000 - val_loss: 944.0195 - val_mae: 944.0195 - val_mse: 2824176.2500 - lr: 0.0010\n",
      "Epoch 337/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 180.0232 - mae: 180.0232 - mse: 158665.9531 - val_loss: 897.3577 - val_mae: 897.3577 - val_mse: 2713146.0000 - lr: 0.0010\n",
      "Epoch 338/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 204.0061 - mae: 204.0061 - mse: 191463.9688 - val_loss: 994.3588 - val_mae: 994.3588 - val_mse: 2924609.5000 - lr: 0.0010\n",
      "Epoch 339/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 253.1690 - mae: 253.1690 - mse: 252372.1094 - val_loss: 1131.0106 - val_mae: 1131.0106 - val_mse: 3443867.7500 - lr: 0.0010\n",
      "Epoch 340/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 188.6027 - mae: 188.6027 - mse: 173928.0000 - val_loss: 903.6848 - val_mae: 903.6848 - val_mse: 2755986.0000 - lr: 0.0010\n",
      "Epoch 341/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 174.2365 - mae: 174.2365 - mse: 151111.4375 - val_loss: 952.4537 - val_mae: 952.4537 - val_mse: 2780240.5000 - lr: 0.0010\n",
      "Epoch 342/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 167.0422 - mae: 167.0422 - mse: 146268.7188 - val_loss: 948.9766 - val_mae: 948.9766 - val_mse: 2756239.2500 - lr: 0.0010\n",
      "Epoch 343/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 196.4549 - mae: 196.4549 - mse: 174235.0469 - val_loss: 885.6779 - val_mae: 885.6779 - val_mse: 2593493.5000 - lr: 0.0010\n",
      "Epoch 344/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 208.8951 - mae: 208.8951 - mse: 198545.1875 - val_loss: 880.9627 - val_mae: 880.9627 - val_mse: 2575985.0000 - lr: 0.0010\n",
      "Epoch 345/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 212.5526 - mae: 212.5526 - mse: 194486.0781 - val_loss: 973.9721 - val_mae: 973.9721 - val_mse: 2810107.7500 - lr: 0.0010\n",
      "Epoch 346/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 195.1374 - mae: 195.1374 - mse: 180895.8125 - val_loss: 872.7310 - val_mae: 872.7310 - val_mse: 2581476.2500 - lr: 0.0010\n",
      "Epoch 347/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 185.6109 - mae: 185.6109 - mse: 161334.7969 - val_loss: 936.4437 - val_mae: 936.4437 - val_mse: 2684675.2500 - lr: 0.0010\n",
      "Epoch 348/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 177.7692 - mae: 177.7692 - mse: 157456.6094 - val_loss: 890.2189 - val_mae: 890.2189 - val_mse: 2550018.5000 - lr: 0.0010\n",
      "Epoch 349/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 198.7756 - mae: 198.7756 - mse: 175776.1250 - val_loss: 898.4977 - val_mae: 898.4977 - val_mse: 2567774.7500 - lr: 0.0010\n",
      "Epoch 350/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 200.2553 - mae: 200.2553 - mse: 186521.7656 - val_loss: 860.4253 - val_mae: 860.4253 - val_mse: 2511495.2500 - lr: 0.0010\n",
      "Epoch 351/5000\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 192.1458 - mae: 192.1458 - mse: 167800.9688 - val_loss: 952.4391 - val_mae: 952.4391 - val_mse: 2707566.2500 - lr: 0.0010\n",
      "Epoch 352/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 178.1584 - mae: 178.1584 - mse: 157727.5156 - val_loss: 868.1718 - val_mae: 868.1718 - val_mse: 2487606.2500 - lr: 0.0010\n",
      "Epoch 353/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 192.1743 - mae: 192.1743 - mse: 167219.2031 - val_loss: 907.1473 - val_mae: 907.1473 - val_mse: 2564846.7500 - lr: 0.0010\n",
      "Epoch 354/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 186.2119 - mae: 186.2119 - mse: 167044.5469 - val_loss: 858.5454 - val_mae: 858.5454 - val_mse: 2452233.0000 - lr: 0.0010\n",
      "Epoch 355/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 194.4883 - mae: 194.4883 - mse: 169631.6719 - val_loss: 930.7442 - val_mae: 930.7442 - val_mse: 2620621.0000 - lr: 0.0010\n",
      "Epoch 356/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 181.0771 - mae: 181.0771 - mse: 160669.0469 - val_loss: 851.0927 - val_mae: 851.0927 - val_mse: 2431215.5000 - lr: 0.0010\n",
      "Epoch 357/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 186.2611 - mae: 186.2611 - mse: 159841.8594 - val_loss: 913.9529 - val_mae: 913.9529 - val_mse: 2563198.2500 - lr: 0.0010\n",
      "Epoch 358/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 175.7635 - mae: 175.7635 - mse: 153588.2656 - val_loss: 863.2814 - val_mae: 863.2814 - val_mse: 2430420.7500 - lr: 0.0010\n",
      "Epoch 359/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 193.4834 - mae: 193.4834 - mse: 167612.0000 - val_loss: 913.1404 - val_mae: 913.1404 - val_mse: 2546049.5000 - lr: 0.0010\n",
      "Epoch 360/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 179.5052 - mae: 179.5052 - mse: 157781.6094 - val_loss: 842.1389 - val_mae: 842.1389 - val_mse: 2378555.0000 - lr: 0.0010\n",
      "Epoch 361/5000\n",
      "3/3 [==============================] - 1s 192ms/step - loss: 186.0188 - mae: 186.0188 - mse: 158507.5938 - val_loss: 898.4073 - val_mae: 898.4073 - val_mse: 2491179.5000 - lr: 0.0010\n",
      "Epoch 362/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 176.7426 - mae: 176.7426 - mse: 153852.3594 - val_loss: 846.6034 - val_mae: 846.6034 - val_mse: 2363164.0000 - lr: 0.0010\n",
      "Epoch 363/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 190.5529 - mae: 190.5529 - mse: 163243.6406 - val_loss: 908.4542 - val_mae: 908.4542 - val_mse: 2506812.7500 - lr: 0.0010\n",
      "Epoch 364/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 175.3576 - mae: 175.3576 - mse: 151999.3594 - val_loss: 835.4868 - val_mae: 835.4868 - val_mse: 2329220.5000 - lr: 0.0010\n",
      "Epoch 365/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 185.2066 - mae: 185.2066 - mse: 156575.8281 - val_loss: 887.8150 - val_mae: 887.8150 - val_mse: 2435735.5000 - lr: 0.0010\n",
      "Epoch 366/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 175.0470 - mae: 175.0470 - mse: 151026.5312 - val_loss: 835.1497 - val_mae: 835.1497 - val_mse: 2305648.5000 - lr: 0.0010\n",
      "Epoch 367/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 188.5278 - mae: 188.5278 - mse: 159867.3125 - val_loss: 883.1151 - val_mae: 883.1151 - val_mse: 2409962.5000 - lr: 0.0010\n",
      "Epoch 368/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 177.5421 - mae: 177.5421 - mse: 153578.9844 - val_loss: 822.1196 - val_mae: 822.1196 - val_mse: 2273718.5000 - lr: 0.0010\n",
      "Epoch 369/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 183.5538 - mae: 183.5538 - mse: 153942.3594 - val_loss: 880.1675 - val_mae: 880.1675 - val_mse: 2390625.2500 - lr: 0.0010\n",
      "Epoch 370/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 172.8346 - mae: 172.8346 - mse: 147652.0000 - val_loss: 824.0499 - val_mae: 824.0499 - val_mse: 2252516.0000 - lr: 0.0010\n",
      "Epoch 371/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 185.3490 - mae: 185.3490 - mse: 155304.7031 - val_loss: 864.8967 - val_mae: 864.8967 - val_mse: 2335515.5000 - lr: 0.0010\n",
      "Epoch 372/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 176.7806 - mae: 176.7806 - mse: 151832.4062 - val_loss: 812.0309 - val_mae: 812.0309 - val_mse: 2223771.5000 - lr: 0.0010\n",
      "Epoch 373/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 182.2642 - mae: 182.2642 - mse: 151481.6094 - val_loss: 874.4769 - val_mae: 874.4769 - val_mse: 2351510.7500 - lr: 0.0010\n",
      "Epoch 374/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 170.0613 - mae: 170.0613 - mse: 143779.5000 - val_loss: 813.6000 - val_mae: 813.6000 - val_mse: 2205519.5000 - lr: 0.0010\n",
      "Epoch 375/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 181.5580 - mae: 181.5580 - mse: 150365.6250 - val_loss: 848.5930 - val_mae: 848.5930 - val_mse: 2271645.0000 - lr: 0.0010\n",
      "Epoch 376/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 175.2191 - mae: 175.2191 - mse: 149086.8125 - val_loss: 803.0781 - val_mae: 803.0781 - val_mse: 2165860.7500 - lr: 0.0010\n",
      "Epoch 377/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 182.0666 - mae: 182.0666 - mse: 150270.3594 - val_loss: 843.9564 - val_mae: 843.9564 - val_mse: 2242465.5000 - lr: 0.0010\n",
      "Epoch 378/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 175.7892 - mae: 175.7892 - mse: 149455.9219 - val_loss: 796.4883 - val_mae: 796.4883 - val_mse: 2150946.7500 - lr: 0.0010\n",
      "Epoch 379/5000\n",
      "3/3 [==============================] - 1s 323ms/step - loss: 179.1662 - mae: 179.1662 - mse: 146726.4531 - val_loss: 851.4343 - val_mae: 851.4343 - val_mse: 2255031.7500 - lr: 0.0010\n",
      "Epoch 380/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 169.6326 - mae: 169.6326 - mse: 142044.0469 - val_loss: 794.5425 - val_mae: 794.5425 - val_mse: 2122539.5000 - lr: 0.0010\n",
      "Epoch 381/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 177.7858 - mae: 177.7858 - mse: 144591.9375 - val_loss: 823.4816 - val_mae: 823.4816 - val_mse: 2165966.7500 - lr: 0.0010\n",
      "Epoch 382/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 174.7913 - mae: 174.7913 - mse: 147214.8750 - val_loss: 787.5031 - val_mae: 787.5031 - val_mse: 2089385.6250 - lr: 0.0010\n",
      "Epoch 383/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 181.3044 - mae: 181.3044 - mse: 147823.6406 - val_loss: 833.2357 - val_mae: 833.2357 - val_mse: 2174568.7500 - lr: 0.0010\n",
      "Epoch 384/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 171.3393 - mae: 171.3393 - mse: 142924.2031 - val_loss: 780.7078 - val_mae: 780.7078 - val_mse: 2057544.7500 - lr: 0.0010\n",
      "Epoch 385/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 178.6679 - mae: 178.6679 - mse: 144555.3594 - val_loss: 817.1486 - val_mae: 817.1486 - val_mse: 2121605.0000 - lr: 0.0010\n",
      "Epoch 386/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 173.7868 - mae: 173.7868 - mse: 145362.1562 - val_loss: 778.2283 - val_mae: 778.2283 - val_mse: 2044065.1250 - lr: 0.0010\n",
      "Epoch 387/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 181.5212 - mae: 181.5212 - mse: 147472.3438 - val_loss: 840.1803 - val_mae: 840.1803 - val_mse: 2177002.2500 - lr: 0.0010\n",
      "Epoch 388/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 166.9048 - mae: 166.9048 - mse: 137513.9062 - val_loss: 773.0583 - val_mae: 773.0583 - val_mse: 2029443.8750 - lr: 0.0010\n",
      "Epoch 389/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 171.8334 - mae: 171.8334 - mse: 136741.6406 - val_loss: 801.3837 - val_mae: 801.3837 - val_mse: 2066029.6250 - lr: 0.0010\n",
      "Epoch 390/5000\n",
      "3/3 [==============================] - ETA: 0s - loss: 169.8947 - mae: 169.8947 - mse: 139901.2656\n",
      "Epoch 390: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 169.8947 - mae: 169.8947 - mse: 139901.2656 - val_loss: 775.5461 - val_mae: 775.5461 - val_mse: 2004405.1250 - lr: 0.0010\n",
      "Epoch 391/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 138.5639 - mae: 138.5639 - mse: 107301.4453 - val_loss: 818.8994 - val_mae: 818.8994 - val_mse: 2100938.7500 - lr: 1.0000e-04\n",
      "Epoch 392/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 141.8728 - mae: 141.8728 - mse: 109144.5859 - val_loss: 831.0596 - val_mae: 831.0596 - val_mse: 2130276.5000 - lr: 1.0000e-04\n",
      "Epoch 393/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 141.0392 - mae: 141.0392 - mse: 108216.9844 - val_loss: 800.9738 - val_mae: 800.9738 - val_mse: 2045697.8750 - lr: 1.0000e-04\n",
      "Epoch 394/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 137.8513 - mae: 137.8513 - mse: 106045.7188 - val_loss: 770.3763 - val_mae: 770.3763 - val_mse: 1969646.5000 - lr: 1.0000e-04\n",
      "Epoch 395/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 136.7139 - mae: 136.7139 - mse: 105188.9844 - val_loss: 758.8911 - val_mae: 758.8911 - val_mse: 1938301.2500 - lr: 1.0000e-04\n",
      "Epoch 396/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 135.9398 - mae: 135.9398 - mse: 104279.4844 - val_loss: 760.2831 - val_mae: 760.2831 - val_mse: 1922306.1250 - lr: 1.0000e-04\n",
      "Epoch 397/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 135.0487 - mae: 135.0487 - mse: 103179.9062 - val_loss: 770.0551 - val_mae: 770.0551 - val_mse: 1926688.8750 - lr: 1.0000e-04\n",
      "Epoch 398/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 135.3364 - mae: 135.3364 - mse: 102614.6328 - val_loss: 771.0400 - val_mae: 771.0400 - val_mse: 1916112.2500 - lr: 1.0000e-04\n",
      "Epoch 399/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 134.6040 - mae: 134.6040 - mse: 101585.3828 - val_loss: 755.6962 - val_mae: 755.6962 - val_mse: 1869061.0000 - lr: 1.0000e-04\n",
      "Epoch 400/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 132.8786 - mae: 132.8786 - mse: 100247.8594 - val_loss: 740.6154 - val_mae: 740.6154 - val_mse: 1825909.6250 - lr: 1.0000e-04\n",
      "Epoch 401/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 131.9683 - mae: 131.9683 - mse: 99392.0859 - val_loss: 736.8804 - val_mae: 736.8804 - val_mse: 1807584.5000 - lr: 1.0000e-04\n",
      "Epoch 402/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 131.4101 - mae: 131.4101 - mse: 98602.6641 - val_loss: 741.6740 - val_mae: 741.6740 - val_mse: 1808365.5000 - lr: 1.0000e-04\n",
      "Epoch 403/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 131.6307 - mae: 131.6307 - mse: 98169.8984 - val_loss: 743.9173 - val_mae: 743.9173 - val_mse: 1806976.0000 - lr: 1.0000e-04\n",
      "Epoch 404/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 131.2382 - mae: 131.2382 - mse: 97575.7969 - val_loss: 735.7036 - val_mae: 735.7036 - val_mse: 1782897.8750 - lr: 1.0000e-04\n",
      "Epoch 405/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 130.2923 - mae: 130.2923 - mse: 96897.0234 - val_loss: 727.9256 - val_mae: 727.9256 - val_mse: 1761122.2500 - lr: 1.0000e-04\n",
      "Epoch 406/5000\n",
      "3/3 [==============================] - 1s 190ms/step - loss: 129.7131 - mae: 129.7131 - mse: 96392.2422 - val_loss: 725.8885 - val_mae: 725.8885 - val_mse: 1751375.1250 - lr: 1.0000e-04\n",
      "Epoch 407/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 224ms/step - loss: 129.4276 - mae: 129.4276 - mse: 95939.1562 - val_loss: 727.8069 - val_mae: 727.8069 - val_mse: 1750007.7500 - lr: 1.0000e-04\n",
      "Epoch 408/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 129.4400 - mae: 129.4400 - mse: 95589.4375 - val_loss: 729.0076 - val_mae: 729.0076 - val_mse: 1747752.6250 - lr: 1.0000e-04\n",
      "Epoch 409/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 129.2536 - mae: 129.2536 - mse: 95182.3359 - val_loss: 724.7917 - val_mae: 724.7917 - val_mse: 1733438.5000 - lr: 1.0000e-04\n",
      "Epoch 410/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 128.6220 - mae: 128.6220 - mse: 94657.9453 - val_loss: 719.1005 - val_mae: 719.1005 - val_mse: 1716034.0000 - lr: 1.0000e-04\n",
      "Epoch 411/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 128.0807 - mae: 128.0807 - mse: 94179.3984 - val_loss: 716.3527 - val_mae: 716.3527 - val_mse: 1704788.3750 - lr: 1.0000e-04\n",
      "Epoch 412/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 127.7566 - mae: 127.7566 - mse: 93754.0547 - val_loss: 715.9355 - val_mae: 715.9355 - val_mse: 1699195.1250 - lr: 1.0000e-04\n",
      "Epoch 413/5000\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 127.5811 - mae: 127.5811 - mse: 93368.8516 - val_loss: 715.2526 - val_mae: 715.2526 - val_mse: 1692469.6250 - lr: 1.0000e-04\n",
      "Epoch 414/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 127.3019 - mae: 127.3019 - mse: 92951.4922 - val_loss: 712.6180 - val_mae: 712.6180 - val_mse: 1681421.6250 - lr: 1.0000e-04\n",
      "Epoch 415/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 126.8782 - mae: 126.8782 - mse: 92492.7734 - val_loss: 708.8447 - val_mae: 708.8447 - val_mse: 1667615.2500 - lr: 1.0000e-04\n",
      "Epoch 416/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 126.3939 - mae: 126.3939 - mse: 92026.0000 - val_loss: 705.9984 - val_mae: 705.9984 - val_mse: 1655604.7500 - lr: 1.0000e-04\n",
      "Epoch 417/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 126.0400 - mae: 126.0400 - mse: 91599.5391 - val_loss: 704.2369 - val_mae: 704.2369 - val_mse: 1646688.0000 - lr: 1.0000e-04\n",
      "Epoch 418/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 125.7351 - mae: 125.7351 - mse: 91181.7969 - val_loss: 702.7778 - val_mae: 702.7778 - val_mse: 1638660.8750 - lr: 1.0000e-04\n",
      "Epoch 419/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 125.4515 - mae: 125.4515 - mse: 90774.9531 - val_loss: 700.8456 - val_mae: 700.8456 - val_mse: 1629513.6250 - lr: 1.0000e-04\n",
      "Epoch 420/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 125.1074 - mae: 125.1074 - mse: 90353.8828 - val_loss: 698.4929 - val_mae: 698.4929 - val_mse: 1619418.0000 - lr: 1.0000e-04\n",
      "Epoch 421/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 124.7423 - mae: 124.7423 - mse: 89927.2500 - val_loss: 696.1773 - val_mae: 696.1773 - val_mse: 1609447.6250 - lr: 1.0000e-04\n",
      "Epoch 422/5000\n",
      "3/3 [==============================] - 1s 198ms/step - loss: 124.3956 - mae: 124.3956 - mse: 89510.0000 - val_loss: 693.9127 - val_mae: 693.9127 - val_mse: 1599639.7500 - lr: 1.0000e-04\n",
      "Epoch 423/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 124.0536 - mae: 124.0536 - mse: 89099.7734 - val_loss: 691.0930 - val_mae: 691.0930 - val_mse: 1588651.2500 - lr: 1.0000e-04\n",
      "Epoch 424/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 123.6400 - mae: 123.6400 - mse: 88662.1406 - val_loss: 688.9197 - val_mae: 688.9197 - val_mse: 1579185.7500 - lr: 1.0000e-04\n",
      "Epoch 425/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 123.3993 - mae: 123.3993 - mse: 88275.8203 - val_loss: 687.3142 - val_mae: 687.3142 - val_mse: 1571242.1250 - lr: 1.0000e-04\n",
      "Epoch 426/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 123.0216 - mae: 123.0216 - mse: 87846.0312 - val_loss: 683.2831 - val_mae: 683.2831 - val_mse: 1557938.1250 - lr: 1.0000e-04\n",
      "Epoch 427/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 122.5494 - mae: 122.5494 - mse: 87403.7266 - val_loss: 680.4628 - val_mae: 680.4628 - val_mse: 1547424.7500 - lr: 1.0000e-04\n",
      "Epoch 428/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 122.2419 - mae: 122.2419 - mse: 87007.2109 - val_loss: 680.2420 - val_mae: 680.2420 - val_mse: 1542916.6250 - lr: 1.0000e-04\n",
      "Epoch 429/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 122.1232 - mae: 122.1232 - mse: 86668.6875 - val_loss: 679.9900 - val_mae: 679.9900 - val_mse: 1538174.5000 - lr: 1.0000e-04\n",
      "Epoch 430/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 121.8709 - mae: 121.8709 - mse: 86284.6250 - val_loss: 676.3309 - val_mae: 676.3309 - val_mse: 1525662.3750 - lr: 1.0000e-04\n",
      "Epoch 431/5000\n",
      "3/3 [==============================] - 1s 199ms/step - loss: 121.3414 - mae: 121.3414 - mse: 85819.6172 - val_loss: 672.4987 - val_mae: 672.4987 - val_mse: 1513095.3750 - lr: 1.0000e-04\n",
      "Epoch 432/5000\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 120.9506 - mae: 120.9506 - mse: 85407.9844 - val_loss: 671.4540 - val_mae: 671.4540 - val_mse: 1506459.8750 - lr: 1.0000e-04\n",
      "Epoch 433/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 120.7727 - mae: 120.7727 - mse: 85054.6484 - val_loss: 670.3318 - val_mae: 670.3318 - val_mse: 1499554.5000 - lr: 1.0000e-04\n",
      "Epoch 434/5000\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 120.4495 - mae: 120.4495 - mse: 84648.5312 - val_loss: 667.4250 - val_mae: 667.4250 - val_mse: 1489029.0000 - lr: 1.0000e-04\n",
      "Epoch 435/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 120.1116 - mae: 120.1116 - mse: 84259.7891 - val_loss: 665.9213 - val_mae: 665.9213 - val_mse: 1481752.1250 - lr: 1.0000e-04\n",
      "Epoch 436/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 119.8979 - mae: 119.8979 - mse: 83922.4766 - val_loss: 664.9166 - val_mae: 664.9166 - val_mse: 1475949.1250 - lr: 1.0000e-04\n",
      "Epoch 437/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 119.6799 - mae: 119.6799 - mse: 83594.4062 - val_loss: 661.6429 - val_mae: 661.6429 - val_mse: 1465850.6250 - lr: 1.0000e-04\n",
      "Epoch 438/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 119.2212 - mae: 119.2212 - mse: 83203.4688 - val_loss: 657.4615 - val_mae: 657.4615 - val_mse: 1454480.6250 - lr: 1.0000e-04\n",
      "Epoch 439/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 118.8843 - mae: 118.8843 - mse: 82893.5000 - val_loss: 657.8798 - val_mae: 657.8798 - val_mse: 1451790.5000 - lr: 1.0000e-04\n",
      "Epoch 440/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 118.9453 - mae: 118.9453 - mse: 82688.6797 - val_loss: 656.7105 - val_mae: 656.7105 - val_mse: 1446582.7500 - lr: 1.0000e-04\n",
      "Epoch 441/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 118.5049 - mae: 118.5049 - mse: 82348.1172 - val_loss: 651.5657 - val_mae: 651.5657 - val_mse: 1434413.2500 - lr: 1.0000e-04\n",
      "Epoch 442/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 118.1239 - mae: 118.1239 - mse: 82082.1328 - val_loss: 651.8389 - val_mae: 651.8389 - val_mse: 1432165.7500 - lr: 1.0000e-04\n",
      "Epoch 443/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 118.2147 - mae: 118.2147 - mse: 81904.2109 - val_loss: 650.5486 - val_mae: 650.5486 - val_mse: 1427269.1250 - lr: 1.0000e-04\n",
      "Epoch 444/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 117.7701 - mae: 117.7701 - mse: 81621.4531 - val_loss: 646.9498 - val_mae: 646.9498 - val_mse: 1418367.1250 - lr: 1.0000e-04\n",
      "Epoch 445/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 117.5850 - mae: 117.5850 - mse: 81415.5938 - val_loss: 647.4128 - val_mae: 647.4128 - val_mse: 1416826.8750 - lr: 1.0000e-04\n",
      "Epoch 446/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 117.5125 - mae: 117.5125 - mse: 81220.0078 - val_loss: 645.2397 - val_mae: 645.2397 - val_mse: 1410721.3750 - lr: 1.0000e-04\n",
      "Epoch 447/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 117.2089 - mae: 117.2089 - mse: 81003.9062 - val_loss: 643.8548 - val_mae: 643.8548 - val_mse: 1406190.5000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 448/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 117.1454 - mae: 117.1454 - mse: 80832.0469 - val_loss: 643.2886 - val_mae: 643.2886 - val_mse: 1403164.3750 - lr: 1.0000e-04\n",
      "Epoch 449/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 116.9334 - mae: 116.9334 - mse: 80641.3672 - val_loss: 641.3871 - val_mae: 641.3871 - val_mse: 1397990.2500 - lr: 1.0000e-04\n",
      "Epoch 450/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 116.7883 - mae: 116.7883 - mse: 80473.0391 - val_loss: 641.1815 - val_mae: 641.1815 - val_mse: 1395679.0000 - lr: 1.0000e-04\n",
      "Epoch 451/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 116.7341 - mae: 116.7341 - mse: 80317.0703 - val_loss: 638.9701 - val_mae: 638.9701 - val_mse: 1390208.7500 - lr: 1.0000e-04\n",
      "Epoch 452/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 116.4262 - mae: 116.4262 - mse: 80149.1172 - val_loss: 637.7414 - val_mae: 637.7414 - val_mse: 1386459.1250 - lr: 1.0000e-04\n",
      "Epoch 453/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 116.4343 - mae: 116.4343 - mse: 80007.6875 - val_loss: 638.4131 - val_mae: 638.4131 - val_mse: 1385713.1250 - lr: 1.0000e-04\n",
      "Epoch 454/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 116.3217 - mae: 116.3217 - mse: 79862.5625 - val_loss: 636.4520 - val_mae: 636.4520 - val_mse: 1381019.1250 - lr: 1.0000e-04\n",
      "Epoch 455/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 116.1560 - mae: 116.1560 - mse: 79726.8281 - val_loss: 636.1018 - val_mae: 636.1018 - val_mse: 1378899.8750 - lr: 1.0000e-04\n",
      "Epoch 456/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 116.1347 - mae: 116.1347 - mse: 79607.0625 - val_loss: 634.6343 - val_mae: 634.6343 - val_mse: 1375198.1250 - lr: 1.0000e-04\n",
      "Epoch 457/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 115.8891 - mae: 115.8891 - mse: 79477.4844 - val_loss: 633.1828 - val_mae: 633.1828 - val_mse: 1371658.7500 - lr: 1.0000e-04\n",
      "Epoch 458/5000\n",
      "3/3 [==============================] - 1s 251ms/step - loss: 115.8551 - mae: 115.8551 - mse: 79360.1719 - val_loss: 634.7340 - val_mae: 634.7340 - val_mse: 1372513.3750 - lr: 1.0000e-04\n",
      "Epoch 459/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 115.9504 - mae: 115.9504 - mse: 79262.3906 - val_loss: 632.6635 - val_mae: 632.6635 - val_mse: 1368028.2500 - lr: 1.0000e-04\n",
      "Epoch 460/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 115.6095 - mae: 115.6095 - mse: 79135.3594 - val_loss: 630.8678 - val_mae: 630.8678 - val_mse: 1364174.7500 - lr: 1.0000e-04\n",
      "Epoch 461/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 115.5911 - mae: 115.5911 - mse: 79024.7188 - val_loss: 632.5090 - val_mae: 632.5090 - val_mse: 1365130.3750 - lr: 1.0000e-04\n",
      "Epoch 462/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 115.6354 - mae: 115.6354 - mse: 78924.2656 - val_loss: 630.4990 - val_mae: 630.4990 - val_mse: 1360876.2500 - lr: 1.0000e-04\n",
      "Epoch 463/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 115.3647 - mae: 115.3647 - mse: 78809.2266 - val_loss: 628.9755 - val_mae: 628.9755 - val_mse: 1357497.8750 - lr: 1.0000e-04\n",
      "Epoch 464/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 115.3156 - mae: 115.3156 - mse: 78705.2422 - val_loss: 630.0986 - val_mae: 630.0986 - val_mse: 1357793.6250 - lr: 1.0000e-04\n",
      "Epoch 465/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 115.3645 - mae: 115.3645 - mse: 78610.4141 - val_loss: 628.4313 - val_mae: 628.4313 - val_mse: 1354162.5000 - lr: 1.0000e-04\n",
      "Epoch 466/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 115.0907 - mae: 115.0907 - mse: 78502.1875 - val_loss: 626.7352 - val_mae: 626.7352 - val_mse: 1350646.6250 - lr: 1.0000e-04\n",
      "Epoch 467/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 115.0476 - mae: 115.0476 - mse: 78399.1953 - val_loss: 628.1512 - val_mae: 628.1512 - val_mse: 1351411.3750 - lr: 1.0000e-04\n",
      "Epoch 468/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 115.1343 - mae: 115.1343 - mse: 78309.7031 - val_loss: 625.5434 - val_mae: 625.5434 - val_mse: 1346565.1250 - lr: 1.0000e-04\n",
      "Epoch 469/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 114.7629 - mae: 114.7629 - mse: 78232.6562 - val_loss: 624.3517 - val_mae: 624.3517 - val_mse: 1343822.0000 - lr: 1.0000e-04\n",
      "Epoch 470/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 114.9387 - mae: 114.9387 - mse: 78118.0703 - val_loss: 626.6086 - val_mae: 626.6086 - val_mse: 1345839.0000 - lr: 1.0000e-04\n",
      "Epoch 471/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 114.7591 - mae: 114.7591 - mse: 78002.9766 - val_loss: 623.6188 - val_mae: 623.6188 - val_mse: 1340368.6250 - lr: 1.0000e-04\n",
      "Epoch 472/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 114.6211 - mae: 114.6211 - mse: 77906.8672 - val_loss: 623.3215 - val_mae: 623.3215 - val_mse: 1338766.2500 - lr: 1.0000e-04\n",
      "Epoch 473/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 114.5287 - mae: 114.5287 - mse: 77809.1094 - val_loss: 621.9355 - val_mae: 621.9355 - val_mse: 1335664.7500 - lr: 1.0000e-04\n",
      "Epoch 474/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 114.3831 - mae: 114.3831 - mse: 77721.7422 - val_loss: 623.0542 - val_mae: 623.0542 - val_mse: 1336138.1250 - lr: 1.0000e-04\n",
      "Epoch 475/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 114.7490 - mae: 114.7490 - mse: 77660.4062 - val_loss: 622.1705 - val_mae: 622.1705 - val_mse: 1333700.5000 - lr: 1.0000e-04\n",
      "Epoch 476/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 114.2256 - mae: 114.2256 - mse: 77561.9141 - val_loss: 619.0587 - val_mae: 619.0587 - val_mse: 1328465.7500 - lr: 1.0000e-04\n",
      "Epoch 477/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 114.2757 - mae: 114.2757 - mse: 77439.0859 - val_loss: 620.7315 - val_mae: 620.7315 - val_mse: 1329415.5000 - lr: 1.0000e-04\n",
      "Epoch 478/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 114.0932 - mae: 114.0932 - mse: 77349.7188 - val_loss: 619.8870 - val_mae: 619.8870 - val_mse: 1327081.8750 - lr: 1.0000e-04\n",
      "Epoch 479/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 114.3297 - mae: 114.3297 - mse: 77276.0312 - val_loss: 619.4039 - val_mae: 619.4039 - val_mse: 1325258.3750 - lr: 1.0000e-04\n",
      "Epoch 480/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 113.9038 - mae: 113.9038 - mse: 77208.0312 - val_loss: 617.2645 - val_mae: 617.2645 - val_mse: 1321452.8750 - lr: 1.0000e-04\n",
      "Epoch 481/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 114.0906 - mae: 114.0906 - mse: 77091.2031 - val_loss: 618.1508 - val_mae: 618.1508 - val_mse: 1321286.0000 - lr: 1.0000e-04\n",
      "Epoch 482/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 113.7534 - mae: 113.7534 - mse: 77040.3516 - val_loss: 616.1488 - val_mae: 616.1488 - val_mse: 1317819.7500 - lr: 1.0000e-04\n",
      "Epoch 483/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 113.9553 - mae: 113.9553 - mse: 76920.6250 - val_loss: 617.1793 - val_mae: 617.1793 - val_mse: 1317790.8750 - lr: 1.0000e-04\n",
      "Epoch 484/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 113.6106 - mae: 113.6106 - mse: 76874.9609 - val_loss: 615.1440 - val_mae: 615.1440 - val_mse: 1314356.2500 - lr: 1.0000e-04\n",
      "Epoch 485/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 113.8205 - mae: 113.8205 - mse: 76753.5781 - val_loss: 616.1651 - val_mae: 616.1651 - val_mse: 1314311.3750 - lr: 1.0000e-04\n",
      "Epoch 486/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 113.4693 - mae: 113.4693 - mse: 76713.2891 - val_loss: 614.7578 - val_mae: 614.7578 - val_mse: 1311611.0000 - lr: 1.0000e-04\n",
      "Epoch 487/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 113.8451 - mae: 113.8451 - mse: 76612.6016 - val_loss: 615.6525 - val_mae: 615.6525 - val_mse: 1311666.6250 - lr: 1.0000e-04\n",
      "Epoch 488/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 113.3452 - mae: 113.3452 - mse: 76581.3516 - val_loss: 612.3751 - val_mae: 612.3751 - val_mse: 1307276.0000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 489/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 113.4972 - mae: 113.4972 - mse: 76436.7734 - val_loss: 614.5499 - val_mae: 614.5499 - val_mse: 1308397.3750 - lr: 1.0000e-04\n",
      "Epoch 490/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 113.2133 - mae: 113.2133 - mse: 76390.6875 - val_loss: 612.3607 - val_mae: 612.3607 - val_mse: 1305042.5000 - lr: 1.0000e-04\n",
      "Epoch 491/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 113.3657 - mae: 113.3657 - mse: 76281.6797 - val_loss: 612.9985 - val_mae: 612.9985 - val_mse: 1304685.8750 - lr: 1.0000e-04\n",
      "Epoch 492/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 113.0661 - mae: 113.0661 - mse: 76264.7188 - val_loss: 611.6967 - val_mae: 611.6967 - val_mse: 1302395.0000 - lr: 1.0000e-04\n",
      "Epoch 493/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 113.3688 - mae: 113.3688 - mse: 76145.4297 - val_loss: 611.8257 - val_mae: 611.8257 - val_mse: 1301554.6250 - lr: 1.0000e-04\n",
      "Epoch 494/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 112.9317 - mae: 112.9317 - mse: 76189.4453 - val_loss: 609.7533 - val_mae: 609.7533 - val_mse: 1298717.8750 - lr: 1.0000e-04\n",
      "Epoch 495/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 113.2122 - mae: 113.2122 - mse: 76001.5547 - val_loss: 612.0599 - val_mae: 612.0599 - val_mse: 1300047.5000 - lr: 1.0000e-04\n",
      "Epoch 496/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 112.8349 - mae: 112.8349 - mse: 75977.6016 - val_loss: 609.4449 - val_mae: 609.4449 - val_mse: 1296392.6250 - lr: 1.0000e-04\n",
      "Epoch 497/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 113.0204 - mae: 113.0204 - mse: 75855.2344 - val_loss: 610.1952 - val_mae: 610.1952 - val_mse: 1296172.0000 - lr: 1.0000e-04\n",
      "Epoch 498/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 112.6823 - mae: 112.6823 - mse: 75869.9062 - val_loss: 608.7003 - val_mae: 608.7003 - val_mse: 1293788.8750 - lr: 1.0000e-04\n",
      "Epoch 499/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 112.9825 - mae: 112.9825 - mse: 75724.4844 - val_loss: 609.0854 - val_mae: 609.0854 - val_mse: 1293215.5000 - lr: 1.0000e-04\n",
      "Epoch 500/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 112.5624 - mae: 112.5624 - mse: 75779.8594 - val_loss: 607.1896 - val_mae: 607.1896 - val_mse: 1290742.5000 - lr: 1.0000e-04\n",
      "Epoch 501/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 112.8163 - mae: 112.8163 - mse: 75598.0938 - val_loss: 608.6507 - val_mae: 608.6507 - val_mse: 1291066.0000 - lr: 1.0000e-04\n",
      "Epoch 502/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 112.4466 - mae: 112.4466 - mse: 75625.1328 - val_loss: 606.5547 - val_mae: 606.5547 - val_mse: 1288416.7500 - lr: 1.0000e-04\n",
      "Epoch 503/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 112.6485 - mae: 112.6485 - mse: 75473.2891 - val_loss: 607.2084 - val_mae: 607.2084 - val_mse: 1288019.2500 - lr: 1.0000e-04\n",
      "Epoch 504/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 112.3320 - mae: 112.3320 - mse: 75528.5781 - val_loss: 606.5604 - val_mae: 606.5604 - val_mse: 1286623.7500 - lr: 1.0000e-04\n",
      "Epoch 505/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 112.7734 - mae: 112.7734 - mse: 75367.0391 - val_loss: 606.9305 - val_mae: 606.9305 - val_mse: 1286114.3750 - lr: 1.0000e-04\n",
      "Epoch 506/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 112.2582 - mae: 112.2582 - mse: 75465.0156 - val_loss: 604.4236 - val_mae: 604.4236 - val_mse: 1283470.2500 - lr: 1.0000e-04\n",
      "Epoch 507/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 112.4908 - mae: 112.4908 - mse: 75243.9688 - val_loss: 606.7339 - val_mae: 606.7339 - val_mse: 1284368.2500 - lr: 1.0000e-04\n",
      "Epoch 508/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 112.1387 - mae: 112.1387 - mse: 75257.9141 - val_loss: 604.2715 - val_mae: 604.2715 - val_mse: 1281520.5000 - lr: 1.0000e-04\n",
      "Epoch 509/5000\n",
      "3/3 [==============================] - 1s 185ms/step - loss: 112.2628 - mae: 112.2628 - mse: 75125.9609 - val_loss: 604.9426 - val_mae: 604.9426 - val_mse: 1281161.0000 - lr: 1.0000e-04\n",
      "Epoch 510/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 112.0140 - mae: 112.0140 - mse: 75151.4688 - val_loss: 605.0156 - val_mae: 605.0156 - val_mse: 1280503.8750 - lr: 1.0000e-04\n",
      "Epoch 511/5000\n",
      "3/3 [==============================] - 1s 189ms/step - loss: 112.4414 - mae: 112.4414 - mse: 75018.5469 - val_loss: 604.3466 - val_mae: 604.3466 - val_mse: 1279236.0000 - lr: 1.0000e-04\n",
      "Epoch 512/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 111.9488 - mae: 111.9488 - mse: 75164.6562 - val_loss: 602.2687 - val_mae: 602.2687 - val_mse: 1277382.7500 - lr: 1.0000e-04\n",
      "Epoch 513/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 112.1498 - mae: 112.1498 - mse: 74919.6719 - val_loss: 604.7798 - val_mae: 604.7798 - val_mse: 1278300.2500 - lr: 1.0000e-04\n",
      "Epoch 514/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 111.8718 - mae: 111.8718 - mse: 74935.2656 - val_loss: 602.5242 - val_mae: 602.5242 - val_mse: 1275885.8750 - lr: 1.0000e-04\n",
      "Epoch 515/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 111.9811 - mae: 111.9811 - mse: 74819.3438 - val_loss: 602.8922 - val_mae: 602.8922 - val_mse: 1275377.2500 - lr: 1.0000e-04\n",
      "Epoch 516/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 111.7351 - mae: 111.7351 - mse: 74876.0469 - val_loss: 602.7113 - val_mae: 602.7113 - val_mse: 1274576.0000 - lr: 1.0000e-04\n",
      "Epoch 517/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 112.0980 - mae: 112.0980 - mse: 74715.1875 - val_loss: 602.2736 - val_mae: 602.2736 - val_mse: 1273624.0000 - lr: 1.0000e-04\n",
      "Epoch 518/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 111.6621 - mae: 111.6621 - mse: 74887.0859 - val_loss: 601.2162 - val_mae: 601.2162 - val_mse: 1272379.3750 - lr: 1.0000e-04\n",
      "Epoch 519/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 112.0434 - mae: 112.0434 - mse: 74624.6094 - val_loss: 602.6483 - val_mae: 602.6483 - val_mse: 1272625.5000 - lr: 1.0000e-04\n",
      "Epoch 520/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 111.5800 - mae: 111.5800 - mse: 74748.4609 - val_loss: 600.1712 - val_mae: 600.1712 - val_mse: 1270580.7500 - lr: 1.0000e-04\n",
      "Epoch 521/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 111.7775 - mae: 111.7775 - mse: 74529.0703 - val_loss: 601.7055 - val_mae: 601.7055 - val_mse: 1270634.6250 - lr: 1.0000e-04\n",
      "Epoch 522/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 111.4692 - mae: 111.4691 - mse: 74605.3125 - val_loss: 600.2106 - val_mae: 600.2106 - val_mse: 1269073.5000 - lr: 1.0000e-04\n",
      "Epoch 523/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 111.6810 - mae: 111.6810 - mse: 74428.9375 - val_loss: 600.7132 - val_mae: 600.7132 - val_mse: 1268636.8750 - lr: 1.0000e-04\n",
      "Epoch 524/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 111.3771 - mae: 111.3771 - mse: 74531.7500 - val_loss: 600.5914 - val_mae: 600.5914 - val_mse: 1267871.0000 - lr: 1.0000e-04\n",
      "Epoch 525/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 111.9318 - mae: 111.9318 - mse: 74338.2969 - val_loss: 601.1482 - val_mae: 601.1482 - val_mse: 1267613.7500 - lr: 1.0000e-04\n",
      "Epoch 526/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 111.3037 - mae: 111.3037 - mse: 74478.6797 - val_loss: 599.0242 - val_mae: 599.0242 - val_mse: 1265577.2500 - lr: 1.0000e-04\n",
      "Epoch 527/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 111.6859 - mae: 111.6859 - mse: 74234.8672 - val_loss: 600.2478 - val_mae: 600.2478 - val_mse: 1265586.7500 - lr: 1.0000e-04\n",
      "Epoch 528/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 111.2017 - mae: 111.2017 - mse: 74369.0156 - val_loss: 599.1904 - val_mae: 599.1904 - val_mse: 1264151.3750 - lr: 1.0000e-04\n",
      "Epoch 529/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 111.7702 - mae: 111.7702 - mse: 74148.2656 - val_loss: 600.1068 - val_mae: 600.1068 - val_mse: 1264154.0000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 530/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 111.1312 - mae: 111.1312 - mse: 74294.5859 - val_loss: 597.9233 - val_mae: 597.9233 - val_mse: 1262103.2500 - lr: 1.0000e-04\n",
      "Epoch 531/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 111.5154 - mae: 111.5154 - mse: 74045.5078 - val_loss: 599.0906 - val_mae: 599.0906 - val_mse: 1262017.1250 - lr: 1.0000e-04\n",
      "Epoch 532/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 111.0339 - mae: 111.0339 - mse: 74194.3906 - val_loss: 598.0737 - val_mae: 598.0737 - val_mse: 1260648.7500 - lr: 1.0000e-04\n",
      "Epoch 533/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 111.6071 - mae: 111.6071 - mse: 73960.2109 - val_loss: 599.0780 - val_mae: 599.0780 - val_mse: 1260724.7500 - lr: 1.0000e-04\n",
      "Epoch 534/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 110.9532 - mae: 110.9532 - mse: 74106.8125 - val_loss: 597.1168 - val_mae: 597.1168 - val_mse: 1258777.7500 - lr: 1.0000e-04\n",
      "Epoch 535/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 111.4078 - mae: 111.4078 - mse: 73858.7266 - val_loss: 598.1193 - val_mae: 598.1193 - val_mse: 1258657.5000 - lr: 1.0000e-04\n",
      "Epoch 536/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 110.8654 - mae: 110.8654 - mse: 74019.1484 - val_loss: 596.9497 - val_mae: 596.9497 - val_mse: 1257207.3750 - lr: 1.0000e-04\n",
      "Epoch 537/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 111.4304 - mae: 111.4303 - mse: 73770.3594 - val_loss: 597.8843 - val_mae: 597.8843 - val_mse: 1257183.1250 - lr: 1.0000e-04\n",
      "Epoch 538/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 110.7886 - mae: 110.7886 - mse: 73935.3594 - val_loss: 595.9622 - val_mae: 595.9622 - val_mse: 1255350.7500 - lr: 1.0000e-04\n",
      "Epoch 539/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 111.2243 - mae: 111.2243 - mse: 73669.3047 - val_loss: 596.9473 - val_mae: 596.9473 - val_mse: 1255153.3750 - lr: 1.0000e-04\n",
      "Epoch 540/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 110.6863 - mae: 110.6863 - mse: 73837.3516 - val_loss: 596.2982 - val_mae: 596.2982 - val_mse: 1254045.3750 - lr: 1.0000e-04\n",
      "Epoch 541/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 111.3791 - mae: 111.3791 - mse: 73592.4922 - val_loss: 597.1472 - val_mae: 597.1472 - val_mse: 1254094.6250 - lr: 1.0000e-04\n",
      "Epoch 542/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 110.6140 - mae: 110.6140 - mse: 73744.2891 - val_loss: 594.9181 - val_mae: 594.9181 - val_mse: 1252024.1250 - lr: 1.0000e-04\n",
      "Epoch 543/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 111.0595 - mae: 111.0595 - mse: 73486.2500 - val_loss: 595.7545 - val_mae: 595.7545 - val_mse: 1251761.1250 - lr: 1.0000e-04\n",
      "Epoch 544/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 110.5518 - mae: 110.5518 - mse: 73697.5469 - val_loss: 594.7534 - val_mae: 594.7534 - val_mse: 1250611.3750 - lr: 1.0000e-04\n",
      "Epoch 545/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 111.1164 - mae: 111.1164 - mse: 73408.9531 - val_loss: 596.0916 - val_mae: 596.0916 - val_mse: 1250932.8750 - lr: 1.0000e-04\n",
      "Epoch 546/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 110.4428 - mae: 110.4428 - mse: 73560.0078 - val_loss: 593.9741 - val_mae: 593.9741 - val_mse: 1249039.7500 - lr: 1.0000e-04\n",
      "Epoch 547/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 110.8251 - mae: 110.8251 - mse: 73313.6094 - val_loss: 595.4915 - val_mae: 595.4915 - val_mse: 1249334.6250 - lr: 1.0000e-04\n",
      "Epoch 548/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 110.3514 - mae: 110.3514 - mse: 73403.2109 - val_loss: 593.4564 - val_mae: 593.4564 - val_mse: 1247511.6250 - lr: 1.0000e-04\n",
      "Epoch 549/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 110.5627 - mae: 110.5627 - mse: 73237.2344 - val_loss: 593.6697 - val_mae: 593.6697 - val_mse: 1246863.8750 - lr: 1.0000e-04\n",
      "Epoch 550/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 110.2543 - mae: 110.2543 - mse: 73354.0547 - val_loss: 593.8058 - val_mae: 593.8058 - val_mse: 1246277.5000 - lr: 1.0000e-04\n",
      "Epoch 551/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 110.6975 - mae: 110.6975 - mse: 73135.8359 - val_loss: 593.1530 - val_mae: 593.1530 - val_mse: 1245266.1250 - lr: 1.0000e-04\n",
      "Epoch 552/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 110.2507 - mae: 110.2507 - mse: 73388.5859 - val_loss: 593.0009 - val_mae: 593.0009 - val_mse: 1244576.2500 - lr: 1.0000e-04\n",
      "Epoch 553/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 110.8579 - mae: 110.8579 - mse: 73071.1328 - val_loss: 594.2397 - val_mae: 594.2397 - val_mse: 1244877.0000 - lr: 1.0000e-04\n",
      "Epoch 554/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 110.1370 - mae: 110.1370 - mse: 73232.0781 - val_loss: 592.1646 - val_mae: 592.1646 - val_mse: 1243006.7500 - lr: 1.0000e-04\n",
      "Epoch 555/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 110.5444 - mae: 110.5444 - mse: 72973.4219 - val_loss: 592.6199 - val_mae: 592.6199 - val_mse: 1242601.5000 - lr: 1.0000e-04\n",
      "Epoch 556/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 110.0870 - mae: 110.0870 - mse: 73206.3906 - val_loss: 592.0801 - val_mae: 592.0801 - val_mse: 1241771.0000 - lr: 1.0000e-04\n",
      "Epoch 557/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 110.6403 - mae: 110.6403 - mse: 72903.8125 - val_loss: 592.9796 - val_mae: 592.9796 - val_mse: 1241702.1250 - lr: 1.0000e-04\n",
      "Epoch 558/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 110.0091 - mae: 110.0091 - mse: 73117.0156 - val_loss: 591.3414 - val_mae: 591.3414 - val_mse: 1240319.2500 - lr: 1.0000e-04\n",
      "Epoch 559/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 110.3862 - mae: 110.3862 - mse: 72820.1406 - val_loss: 591.9031 - val_mae: 591.9031 - val_mse: 1239925.8750 - lr: 1.0000e-04\n",
      "Epoch 560/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 109.9344 - mae: 109.9344 - mse: 73049.5703 - val_loss: 591.4644 - val_mae: 591.4644 - val_mse: 1239146.3750 - lr: 1.0000e-04\n",
      "Epoch 561/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 110.5263 - mae: 110.5263 - mse: 72752.1484 - val_loss: 591.8470 - val_mae: 591.8470 - val_mse: 1238786.7500 - lr: 1.0000e-04\n",
      "Epoch 562/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 109.8971 - mae: 109.8971 - mse: 73025.3203 - val_loss: 590.5172 - val_mae: 590.5172 - val_mse: 1237706.1250 - lr: 1.0000e-04\n",
      "Epoch 563/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 110.2130 - mae: 110.2130 - mse: 72674.1797 - val_loss: 592.0740 - val_mae: 592.0740 - val_mse: 1237893.1250 - lr: 1.0000e-04\n",
      "Epoch 564/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 109.7575 - mae: 109.7575 - mse: 72792.9297 - val_loss: 590.0163 - val_mae: 590.0163 - val_mse: 1236436.6250 - lr: 1.0000e-04\n",
      "Epoch 565/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 109.8300 - mae: 109.8300 - mse: 72653.4531 - val_loss: 590.6329 - val_mae: 590.6329 - val_mse: 1235725.3750 - lr: 1.0000e-04\n",
      "Epoch 566/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.7212 - mae: 109.7212 - mse: 72646.6641 - val_loss: 589.3560 - val_mae: 589.3560 - val_mse: 1235400.6250 - lr: 1.0000e-04\n",
      "Epoch 567/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.7014 - mae: 109.7014 - mse: 72804.8828 - val_loss: 591.0486 - val_mae: 591.0486 - val_mse: 1234772.3750 - lr: 1.0000e-04\n",
      "Epoch 568/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 110.4026 - mae: 110.4026 - mse: 72483.6484 - val_loss: 589.6337 - val_mae: 589.6337 - val_mse: 1233203.3750 - lr: 1.0000e-04\n",
      "Epoch 569/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 109.8440 - mae: 109.8440 - mse: 72994.4141 - val_loss: 589.0053 - val_mae: 589.0053 - val_mse: 1232556.5000 - lr: 1.0000e-04\n",
      "Epoch 570/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 110.3098 - mae: 110.3098 - mse: 72421.6016 - val_loss: 591.1927 - val_mae: 591.1927 - val_mse: 1233290.1250 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 571/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.5350 - mae: 109.5350 - mse: 72610.0234 - val_loss: 588.5959 - val_mae: 588.5959 - val_mse: 1231250.0000 - lr: 1.0000e-04\n",
      "Epoch 572/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 109.7631 - mae: 109.7631 - mse: 72326.4922 - val_loss: 589.5218 - val_mae: 589.5218 - val_mse: 1230696.5000 - lr: 1.0000e-04\n",
      "Epoch 573/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 109.4316 - mae: 109.4316 - mse: 72440.7734 - val_loss: 588.0520 - val_mae: 588.0520 - val_mse: 1230412.8750 - lr: 1.0000e-04\n",
      "Epoch 574/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 109.4376 - mae: 109.4376 - mse: 72417.9922 - val_loss: 588.3994 - val_mae: 588.3994 - val_mse: 1228931.8750 - lr: 1.0000e-04\n",
      "Epoch 575/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 109.4445 - mae: 109.4445 - mse: 72267.6641 - val_loss: 588.2536 - val_mae: 588.2536 - val_mse: 1228169.1250 - lr: 1.0000e-04\n",
      "Epoch 576/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 109.3614 - mae: 109.3614 - mse: 72269.1719 - val_loss: 587.4783 - val_mae: 587.4783 - val_mse: 1227740.5000 - lr: 1.0000e-04\n",
      "Epoch 577/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 109.3126 - mae: 109.3126 - mse: 72337.1797 - val_loss: 587.6129 - val_mae: 587.6129 - val_mse: 1226600.8750 - lr: 1.0000e-04\n",
      "Epoch 578/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.3725 - mae: 109.3725 - mse: 72126.5625 - val_loss: 587.4178 - val_mae: 587.4178 - val_mse: 1225858.2500 - lr: 1.0000e-04\n",
      "Epoch 579/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 109.2219 - mae: 109.2219 - mse: 72253.6094 - val_loss: 586.9523 - val_mae: 586.9523 - val_mse: 1225380.6250 - lr: 1.0000e-04\n",
      "Epoch 580/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 109.2570 - mae: 109.2570 - mse: 72079.0469 - val_loss: 587.4673 - val_mae: 587.4673 - val_mse: 1224542.2500 - lr: 1.0000e-04\n",
      "Epoch 581/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 109.1948 - mae: 109.1948 - mse: 72040.9609 - val_loss: 586.4994 - val_mae: 586.4994 - val_mse: 1224113.8750 - lr: 1.0000e-04\n",
      "Epoch 582/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 109.1241 - mae: 109.1241 - mse: 72148.5859 - val_loss: 586.5117 - val_mae: 586.5117 - val_mse: 1223090.0000 - lr: 1.0000e-04\n",
      "Epoch 583/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 109.1627 - mae: 109.1626 - mse: 71937.9297 - val_loss: 586.3086 - val_mae: 586.3086 - val_mse: 1222364.2500 - lr: 1.0000e-04\n",
      "Epoch 584/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 109.0367 - mae: 109.0367 - mse: 72074.1719 - val_loss: 586.0281 - val_mae: 586.0281 - val_mse: 1221759.3750 - lr: 1.0000e-04\n",
      "Epoch 585/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 109.0939 - mae: 109.0939 - mse: 71857.5000 - val_loss: 586.1179 - val_mae: 586.1179 - val_mse: 1220864.0000 - lr: 1.0000e-04\n",
      "Epoch 586/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 108.9556 - mae: 108.9556 - mse: 71947.7109 - val_loss: 585.5802 - val_mae: 585.5802 - val_mse: 1220617.3750 - lr: 1.0000e-04\n",
      "Epoch 587/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 108.9522 - mae: 108.9522 - mse: 71844.8281 - val_loss: 585.7984 - val_mae: 585.7984 - val_mse: 1219459.8750 - lr: 1.0000e-04\n",
      "Epoch 588/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 108.9139 - mae: 108.9139 - mse: 71779.5938 - val_loss: 585.2317 - val_mae: 585.2317 - val_mse: 1219128.0000 - lr: 1.0000e-04\n",
      "Epoch 589/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 108.8549 - mae: 108.8549 - mse: 71847.6250 - val_loss: 585.2792 - val_mae: 585.2792 - val_mse: 1218011.6250 - lr: 1.0000e-04\n",
      "Epoch 590/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 108.9127 - mae: 108.9127 - mse: 71645.5703 - val_loss: 585.0859 - val_mae: 585.0859 - val_mse: 1217241.1250 - lr: 1.0000e-04\n",
      "Epoch 591/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.7632 - mae: 108.7632 - mse: 71748.6797 - val_loss: 584.7150 - val_mae: 584.7150 - val_mse: 1216624.7500 - lr: 1.0000e-04\n",
      "Epoch 592/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 108.8085 - mae: 108.8085 - mse: 71588.5859 - val_loss: 584.8834 - val_mae: 584.8834 - val_mse: 1215749.5000 - lr: 1.0000e-04\n",
      "Epoch 593/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 108.7162 - mae: 108.7162 - mse: 71591.8906 - val_loss: 584.2800 - val_mae: 584.2800 - val_mse: 1215368.0000 - lr: 1.0000e-04\n",
      "Epoch 594/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 108.6684 - mae: 108.6684 - mse: 71589.4531 - val_loss: 584.6026 - val_mae: 584.6026 - val_mse: 1214444.2500 - lr: 1.0000e-04\n",
      "Epoch 595/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 108.7500 - mae: 108.7500 - mse: 71438.8047 - val_loss: 583.9760 - val_mae: 583.9760 - val_mse: 1214046.7500 - lr: 1.0000e-04\n",
      "Epoch 596/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.6075 - mae: 108.6075 - mse: 71653.4688 - val_loss: 584.1673 - val_mae: 584.1673 - val_mse: 1213128.2500 - lr: 1.0000e-04\n",
      "Epoch 597/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 108.9526 - mae: 108.9526 - mse: 71321.2969 - val_loss: 583.5032 - val_mae: 583.5032 - val_mse: 1213084.6250 - lr: 1.0000e-04\n",
      "Epoch 598/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 108.8807 - mae: 108.8807 - mse: 72031.7344 - val_loss: 583.7864 - val_mae: 583.7864 - val_mse: 1211944.6250 - lr: 1.0000e-04\n",
      "Epoch 599/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 109.8012 - mae: 109.8012 - mse: 71375.4922 - val_loss: 585.0880 - val_mae: 585.0880 - val_mse: 1212465.0000 - lr: 1.0000e-04\n",
      "Epoch 600/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.6504 - mae: 108.6504 - mse: 71798.5391 - val_loss: 582.9175 - val_mae: 582.9175 - val_mse: 1212271.3750 - lr: 1.0000e-04\n",
      "Epoch 601/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 108.8604 - mae: 108.8604 - mse: 71208.8672 - val_loss: 584.0454 - val_mae: 584.0454 - val_mse: 1210634.2500 - lr: 1.0000e-04\n",
      "Epoch 602/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 108.4043 - mae: 108.4043 - mse: 71432.6875 - val_loss: 582.7642 - val_mae: 582.7642 - val_mse: 1210134.2500 - lr: 1.0000e-04\n",
      "Epoch 603/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 108.5643 - mae: 108.5643 - mse: 71156.7734 - val_loss: 583.1625 - val_mae: 583.1625 - val_mse: 1209222.5000 - lr: 1.0000e-04\n",
      "Epoch 604/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 108.3291 - mae: 108.3291 - mse: 71296.3203 - val_loss: 582.4163 - val_mae: 582.4163 - val_mse: 1209026.1250 - lr: 1.0000e-04\n",
      "Epoch 605/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 108.3629 - mae: 108.3629 - mse: 71162.0312 - val_loss: 582.9790 - val_mae: 582.9790 - val_mse: 1208216.2500 - lr: 1.0000e-04\n",
      "Epoch 606/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 108.3675 - mae: 108.3675 - mse: 71091.8594 - val_loss: 582.1555 - val_mae: 582.1555 - val_mse: 1207652.2500 - lr: 1.0000e-04\n",
      "Epoch 607/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 108.2473 - mae: 108.2473 - mse: 71194.5234 - val_loss: 582.4581 - val_mae: 582.4581 - val_mse: 1207007.7500 - lr: 1.0000e-04\n",
      "Epoch 608/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.4650 - mae: 108.4650 - mse: 70980.0625 - val_loss: 581.7809 - val_mae: 581.7809 - val_mse: 1206565.7500 - lr: 1.0000e-04\n",
      "Epoch 609/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 108.2171 - mae: 108.2171 - mse: 71290.0078 - val_loss: 581.7197 - val_mae: 581.7197 - val_mse: 1205947.7500 - lr: 1.0000e-04\n",
      "Epoch 610/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 108.4654 - mae: 108.4654 - mse: 70912.8906 - val_loss: 581.2825 - val_mae: 581.2825 - val_mse: 1206079.3750 - lr: 1.0000e-04\n",
      "Epoch 611/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.4229 - mae: 108.4229 - mse: 71583.9922 - val_loss: 581.4924 - val_mae: 581.4924 - val_mse: 1204861.6250 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 612/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 109.1154 - mae: 109.1154 - mse: 70899.8984 - val_loss: 582.0305 - val_mae: 582.0305 - val_mse: 1204570.0000 - lr: 1.0000e-04\n",
      "Epoch 613/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 108.2748 - mae: 108.2748 - mse: 71445.5000 - val_loss: 580.8815 - val_mae: 580.8815 - val_mse: 1204848.6250 - lr: 1.0000e-04\n",
      "Epoch 614/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 108.5330 - mae: 108.5330 - mse: 70798.5547 - val_loss: 582.0941 - val_mae: 582.0941 - val_mse: 1203836.7500 - lr: 1.0000e-04\n",
      "Epoch 615/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 108.0019 - mae: 108.0019 - mse: 71031.6797 - val_loss: 580.6171 - val_mae: 580.6171 - val_mse: 1203196.1250 - lr: 1.0000e-04\n",
      "Epoch 616/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 108.1630 - mae: 108.1630 - mse: 70750.6562 - val_loss: 580.8564 - val_mae: 580.8564 - val_mse: 1202275.0000 - lr: 1.0000e-04\n",
      "Epoch 617/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 107.9318 - mae: 107.9318 - mse: 70943.2109 - val_loss: 580.3301 - val_mae: 580.3301 - val_mse: 1202074.2500 - lr: 1.0000e-04\n",
      "Epoch 618/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.0117 - mae: 108.0117 - mse: 70717.6094 - val_loss: 580.8462 - val_mae: 580.8462 - val_mse: 1201342.8750 - lr: 1.0000e-04\n",
      "Epoch 619/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.9177 - mae: 107.9177 - mse: 70731.3984 - val_loss: 580.1794 - val_mae: 580.1794 - val_mse: 1200837.5000 - lr: 1.0000e-04\n",
      "Epoch 620/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.9090 - mae: 107.9090 - mse: 70686.1562 - val_loss: 580.6141 - val_mae: 580.6141 - val_mse: 1200541.0000 - lr: 1.0000e-04\n",
      "Epoch 621/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.9648 - mae: 107.9648 - mse: 70608.6719 - val_loss: 580.1199 - val_mae: 580.1199 - val_mse: 1200057.0000 - lr: 1.0000e-04\n",
      "Epoch 622/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.8260 - mae: 107.8260 - mse: 70678.0469 - val_loss: 579.8114 - val_mae: 579.8114 - val_mse: 1199807.1250 - lr: 1.0000e-04\n",
      "Epoch 623/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.8401 - mae: 107.8401 - mse: 70609.3125 - val_loss: 580.6675 - val_mae: 580.6675 - val_mse: 1199858.5000 - lr: 1.0000e-04\n",
      "Epoch 624/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.9618 - mae: 107.9618 - mse: 70523.2266 - val_loss: 579.4688 - val_mae: 579.4688 - val_mse: 1199727.2500 - lr: 1.0000e-04\n",
      "Epoch 625/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 107.8069 - mae: 107.8069 - mse: 70910.4609 - val_loss: 579.6235 - val_mae: 579.6235 - val_mse: 1198769.1250 - lr: 1.0000e-04\n",
      "Epoch 626/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 108.1700 - mae: 108.1700 - mse: 70455.6797 - val_loss: 579.3623 - val_mae: 579.3623 - val_mse: 1198373.0000 - lr: 1.0000e-04\n",
      "Epoch 627/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.8028 - mae: 107.8028 - mse: 70947.4062 - val_loss: 579.1826 - val_mae: 579.1826 - val_mse: 1197961.8750 - lr: 1.0000e-04\n",
      "Epoch 628/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.1900 - mae: 108.1900 - mse: 70402.4219 - val_loss: 579.4990 - val_mae: 579.4990 - val_mse: 1197409.0000 - lr: 1.0000e-04\n",
      "Epoch 629/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.6416 - mae: 107.6416 - mse: 70745.0234 - val_loss: 578.7914 - val_mae: 578.7914 - val_mse: 1197097.8750 - lr: 1.0000e-04\n",
      "Epoch 630/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.8710 - mae: 107.8710 - mse: 70349.8828 - val_loss: 578.9196 - val_mae: 578.9196 - val_mse: 1196208.1250 - lr: 1.0000e-04\n",
      "Epoch 631/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.5432 - mae: 107.5432 - mse: 70617.5938 - val_loss: 578.4960 - val_mae: 578.4960 - val_mse: 1196300.1250 - lr: 1.0000e-04\n",
      "Epoch 632/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 107.6125 - mae: 107.6125 - mse: 70342.4062 - val_loss: 578.4236 - val_mae: 578.4236 - val_mse: 1195256.0000 - lr: 1.0000e-04\n",
      "Epoch 633/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.4735 - mae: 107.4735 - mse: 70501.4062 - val_loss: 578.3558 - val_mae: 578.3558 - val_mse: 1194684.0000 - lr: 1.0000e-04\n",
      "Epoch 634/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 107.6960 - mae: 107.6960 - mse: 70219.7969 - val_loss: 578.0825 - val_mae: 578.0825 - val_mse: 1194440.3750 - lr: 1.0000e-04\n",
      "Epoch 635/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 107.4808 - mae: 107.4808 - mse: 70611.1172 - val_loss: 578.1269 - val_mae: 578.1269 - val_mse: 1193722.0000 - lr: 1.0000e-04\n",
      "Epoch 636/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 107.9144 - mae: 107.9144 - mse: 70141.5547 - val_loss: 577.8615 - val_mae: 577.8615 - val_mse: 1193283.7500 - lr: 1.0000e-04\n",
      "Epoch 637/5000\n",
      "3/3 [==============================] - 1s 254ms/step - loss: 107.4998 - mae: 107.4998 - mse: 70666.1250 - val_loss: 577.7866 - val_mae: 577.7866 - val_mse: 1192702.3750 - lr: 1.0000e-04\n",
      "Epoch 638/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 108.1120 - mae: 108.1120 - mse: 70100.0312 - val_loss: 577.8637 - val_mae: 577.8637 - val_mse: 1192122.0000 - lr: 1.0000e-04\n",
      "Epoch 639/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.3931 - mae: 107.3931 - mse: 70564.4062 - val_loss: 577.3701 - val_mae: 577.3701 - val_mse: 1191571.3750 - lr: 1.0000e-04\n",
      "Epoch 640/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.8777 - mae: 107.8777 - mse: 70024.8047 - val_loss: 577.6675 - val_mae: 577.6675 - val_mse: 1190931.7500 - lr: 1.0000e-04\n",
      "Epoch 641/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 107.2267 - mae: 107.2267 - mse: 70354.6641 - val_loss: 577.0394 - val_mae: 577.0394 - val_mse: 1190398.5000 - lr: 1.0000e-04\n",
      "Epoch 642/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.5362 - mae: 107.5362 - mse: 69962.1562 - val_loss: 577.0770 - val_mae: 577.0770 - val_mse: 1189640.0000 - lr: 1.0000e-04\n",
      "Epoch 643/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.1482 - mae: 107.1482 - mse: 70229.2891 - val_loss: 576.8285 - val_mae: 576.8285 - val_mse: 1190340.0000 - lr: 1.0000e-04\n",
      "Epoch 644/5000\n",
      "3/3 [==============================] - 1s 184ms/step - loss: 107.1926 - mae: 107.1926 - mse: 70010.4922 - val_loss: 577.2206 - val_mae: 577.2206 - val_mse: 1189112.0000 - lr: 1.0000e-04\n",
      "Epoch 645/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 107.2535 - mae: 107.2535 - mse: 69919.5703 - val_loss: 576.5934 - val_mae: 576.5934 - val_mse: 1189270.7500 - lr: 1.0000e-04\n",
      "Epoch 646/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 107.0913 - mae: 107.0913 - mse: 70180.4453 - val_loss: 576.8481 - val_mae: 576.8481 - val_mse: 1188518.5000 - lr: 1.0000e-04\n",
      "Epoch 647/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 107.5473 - mae: 107.5473 - mse: 69828.2031 - val_loss: 576.4630 - val_mae: 576.4630 - val_mse: 1188562.8750 - lr: 1.0000e-04\n",
      "Epoch 648/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 107.2521 - mae: 107.2521 - mse: 70454.2500 - val_loss: 576.4521 - val_mae: 576.4521 - val_mse: 1187754.3750 - lr: 1.0000e-04\n",
      "Epoch 649/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 107.9685 - mae: 107.9685 - mse: 69826.6328 - val_loss: 576.5679 - val_mae: 576.5679 - val_mse: 1187289.2500 - lr: 1.0000e-04\n",
      "Epoch 650/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 107.1338 - mae: 107.1338 - mse: 70354.0703 - val_loss: 576.1345 - val_mae: 576.1345 - val_mse: 1187393.0000 - lr: 1.0000e-04\n",
      "Epoch 651/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 107.4054 - mae: 107.4054 - mse: 69743.6094 - val_loss: 576.3928 - val_mae: 576.3928 - val_mse: 1186138.1250 - lr: 1.0000e-04\n",
      "Epoch 652/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 106.9001 - mae: 106.9001 - mse: 70041.6250 - val_loss: 575.8373 - val_mae: 575.8373 - val_mse: 1186013.8750 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 653/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.0696 - mae: 107.0696 - mse: 69715.4844 - val_loss: 576.1133 - val_mae: 576.1133 - val_mse: 1184921.0000 - lr: 1.0000e-04\n",
      "Epoch 654/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 106.8731 - mae: 106.8731 - mse: 69791.8906 - val_loss: 575.6125 - val_mae: 575.6125 - val_mse: 1185274.5000 - lr: 1.0000e-04\n",
      "Epoch 655/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.8224 - mae: 106.8224 - mse: 69816.1406 - val_loss: 576.1223 - val_mae: 576.1223 - val_mse: 1184354.0000 - lr: 1.0000e-04\n",
      "Epoch 656/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.1801 - mae: 107.1801 - mse: 69600.3203 - val_loss: 575.4433 - val_mae: 575.4433 - val_mse: 1184415.2500 - lr: 1.0000e-04\n",
      "Epoch 657/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.8549 - mae: 106.8549 - mse: 70058.4453 - val_loss: 575.3859 - val_mae: 575.3859 - val_mse: 1183821.1250 - lr: 1.0000e-04\n",
      "Epoch 658/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.1537 - mae: 107.1536 - mse: 69567.0469 - val_loss: 575.3520 - val_mae: 575.3520 - val_mse: 1183427.8750 - lr: 1.0000e-04\n",
      "Epoch 659/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 106.7437 - mae: 106.7437 - mse: 69937.8906 - val_loss: 575.2078 - val_mae: 575.2078 - val_mse: 1183404.3750 - lr: 1.0000e-04\n",
      "Epoch 660/5000\n",
      "3/3 [==============================] - 1s 188ms/step - loss: 106.9624 - mae: 106.9624 - mse: 69546.1719 - val_loss: 575.4902 - val_mae: 575.4902 - val_mse: 1182736.7500 - lr: 1.0000e-04\n",
      "Epoch 661/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 106.6715 - mae: 106.6715 - mse: 69700.6562 - val_loss: 574.9835 - val_mae: 574.9835 - val_mse: 1182519.5000 - lr: 1.0000e-04\n",
      "Epoch 662/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 106.7874 - mae: 106.7874 - mse: 69539.9609 - val_loss: 574.9262 - val_mae: 574.9262 - val_mse: 1182014.0000 - lr: 1.0000e-04\n",
      "Epoch 663/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 106.6107 - mae: 106.6107 - mse: 69679.9922 - val_loss: 575.1243 - val_mae: 575.1243 - val_mse: 1181602.2500 - lr: 1.0000e-04\n",
      "Epoch 664/5000\n",
      "3/3 [==============================] - 1s 257ms/step - loss: 106.9226 - mae: 106.9226 - mse: 69448.3203 - val_loss: 574.8754 - val_mae: 574.8754 - val_mse: 1181217.3750 - lr: 1.0000e-04\n",
      "Epoch 665/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 106.5622 - mae: 106.5622 - mse: 69670.0703 - val_loss: 574.5712 - val_mae: 574.5712 - val_mse: 1181105.0000 - lr: 1.0000e-04\n",
      "Epoch 666/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 106.7099 - mae: 106.7099 - mse: 69445.4062 - val_loss: 574.6482 - val_mae: 574.6482 - val_mse: 1180522.1250 - lr: 1.0000e-04\n",
      "Epoch 667/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 106.5193 - mae: 106.5193 - mse: 69582.8047 - val_loss: 574.5638 - val_mae: 574.5638 - val_mse: 1180187.6250 - lr: 1.0000e-04\n",
      "Epoch 668/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 106.7332 - mae: 106.7332 - mse: 69379.9609 - val_loss: 574.3598 - val_mae: 574.3598 - val_mse: 1179883.2500 - lr: 1.0000e-04\n",
      "Epoch 669/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 106.4642 - mae: 106.4642 - mse: 69602.7734 - val_loss: 574.2881 - val_mae: 574.2881 - val_mse: 1179541.8750 - lr: 1.0000e-04\n",
      "Epoch 670/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.6824 - mae: 106.6824 - mse: 69338.1797 - val_loss: 574.2996 - val_mae: 574.2996 - val_mse: 1179108.0000 - lr: 1.0000e-04\n",
      "Epoch 671/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.4109 - mae: 106.4109 - mse: 69522.1328 - val_loss: 574.2255 - val_mae: 574.2255 - val_mse: 1178759.3750 - lr: 1.0000e-04\n",
      "Epoch 672/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.6556 - mae: 106.6556 - mse: 69288.7656 - val_loss: 574.1515 - val_mae: 574.1515 - val_mse: 1178376.0000 - lr: 1.0000e-04\n",
      "Epoch 673/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.3614 - mae: 106.3614 - mse: 69480.7656 - val_loss: 574.0071 - val_mae: 574.0071 - val_mse: 1178052.1250 - lr: 1.0000e-04\n",
      "Epoch 674/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.5886 - mae: 106.5886 - mse: 69249.0625 - val_loss: 573.9065 - val_mae: 573.9065 - val_mse: 1177673.7500 - lr: 1.0000e-04\n",
      "Epoch 675/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.3129 - mae: 106.3129 - mse: 69451.0234 - val_loss: 573.8101 - val_mae: 573.8101 - val_mse: 1177347.7500 - lr: 1.0000e-04\n",
      "Epoch 676/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 106.5390 - mae: 106.5390 - mse: 69205.1406 - val_loss: 573.8368 - val_mae: 573.8368 - val_mse: 1176939.0000 - lr: 1.0000e-04\n",
      "Epoch 677/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 106.2625 - mae: 106.2625 - mse: 69381.6094 - val_loss: 573.6490 - val_mae: 573.6490 - val_mse: 1176619.8750 - lr: 1.0000e-04\n",
      "Epoch 678/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 106.4720 - mae: 106.4720 - mse: 69164.4609 - val_loss: 573.5270 - val_mae: 573.5270 - val_mse: 1176242.1250 - lr: 1.0000e-04\n",
      "Epoch 679/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.2105 - mae: 106.2105 - mse: 69370.0938 - val_loss: 573.4538 - val_mae: 573.4538 - val_mse: 1175892.6250 - lr: 1.0000e-04\n",
      "Epoch 680/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 106.4370 - mae: 106.4370 - mse: 69117.7188 - val_loss: 573.3346 - val_mae: 573.3346 - val_mse: 1175524.0000 - lr: 1.0000e-04\n",
      "Epoch 681/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 106.1590 - mae: 106.1590 - mse: 69340.4531 - val_loss: 573.2418 - val_mae: 573.2418 - val_mse: 1175193.6250 - lr: 1.0000e-04\n",
      "Epoch 682/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.3709 - mae: 106.3709 - mse: 69078.8125 - val_loss: 573.1542 - val_mae: 573.1542 - val_mse: 1174821.1250 - lr: 1.0000e-04\n",
      "Epoch 683/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 106.1082 - mae: 106.1082 - mse: 69306.2578 - val_loss: 573.0761 - val_mae: 573.0761 - val_mse: 1174494.3750 - lr: 1.0000e-04\n",
      "Epoch 684/5000\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 106.3161 - mae: 106.3161 - mse: 69037.6797 - val_loss: 573.0192 - val_mae: 573.0192 - val_mse: 1174093.8750 - lr: 1.0000e-04\n",
      "Epoch 685/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.0572 - mae: 106.0572 - mse: 69253.5938 - val_loss: 572.9379 - val_mae: 572.9379 - val_mse: 1173763.6250 - lr: 1.0000e-04\n",
      "Epoch 686/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 106.2751 - mae: 106.2751 - mse: 68995.2344 - val_loss: 572.8259 - val_mae: 572.8259 - val_mse: 1173397.5000 - lr: 1.0000e-04\n",
      "Epoch 687/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.0060 - mae: 106.0060 - mse: 69225.2969 - val_loss: 572.7854 - val_mae: 572.7854 - val_mse: 1173011.8750 - lr: 1.0000e-04\n",
      "Epoch 688/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.2455 - mae: 106.2455 - mse: 68949.0703 - val_loss: 572.7496 - val_mae: 572.7496 - val_mse: 1172580.1250 - lr: 1.0000e-04\n",
      "Epoch 689/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 105.9510 - mae: 105.9510 - mse: 69151.2031 - val_loss: 572.4119 - val_mae: 572.4119 - val_mse: 1172697.8750 - lr: 1.0000e-04\n",
      "Epoch 690/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 106.0019 - mae: 106.0019 - mse: 68976.9531 - val_loss: 573.4825 - val_mae: 573.4825 - val_mse: 1172348.7500 - lr: 1.0000e-04\n",
      "Epoch 691/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 106.2156 - mae: 106.2156 - mse: 68878.6406 - val_loss: 572.3205 - val_mae: 572.3205 - val_mse: 1171450.2500 - lr: 1.0000e-04\n",
      "Epoch 692/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 105.8769 - mae: 105.8769 - mse: 69050.6797 - val_loss: 572.1662 - val_mae: 572.1662 - val_mse: 1171130.8750 - lr: 1.0000e-04\n",
      "Epoch 693/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 105.9283 - mae: 105.9283 - mse: 68893.7734 - val_loss: 573.5161 - val_mae: 573.5161 - val_mse: 1171457.2500 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 694/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 106.2720 - mae: 106.2720 - mse: 68793.9453 - val_loss: 571.9160 - val_mae: 571.9160 - val_mse: 1170671.6250 - lr: 1.0000e-04\n",
      "Epoch 695/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 105.8080 - mae: 105.8080 - mse: 69132.8828 - val_loss: 572.1536 - val_mae: 572.1536 - val_mse: 1169583.2500 - lr: 1.0000e-04\n",
      "Epoch 696/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.1213 - mae: 106.1213 - mse: 68747.9609 - val_loss: 571.7010 - val_mae: 571.7010 - val_mse: 1169673.0000 - lr: 1.0000e-04\n",
      "Epoch 697/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 105.7917 - mae: 105.7917 - mse: 69158.6328 - val_loss: 572.9847 - val_mae: 572.9847 - val_mse: 1169589.7500 - lr: 1.0000e-04\n",
      "Epoch 698/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 106.9065 - mae: 106.9065 - mse: 68756.2109 - val_loss: 571.8569 - val_mae: 571.8569 - val_mse: 1170666.8750 - lr: 1.0000e-04\n",
      "Epoch 699/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 106.6810 - mae: 106.6810 - mse: 69986.4375 - val_loss: 576.3414 - val_mae: 576.3414 - val_mse: 1174524.2500 - lr: 1.0000e-04\n",
      "Epoch 700/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 111.8376 - mae: 111.8376 - mse: 70273.1719 - val_loss: 582.1768 - val_mae: 582.1768 - val_mse: 1195141.3750 - lr: 1.0000e-04\n",
      "Epoch 701/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 122.3057 - mae: 122.3057 - mse: 81651.0078 - val_loss: 572.0041 - val_mae: 572.0041 - val_mse: 1169114.3750 - lr: 1.0000e-04\n",
      "Epoch 702/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 128.9835 - mae: 128.9835 - mse: 80293.9688 - val_loss: 648.7343 - val_mae: 648.7343 - val_mse: 1325877.1250 - lr: 1.0000e-04\n",
      "Epoch 703/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 108.6967 - mae: 108.6967 - mse: 70689.5000 - val_loss: 601.0735 - val_mae: 601.0735 - val_mse: 1242052.8750 - lr: 1.0000e-04\n",
      "Epoch 704/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.0177 - mae: 107.0177 - mse: 69854.3984 - val_loss: 597.2596 - val_mae: 597.2596 - val_mse: 1217249.5000 - lr: 1.0000e-04\n",
      "Epoch 705/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 113.9052 - mae: 113.9052 - mse: 71276.4688 - val_loss: 580.3619 - val_mae: 580.3619 - val_mse: 1194462.8750 - lr: 1.0000e-04\n",
      "Epoch 706/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 121.7706 - mae: 121.7706 - mse: 81415.7969 - val_loss: 574.6722 - val_mae: 574.6722 - val_mse: 1181667.5000 - lr: 1.0000e-04\n",
      "Epoch 707/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 121.3910 - mae: 121.3910 - mse: 75649.7734 - val_loss: 628.3732 - val_mae: 628.3732 - val_mse: 1284396.3750 - lr: 1.0000e-04\n",
      "Epoch 708/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 108.0009 - mae: 108.0009 - mse: 70320.4453 - val_loss: 590.6902 - val_mae: 590.6902 - val_mse: 1222382.1250 - lr: 1.0000e-04\n",
      "Epoch 709/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 106.7795 - mae: 106.7795 - mse: 69810.1953 - val_loss: 589.5369 - val_mae: 589.5369 - val_mse: 1203961.8750 - lr: 1.0000e-04\n",
      "Epoch 710/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 111.0306 - mae: 111.0306 - mse: 70243.9453 - val_loss: 578.0266 - val_mae: 578.0266 - val_mse: 1191174.6250 - lr: 1.0000e-04\n",
      "Epoch 711/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 115.8525 - mae: 115.8525 - mse: 76889.4453 - val_loss: 573.6694 - val_mae: 573.6694 - val_mse: 1180085.8750 - lr: 1.0000e-04\n",
      "Epoch 712/5000\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 117.8448 - mae: 117.8448 - mse: 73607.3750 - val_loss: 595.5014 - val_mae: 595.5014 - val_mse: 1216500.0000 - lr: 1.0000e-04\n",
      "Epoch 713/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 109.0785 - mae: 109.0785 - mse: 71861.3984 - val_loss: 585.3682 - val_mae: 585.3682 - val_mse: 1210673.7500 - lr: 1.0000e-04\n",
      "Epoch 714/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 106.6812 - mae: 106.6812 - mse: 69268.0469 - val_loss: 582.4348 - val_mae: 582.4348 - val_mse: 1190920.8750 - lr: 1.0000e-04\n",
      "Epoch 715/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 106.2655 - mae: 106.2655 - mse: 69137.0000 - val_loss: 573.8969 - val_mae: 573.8969 - val_mse: 1180465.3750 - lr: 1.0000e-04\n",
      "Epoch 716/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 105.9986 - mae: 105.9986 - mse: 69102.1406 - val_loss: 575.1843 - val_mae: 575.1843 - val_mse: 1179714.8750 - lr: 1.0000e-04\n",
      "Epoch 717/5000\n",
      "3/3 [==============================] - 1s 342ms/step - loss: 106.0830 - mae: 106.0830 - mse: 68985.2266 - val_loss: 573.7663 - val_mae: 573.7663 - val_mse: 1177978.5000 - lr: 1.0000e-04\n",
      "Epoch 718/5000\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 105.8593 - mae: 105.8593 - mse: 69088.3047 - val_loss: 574.5513 - val_mae: 574.5513 - val_mse: 1177338.7500 - lr: 1.0000e-04\n",
      "Epoch 719/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 106.2911 - mae: 106.2911 - mse: 68840.7109 - val_loss: 574.0693 - val_mae: 574.0693 - val_mse: 1175915.6250 - lr: 1.0000e-04\n",
      "Epoch 720/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 105.7807 - mae: 105.7807 - mse: 68934.9219 - val_loss: 572.7527 - val_mae: 572.7527 - val_mse: 1174062.2500 - lr: 1.0000e-04\n",
      "Epoch 721/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 105.8060 - mae: 105.8060 - mse: 68776.3594 - val_loss: 572.9850 - val_mae: 572.9850 - val_mse: 1172886.8750 - lr: 1.0000e-04\n",
      "Epoch 722/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 105.7011 - mae: 105.7011 - mse: 68762.9375 - val_loss: 572.3003 - val_mae: 572.3003 - val_mse: 1171642.2500 - lr: 1.0000e-04\n",
      "Epoch 723/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 105.6754 - mae: 105.6754 - mse: 68691.7422 - val_loss: 572.4357 - val_mae: 572.4357 - val_mse: 1170838.7500 - lr: 1.0000e-04\n",
      "Epoch 724/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 105.6897 - mae: 105.6896 - mse: 68620.4922 - val_loss: 571.9781 - val_mae: 571.9781 - val_mse: 1169901.5000 - lr: 1.0000e-04\n",
      "Epoch 725/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 105.5728 - mae: 105.5728 - mse: 68613.3203 - val_loss: 571.7546 - val_mae: 571.7546 - val_mse: 1169162.0000 - lr: 1.0000e-04\n",
      "Epoch 726/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 105.5594 - mae: 105.5594 - mse: 68561.4531 - val_loss: 571.7951 - val_mae: 571.7951 - val_mse: 1168638.7500 - lr: 1.0000e-04\n",
      "Epoch 727/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 105.5733 - mae: 105.5733 - mse: 68507.2812 - val_loss: 571.5590 - val_mae: 571.5590 - val_mse: 1167976.5000 - lr: 1.0000e-04\n",
      "Epoch 728/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 105.4977 - mae: 105.4977 - mse: 68494.2891 - val_loss: 571.4147 - val_mae: 571.4147 - val_mse: 1167426.8750 - lr: 1.0000e-04\n",
      "Epoch 729/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 105.4801 - mae: 105.4801 - mse: 68454.5938 - val_loss: 571.4324 - val_mae: 571.4324 - val_mse: 1167024.7500 - lr: 1.0000e-04\n",
      "Epoch 730/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 105.4870 - mae: 105.4870 - mse: 68419.3516 - val_loss: 570.9869 - val_mae: 570.9869 - val_mse: 1166421.7500 - lr: 1.0000e-04\n",
      "Epoch 731/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 105.3534 - mae: 105.3534 - mse: 68454.0625 - val_loss: 571.4599 - val_mae: 571.4599 - val_mse: 1166331.1250 - lr: 1.0000e-04\n",
      "Epoch 732/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 105.6173 - mae: 105.6173 - mse: 68326.5391 - val_loss: 570.7508 - val_mae: 570.7508 - val_mse: 1165733.8750 - lr: 1.0000e-04\n",
      "Epoch 733/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 105.2527 - mae: 105.2527 - mse: 68542.9141 - val_loss: 570.7473 - val_mae: 570.7473 - val_mse: 1165379.5000 - lr: 1.0000e-04\n",
      "Epoch 734/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 105.4776 - mae: 105.4776 - mse: 68297.2188 - val_loss: 570.8138 - val_mae: 570.8138 - val_mse: 1165109.5000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 735/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 105.2427 - mae: 105.2427 - mse: 68413.2500 - val_loss: 570.6172 - val_mae: 570.6172 - val_mse: 1164808.0000 - lr: 1.0000e-04\n",
      "Epoch 736/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 105.3598 - mae: 105.3598 - mse: 68273.8750 - val_loss: 570.8518 - val_mae: 570.8518 - val_mse: 1164629.3750 - lr: 1.0000e-04\n",
      "Epoch 737/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 105.2412 - mae: 105.2412 - mse: 68306.0156 - val_loss: 571.1453 - val_mae: 571.1453 - val_mse: 1164655.6250 - lr: 1.0000e-04\n",
      "Epoch 738/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 105.5136 - mae: 105.5136 - mse: 68206.0938 - val_loss: 570.2631 - val_mae: 570.2631 - val_mse: 1164127.8750 - lr: 1.0000e-04\n",
      "Epoch 739/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 105.1164 - mae: 105.1164 - mse: 68461.8672 - val_loss: 570.3598 - val_mae: 570.3598 - val_mse: 1163687.7500 - lr: 1.0000e-04\n",
      "Epoch 740/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 105.3861 - mae: 105.3861 - mse: 68177.0859 - val_loss: 570.2614 - val_mae: 570.2614 - val_mse: 1163392.0000 - lr: 1.0000e-04\n",
      "Epoch 741/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 105.0832 - mae: 105.0832 - mse: 68395.2188 - val_loss: 570.2889 - val_mae: 570.2889 - val_mse: 1163088.5000 - lr: 1.0000e-04\n",
      "Epoch 742/5000\n",
      "3/3 [==============================] - 1s 201ms/step - loss: 105.3759 - mae: 105.3759 - mse: 68141.0156 - val_loss: 570.2523 - val_mae: 570.2523 - val_mse: 1162804.5000 - lr: 1.0000e-04\n",
      "Epoch 743/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 105.0474 - mae: 105.0474 - mse: 68348.7969 - val_loss: 570.2088 - val_mae: 570.2088 - val_mse: 1162527.2500 - lr: 1.0000e-04\n",
      "Epoch 744/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 105.3376 - mae: 105.3376 - mse: 68112.5547 - val_loss: 570.5664 - val_mae: 570.5664 - val_mse: 1162456.1250 - lr: 1.0000e-04\n",
      "Epoch 745/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 105.0708 - mae: 105.0708 - mse: 68205.9219 - val_loss: 570.2629 - val_mae: 570.2629 - val_mse: 1162019.6250 - lr: 1.0000e-04\n",
      "Epoch 746/5000\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 105.2183 - mae: 105.2183 - mse: 68102.5859 - val_loss: 570.4282 - val_mae: 570.4282 - val_mse: 1161851.1250 - lr: 1.0000e-04\n",
      "Epoch 747/5000\n",
      "3/3 [==============================] - 1s 251ms/step - loss: 105.0870 - mae: 105.0870 - mse: 68124.5781 - val_loss: 570.7312 - val_mae: 570.7312 - val_mse: 1161919.0000 - lr: 1.0000e-04\n",
      "Epoch 748/5000\n",
      "3/3 [==============================] - 1s 251ms/step - loss: 105.3403 - mae: 105.3403 - mse: 68050.8047 - val_loss: 570.0717 - val_mae: 570.0717 - val_mse: 1161095.1250 - lr: 1.0000e-04\n",
      "Epoch 749/5000\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 104.9818 - mae: 104.9818 - mse: 68147.8359 - val_loss: 570.3191 - val_mae: 570.3191 - val_mse: 1160990.7500 - lr: 1.0000e-04\n",
      "Epoch 750/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 105.2740 - mae: 105.2740 - mse: 68019.3906 - val_loss: 570.1104 - val_mae: 570.1104 - val_mse: 1160569.2500 - lr: 1.0000e-04\n",
      "Epoch 751/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 104.9738 - mae: 104.9738 - mse: 68085.4062 - val_loss: 570.4047 - val_mae: 570.4047 - val_mse: 1160599.7500 - lr: 1.0000e-04\n",
      "Epoch 752/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 105.2831 - mae: 105.2831 - mse: 67983.8750 - val_loss: 569.8165 - val_mae: 569.8165 - val_mse: 1159879.8750 - lr: 1.0000e-04\n",
      "Epoch 753/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 104.9083 - mae: 104.9083 - mse: 68094.4141 - val_loss: 569.9647 - val_mae: 569.9647 - val_mse: 1159700.6250 - lr: 1.0000e-04\n",
      "Epoch 754/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 105.1669 - mae: 105.1669 - mse: 67960.8672 - val_loss: 570.2455 - val_mae: 570.2455 - val_mse: 1159703.3750 - lr: 1.0000e-04\n",
      "Epoch 755/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 105.0313 - mae: 105.0313 - mse: 67971.3203 - val_loss: 570.0259 - val_mae: 570.0259 - val_mse: 1159214.8750 - lr: 1.0000e-04\n",
      "Epoch 756/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 105.0775 - mae: 105.0775 - mse: 67944.5078 - val_loss: 569.8611 - val_mae: 569.8611 - val_mse: 1158791.0000 - lr: 1.0000e-04\n",
      "Epoch 757/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 104.9912 - mae: 104.9912 - mse: 67932.7656 - val_loss: 570.2830 - val_mae: 570.2830 - val_mse: 1159033.0000 - lr: 1.0000e-04\n",
      "Epoch 758/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 105.1850 - mae: 105.1850 - mse: 67892.6484 - val_loss: 569.3826 - val_mae: 569.3826 - val_mse: 1157866.8750 - lr: 1.0000e-04\n",
      "Epoch 759/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 104.8107 - mae: 104.8107 - mse: 67969.8125 - val_loss: 569.9238 - val_mae: 569.9238 - val_mse: 1158038.1250 - lr: 1.0000e-04\n",
      "Epoch 760/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 105.2104 - mae: 105.2104 - mse: 67851.6797 - val_loss: 568.9095 - val_mae: 568.9095 - val_mse: 1157424.7500 - lr: 1.0000e-04\n",
      "Epoch 761/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 104.7423 - mae: 104.7423 - mse: 68161.2266 - val_loss: 569.3037 - val_mae: 569.3037 - val_mse: 1157106.1250 - lr: 1.0000e-04\n",
      "Epoch 762/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 105.2296 - mae: 105.2296 - mse: 67828.1406 - val_loss: 568.9443 - val_mae: 568.9443 - val_mse: 1157081.5000 - lr: 1.0000e-04\n",
      "Epoch 763/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 104.7450 - mae: 104.7450 - mse: 68210.5547 - val_loss: 569.8779 - val_mae: 569.8779 - val_mse: 1157508.0000 - lr: 1.0000e-04\n",
      "Epoch 764/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 105.9128 - mae: 105.9128 - mse: 67866.1953 - val_loss: 569.4641 - val_mae: 569.4641 - val_mse: 1159399.8750 - lr: 1.0000e-04\n",
      "Epoch 765/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 105.8285 - mae: 105.8285 - mse: 69268.6016 - val_loss: 575.5378 - val_mae: 575.5378 - val_mse: 1166205.8750 - lr: 1.0000e-04\n",
      "Epoch 766/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 112.6166 - mae: 112.6166 - mse: 70044.2500 - val_loss: 579.6801 - val_mae: 579.6801 - val_mse: 1182585.5000 - lr: 1.0000e-04\n",
      "Epoch 767/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 123.6882 - mae: 123.6882 - mse: 82731.2500 - val_loss: 569.0678 - val_mae: 569.0678 - val_mse: 1158993.8750 - lr: 1.0000e-04\n",
      "Epoch 768/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 127.1167 - mae: 127.1167 - mse: 78679.9531 - val_loss: 632.1412 - val_mae: 632.1412 - val_mse: 1285948.6250 - lr: 1.0000e-04\n",
      "Epoch 769/5000\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 107.9861 - mae: 107.9861 - mse: 70414.9453 - val_loss: 588.8090 - val_mae: 588.8090 - val_mse: 1208991.0000 - lr: 1.0000e-04\n",
      "Epoch 770/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 105.4032 - mae: 105.4032 - mse: 68377.4297 - val_loss: 579.8687 - val_mae: 579.8687 - val_mse: 1178080.3750 - lr: 1.0000e-04\n",
      "Epoch 771/5000\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 105.7836 - mae: 105.7836 - mse: 68114.3984 - val_loss: 570.8853 - val_mae: 570.8853 - val_mse: 1167585.0000 - lr: 1.0000e-04\n",
      "Epoch 772/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 105.2007 - mae: 105.2007 - mse: 68714.9922 - val_loss: 573.8408 - val_mae: 573.8408 - val_mse: 1168815.5000 - lr: 1.0000e-04\n",
      "Epoch 773/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 107.1701 - mae: 107.1701 - mse: 68379.3984 - val_loss: 571.0988 - val_mae: 571.0988 - val_mse: 1168291.8750 - lr: 1.0000e-04\n",
      "Epoch 774/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 107.8231 - mae: 107.8231 - mse: 70870.4453 - val_loss: 573.4756 - val_mae: 573.4756 - val_mse: 1168108.3750 - lr: 1.0000e-04\n",
      "Epoch 775/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 113.6962 - mae: 113.6962 - mse: 70865.8672 - val_loss: 570.5233 - val_mae: 570.5233 - val_mse: 1166394.5000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 776/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 117.3952 - mae: 117.3952 - mse: 78108.6328 - val_loss: 572.0500 - val_mae: 572.0500 - val_mse: 1170098.0000 - lr: 1.0000e-04\n",
      "Epoch 777/5000\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 118.4509 - mae: 118.4509 - mse: 73498.0000 - val_loss: 600.3270 - val_mae: 600.3270 - val_mse: 1218779.5000 - lr: 1.0000e-04\n",
      "Epoch 778/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 107.8533 - mae: 107.8533 - mse: 70723.7734 - val_loss: 579.4518 - val_mae: 579.4518 - val_mse: 1188262.8750 - lr: 1.0000e-04\n",
      "Epoch 779/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.1449 - mae: 106.1449 - mse: 68342.5938 - val_loss: 570.4619 - val_mae: 570.4619 - val_mse: 1166067.3750 - lr: 1.0000e-04\n",
      "Epoch 780/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.7400 - mae: 106.7400 - mse: 70099.6406 - val_loss: 570.3846 - val_mae: 570.3846 - val_mse: 1166046.0000 - lr: 1.0000e-04\n",
      "Epoch 781/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 108.9713 - mae: 108.9713 - mse: 68953.8984 - val_loss: 571.1638 - val_mae: 571.1638 - val_mse: 1168934.7500 - lr: 1.0000e-04\n",
      "Epoch 782/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 111.6909 - mae: 111.6909 - mse: 73729.4844 - val_loss: 570.3215 - val_mae: 570.3215 - val_mse: 1165766.6250 - lr: 1.0000e-04\n",
      "Epoch 783/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 115.9838 - mae: 115.9838 - mse: 72065.1328 - val_loss: 576.0248 - val_mae: 576.0248 - val_mse: 1172738.2500 - lr: 1.0000e-04\n",
      "Epoch 784/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 111.8662 - mae: 111.8662 - mse: 74033.6562 - val_loss: 576.7256 - val_mae: 576.7256 - val_mse: 1181711.1250 - lr: 1.0000e-04\n",
      "Epoch 785/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 110.1968 - mae: 110.1968 - mse: 69510.1875 - val_loss: 574.0704 - val_mae: 574.0704 - val_mse: 1170378.8750 - lr: 1.0000e-04\n",
      "Epoch 786/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.5647 - mae: 108.5647 - mse: 71513.0469 - val_loss: 571.4140 - val_mae: 571.4140 - val_mse: 1170137.3750 - lr: 1.0000e-04\n",
      "Epoch 787/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 109.7144 - mae: 109.7144 - mse: 69288.9688 - val_loss: 570.8436 - val_mae: 570.8436 - val_mse: 1167395.3750 - lr: 1.0000e-04\n",
      "Epoch 788/5000\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 109.6370 - mae: 109.6370 - mse: 72329.3516 - val_loss: 571.2611 - val_mae: 571.2611 - val_mse: 1169813.1250 - lr: 1.0000e-04\n",
      "Epoch 789/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 110.8379 - mae: 110.8379 - mse: 69748.1016 - val_loss: 572.8173 - val_mae: 572.8173 - val_mse: 1169285.0000 - lr: 1.0000e-04\n",
      "Epoch 790/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 109.4039 - mae: 109.4039 - mse: 72174.9219 - val_loss: 571.8261 - val_mae: 571.8261 - val_mse: 1171347.6250 - lr: 1.0000e-04\n",
      "Epoch 791/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 110.3198 - mae: 110.3198 - mse: 69538.3438 - val_loss: 572.7635 - val_mae: 572.7635 - val_mse: 1169172.8750 - lr: 1.0000e-04\n",
      "Epoch 792/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 109.0120 - mae: 109.0120 - mse: 71872.7109 - val_loss: 572.5262 - val_mae: 572.5262 - val_mse: 1173010.3750 - lr: 1.0000e-04\n",
      "Epoch 793/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 109.0061 - mae: 109.0061 - mse: 69044.6875 - val_loss: 571.7574 - val_mae: 571.7574 - val_mse: 1167888.3750 - lr: 1.0000e-04\n",
      "Epoch 794/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.1810 - mae: 108.1810 - mse: 71235.2031 - val_loss: 570.7435 - val_mae: 570.7435 - val_mse: 1167978.3750 - lr: 1.0000e-04\n",
      "Epoch 795/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 110.0418 - mae: 110.0418 - mse: 69377.4141 - val_loss: 571.2154 - val_mae: 571.2154 - val_mse: 1166999.6250 - lr: 1.0000e-04\n",
      "Epoch 796/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 109.2669 - mae: 109.2669 - mse: 72074.9844 - val_loss: 571.8222 - val_mae: 571.8222 - val_mse: 1170952.7500 - lr: 1.0000e-04\n",
      "Epoch 797/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 109.6012 - mae: 109.6012 - mse: 69226.5391 - val_loss: 572.0461 - val_mae: 572.0461 - val_mse: 1167549.0000 - lr: 1.0000e-04\n",
      "Epoch 798/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 108.4924 - mae: 108.4924 - mse: 71478.0781 - val_loss: 571.3976 - val_mae: 571.3976 - val_mse: 1169703.3750 - lr: 1.0000e-04\n",
      "Epoch 799/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 109.2319 - mae: 109.2319 - mse: 69079.4297 - val_loss: 571.1151 - val_mae: 571.1151 - val_mse: 1166443.0000 - lr: 1.0000e-04\n",
      "Epoch 800/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 108.6641 - mae: 108.6641 - mse: 71610.2422 - val_loss: 571.1686 - val_mae: 571.1686 - val_mse: 1168979.0000 - lr: 1.0000e-04\n",
      "Epoch 801/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 109.5557 - mae: 109.5557 - mse: 69187.0547 - val_loss: 571.2397 - val_mae: 571.2397 - val_mse: 1166350.8750 - lr: 1.0000e-04\n",
      "Epoch 802/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.8662 - mae: 108.8662 - mse: 71769.6562 - val_loss: 571.5568 - val_mae: 571.5568 - val_mse: 1169986.3750 - lr: 1.0000e-04\n",
      "Epoch 803/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 109.3766 - mae: 109.3766 - mse: 69126.5156 - val_loss: 571.4360 - val_mae: 571.4360 - val_mse: 1166382.0000 - lr: 1.0000e-04\n",
      "Epoch 804/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 108.5546 - mae: 108.5546 - mse: 71530.3672 - val_loss: 571.3177 - val_mae: 571.3177 - val_mse: 1169267.8750 - lr: 1.0000e-04\n",
      "Epoch 805/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 109.1724 - mae: 109.1724 - mse: 69050.5625 - val_loss: 571.4272 - val_mae: 571.4272 - val_mse: 1166251.2500 - lr: 1.0000e-04\n",
      "Epoch 806/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 108.2590 - mae: 108.2590 - mse: 71304.4922 - val_loss: 571.0842 - val_mae: 571.0842 - val_mse: 1168544.8750 - lr: 1.0000e-04\n",
      "Epoch 807/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.9821 - mae: 108.9821 - mse: 68976.3594 - val_loss: 571.1382 - val_mae: 571.1382 - val_mse: 1165834.6250 - lr: 1.0000e-04\n",
      "Epoch 808/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.1511 - mae: 108.1511 - mse: 71224.7969 - val_loss: 570.7491 - val_mae: 570.7491 - val_mse: 1167366.5000 - lr: 1.0000e-04\n",
      "Epoch 809/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 109.2800 - mae: 109.2800 - mse: 69072.7812 - val_loss: 571.0295 - val_mae: 571.0295 - val_mse: 1165493.1250 - lr: 1.0000e-04\n",
      "Epoch 810/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 108.4934 - mae: 108.4934 - mse: 71491.1094 - val_loss: 571.2665 - val_mae: 571.2665 - val_mse: 1168713.1250 - lr: 1.0000e-04\n",
      "Epoch 811/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 108.9864 - mae: 108.9864 - mse: 68974.9922 - val_loss: 571.7408 - val_mae: 571.7408 - val_mse: 1165951.6250 - lr: 1.0000e-04\n",
      "Epoch 812/5000\n",
      "3/3 [==============================] - 1s 256ms/step - loss: 107.7032 - mae: 107.7032 - mse: 70893.1406 - val_loss: 570.7054 - val_mae: 570.7054 - val_mse: 1166847.5000 - lr: 1.0000e-04\n",
      "Epoch 813/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 108.6963 - mae: 108.6963 - mse: 68856.4609 - val_loss: 570.2578 - val_mae: 570.2578 - val_mse: 1164314.0000 - lr: 1.0000e-04\n",
      "Epoch 814/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 108.7917 - mae: 108.7917 - mse: 71727.4453 - val_loss: 571.1628 - val_mae: 571.1628 - val_mse: 1168062.3750 - lr: 1.0000e-04\n",
      "Epoch 815/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 109.2164 - mae: 109.2164 - mse: 69044.4219 - val_loss: 571.1732 - val_mae: 571.1732 - val_mse: 1164943.7500 - lr: 1.0000e-04\n",
      "Epoch 816/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 108.3619 - mae: 108.3619 - mse: 71402.5703 - val_loss: 571.2978 - val_mae: 571.2978 - val_mse: 1168292.8750 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 817/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 108.6973 - mae: 108.6973 - mse: 68860.1406 - val_loss: 570.9401 - val_mae: 570.9401 - val_mse: 1164587.2500 - lr: 1.0000e-04\n",
      "Epoch 818/5000\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 107.8798 - mae: 107.8798 - mse: 71038.9922 - val_loss: 570.3864 - val_mae: 570.3864 - val_mse: 1165599.7500 - lr: 1.0000e-04\n",
      "Epoch 819/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 109.2388 - mae: 109.2388 - mse: 69021.2500 - val_loss: 570.5837 - val_mae: 570.5837 - val_mse: 1164061.5000 - lr: 1.0000e-04\n",
      "Epoch 820/5000\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 108.5273 - mae: 108.5273 - mse: 71537.0625 - val_loss: 571.3571 - val_mae: 571.3571 - val_mse: 1168281.1250 - lr: 1.0000e-04\n",
      "Epoch 821/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 108.6641 - mae: 108.6641 - mse: 68839.1875 - val_loss: 571.0983 - val_mae: 571.0983 - val_mse: 1164431.2500 - lr: 1.0000e-04\n",
      "Epoch 822/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 107.6580 - mae: 107.6579 - mse: 70874.1719 - val_loss: 570.9233 - val_mae: 570.9233 - val_mse: 1167181.8750 - lr: 1.0000e-04\n",
      "Epoch 823/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 107.8622 - mae: 107.8622 - mse: 68574.5000 - val_loss: 570.1119 - val_mae: 570.1119 - val_mse: 1163363.2500 - lr: 1.0000e-04\n",
      "Epoch 824/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 107.6002 - mae: 107.6002 - mse: 70824.2734 - val_loss: 570.3340 - val_mae: 570.3340 - val_mse: 1165487.8750 - lr: 1.0000e-04\n",
      "Epoch 825/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 108.2524 - mae: 108.2524 - mse: 68673.3281 - val_loss: 569.9929 - val_mae: 569.9929 - val_mse: 1163052.2500 - lr: 1.0000e-04\n",
      "Epoch 826/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 107.9798 - mae: 107.9798 - mse: 71115.3594 - val_loss: 569.9276 - val_mae: 569.9276 - val_mse: 1164332.0000 - lr: 1.0000e-04\n",
      "Epoch 827/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 109.5186 - mae: 109.5186 - mse: 69092.0547 - val_loss: 570.5017 - val_mae: 570.5017 - val_mse: 1163328.5000 - lr: 1.0000e-04\n",
      "Epoch 828/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 108.6091 - mae: 108.6091 - mse: 71599.8359 - val_loss: 571.5733 - val_mae: 571.5733 - val_mse: 1168536.6250 - lr: 1.0000e-04\n",
      "Epoch 829/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 108.5069 - mae: 108.5069 - mse: 68768.5000 - val_loss: 571.0447 - val_mae: 571.0447 - val_mse: 1163870.1250 - lr: 1.0000e-04\n",
      "Epoch 830/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.3953 - mae: 107.3953 - mse: 70664.5938 - val_loss: 570.4444 - val_mae: 570.4444 - val_mse: 1165908.2500 - lr: 1.0000e-04\n",
      "Epoch 831/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 107.8223 - mae: 107.8223 - mse: 68540.9609 - val_loss: 569.8734 - val_mae: 569.8734 - val_mse: 1162623.8750 - lr: 1.0000e-04\n",
      "Epoch 832/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 107.5035 - mae: 107.5035 - mse: 70740.6406 - val_loss: 570.0163 - val_mae: 570.0163 - val_mse: 1164696.8750 - lr: 1.0000e-04\n",
      "Epoch 833/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 108.1671 - mae: 108.1671 - mse: 68626.8047 - val_loss: 569.7017 - val_mae: 569.7017 - val_mse: 1162330.2500 - lr: 1.0000e-04\n",
      "Epoch 834/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 107.9906 - mae: 107.9906 - mse: 71111.8281 - val_loss: 569.7588 - val_mae: 569.7588 - val_mse: 1163941.1250 - lr: 1.0000e-04\n",
      "Epoch 835/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.3201 - mae: 109.3201 - mse: 69007.6328 - val_loss: 570.7313 - val_mae: 570.7313 - val_mse: 1163186.5000 - lr: 1.0000e-04\n",
      "Epoch 836/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.9637 - mae: 107.9637 - mse: 71092.3516 - val_loss: 570.4053 - val_mae: 570.4053 - val_mse: 1165679.7500 - lr: 1.0000e-04\n",
      "Epoch 837/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 108.5169 - mae: 108.5169 - mse: 68739.1562 - val_loss: 570.0594 - val_mae: 570.0594 - val_mse: 1162326.0000 - lr: 1.0000e-04\n",
      "Epoch 838/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.7745 - mae: 107.7745 - mse: 70945.2266 - val_loss: 570.3325 - val_mae: 570.3325 - val_mse: 1165415.2500 - lr: 1.0000e-04\n",
      "Epoch 839/5000\n",
      "3/3 [==============================] - 1s 253ms/step - loss: 108.0678 - mae: 108.0678 - mse: 68586.4688 - val_loss: 569.3557 - val_mae: 569.3557 - val_mse: 1161492.8750 - lr: 1.0000e-04\n",
      "Epoch 840/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 108.4413 - mae: 108.4413 - mse: 71453.9531 - val_loss: 570.0184 - val_mae: 570.0184 - val_mse: 1164515.5000 - lr: 1.0000e-04\n",
      "Epoch 841/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 109.1562 - mae: 109.1562 - mse: 68936.8750 - val_loss: 571.1834 - val_mae: 571.1834 - val_mse: 1163282.7500 - lr: 1.0000e-04\n",
      "Epoch 842/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.4572 - mae: 107.4572 - mse: 70704.7500 - val_loss: 571.2245 - val_mae: 571.2245 - val_mse: 1167273.5000 - lr: 1.0000e-04\n",
      "Epoch 843/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.1174 - mae: 107.1174 - mse: 68312.8984 - val_loss: 569.5958 - val_mae: 569.5958 - val_mse: 1161378.5000 - lr: 1.0000e-04\n",
      "Epoch 844/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 106.8955 - mae: 106.8955 - mse: 70267.5312 - val_loss: 569.4499 - val_mae: 569.4499 - val_mse: 1162800.7500 - lr: 1.0000e-04\n",
      "Epoch 845/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.6210 - mae: 107.6210 - mse: 68401.0703 - val_loss: 569.1218 - val_mae: 569.1218 - val_mse: 1160638.0000 - lr: 1.0000e-04\n",
      "Epoch 846/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.7980 - mae: 107.7980 - mse: 70959.2656 - val_loss: 569.5897 - val_mae: 569.5897 - val_mse: 1162914.6250 - lr: 1.0000e-04\n",
      "Epoch 847/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 108.4491 - mae: 108.4491 - mse: 68640.1797 - val_loss: 569.2730 - val_mae: 569.2730 - val_mse: 1160240.0000 - lr: 1.0000e-04\n",
      "Epoch 848/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 108.2766 - mae: 108.2766 - mse: 71333.4062 - val_loss: 569.4162 - val_mae: 569.4162 - val_mse: 1162339.7500 - lr: 1.0000e-04\n",
      "Epoch 849/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 109.6626 - mae: 109.6626 - mse: 69068.2734 - val_loss: 571.6273 - val_mae: 571.6273 - val_mse: 1163014.2500 - lr: 1.0000e-04\n",
      "Epoch 850/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.4303 - mae: 107.4303 - mse: 70681.1016 - val_loss: 571.4804 - val_mae: 571.4804 - val_mse: 1167052.3750 - lr: 1.0000e-04\n",
      "Epoch 851/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.0376 - mae: 107.0376 - mse: 68254.3359 - val_loss: 569.4966 - val_mae: 569.4966 - val_mse: 1160492.2500 - lr: 1.0000e-04\n",
      "Epoch 852/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 106.6847 - mae: 106.6847 - mse: 70098.5469 - val_loss: 569.2275 - val_mae: 569.2275 - val_mse: 1161897.6250 - lr: 1.0000e-04\n",
      "Epoch 853/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 107.4198 - mae: 107.4198 - mse: 68308.8359 - val_loss: 568.9741 - val_mae: 568.9741 - val_mse: 1159717.5000 - lr: 1.0000e-04\n",
      "Epoch 854/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 107.3872 - mae: 107.3872 - mse: 70642.6719 - val_loss: 568.7906 - val_mae: 568.7906 - val_mse: 1160560.2500 - lr: 1.0000e-04\n",
      "Epoch 855/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 108.9374 - mae: 108.9374 - mse: 68759.0391 - val_loss: 569.3596 - val_mae: 569.3596 - val_mse: 1159589.7500 - lr: 1.0000e-04\n",
      "Epoch 856/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 108.0370 - mae: 108.0370 - mse: 71148.5938 - val_loss: 569.4311 - val_mae: 569.4311 - val_mse: 1162107.3750 - lr: 1.0000e-04\n",
      "Epoch 857/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.1092 - mae: 109.1092 - mse: 68830.7031 - val_loss: 570.6469 - val_mae: 570.6469 - val_mse: 1160942.0000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 858/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 107.3027 - mae: 107.3027 - mse: 70583.1094 - val_loss: 570.8715 - val_mae: 570.8715 - val_mse: 1165214.8750 - lr: 1.0000e-04\n",
      "Epoch 859/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 106.9793 - mae: 106.9793 - mse: 68189.9766 - val_loss: 569.0806 - val_mae: 569.0806 - val_mse: 1159062.6250 - lr: 1.0000e-04\n",
      "Epoch 860/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 106.7984 - mae: 106.7984 - mse: 70187.9688 - val_loss: 568.6851 - val_mae: 568.6851 - val_mse: 1160102.2500 - lr: 1.0000e-04\n",
      "Epoch 861/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 108.0358 - mae: 108.0358 - mse: 68439.0938 - val_loss: 568.6383 - val_mae: 568.6383 - val_mse: 1158798.3750 - lr: 1.0000e-04\n",
      "Epoch 862/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 108.2926 - mae: 108.2926 - mse: 71334.3828 - val_loss: 568.7646 - val_mae: 568.7646 - val_mse: 1160285.2500 - lr: 1.0000e-04\n",
      "Epoch 863/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 110.0794 - mae: 110.0794 - mse: 69183.0781 - val_loss: 571.8312 - val_mae: 571.8312 - val_mse: 1162722.1250 - lr: 1.0000e-04\n",
      "Epoch 864/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 107.4042 - mae: 107.4042 - mse: 70657.1016 - val_loss: 572.2598 - val_mae: 572.2598 - val_mse: 1168316.5000 - lr: 1.0000e-04\n",
      "Epoch 865/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 106.5433 - mae: 106.5433 - mse: 68092.8047 - val_loss: 569.1722 - val_mae: 569.1722 - val_mse: 1159459.2500 - lr: 1.0000e-04\n",
      "Epoch 866/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 106.3494 - mae: 106.3494 - mse: 69828.7266 - val_loss: 569.0307 - val_mae: 569.0307 - val_mse: 1161168.7500 - lr: 1.0000e-04\n",
      "Epoch 867/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 106.7716 - mae: 106.7716 - mse: 68103.3203 - val_loss: 568.4219 - val_mae: 568.4219 - val_mse: 1159280.5000 - lr: 1.0000e-04\n",
      "Epoch 868/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 107.8010 - mae: 107.8010 - mse: 70953.1797 - val_loss: 568.5413 - val_mae: 568.5413 - val_mse: 1159695.1250 - lr: 1.0000e-04\n",
      "Epoch 869/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 109.1815 - mae: 109.1815 - mse: 68817.4062 - val_loss: 569.4811 - val_mae: 569.4811 - val_mse: 1159155.3750 - lr: 1.0000e-04\n",
      "Epoch 870/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 107.8598 - mae: 107.8598 - mse: 71009.9062 - val_loss: 569.3892 - val_mae: 569.3892 - val_mse: 1161869.5000 - lr: 1.0000e-04\n",
      "Epoch 871/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 108.6474 - mae: 108.6474 - mse: 68644.1172 - val_loss: 570.0460 - val_mae: 570.0460 - val_mse: 1159691.5000 - lr: 1.0000e-04\n",
      "Epoch 872/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 107.0891 - mae: 107.0891 - mse: 70412.2734 - val_loss: 569.9455 - val_mae: 569.9455 - val_mse: 1163073.1250 - lr: 1.0000e-04\n",
      "Epoch 873/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 107.0505 - mae: 107.0505 - mse: 68164.8438 - val_loss: 568.5172 - val_mae: 568.5172 - val_mse: 1157996.7500 - lr: 1.0000e-04\n",
      "Epoch 874/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 107.3687 - mae: 107.3687 - mse: 70624.7734 - val_loss: 568.6021 - val_mae: 568.6021 - val_mse: 1159687.1250 - lr: 1.0000e-04\n",
      "Epoch 875/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 108.4866 - mae: 108.4866 - mse: 68562.7031 - val_loss: 568.6912 - val_mae: 568.6912 - val_mse: 1157990.3750 - lr: 1.0000e-04\n",
      "Epoch 876/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.1556 - mae: 108.1556 - mse: 71233.4688 - val_loss: 568.5885 - val_mae: 568.5885 - val_mse: 1159651.7500 - lr: 1.0000e-04\n",
      "Epoch 877/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 110.0129 - mae: 110.0129 - mse: 69133.4062 - val_loss: 570.4006 - val_mae: 570.4006 - val_mse: 1160192.5000 - lr: 1.0000e-04\n",
      "Epoch 878/5000\n",
      "3/3 [==============================] - 1s 290ms/step - loss: 108.1776 - mae: 108.1776 - mse: 71247.0312 - val_loss: 571.3831 - val_mae: 571.3831 - val_mse: 1166206.2500 - lr: 1.0000e-04\n",
      "Epoch 879/5000\n",
      "3/3 [==============================] - 1s 369ms/step - loss: 107.7502 - mae: 107.7502 - mse: 68386.3828 - val_loss: 569.3430 - val_mae: 569.3430 - val_mse: 1159333.2500 - lr: 1.0000e-04\n",
      "Epoch 880/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.0404 - mae: 107.0404 - mse: 70378.3516 - val_loss: 569.4685 - val_mae: 569.4685 - val_mse: 1162526.3750 - lr: 1.0000e-04\n",
      "Epoch 881/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.1701 - mae: 107.1701 - mse: 68203.6797 - val_loss: 568.5820 - val_mae: 568.5820 - val_mse: 1158566.2500 - lr: 1.0000e-04\n",
      "Epoch 882/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.3344 - mae: 107.3344 - mse: 70598.0234 - val_loss: 568.7084 - val_mae: 568.7084 - val_mse: 1160389.0000 - lr: 1.0000e-04\n",
      "Epoch 883/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 108.2732 - mae: 108.2732 - mse: 68507.6797 - val_loss: 568.5960 - val_mae: 568.5960 - val_mse: 1158357.8750 - lr: 1.0000e-04\n",
      "Epoch 884/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.2294 - mae: 108.2294 - mse: 71286.3828 - val_loss: 568.7087 - val_mae: 568.7087 - val_mse: 1160307.1250 - lr: 1.0000e-04\n",
      "Epoch 885/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 109.7933 - mae: 109.7933 - mse: 69060.3672 - val_loss: 572.4088 - val_mae: 572.4088 - val_mse: 1163342.7500 - lr: 1.0000e-04\n",
      "Epoch 886/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.8792 - mae: 106.8792 - mse: 70233.8594 - val_loss: 572.1383 - val_mae: 572.1383 - val_mse: 1168024.0000 - lr: 1.0000e-04\n",
      "Epoch 887/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 105.9452 - mae: 105.9452 - mse: 67929.3594 - val_loss: 568.5375 - val_mae: 568.5375 - val_mse: 1158275.0000 - lr: 1.0000e-04\n",
      "Epoch 888/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 106.2873 - mae: 106.2873 - mse: 69779.7578 - val_loss: 568.3420 - val_mae: 568.3420 - val_mse: 1159341.1250 - lr: 1.0000e-04\n",
      "Epoch 889/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 107.0383 - mae: 107.0383 - mse: 68116.0703 - val_loss: 568.0991 - val_mae: 568.0991 - val_mse: 1158144.2500 - lr: 1.0000e-04\n",
      "Epoch 890/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 107.8006 - mae: 107.8006 - mse: 70953.6328 - val_loss: 568.6329 - val_mae: 568.6329 - val_mse: 1159811.6250 - lr: 1.0000e-04\n",
      "Epoch 891/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 108.4771 - mae: 108.4771 - mse: 68540.0234 - val_loss: 568.9109 - val_mae: 568.9109 - val_mse: 1157763.0000 - lr: 1.0000e-04\n",
      "Epoch 892/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.5403 - mae: 107.5403 - mse: 70767.1406 - val_loss: 569.9483 - val_mae: 569.9483 - val_mse: 1162732.6250 - lr: 1.0000e-04\n",
      "Epoch 893/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.3345 - mae: 107.3345 - mse: 68196.7109 - val_loss: 568.5906 - val_mae: 568.5906 - val_mse: 1157198.6250 - lr: 1.0000e-04\n",
      "Epoch 894/5000\n",
      "3/3 [==============================] - 1s 197ms/step - loss: 106.9542 - mae: 106.9542 - mse: 70313.5156 - val_loss: 568.5532 - val_mae: 568.5532 - val_mse: 1159399.6250 - lr: 1.0000e-04\n",
      "Epoch 895/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.6280 - mae: 107.6280 - mse: 68248.0859 - val_loss: 568.2006 - val_mae: 568.2006 - val_mse: 1156856.5000 - lr: 1.0000e-04\n",
      "Epoch 896/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.7237 - mae: 107.7237 - mse: 70908.8672 - val_loss: 568.8222 - val_mae: 568.8222 - val_mse: 1160194.3750 - lr: 1.0000e-04\n",
      "Epoch 897/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 108.1566 - mae: 108.1566 - mse: 68420.1328 - val_loss: 568.5244 - val_mae: 568.5244 - val_mse: 1157078.5000 - lr: 1.0000e-04\n",
      "Epoch 898/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 107.7074 - mae: 107.7074 - mse: 70900.3359 - val_loss: 568.7828 - val_mae: 568.7828 - val_mse: 1160093.1250 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 899/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 108.5042 - mae: 108.5042 - mse: 68539.4062 - val_loss: 569.4354 - val_mae: 569.4354 - val_mse: 1158202.1250 - lr: 1.0000e-04\n",
      "Epoch 900/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 107.0736 - mae: 107.0736 - mse: 70409.4531 - val_loss: 569.7638 - val_mae: 569.7638 - val_mse: 1162371.1250 - lr: 1.0000e-04\n",
      "Epoch 901/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 106.8958 - mae: 106.8958 - mse: 68069.7188 - val_loss: 568.4874 - val_mae: 568.4874 - val_mse: 1156961.0000 - lr: 1.0000e-04\n",
      "Epoch 902/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 106.5929 - mae: 106.5929 - mse: 70034.7109 - val_loss: 568.5531 - val_mae: 568.5531 - val_mse: 1159405.8750 - lr: 1.0000e-04\n",
      "Epoch 903/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.9971 - mae: 106.9971 - mse: 68068.8828 - val_loss: 568.0483 - val_mae: 568.0483 - val_mse: 1156661.3750 - lr: 1.0000e-04\n",
      "Epoch 904/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.3476 - mae: 107.3476 - mse: 70618.2812 - val_loss: 568.3502 - val_mae: 568.3502 - val_mse: 1158738.1250 - lr: 1.0000e-04\n",
      "Epoch 905/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 108.1915 - mae: 108.1915 - mse: 68405.3984 - val_loss: 568.6549 - val_mae: 568.6549 - val_mse: 1156788.1250 - lr: 1.0000e-04\n",
      "Epoch 906/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.3147 - mae: 107.3147 - mse: 70599.2344 - val_loss: 569.7032 - val_mae: 569.7032 - val_mse: 1161950.3750 - lr: 1.0000e-04\n",
      "Epoch 907/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 107.0315 - mae: 107.0315 - mse: 68081.3203 - val_loss: 568.1038 - val_mae: 568.1038 - val_mse: 1156323.6250 - lr: 1.0000e-04\n",
      "Epoch 908/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.3431 - mae: 107.3431 - mse: 70619.3438 - val_loss: 568.6139 - val_mae: 568.6139 - val_mse: 1159466.1250 - lr: 1.0000e-04\n",
      "Epoch 909/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.7702 - mae: 107.7702 - mse: 68275.5938 - val_loss: 568.2579 - val_mae: 568.2579 - val_mse: 1156366.3750 - lr: 1.0000e-04\n",
      "Epoch 910/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.5228 - mae: 107.5228 - mse: 70764.7891 - val_loss: 569.7710 - val_mae: 569.7710 - val_mse: 1162095.6250 - lr: 1.0000e-04\n",
      "Epoch 911/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 107.1014 - mae: 107.1014 - mse: 68102.7734 - val_loss: 568.2219 - val_mae: 568.2219 - val_mse: 1156322.8750 - lr: 1.0000e-04\n",
      "Epoch 912/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.0951 - mae: 107.0951 - mse: 70430.4844 - val_loss: 568.6335 - val_mae: 568.6335 - val_mse: 1159541.5000 - lr: 1.0000e-04\n",
      "Epoch 913/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 107.3680 - mae: 107.3680 - mse: 68151.5000 - val_loss: 568.0011 - val_mae: 568.0011 - val_mse: 1156199.6250 - lr: 1.0000e-04\n",
      "Epoch 914/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.6296 - mae: 107.6296 - mse: 70848.1016 - val_loss: 568.9240 - val_mae: 568.9240 - val_mse: 1160363.8750 - lr: 1.0000e-04\n",
      "Epoch 915/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.6146 - mae: 107.6146 - mse: 68231.6562 - val_loss: 568.2938 - val_mae: 568.2938 - val_mse: 1156311.5000 - lr: 1.0000e-04\n",
      "Epoch 916/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.3767 - mae: 107.3767 - mse: 70654.0078 - val_loss: 569.3452 - val_mae: 569.3452 - val_mse: 1161308.1250 - lr: 1.0000e-04\n",
      "Epoch 917/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.1615 - mae: 107.1615 - mse: 68109.9297 - val_loss: 568.2044 - val_mae: 568.2044 - val_mse: 1156257.3750 - lr: 1.0000e-04\n",
      "Epoch 918/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.1506 - mae: 107.1506 - mse: 70476.0391 - val_loss: 568.8167 - val_mae: 568.8167 - val_mse: 1160104.2500 - lr: 1.0000e-04\n",
      "Epoch 919/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.1960 - mae: 107.1960 - mse: 68103.1094 - val_loss: 567.9903 - val_mae: 567.9903 - val_mse: 1156163.2500 - lr: 1.0000e-04\n",
      "Epoch 920/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 107.5663 - mae: 107.5663 - mse: 70801.4062 - val_loss: 568.7259 - val_mae: 568.7259 - val_mse: 1159812.8750 - lr: 1.0000e-04\n",
      "Epoch 921/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.7145 - mae: 107.7145 - mse: 68249.8047 - val_loss: 568.3516 - val_mae: 568.3516 - val_mse: 1156268.2500 - lr: 1.0000e-04\n",
      "Epoch 922/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.3429 - mae: 107.3429 - mse: 70632.6250 - val_loss: 569.3697 - val_mae: 569.3697 - val_mse: 1161317.6250 - lr: 1.0000e-04\n",
      "Epoch 923/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.1177 - mae: 107.1177 - mse: 68090.1484 - val_loss: 568.2211 - val_mae: 568.2211 - val_mse: 1156174.6250 - lr: 1.0000e-04\n",
      "Epoch 924/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.0711 - mae: 107.0711 - mse: 70420.0000 - val_loss: 568.6548 - val_mae: 568.6548 - val_mse: 1159622.5000 - lr: 1.0000e-04\n",
      "Epoch 925/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.2476 - mae: 107.2476 - mse: 68104.3125 - val_loss: 567.9641 - val_mae: 567.9641 - val_mse: 1156050.0000 - lr: 1.0000e-04\n",
      "Epoch 926/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.6237 - mae: 107.6237 - mse: 70852.4609 - val_loss: 568.9062 - val_mae: 568.9062 - val_mse: 1160304.5000 - lr: 1.0000e-04\n",
      "Epoch 927/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 107.5320 - mae: 107.5320 - mse: 68190.9609 - val_loss: 568.2192 - val_mae: 568.2192 - val_mse: 1156074.3750 - lr: 1.0000e-04\n",
      "Epoch 928/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.3863 - mae: 107.3863 - mse: 70673.3359 - val_loss: 569.3755 - val_mae: 569.3755 - val_mse: 1161294.5000 - lr: 1.0000e-04\n",
      "Epoch 929/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.0970 - mae: 107.0970 - mse: 68077.5625 - val_loss: 568.2290 - val_mae: 568.2290 - val_mse: 1156056.3750 - lr: 1.0000e-04\n",
      "Epoch 930/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.0270 - mae: 107.0270 - mse: 70392.6797 - val_loss: 568.6213 - val_mae: 568.6213 - val_mse: 1159454.6250 - lr: 1.0000e-04\n",
      "Epoch 931/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.2091 - mae: 107.2091 - mse: 68082.8750 - val_loss: 567.9602 - val_mae: 567.9602 - val_mse: 1155917.5000 - lr: 1.0000e-04\n",
      "Epoch 932/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.6484 - mae: 107.6484 - mse: 70878.1641 - val_loss: 568.5508 - val_mae: 568.5508 - val_mse: 1159195.5000 - lr: 1.0000e-04\n",
      "Epoch 933/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 108.0540 - mae: 108.0541 - mse: 68337.8906 - val_loss: 568.4581 - val_mae: 568.4581 - val_mse: 1156157.0000 - lr: 1.0000e-04\n",
      "Epoch 934/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.5411 - mae: 107.5411 - mse: 70801.0078 - val_loss: 568.2056 - val_mae: 568.2056 - val_mse: 1158113.1250 - lr: 1.0000e-04\n",
      "Epoch 935/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 109.0459 - mae: 109.0459 - mse: 68677.9844 - val_loss: 570.0303 - val_mae: 570.0303 - val_mse: 1158561.8750 - lr: 1.0000e-04\n",
      "Epoch 936/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.9499 - mae: 106.9499 - mse: 70336.4688 - val_loss: 571.3802 - val_mae: 571.3802 - val_mse: 1165556.7500 - lr: 1.0000e-04\n",
      "Epoch 937/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 105.8891 - mae: 105.8891 - mse: 67800.7812 - val_loss: 568.2585 - val_mae: 568.2585 - val_mse: 1156285.1250 - lr: 1.0000e-04\n",
      "Epoch 938/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.0416 - mae: 106.0416 - mse: 69615.3281 - val_loss: 568.0204 - val_mae: 568.0204 - val_mse: 1157444.2500 - lr: 1.0000e-04\n",
      "Epoch 939/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.6889 - mae: 106.6889 - mse: 67918.6016 - val_loss: 567.9017 - val_mae: 567.9017 - val_mse: 1156530.1250 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 940/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 107.9808 - mae: 107.9808 - mse: 71113.6172 - val_loss: 567.8420 - val_mae: 567.8420 - val_mse: 1156016.5000 - lr: 1.0000e-04\n",
      "Epoch 941/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 110.0720 - mae: 110.0720 - mse: 69026.3359 - val_loss: 569.4515 - val_mae: 569.4515 - val_mse: 1156961.6250 - lr: 1.0000e-04\n",
      "Epoch 942/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.1251 - mae: 108.1251 - mse: 71234.9297 - val_loss: 570.2136 - val_mae: 570.2136 - val_mse: 1162342.7500 - lr: 1.0000e-04\n",
      "Epoch 943/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.9586 - mae: 107.9587 - mse: 68300.4531 - val_loss: 569.6030 - val_mae: 569.6030 - val_mse: 1157152.0000 - lr: 1.0000e-04\n",
      "Epoch 944/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.4825 - mae: 106.4825 - mse: 69964.8281 - val_loss: 569.3448 - val_mae: 569.3448 - val_mse: 1160625.8750 - lr: 1.0000e-04\n",
      "Epoch 945/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.2710 - mae: 106.2710 - mse: 67809.0469 - val_loss: 567.8188 - val_mae: 567.8188 - val_mse: 1155430.1250 - lr: 1.0000e-04\n",
      "Epoch 946/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.1916 - mae: 107.1916 - mse: 70522.7031 - val_loss: 568.0041 - val_mae: 568.0041 - val_mse: 1157066.3750 - lr: 1.0000e-04\n",
      "Epoch 947/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 108.0161 - mae: 108.0161 - mse: 68269.2109 - val_loss: 568.4483 - val_mae: 568.4483 - val_mse: 1155286.1250 - lr: 1.0000e-04\n",
      "Epoch 948/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 107.1851 - mae: 107.1851 - mse: 70529.9766 - val_loss: 569.4767 - val_mae: 569.4767 - val_mse: 1160683.5000 - lr: 1.0000e-04\n",
      "Epoch 949/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 106.8222 - mae: 106.8222 - mse: 67942.3281 - val_loss: 567.9483 - val_mae: 567.9483 - val_mse: 1154839.1250 - lr: 1.0000e-04\n",
      "Epoch 950/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.1737 - mae: 107.1737 - mse: 70516.5078 - val_loss: 568.5692 - val_mae: 568.5692 - val_mse: 1158828.0000 - lr: 1.0000e-04\n",
      "Epoch 951/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 107.1665 - mae: 107.1665 - mse: 68019.3203 - val_loss: 567.9256 - val_mae: 567.9256 - val_mse: 1154773.8750 - lr: 1.0000e-04\n",
      "Epoch 952/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.4075 - mae: 107.4075 - mse: 70702.5547 - val_loss: 568.2447 - val_mae: 568.2447 - val_mse: 1157786.7500 - lr: 1.0000e-04\n",
      "Epoch 953/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 108.0943 - mae: 108.0943 - mse: 68307.7734 - val_loss: 568.5433 - val_mae: 568.5433 - val_mse: 1155396.3750 - lr: 1.0000e-04\n",
      "Epoch 954/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.2879 - mae: 107.2879 - mse: 70612.7656 - val_loss: 568.6452 - val_mae: 568.6452 - val_mse: 1159180.1250 - lr: 1.0000e-04\n",
      "Epoch 955/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.6436 - mae: 107.6436 - mse: 68181.3750 - val_loss: 568.5404 - val_mae: 568.5404 - val_mse: 1155638.1250 - lr: 1.0000e-04\n",
      "Epoch 956/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.9498 - mae: 106.9498 - mse: 70343.0391 - val_loss: 569.2958 - val_mae: 569.2958 - val_mse: 1160762.7500 - lr: 1.0000e-04\n",
      "Epoch 957/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 106.5736 - mae: 106.5736 - mse: 67899.2031 - val_loss: 568.1053 - val_mae: 568.1053 - val_mse: 1155315.5000 - lr: 1.0000e-04\n",
      "Epoch 958/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 106.5933 - mae: 106.5933 - mse: 70062.6797 - val_loss: 568.0082 - val_mae: 568.0082 - val_mse: 1157159.8750 - lr: 1.0000e-04\n",
      "Epoch 959/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 107.2952 - mae: 107.2952 - mse: 68060.2969 - val_loss: 567.8153 - val_mae: 567.8153 - val_mse: 1155155.6250 - lr: 1.0000e-04\n",
      "Epoch 960/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 107.7641 - mae: 107.7641 - mse: 70963.6875 - val_loss: 567.9403 - val_mae: 567.9403 - val_mse: 1156754.7500 - lr: 1.0000e-04\n",
      "Epoch 961/5000\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 109.0269 - mae: 109.0269 - mse: 68627.8359 - val_loss: 569.7684 - val_mae: 569.7684 - val_mse: 1157281.5000 - lr: 1.0000e-04\n",
      "Epoch 962/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.9321 - mae: 106.9321 - mse: 70329.1797 - val_loss: 571.6339 - val_mae: 571.6339 - val_mse: 1165350.8750 - lr: 1.0000e-04\n",
      "Epoch 963/5000\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 105.7082 - mae: 105.7082 - mse: 67713.3672 - val_loss: 568.2972 - val_mae: 568.2972 - val_mse: 1155117.1250 - lr: 1.0000e-04\n",
      "Epoch 964/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 105.6825 - mae: 105.6825 - mse: 69321.8750 - val_loss: 567.9302 - val_mae: 567.9302 - val_mse: 1156728.5000 - lr: 1.0000e-04\n",
      "Epoch 965/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 105.9471 - mae: 105.9471 - mse: 67687.3359 - val_loss: 567.6701 - val_mae: 567.6701 - val_mse: 1154259.0000 - lr: 1.0000e-04\n",
      "Epoch 966/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 106.2953 - mae: 106.2953 - mse: 69825.4531 - val_loss: 567.8794 - val_mae: 567.8794 - val_mse: 1156204.6250 - lr: 1.0000e-04\n",
      "Epoch 967/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.2860 - mae: 106.2860 - mse: 67722.1328 - val_loss: 567.5619 - val_mae: 567.5619 - val_mse: 1153899.0000 - lr: 1.0000e-04\n",
      "Epoch 968/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.3914 - mae: 107.3914 - mse: 70672.2188 - val_loss: 567.5893 - val_mae: 567.5893 - val_mse: 1154330.5000 - lr: 1.0000e-04\n",
      "Epoch 969/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 108.4419 - mae: 108.4419 - mse: 68309.7812 - val_loss: 568.4438 - val_mae: 568.4438 - val_mse: 1153283.2500 - lr: 1.0000e-04\n",
      "Epoch 970/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.9441 - mae: 106.9441 - mse: 70344.3047 - val_loss: 568.4861 - val_mae: 568.4861 - val_mse: 1156957.7500 - lr: 1.0000e-04\n",
      "Epoch 971/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.2203 - mae: 107.2203 - mse: 67941.5703 - val_loss: 567.7820 - val_mae: 567.7820 - val_mse: 1152543.2500 - lr: 1.0000e-04\n",
      "Epoch 972/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.0760 - mae: 107.0760 - mse: 70446.3984 - val_loss: 567.6530 - val_mae: 567.6530 - val_mse: 1154767.7500 - lr: 1.0000e-04\n",
      "Epoch 973/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.2425 - mae: 108.2425 - mse: 68256.6875 - val_loss: 568.3856 - val_mae: 568.3856 - val_mse: 1153532.8750 - lr: 1.0000e-04\n",
      "Epoch 974/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 106.9519 - mae: 106.9519 - mse: 70349.6953 - val_loss: 568.1572 - val_mae: 568.1572 - val_mse: 1156861.5000 - lr: 1.0000e-04\n",
      "Epoch 975/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.4345 - mae: 107.4345 - mse: 68040.3125 - val_loss: 567.8661 - val_mae: 567.8661 - val_mse: 1153355.0000 - lr: 1.0000e-04\n",
      "Epoch 976/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.2752 - mae: 107.2752 - mse: 70592.7031 - val_loss: 568.5608 - val_mae: 568.5608 - val_mse: 1158094.5000 - lr: 1.0000e-04\n",
      "Epoch 977/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.2292 - mae: 107.2292 - mse: 68005.4062 - val_loss: 567.7963 - val_mae: 567.7963 - val_mse: 1153768.0000 - lr: 1.0000e-04\n",
      "Epoch 978/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.3651 - mae: 107.3651 - mse: 70659.0469 - val_loss: 568.4449 - val_mae: 568.4449 - val_mse: 1158229.3750 - lr: 1.0000e-04\n",
      "Epoch 979/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 107.3436 - mae: 107.3436 - mse: 68053.1484 - val_loss: 567.9623 - val_mae: 567.9623 - val_mse: 1154221.7500 - lr: 1.0000e-04\n",
      "Epoch 980/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 107.2079 - mae: 107.2079 - mse: 70542.2422 - val_loss: 569.1492 - val_mae: 569.1492 - val_mse: 1159978.0000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 981/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 106.6553 - mae: 106.6553 - mse: 67878.9297 - val_loss: 568.2117 - val_mae: 568.2117 - val_mse: 1154566.6250 - lr: 1.0000e-04\n",
      "Epoch 982/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.2412 - mae: 106.2412 - mse: 69793.8047 - val_loss: 567.8635 - val_mae: 567.8635 - val_mse: 1156443.1250 - lr: 1.0000e-04\n",
      "Epoch 983/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.7503 - mae: 106.7503 - mse: 67863.1953 - val_loss: 567.6186 - val_mae: 567.6186 - val_mse: 1154212.1250 - lr: 1.0000e-04\n",
      "Epoch 984/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 107.3582 - mae: 107.3582 - mse: 70650.4609 - val_loss: 567.9448 - val_mae: 567.9448 - val_mse: 1156725.1250 - lr: 1.0000e-04\n",
      "Epoch 985/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 107.6501 - mae: 107.6501 - mse: 68112.9531 - val_loss: 567.9643 - val_mae: 567.9643 - val_mse: 1153712.8750 - lr: 1.0000e-04\n",
      "Epoch 986/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.2430 - mae: 107.2430 - mse: 70571.3281 - val_loss: 568.0315 - val_mae: 568.0315 - val_mse: 1156937.5000 - lr: 1.0000e-04\n",
      "Epoch 987/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.7317 - mae: 107.7317 - mse: 68138.7422 - val_loss: 568.2505 - val_mae: 568.2505 - val_mse: 1154031.5000 - lr: 1.0000e-04\n",
      "Epoch 988/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 106.9322 - mae: 106.9322 - mse: 70333.0234 - val_loss: 569.0299 - val_mae: 569.0299 - val_mse: 1159209.5000 - lr: 1.0000e-04\n",
      "Epoch 989/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.5334 - mae: 106.5334 - mse: 67816.7891 - val_loss: 567.9250 - val_mae: 567.9250 - val_mse: 1153692.2500 - lr: 1.0000e-04\n",
      "Epoch 990/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.3913 - mae: 106.3913 - mse: 69908.9375 - val_loss: 567.6783 - val_mae: 567.6783 - val_mse: 1155325.6250 - lr: 1.0000e-04\n",
      "Epoch 991/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 107.2403 - mae: 107.2403 - mse: 67973.2109 - val_loss: 567.5677 - val_mae: 567.5677 - val_mse: 1153575.1250 - lr: 1.0000e-04\n",
      "Epoch 992/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.7881 - mae: 107.7881 - mse: 70966.3438 - val_loss: 567.6082 - val_mae: 567.6082 - val_mse: 1154674.7500 - lr: 1.0000e-04\n",
      "Epoch 993/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 109.5668 - mae: 109.5668 - mse: 68766.5625 - val_loss: 569.0798 - val_mae: 569.0798 - val_mse: 1155155.7500 - lr: 1.0000e-04\n",
      "Epoch 994/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 107.7130 - mae: 107.7130 - mse: 70918.3906 - val_loss: 569.1140 - val_mae: 569.1140 - val_mse: 1159310.7500 - lr: 1.0000e-04\n",
      "Epoch 995/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 107.7958 - mae: 107.7958 - mse: 68175.5703 - val_loss: 568.6923 - val_mae: 568.6923 - val_mse: 1154596.8750 - lr: 1.0000e-04\n",
      "Epoch 996/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 106.6802 - mae: 106.6802 - mse: 70137.2188 - val_loss: 569.2672 - val_mae: 569.2672 - val_mse: 1159638.2500 - lr: 1.0000e-04\n",
      "Epoch 997/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.1750 - mae: 106.1750 - mse: 67708.3047 - val_loss: 567.7813 - val_mae: 567.7813 - val_mse: 1153376.2500 - lr: 1.0000e-04\n",
      "Epoch 998/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 106.2385 - mae: 106.2385 - mse: 69790.9609 - val_loss: 567.6581 - val_mae: 567.6581 - val_mse: 1155124.0000 - lr: 1.0000e-04\n",
      "Epoch 999/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.8996 - mae: 106.8996 - mse: 67852.3750 - val_loss: 567.7401 - val_mae: 567.7401 - val_mse: 1153068.2500 - lr: 1.0000e-04\n",
      "Epoch 1000/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.6160 - mae: 106.6160 - mse: 70091.6094 - val_loss: 567.7016 - val_mae: 567.7016 - val_mse: 1155326.5000 - lr: 1.0000e-04\n",
      "Epoch 1001/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 107.1502 - mae: 107.1502 - mse: 67915.7109 - val_loss: 567.5453 - val_mae: 567.5453 - val_mse: 1152860.2500 - lr: 1.0000e-04\n",
      "Epoch 1002/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 107.5849 - mae: 107.5849 - mse: 70824.6328 - val_loss: 567.6248 - val_mae: 567.6248 - val_mse: 1154918.5000 - lr: 1.0000e-04\n",
      "Epoch 1003/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 108.5160 - mae: 108.5160 - mse: 68348.5234 - val_loss: 568.2825 - val_mae: 568.2825 - val_mse: 1153352.2500 - lr: 1.0000e-04\n",
      "Epoch 1004/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.4525 - mae: 107.4525 - mse: 70729.8125 - val_loss: 567.6574 - val_mae: 567.6574 - val_mse: 1155237.0000 - lr: 1.0000e-04\n",
      "Epoch 1005/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 109.0093 - mae: 109.0093 - mse: 68542.7344 - val_loss: 568.7480 - val_mae: 568.7480 - val_mse: 1154311.8750 - lr: 1.0000e-04\n",
      "Epoch 1006/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.4752 - mae: 107.4752 - mse: 70744.7500 - val_loss: 568.0963 - val_mae: 568.0963 - val_mse: 1157030.5000 - lr: 1.0000e-04\n",
      "Epoch 1007/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 108.2836 - mae: 108.2836 - mse: 68305.8047 - val_loss: 568.7205 - val_mae: 568.7205 - val_mse: 1154442.0000 - lr: 1.0000e-04\n",
      "Epoch 1008/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.9268 - mae: 106.9268 - mse: 70333.8516 - val_loss: 569.5314 - val_mae: 569.5314 - val_mse: 1160181.3750 - lr: 1.0000e-04\n",
      "Epoch 1009/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 106.3191 - mae: 106.3191 - mse: 67740.8750 - val_loss: 568.2155 - val_mae: 568.2155 - val_mse: 1153771.2500 - lr: 1.0000e-04\n",
      "Epoch 1010/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 105.8027 - mae: 105.8027 - mse: 69439.4688 - val_loss: 568.2509 - val_mae: 568.2509 - val_mse: 1157488.6250 - lr: 1.0000e-04\n",
      "Epoch 1011/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 105.4570 - mae: 105.4570 - mse: 67524.1641 - val_loss: 567.6236 - val_mae: 567.6236 - val_mse: 1152996.1250 - lr: 1.0000e-04\n",
      "Epoch 1012/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 105.6983 - mae: 105.6983 - mse: 69357.1328 - val_loss: 567.5487 - val_mae: 567.5487 - val_mse: 1154380.3750 - lr: 1.0000e-04\n",
      "Epoch 1013/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 105.9920 - mae: 105.9920 - mse: 67580.7344 - val_loss: 567.4208 - val_mae: 567.4208 - val_mse: 1153149.2500 - lr: 1.0000e-04\n",
      "Epoch 1014/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.0068 - mae: 107.0068 - mse: 70382.0703 - val_loss: 567.3815 - val_mae: 567.3815 - val_mse: 1152925.7500 - lr: 1.0000e-04\n",
      "Epoch 1015/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 108.2169 - mae: 108.2169 - mse: 68180.7656 - val_loss: 567.9259 - val_mae: 567.9259 - val_mse: 1151769.0000 - lr: 1.0000e-04\n",
      "Epoch 1016/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 107.1749 - mae: 107.1749 - mse: 70527.4609 - val_loss: 567.8733 - val_mae: 567.8733 - val_mse: 1155249.8750 - lr: 1.0000e-04\n",
      "Epoch 1017/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.7299 - mae: 107.7299 - mse: 68041.9531 - val_loss: 568.0654 - val_mae: 568.0654 - val_mse: 1151976.5000 - lr: 1.0000e-04\n",
      "Epoch 1018/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 106.7437 - mae: 106.7437 - mse: 70200.1562 - val_loss: 567.5005 - val_mae: 567.5005 - val_mse: 1154306.0000 - lr: 1.0000e-04\n",
      "Epoch 1019/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 107.7191 - mae: 107.7191 - mse: 68043.9219 - val_loss: 567.7756 - val_mae: 567.7756 - val_mse: 1152035.0000 - lr: 1.0000e-04\n",
      "Epoch 1020/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.1376 - mae: 107.1376 - mse: 70497.5156 - val_loss: 567.8229 - val_mae: 567.8229 - val_mse: 1155795.1250 - lr: 1.0000e-04\n",
      "Epoch 1021/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 107.5837 - mae: 107.5837 - mse: 68035.2656 - val_loss: 567.9588 - val_mae: 567.9588 - val_mse: 1152755.2500 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1022/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.9121 - mae: 106.9121 - mse: 70323.3203 - val_loss: 567.8846 - val_mae: 567.8846 - val_mse: 1156473.2500 - lr: 1.0000e-04\n",
      "Epoch 1023/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.2141 - mae: 107.2141 - mse: 67950.3125 - val_loss: 567.6248 - val_mae: 567.6248 - val_mse: 1153009.0000 - lr: 1.0000e-04\n",
      "Epoch 1024/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.3631 - mae: 107.3631 - mse: 70659.4297 - val_loss: 567.7710 - val_mae: 567.7710 - val_mse: 1156297.6250 - lr: 1.0000e-04\n",
      "Epoch 1025/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.8719 - mae: 107.8719 - mse: 68167.2109 - val_loss: 567.9407 - val_mae: 567.9407 - val_mse: 1153576.3750 - lr: 1.0000e-04\n",
      "Epoch 1026/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.3471 - mae: 107.3471 - mse: 70650.4766 - val_loss: 568.0375 - val_mae: 568.0375 - val_mse: 1157391.2500 - lr: 1.0000e-04\n",
      "Epoch 1027/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 107.6693 - mae: 107.6693 - mse: 68122.7031 - val_loss: 567.9833 - val_mae: 567.9833 - val_mse: 1153840.7500 - lr: 1.0000e-04\n",
      "Epoch 1028/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.1828 - mae: 107.1828 - mse: 70525.2422 - val_loss: 568.7012 - val_mae: 568.7012 - val_mse: 1158936.1250 - lr: 1.0000e-04\n",
      "Epoch 1029/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 106.8163 - mae: 106.8163 - mse: 67878.6406 - val_loss: 568.1026 - val_mae: 568.1026 - val_mse: 1154044.7500 - lr: 1.0000e-04\n",
      "Epoch 1030/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 106.2697 - mae: 106.2697 - mse: 69818.0469 - val_loss: 568.0472 - val_mae: 568.0472 - val_mse: 1157529.8750 - lr: 1.0000e-04\n",
      "Epoch 1031/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.1751 - mae: 106.1751 - mse: 67691.7109 - val_loss: 567.6827 - val_mae: 567.6827 - val_mse: 1153562.3750 - lr: 1.0000e-04\n",
      "Epoch 1032/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.2335 - mae: 106.2335 - mse: 69792.4688 - val_loss: 567.5287 - val_mae: 567.5287 - val_mse: 1154852.1250 - lr: 1.0000e-04\n",
      "Epoch 1033/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.0330 - mae: 107.0330 - mse: 67883.1016 - val_loss: 567.7809 - val_mae: 567.7809 - val_mse: 1153148.1250 - lr: 1.0000e-04\n",
      "Epoch 1034/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 106.4414 - mae: 106.4414 - mse: 69958.0156 - val_loss: 567.9336 - val_mae: 567.9336 - val_mse: 1156736.6250 - lr: 1.0000e-04\n",
      "Epoch 1035/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 106.2889 - mae: 106.2889 - mse: 67682.1016 - val_loss: 567.6012 - val_mae: 567.6012 - val_mse: 1152630.6250 - lr: 1.0000e-04\n",
      "Epoch 1036/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.1782 - mae: 106.1782 - mse: 69753.9062 - val_loss: 567.3907 - val_mae: 567.3907 - val_mse: 1153898.6250 - lr: 1.0000e-04\n",
      "Epoch 1037/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 107.0421 - mae: 107.0421 - mse: 67848.7734 - val_loss: 567.6134 - val_mae: 567.6134 - val_mse: 1152158.1250 - lr: 1.0000e-04\n",
      "Epoch 1038/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 106.4612 - mae: 106.4612 - mse: 69976.1328 - val_loss: 568.0167 - val_mae: 568.0167 - val_mse: 1156217.7500 - lr: 1.0000e-04\n",
      "Epoch 1039/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 106.2155 - mae: 106.2155 - mse: 67628.5938 - val_loss: 567.4172 - val_mae: 567.4172 - val_mse: 1151738.2500 - lr: 1.0000e-04\n",
      "Epoch 1040/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 106.1911 - mae: 106.1911 - mse: 69766.5469 - val_loss: 567.2371 - val_mae: 567.2371 - val_mse: 1152870.8750 - lr: 1.0000e-04\n",
      "Epoch 1041/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 107.1957 - mae: 107.1957 - mse: 67853.6328 - val_loss: 567.2208 - val_mae: 567.2208 - val_mse: 1151601.7500 - lr: 1.0000e-04\n",
      "Epoch 1042/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 107.5634 - mae: 107.5634 - mse: 70809.1250 - val_loss: 567.2388 - val_mae: 567.2388 - val_mse: 1153042.5000 - lr: 1.0000e-04\n",
      "Epoch 1043/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 109.0513 - mae: 109.0513 - mse: 68488.9844 - val_loss: 568.1773 - val_mae: 568.1773 - val_mse: 1152371.6250 - lr: 1.0000e-04\n",
      "Epoch 1044/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.6289 - mae: 107.6289 - mse: 70866.0156 - val_loss: 567.8850 - val_mae: 567.8850 - val_mse: 1155711.5000 - lr: 1.0000e-04\n",
      "Epoch 1045/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 108.3712 - mae: 108.3712 - mse: 68271.8281 - val_loss: 568.2520 - val_mae: 568.2520 - val_mse: 1152585.5000 - lr: 1.0000e-04\n",
      "Epoch 1046/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 107.1249 - mae: 107.1249 - mse: 70498.3359 - val_loss: 567.5175 - val_mae: 567.5175 - val_mse: 1154802.0000 - lr: 1.0000e-04\n",
      "Epoch 1047/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 108.2326 - mae: 108.2326 - mse: 68219.7344 - val_loss: 567.7542 - val_mae: 567.7542 - val_mse: 1152024.2500 - lr: 1.0000e-04\n",
      "Epoch 1048/5000\n",
      "3/3 [==============================] - 1s 204ms/step - loss: 107.6891 - mae: 107.6891 - mse: 70917.4766 - val_loss: 567.4493 - val_mae: 567.4493 - val_mse: 1154581.6250 - lr: 1.0000e-04\n",
      "Epoch 1049/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 109.0316 - mae: 109.0316 - mse: 68507.6953 - val_loss: 568.4662 - val_mae: 568.4662 - val_mse: 1153078.0000 - lr: 1.0000e-04\n",
      "Epoch 1050/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.5892 - mae: 107.5892 - mse: 70848.8672 - val_loss: 568.6512 - val_mae: 568.6512 - val_mse: 1157527.7500 - lr: 1.0000e-04\n",
      "Epoch 1051/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.7711 - mae: 107.7711 - mse: 68082.4688 - val_loss: 568.4091 - val_mae: 568.4091 - val_mse: 1152913.6250 - lr: 1.0000e-04\n",
      "Epoch 1052/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 106.5185 - mae: 106.5185 - mse: 70044.0469 - val_loss: 568.9257 - val_mae: 568.9257 - val_mse: 1158029.5000 - lr: 1.0000e-04\n",
      "Epoch 1053/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.0789 - mae: 106.0789 - mse: 67594.4766 - val_loss: 567.6725 - val_mae: 567.6725 - val_mse: 1151964.3750 - lr: 1.0000e-04\n",
      "Epoch 1054/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 105.8072 - mae: 105.8072 - mse: 69475.4141 - val_loss: 567.4855 - val_mae: 567.4855 - val_mse: 1154690.5000 - lr: 1.0000e-04\n",
      "Epoch 1055/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 105.9203 - mae: 105.9203 - mse: 67520.5000 - val_loss: 567.2645 - val_mae: 567.2645 - val_mse: 1151977.1250 - lr: 1.0000e-04\n",
      "Epoch 1056/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.5491 - mae: 106.5491 - mse: 70053.0078 - val_loss: 567.2656 - val_mae: 567.2656 - val_mse: 1153205.8750 - lr: 1.0000e-04\n",
      "Epoch 1057/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 107.1944 - mae: 107.1944 - mse: 67837.1016 - val_loss: 567.3837 - val_mae: 567.3837 - val_mse: 1151128.8750 - lr: 1.0000e-04\n",
      "Epoch 1058/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 106.9484 - mae: 106.9484 - mse: 70374.0078 - val_loss: 567.3441 - val_mae: 567.3441 - val_mse: 1153892.0000 - lr: 1.0000e-04\n",
      "Epoch 1059/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 107.6007 - mae: 107.6007 - mse: 67965.5859 - val_loss: 567.5046 - val_mae: 567.5046 - val_mse: 1151256.3750 - lr: 1.0000e-04\n",
      "Epoch 1060/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 107.1379 - mae: 107.1379 - mse: 70514.7344 - val_loss: 567.5502 - val_mae: 567.5502 - val_mse: 1154851.5000 - lr: 1.0000e-04\n",
      "Epoch 1061/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.6593 - mae: 107.6593 - mse: 68009.5938 - val_loss: 567.8455 - val_mae: 567.8455 - val_mse: 1152007.5000 - lr: 1.0000e-04\n",
      "Epoch 1062/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.8063 - mae: 106.8063 - mse: 70262.2812 - val_loss: 567.5057 - val_mae: 567.5057 - val_mse: 1155080.0000 - lr: 1.0000e-04\n",
      "Epoch 1063/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.5080 - mae: 107.5080 - mse: 67989.0469 - val_loss: 567.6310 - val_mae: 567.6310 - val_mse: 1152353.2500 - lr: 1.0000e-04\n",
      "Epoch 1064/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 107.0913 - mae: 107.0913 - mse: 70473.5703 - val_loss: 568.0065 - val_mae: 568.0065 - val_mse: 1156975.2500 - lr: 1.0000e-04\n",
      "Epoch 1065/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 107.0613 - mae: 107.0613 - mse: 67891.9141 - val_loss: 567.8243 - val_mae: 567.8243 - val_mse: 1152943.0000 - lr: 1.0000e-04\n",
      "Epoch 1066/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 106.5029 - mae: 106.5029 - mse: 70015.4922 - val_loss: 568.7797 - val_mae: 568.7797 - val_mse: 1158806.5000 - lr: 1.0000e-04\n",
      "Epoch 1067/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 105.7652 - mae: 105.7652 - mse: 67567.8984 - val_loss: 567.6167 - val_mae: 567.6167 - val_mse: 1152696.3750 - lr: 1.0000e-04\n",
      "Epoch 1068/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 105.6771 - mae: 105.6771 - mse: 69366.3828 - val_loss: 567.3675 - val_mae: 567.3675 - val_mse: 1154570.6250 - lr: 1.0000e-04\n",
      "Epoch 1069/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 105.9011 - mae: 105.9011 - mse: 67543.4375 - val_loss: 567.2189 - val_mae: 567.2189 - val_mse: 1152657.0000 - lr: 1.0000e-04\n",
      "Epoch 1070/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 106.7908 - mae: 106.7908 - mse: 70226.2578 - val_loss: 567.2120 - val_mae: 567.2120 - val_mse: 1153360.2500 - lr: 1.0000e-04\n",
      "Epoch 1071/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.3161 - mae: 107.3161 - mse: 67884.2031 - val_loss: 567.2766 - val_mae: 567.2766 - val_mse: 1151146.3750 - lr: 1.0000e-04\n",
      "Epoch 1072/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.2633 - mae: 107.2633 - mse: 70601.3672 - val_loss: 567.2073 - val_mae: 567.2073 - val_mse: 1153328.2500 - lr: 1.0000e-04\n",
      "Epoch 1073/5000\n",
      "3/3 [==============================] - 1s 208ms/step - loss: 108.2828 - mae: 108.2828 - mse: 68194.3750 - val_loss: 567.4755 - val_mae: 567.4755 - val_mse: 1151092.2500 - lr: 1.0000e-04\n",
      "Epoch 1074/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.9233 - mae: 107.9233 - mse: 71087.9453 - val_loss: 567.4476 - val_mae: 567.4476 - val_mse: 1154294.3750 - lr: 1.0000e-04\n",
      "Epoch 1075/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 108.9884 - mae: 108.9884 - mse: 68459.6953 - val_loss: 568.4553 - val_mae: 568.4553 - val_mse: 1152386.1250 - lr: 1.0000e-04\n",
      "Epoch 1076/5000\n",
      "3/3 [==============================] - 1s 330ms/step - loss: 107.3850 - mae: 107.3850 - mse: 70699.9219 - val_loss: 567.9172 - val_mae: 567.9172 - val_mse: 1155343.0000 - lr: 1.0000e-04\n",
      "Epoch 1077/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 108.1354 - mae: 108.1354 - mse: 68155.6250 - val_loss: 567.9394 - val_mae: 567.9394 - val_mse: 1151506.7500 - lr: 1.0000e-04\n",
      "Epoch 1078/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 107.2034 - mae: 107.2034 - mse: 70571.1797 - val_loss: 567.7801 - val_mae: 567.7801 - val_mse: 1155029.8750 - lr: 1.0000e-04\n",
      "Epoch 1079/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 107.8093 - mae: 107.8093 - mse: 68040.3516 - val_loss: 568.4246 - val_mae: 568.4246 - val_mse: 1152312.5000 - lr: 1.0000e-04\n",
      "Epoch 1080/5000\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 106.2874 - mae: 106.2874 - mse: 69865.2266 - val_loss: 570.4393 - val_mae: 570.4393 - val_mse: 1160737.1250 - lr: 1.0000e-04\n",
      "Epoch 1081/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 105.1217 - mae: 105.1217 - mse: 67383.7969 - val_loss: 567.5057 - val_mae: 567.5057 - val_mse: 1151203.1250 - lr: 1.0000e-04\n",
      "Epoch 1082/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 105.2344 - mae: 105.2344 - mse: 69015.3516 - val_loss: 567.2504 - val_mae: 567.2504 - val_mse: 1153249.7500 - lr: 1.0000e-04\n",
      "Epoch 1083/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 105.3893 - mae: 105.3893 - mse: 67370.3438 - val_loss: 567.2374 - val_mae: 567.2374 - val_mse: 1150870.1250 - lr: 1.0000e-04\n",
      "Epoch 1084/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 105.5154 - mae: 105.5154 - mse: 69259.7109 - val_loss: 567.1685 - val_mae: 567.1685 - val_mse: 1152335.2500 - lr: 1.0000e-04\n",
      "Epoch 1085/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 105.7076 - mae: 105.7076 - mse: 67398.7109 - val_loss: 567.0850 - val_mae: 567.0850 - val_mse: 1151139.5000 - lr: 1.0000e-04\n",
      "Epoch 1086/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.6569 - mae: 106.6569 - mse: 70152.4531 - val_loss: 567.0364 - val_mae: 567.0364 - val_mse: 1150653.0000 - lr: 1.0000e-04\n",
      "Epoch 1087/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 107.9050 - mae: 107.9050 - mse: 67970.3203 - val_loss: 567.4954 - val_mae: 567.4954 - val_mse: 1149508.8750 - lr: 1.0000e-04\n",
      "Epoch 1088/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.8100 - mae: 106.8100 - mse: 70289.3984 - val_loss: 567.4423 - val_mae: 567.4423 - val_mse: 1152676.0000 - lr: 1.0000e-04\n",
      "Epoch 1089/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 107.5728 - mae: 107.5728 - mse: 67886.8672 - val_loss: 567.8056 - val_mae: 567.8056 - val_mse: 1149974.5000 - lr: 1.0000e-04\n",
      "Epoch 1090/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 106.3018 - mae: 106.3018 - mse: 69888.3516 - val_loss: 567.8704 - val_mae: 567.8704 - val_mse: 1153906.1250 - lr: 1.0000e-04\n",
      "Epoch 1091/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.4906 - mae: 106.4906 - mse: 67601.7422 - val_loss: 567.3480 - val_mae: 567.3480 - val_mse: 1149865.0000 - lr: 1.0000e-04\n",
      "Epoch 1092/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 106.0618 - mae: 106.0618 - mse: 69695.8359 - val_loss: 567.1625 - val_mae: 567.1625 - val_mse: 1152544.8750 - lr: 1.0000e-04\n",
      "Epoch 1093/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 106.5724 - mae: 106.5724 - mse: 67621.4375 - val_loss: 567.1439 - val_mae: 567.1439 - val_mse: 1150108.3750 - lr: 1.0000e-04\n",
      "Epoch 1094/5000\n",
      "3/3 [==============================] - 1s 206ms/step - loss: 106.6299 - mae: 106.6299 - mse: 70138.5469 - val_loss: 567.1622 - val_mae: 567.1622 - val_mse: 1152570.8750 - lr: 1.0000e-04\n",
      "Epoch 1095/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 107.1829 - mae: 107.1829 - mse: 67796.5234 - val_loss: 567.1683 - val_mae: 567.1683 - val_mse: 1150211.5000 - lr: 1.0000e-04\n",
      "Epoch 1096/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 107.3137 - mae: 107.3137 - mse: 70654.4141 - val_loss: 567.2206 - val_mae: 567.2206 - val_mse: 1152985.5000 - lr: 1.0000e-04\n",
      "Epoch 1097/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 108.1512 - mae: 108.1512 - mse: 68129.3125 - val_loss: 567.5698 - val_mae: 567.5698 - val_mse: 1150605.0000 - lr: 1.0000e-04\n",
      "Epoch 1098/5000\n",
      "3/3 [==============================] - 1s 202ms/step - loss: 107.4227 - mae: 107.4227 - mse: 70739.7734 - val_loss: 567.1208 - val_mae: 567.1208 - val_mse: 1152153.8750 - lr: 1.0000e-04\n",
      "Epoch 1099/5000\n",
      "3/3 [==============================] - 1s 186ms/step - loss: 109.5059 - mae: 109.5059 - mse: 68626.7344 - val_loss: 568.3670 - val_mae: 568.3670 - val_mse: 1151846.0000 - lr: 1.0000e-04\n",
      "Epoch 1100/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 107.7934 - mae: 107.7934 - mse: 71013.1328 - val_loss: 568.6200 - val_mae: 568.6200 - val_mse: 1156549.5000 - lr: 1.0000e-04\n",
      "Epoch 1101/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 108.0855 - mae: 108.0855 - mse: 68138.3516 - val_loss: 568.3143 - val_mae: 568.3143 - val_mse: 1151800.2500 - lr: 1.0000e-04\n",
      "Epoch 1102/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 106.8120 - mae: 106.8120 - mse: 70294.5078 - val_loss: 568.8530 - val_mae: 568.8530 - val_mse: 1157112.5000 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1103/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 106.5745 - mae: 106.5745 - mse: 67674.3047 - val_loss: 567.6651 - val_mae: 567.6651 - val_mse: 1151056.8750 - lr: 1.0000e-04\n",
      "Epoch 1104/5000\n",
      "3/3 [==============================] - 1s 210ms/step - loss: 106.2195 - mae: 106.2195 - mse: 69829.7266 - val_loss: 567.9976 - val_mae: 567.9976 - val_mse: 1155494.5000 - lr: 1.0000e-04\n",
      "Epoch 1105/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 106.0344 - mae: 106.0344 - mse: 67522.2578 - val_loss: 567.4044 - val_mae: 567.4044 - val_mse: 1150929.8750 - lr: 1.0000e-04\n",
      "Epoch 1106/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 106.1421 - mae: 106.1421 - mse: 69771.5156 - val_loss: 567.2502 - val_mae: 567.2502 - val_mse: 1152615.8750 - lr: 1.0000e-04\n",
      "Epoch 1107/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.8956 - mae: 106.8956 - mse: 67718.8516 - val_loss: 567.3207 - val_mae: 567.3207 - val_mse: 1150554.0000 - lr: 1.0000e-04\n",
      "Epoch 1108/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 106.8549 - mae: 106.8549 - mse: 70326.2578 - val_loss: 567.3495 - val_mae: 567.3495 - val_mse: 1153330.6250 - lr: 1.0000e-04\n",
      "Epoch 1109/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 107.3194 - mae: 107.3194 - mse: 67848.9297 - val_loss: 567.5509 - val_mae: 567.5509 - val_mse: 1150575.5000 - lr: 1.0000e-04\n",
      "Epoch 1110/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.7458 - mae: 106.7458 - mse: 70247.5156 - val_loss: 567.9589 - val_mae: 567.9589 - val_mse: 1155096.0000 - lr: 1.0000e-04\n",
      "Epoch 1111/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 106.7019 - mae: 106.7019 - mse: 67698.8047 - val_loss: 567.4485 - val_mae: 567.4485 - val_mse: 1150904.2500 - lr: 1.0000e-04\n",
      "Epoch 1112/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 106.6405 - mae: 106.6405 - mse: 70160.5781 - val_loss: 567.6511 - val_mae: 567.6511 - val_mse: 1154760.2500 - lr: 1.0000e-04\n",
      "Epoch 1113/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 106.7087 - mae: 106.7087 - mse: 67713.5938 - val_loss: 567.7637 - val_mae: 567.7637 - val_mse: 1151423.8750 - lr: 1.0000e-04\n",
      "Epoch 1114/5000\n",
      "3/3 [==============================] - 1s 211ms/step - loss: 105.9696 - mae: 105.9696 - mse: 69632.8047 - val_loss: 567.3881 - val_mae: 567.3881 - val_mse: 1154019.1250 - lr: 1.0000e-04\n",
      "Epoch 1115/5000\n",
      "3/3 [==============================] - 1s 207ms/step - loss: 106.3461 - mae: 106.3461 - mse: 67606.8750 - val_loss: 567.3807 - val_mae: 567.3807 - val_mse: 1151069.5000 - lr: 1.0000e-04\n",
      "Epoch 1116/5000\n",
      "3/3 [==============================] - 1s 209ms/step - loss: 106.3285 - mae: 106.3285 - mse: 69914.0703 - val_loss: 567.3177 - val_mae: 567.3177 - val_mse: 1153496.8750 - lr: 1.0000e-04\n",
      "Epoch 1117/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 106.6691 - mae: 106.6692 - mse: 67674.8281 - val_loss: 567.4117 - val_mae: 567.4117 - val_mse: 1150508.3750 - lr: 1.0000e-04\n",
      "Epoch 1118/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.3362 - mae: 106.3362 - mse: 69925.6875 - val_loss: 567.7286 - val_mae: 567.7286 - val_mse: 1154210.5000 - lr: 1.0000e-04\n",
      "Epoch 1119/5000\n",
      "3/3 [==============================] - 1s 194ms/step - loss: 106.3258 - mae: 106.3258 - mse: 67577.2812 - val_loss: 567.4639 - val_mae: 567.4639 - val_mse: 1150096.7500 - lr: 1.0000e-04\n",
      "Epoch 1120/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 105.8495 - mae: 105.8495 - mse: 69549.1016 - val_loss: 567.0905 - val_mae: 567.0905 - val_mse: 1151299.0000 - lr: 1.0000e-04\n",
      "Epoch 1121/5000\n",
      "3/3 [==============================] - 1s 250ms/step - loss: 106.9059 - mae: 106.9059 - mse: 67684.6406 - val_loss: 567.1815 - val_mae: 567.1815 - val_mse: 1149614.2500 - lr: 1.0000e-04\n",
      "Epoch 1122/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 106.6554 - mae: 106.6554 - mse: 70175.1328 - val_loss: 567.0955 - val_mae: 567.0955 - val_mse: 1151405.7500 - lr: 1.0000e-04\n",
      "Epoch 1123/5000\n",
      "3/3 [==============================] - 1s 318ms/step - loss: 107.7456 - mae: 107.7456 - mse: 67947.5547 - val_loss: 567.6979 - val_mae: 567.6979 - val_mse: 1149994.5000 - lr: 1.0000e-04\n",
      "Epoch 1124/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 106.5631 - mae: 106.5631 - mse: 70110.2109 - val_loss: 568.5047 - val_mae: 568.5047 - val_mse: 1155496.7500 - lr: 1.0000e-04\n",
      "Epoch 1125/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 106.3000 - mae: 106.3000 - mse: 67580.3281 - val_loss: 567.5548 - val_mae: 567.5548 - val_mse: 1150252.5000 - lr: 1.0000e-04\n",
      "Epoch 1126/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 105.8158 - mae: 105.8158 - mse: 69522.5469 - val_loss: 567.1423 - val_mae: 567.1423 - val_mse: 1151967.1250 - lr: 1.0000e-04\n",
      "Epoch 1127/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.7258 - mae: 106.7258 - mse: 67669.2812 - val_loss: 567.2063 - val_mae: 567.2063 - val_mse: 1150344.5000 - lr: 1.0000e-04\n",
      "Epoch 1128/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 106.7508 - mae: 106.7508 - mse: 70245.1875 - val_loss: 567.1617 - val_mae: 567.1617 - val_mse: 1152158.3750 - lr: 1.0000e-04\n",
      "Epoch 1129/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.7457 - mae: 107.7457 - mse: 67984.8906 - val_loss: 567.5504 - val_mae: 567.5504 - val_mse: 1150472.7500 - lr: 1.0000e-04\n",
      "Epoch 1130/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.0038 - mae: 107.0038 - mse: 70446.8281 - val_loss: 567.9033 - val_mae: 567.9033 - val_mse: 1154822.2500 - lr: 1.0000e-04\n",
      "Epoch 1131/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 107.0775 - mae: 107.0775 - mse: 67804.1641 - val_loss: 567.5197 - val_mae: 567.5197 - val_mse: 1150725.7500 - lr: 1.0000e-04\n",
      "Epoch 1132/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 106.7367 - mae: 106.7367 - mse: 70241.6562 - val_loss: 567.7220 - val_mae: 567.7220 - val_mse: 1154738.0000 - lr: 1.0000e-04\n",
      "Epoch 1133/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 106.8575 - mae: 106.8575 - mse: 67760.0391 - val_loss: 567.5418 - val_mae: 567.5418 - val_mse: 1151124.8750 - lr: 1.0000e-04\n",
      "Epoch 1134/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 106.5854 - mae: 106.5854 - mse: 70123.5547 - val_loss: 567.6201 - val_mae: 567.6201 - val_mse: 1154743.5000 - lr: 1.0000e-04\n",
      "Epoch 1135/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.7051 - mae: 106.7051 - mse: 67728.3984 - val_loss: 567.9928 - val_mae: 567.9928 - val_mse: 1151785.6250 - lr: 1.0000e-04\n",
      "Epoch 1136/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 105.6367 - mae: 105.6367 - mse: 69383.5000 - val_loss: 567.2943 - val_mae: 567.2943 - val_mse: 1153209.5000 - lr: 1.0000e-04\n",
      "Epoch 1137/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.2381 - mae: 106.2381 - mse: 67578.2656 - val_loss: 567.2313 - val_mae: 567.2313 - val_mse: 1151275.0000 - lr: 1.0000e-04\n",
      "Epoch 1138/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 106.7808 - mae: 106.7808 - mse: 70257.9531 - val_loss: 567.1972 - val_mae: 567.1972 - val_mse: 1152238.3750 - lr: 1.0000e-04\n",
      "Epoch 1139/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 107.6944 - mae: 107.6944 - mse: 67977.9375 - val_loss: 567.4559 - val_mae: 567.4559 - val_mse: 1150424.5000 - lr: 1.0000e-04\n",
      "Epoch 1140/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.1929 - mae: 107.1929 - mse: 70586.8984 - val_loss: 567.2095 - val_mae: 567.2095 - val_mse: 1152563.5000 - lr: 1.0000e-04\n",
      "Epoch 1141/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 108.4513 - mae: 108.4513 - mse: 68235.5703 - val_loss: 567.7327 - val_mae: 567.7327 - val_mse: 1150621.8750 - lr: 1.0000e-04\n",
      "Epoch 1142/5000\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 107.5917 - mae: 107.5917 - mse: 70883.8203 - val_loss: 567.3818 - val_mae: 567.3818 - val_mse: 1153336.2500 - lr: 1.0000e-04\n",
      "Epoch 1143/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 108.8643 - mae: 108.8643 - mse: 68391.1719 - val_loss: 568.0080 - val_mae: 568.0080 - val_mse: 1150940.8750 - lr: 1.0000e-04\n",
      "Epoch 1144/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 107.7087 - mae: 107.7087 - mse: 70975.0859 - val_loss: 567.6031 - val_mae: 567.6031 - val_mse: 1153913.5000 - lr: 1.0000e-04\n",
      "Epoch 1145/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 108.8625 - mae: 108.8625 - mse: 68389.7812 - val_loss: 568.4230 - val_mae: 568.4230 - val_mse: 1151410.7500 - lr: 1.0000e-04\n",
      "Epoch 1146/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 107.2624 - mae: 107.2624 - mse: 70653.5156 - val_loss: 567.5618 - val_mae: 567.5618 - val_mse: 1153719.5000 - lr: 1.0000e-04\n",
      "Epoch 1147/5000\n",
      "3/3 [==============================] - 1s 200ms/step - loss: 108.3911 - mae: 108.3911 - mse: 68203.2031 - val_loss: 568.1823 - val_mae: 568.1823 - val_mse: 1150934.5000 - lr: 1.0000e-04\n",
      "Epoch 1148/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.9898 - mae: 106.9898 - mse: 70456.7188 - val_loss: 567.6121 - val_mae: 567.6121 - val_mse: 1153850.8750 - lr: 1.0000e-04\n",
      "Epoch 1149/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 107.8327 - mae: 107.8327 - mse: 68009.1953 - val_loss: 568.6234 - val_mae: 568.6234 - val_mse: 1151686.8750 - lr: 1.0000e-04\n",
      "Epoch 1150/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 106.0388 - mae: 106.0388 - mse: 69712.5312 - val_loss: 568.8959 - val_mae: 568.8959 - val_mse: 1156767.0000 - lr: 1.0000e-04\n",
      "Epoch 1151/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 105.5546 - mae: 105.5546 - mse: 67396.4375 - val_loss: 567.3927 - val_mae: 567.3927 - val_mse: 1150275.8750 - lr: 1.0000e-04\n",
      "Epoch 1152/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 105.7047 - mae: 105.7047 - mse: 69459.0312 - val_loss: 567.1979 - val_mae: 567.1979 - val_mse: 1151491.5000 - lr: 1.0000e-04\n",
      "Epoch 1153/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 106.5571 - mae: 106.5571 - mse: 67586.8984 - val_loss: 567.1913 - val_mae: 567.1913 - val_mse: 1149945.2500 - lr: 1.0000e-04\n",
      "Epoch 1154/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 106.6037 - mae: 106.6037 - mse: 70156.2266 - val_loss: 567.0963 - val_mae: 567.0963 - val_mse: 1150860.5000 - lr: 1.0000e-04\n",
      "Epoch 1155/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 108.0141 - mae: 108.0141 - mse: 68020.6406 - val_loss: 567.6911 - val_mae: 567.6911 - val_mse: 1149813.3750 - lr: 1.0000e-04\n",
      "Epoch 1156/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 106.7327 - mae: 106.7327 - mse: 70262.2656 - val_loss: 568.9584 - val_mae: 568.9584 - val_mse: 1156125.3750 - lr: 1.0000e-04\n",
      "Epoch 1157/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 106.1518 - mae: 106.1518 - mse: 67517.5781 - val_loss: 567.5226 - val_mae: 567.5226 - val_mse: 1149744.8750 - lr: 1.0000e-04\n",
      "Epoch 1158/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 105.7344 - mae: 105.7344 - mse: 69476.8906 - val_loss: 567.1118 - val_mae: 567.1118 - val_mse: 1151162.0000 - lr: 1.0000e-04\n",
      "Epoch 1159/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 106.8412 - mae: 106.8412 - mse: 67662.7969 - val_loss: 567.2014 - val_mae: 567.2014 - val_mse: 1149792.1250 - lr: 1.0000e-04\n",
      "Epoch 1160/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 106.7293 - mae: 106.7293 - mse: 70246.3203 - val_loss: 567.2171 - val_mae: 567.2171 - val_mse: 1152078.8750 - lr: 1.0000e-04\n",
      "Epoch 1161/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 107.5140 - mae: 107.5140 - mse: 67885.6953 - val_loss: 567.5979 - val_mae: 567.5979 - val_mse: 1150053.5000 - lr: 1.0000e-04\n",
      "Epoch 1162/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.6349 - mae: 106.6349 - mse: 70181.9609 - val_loss: 567.9933 - val_mae: 567.9933 - val_mse: 1154653.5000 - lr: 1.0000e-04\n",
      "Epoch 1163/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.5957 - mae: 106.5957 - mse: 67654.0469 - val_loss: 567.4480 - val_mae: 567.4480 - val_mse: 1150318.3750 - lr: 1.0000e-04\n",
      "Epoch 1164/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 106.3300 - mae: 106.3300 - mse: 69941.2578 - val_loss: 567.7278 - val_mae: 567.7278 - val_mse: 1154376.2500 - lr: 1.0000e-04\n",
      "Epoch 1165/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.2984 - mae: 106.2984 - mse: 67585.8359 - val_loss: 567.5847 - val_mae: 567.5847 - val_mse: 1150443.0000 - lr: 1.0000e-04\n",
      "Epoch 1166/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 105.7623 - mae: 105.7623 - mse: 69498.6094 - val_loss: 567.1488 - val_mae: 567.1488 - val_mse: 1151404.8750 - lr: 1.0000e-04\n",
      "Epoch 1167/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.9435 - mae: 106.9435 - mse: 67712.5156 - val_loss: 567.2479 - val_mae: 567.2479 - val_mse: 1149953.6250 - lr: 1.0000e-04\n",
      "Epoch 1168/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.7099 - mae: 106.7099 - mse: 70230.1641 - val_loss: 567.1879 - val_mae: 567.1879 - val_mse: 1151847.2500 - lr: 1.0000e-04\n",
      "Epoch 1169/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 107.6503 - mae: 107.6503 - mse: 67933.1250 - val_loss: 567.4868 - val_mae: 567.4868 - val_mse: 1149846.1250 - lr: 1.0000e-04\n",
      "Epoch 1170/5000\n",
      "3/3 [==============================] - 1s 215ms/step - loss: 106.9963 - mae: 106.9963 - mse: 70459.7188 - val_loss: 568.8898 - val_mae: 568.8898 - val_mse: 1156319.0000 - lr: 1.0000e-04\n",
      "Epoch 1171/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.3488 - mae: 106.3488 - mse: 67598.6250 - val_loss: 567.5946 - val_mae: 567.5946 - val_mse: 1150128.7500 - lr: 1.0000e-04\n",
      "Epoch 1172/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 105.9691 - mae: 105.9691 - mse: 69668.3281 - val_loss: 567.3420 - val_mae: 567.3420 - val_mse: 1152729.8750 - lr: 1.0000e-04\n",
      "Epoch 1173/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.4444 - mae: 106.4444 - mse: 67593.0547 - val_loss: 567.3078 - val_mae: 567.3078 - val_mse: 1150031.3750 - lr: 1.0000e-04\n",
      "Epoch 1174/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 106.3210 - mae: 106.3210 - mse: 69945.1562 - val_loss: 567.3435 - val_mae: 567.3435 - val_mse: 1152582.2500 - lr: 1.0000e-04\n",
      "Epoch 1175/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 106.6596 - mae: 106.6596 - mse: 67639.1172 - val_loss: 567.4191 - val_mae: 567.4191 - val_mse: 1149598.2500 - lr: 1.0000e-04\n",
      "Epoch 1176/5000\n",
      "3/3 [==============================] - 1s 214ms/step - loss: 106.0898 - mae: 106.0898 - mse: 69768.7188 - val_loss: 567.4346 - val_mae: 567.4346 - val_mse: 1152536.0000 - lr: 1.0000e-04\n",
      "Epoch 1177/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.3745 - mae: 106.3745 - mse: 67550.7891 - val_loss: 567.2432 - val_mae: 567.2432 - val_mse: 1149063.5000 - lr: 1.0000e-04\n",
      "Epoch 1178/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.1034 - mae: 106.1034 - mse: 69783.3750 - val_loss: 567.1586 - val_mae: 567.1586 - val_mse: 1151030.1250 - lr: 1.0000e-04\n",
      "Epoch 1179/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 106.8085 - mae: 106.8085 - mse: 67637.6562 - val_loss: 566.9856 - val_mae: 566.9856 - val_mse: 1149188.1250 - lr: 1.0000e-04\n",
      "Epoch 1180/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.4934 - mae: 107.4934 - mse: 70835.0703 - val_loss: 567.0555 - val_mae: 567.0555 - val_mse: 1150217.0000 - lr: 1.0000e-04\n",
      "Epoch 1181/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 109.2220 - mae: 109.2220 - mse: 68459.1328 - val_loss: 567.6109 - val_mae: 567.6109 - val_mse: 1149080.7500 - lr: 1.0000e-04\n",
      "Epoch 1182/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 108.3700 - mae: 108.3700 - mse: 71504.1328 - val_loss: 569.5580 - val_mae: 569.5580 - val_mse: 1156888.3750 - lr: 1.0000e-04\n",
      "Epoch 1183/5000\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 107.9682 - mae: 107.9682 - mse: 68060.8516 - val_loss: 568.3974 - val_mae: 568.3974 - val_mse: 1150319.1250 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1184/5000\n",
      "3/3 [==============================] - 1s 242ms/step - loss: 106.5528 - mae: 106.5528 - mse: 70150.8984 - val_loss: 570.2517 - val_mae: 570.2517 - val_mse: 1158602.7500 - lr: 1.0000e-04\n",
      "Epoch 1185/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 105.5049 - mae: 105.5049 - mse: 67379.4297 - val_loss: 567.4153 - val_mae: 567.4153 - val_mse: 1149164.6250 - lr: 1.0000e-04\n",
      "Epoch 1186/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 105.5200 - mae: 105.5200 - mse: 69337.6641 - val_loss: 567.3196 - val_mae: 567.3196 - val_mse: 1151654.8750 - lr: 1.0000e-04\n",
      "Epoch 1187/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 105.7891 - mae: 105.7891 - mse: 67385.2969 - val_loss: 567.0820 - val_mae: 567.0820 - val_mse: 1149939.2500 - lr: 1.0000e-04\n",
      "Epoch 1188/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.6980 - mae: 106.6980 - mse: 70234.1172 - val_loss: 567.0776 - val_mae: 567.0776 - val_mse: 1149096.2500 - lr: 1.0000e-04\n",
      "Epoch 1189/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 109.0461 - mae: 109.0461 - mse: 68364.8047 - val_loss: 567.3729 - val_mae: 567.3729 - val_mse: 1148639.5000 - lr: 1.0000e-04\n",
      "Epoch 1190/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 108.4472 - mae: 108.4472 - mse: 71563.9141 - val_loss: 568.8318 - val_mae: 568.8318 - val_mse: 1154908.8750 - lr: 1.0000e-04\n",
      "Epoch 1191/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 108.5448 - mae: 108.5448 - mse: 68234.2500 - val_loss: 567.9555 - val_mae: 567.9555 - val_mse: 1149359.1250 - lr: 1.0000e-04\n",
      "Epoch 1192/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.4858 - mae: 107.4858 - mse: 70850.1016 - val_loss: 567.4952 - val_mae: 567.4952 - val_mse: 1151920.1250 - lr: 1.0000e-04\n",
      "Epoch 1193/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 109.0091 - mae: 109.0091 - mse: 68378.4453 - val_loss: 568.0551 - val_mae: 568.0551 - val_mse: 1149505.6250 - lr: 1.0000e-04\n",
      "Epoch 1194/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 107.7040 - mae: 107.7040 - mse: 71017.2578 - val_loss: 568.3235 - val_mae: 568.3235 - val_mse: 1153851.3750 - lr: 1.0000e-04\n",
      "Epoch 1195/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 108.4284 - mae: 108.4284 - mse: 68172.0781 - val_loss: 568.3754 - val_mae: 568.3754 - val_mse: 1149950.1250 - lr: 1.0000e-04\n",
      "Epoch 1196/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 106.8569 - mae: 106.8569 - mse: 70394.8750 - val_loss: 568.7045 - val_mae: 568.7045 - val_mse: 1154767.7500 - lr: 1.0000e-04\n",
      "Epoch 1197/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.8775 - mae: 106.8775 - mse: 67662.0938 - val_loss: 567.6209 - val_mae: 567.6209 - val_mse: 1149125.1250 - lr: 1.0000e-04\n",
      "Epoch 1198/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.3463 - mae: 106.3463 - mse: 69998.2891 - val_loss: 567.6282 - val_mae: 567.6282 - val_mse: 1152633.3750 - lr: 1.0000e-04\n",
      "Epoch 1199/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.8165 - mae: 106.8165 - mse: 67647.4375 - val_loss: 567.3150 - val_mae: 567.3150 - val_mse: 1149720.0000 - lr: 1.0000e-04\n",
      "Epoch 1200/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 107.2130 - mae: 107.2130 - mse: 70648.8750 - val_loss: 567.8027 - val_mae: 567.8027 - val_mse: 1153613.0000 - lr: 1.0000e-04\n",
      "Epoch 1201/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 107.4340 - mae: 107.4340 - mse: 67867.4141 - val_loss: 567.8846 - val_mae: 567.8846 - val_mse: 1150307.6250 - lr: 1.0000e-04\n",
      "Epoch 1202/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 106.5524 - mae: 106.5524 - mse: 70154.6250 - val_loss: 568.3055 - val_mae: 568.3055 - val_mse: 1155198.7500 - lr: 1.0000e-04\n",
      "Epoch 1203/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 106.4127 - mae: 106.4127 - mse: 67606.8906 - val_loss: 568.1905 - val_mae: 568.1905 - val_mse: 1150992.7500 - lr: 1.0000e-04\n",
      "Epoch 1204/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 105.3362 - mae: 105.3362 - mse: 69194.5156 - val_loss: 567.4820 - val_mae: 567.4820 - val_mse: 1152750.3750 - lr: 1.0000e-04\n",
      "Epoch 1205/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 105.7397 - mae: 105.7397 - mse: 67407.2188 - val_loss: 567.2411 - val_mae: 567.2411 - val_mse: 1150995.6250 - lr: 1.0000e-04\n",
      "Epoch 1206/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.7441 - mae: 106.7441 - mse: 70270.6484 - val_loss: 567.2346 - val_mae: 567.2346 - val_mse: 1150063.1250 - lr: 1.0000e-04\n",
      "Epoch 1207/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 108.9573 - mae: 108.9573 - mse: 68361.1250 - val_loss: 567.5407 - val_mae: 567.5407 - val_mse: 1149505.1250 - lr: 1.0000e-04\n",
      "Epoch 1208/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 108.4440 - mae: 108.4440 - mse: 71563.8750 - val_loss: 568.9738 - val_mae: 568.9738 - val_mse: 1155830.1250 - lr: 1.0000e-04\n",
      "Epoch 1209/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 108.3878 - mae: 108.3878 - mse: 68201.7109 - val_loss: 568.3273 - val_mae: 568.3273 - val_mse: 1150352.3750 - lr: 1.0000e-04\n",
      "Epoch 1210/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 107.0456 - mae: 107.0456 - mse: 70530.0312 - val_loss: 569.0941 - val_mae: 569.0941 - val_mse: 1155966.3750 - lr: 1.0000e-04\n",
      "Epoch 1211/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.7230 - mae: 106.7230 - mse: 67650.5391 - val_loss: 567.6517 - val_mae: 567.6517 - val_mse: 1149409.6250 - lr: 1.0000e-04\n",
      "Epoch 1212/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 106.2776 - mae: 106.2776 - mse: 69937.3672 - val_loss: 567.6185 - val_mae: 567.6185 - val_mse: 1152756.7500 - lr: 1.0000e-04\n",
      "Epoch 1213/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 106.7803 - mae: 106.7803 - mse: 67653.4062 - val_loss: 567.4136 - val_mae: 567.4136 - val_mse: 1149835.7500 - lr: 1.0000e-04\n",
      "Epoch 1214/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 106.8077 - mae: 106.8077 - mse: 70337.7422 - val_loss: 567.6186 - val_mae: 567.6186 - val_mse: 1153170.3750 - lr: 1.0000e-04\n",
      "Epoch 1215/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 107.1827 - mae: 107.1827 - mse: 67797.1641 - val_loss: 567.5388 - val_mae: 567.5388 - val_mse: 1150357.1250 - lr: 1.0000e-04\n",
      "Epoch 1216/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.1772 - mae: 107.1772 - mse: 70622.0469 - val_loss: 568.1174 - val_mae: 568.1174 - val_mse: 1155051.0000 - lr: 1.0000e-04\n",
      "Epoch 1217/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 107.1146 - mae: 107.1146 - mse: 67814.2266 - val_loss: 567.8107 - val_mae: 567.8107 - val_mse: 1150782.6250 - lr: 1.0000e-04\n",
      "Epoch 1218/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.6780 - mae: 106.6780 - mse: 70248.9453 - val_loss: 568.1391 - val_mae: 568.1391 - val_mse: 1155355.7500 - lr: 1.0000e-04\n",
      "Epoch 1219/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.5514 - mae: 106.5514 - mse: 67663.7734 - val_loss: 567.9556 - val_mae: 567.9556 - val_mse: 1151051.5000 - lr: 1.0000e-04\n",
      "Epoch 1220/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 105.8337 - mae: 105.8337 - mse: 69592.7031 - val_loss: 567.5516 - val_mae: 567.5516 - val_mse: 1153127.0000 - lr: 1.0000e-04\n",
      "Epoch 1221/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 106.3916 - mae: 106.3916 - mse: 67596.7266 - val_loss: 567.5337 - val_mae: 567.5337 - val_mse: 1150519.7500 - lr: 1.0000e-04\n",
      "Epoch 1222/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 106.2243 - mae: 106.2243 - mse: 69899.6562 - val_loss: 567.4379 - val_mae: 567.4379 - val_mse: 1152307.3750 - lr: 1.0000e-04\n",
      "Epoch 1223/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 106.8335 - mae: 106.8335 - mse: 67696.0234 - val_loss: 567.5909 - val_mae: 567.5909 - val_mse: 1149879.5000 - lr: 1.0000e-04\n",
      "Epoch 1224/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 106.2542 - mae: 106.2542 - mse: 69928.7578 - val_loss: 567.3194 - val_mae: 567.3194 - val_mse: 1151433.1250 - lr: 1.0000e-04\n",
      "Epoch 1225/5000\n",
      "3/3 [==============================] - 1s 205ms/step - loss: 107.4038 - mae: 107.4038 - mse: 67846.0078 - val_loss: 567.3726 - val_mae: 567.3726 - val_mse: 1149629.8750 - lr: 1.0000e-04\n",
      "Epoch 1226/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 107.4245 - mae: 107.4245 - mse: 70813.7734 - val_loss: 567.4113 - val_mae: 567.4113 - val_mse: 1151826.5000 - lr: 1.0000e-04\n",
      "Epoch 1227/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.8241 - mae: 108.8241 - mse: 68348.5234 - val_loss: 567.9620 - val_mae: 567.9620 - val_mse: 1150063.8750 - lr: 1.0000e-04\n",
      "Epoch 1228/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 107.8159 - mae: 107.8159 - mse: 71115.0000 - val_loss: 568.2272 - val_mae: 568.2272 - val_mse: 1154295.8750 - lr: 1.0000e-04\n",
      "Epoch 1229/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 108.5394 - mae: 108.5394 - mse: 68256.8516 - val_loss: 568.2583 - val_mae: 568.2583 - val_mse: 1150309.6250 - lr: 1.0000e-04\n",
      "Epoch 1230/5000\n",
      "3/3 [==============================] - 1s 247ms/step - loss: 107.3299 - mae: 107.3299 - mse: 70762.1875 - val_loss: 568.6192 - val_mae: 568.6192 - val_mse: 1155067.0000 - lr: 1.0000e-04\n",
      "Epoch 1231/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 107.5433 - mae: 107.5433 - mse: 67907.7188 - val_loss: 568.8571 - val_mae: 568.8571 - val_mse: 1150992.1250 - lr: 1.0000e-04\n",
      "Epoch 1232/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 105.8309 - mae: 105.8309 - mse: 69605.4766 - val_loss: 567.9650 - val_mae: 567.9650 - val_mse: 1153363.5000 - lr: 1.0000e-04\n",
      "Epoch 1233/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 106.2626 - mae: 106.2626 - mse: 67519.2578 - val_loss: 567.7315 - val_mae: 567.7315 - val_mse: 1149567.2500 - lr: 1.0000e-04\n",
      "Epoch 1234/5000\n",
      "3/3 [==============================] - 1s 259ms/step - loss: 105.7745 - mae: 105.7745 - mse: 69573.0000 - val_loss: 567.4606 - val_mae: 567.4606 - val_mse: 1151301.5000 - lr: 1.0000e-04\n",
      "Epoch 1235/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 106.6703 - mae: 106.6703 - mse: 67600.1328 - val_loss: 567.5925 - val_mae: 567.5925 - val_mse: 1149241.3750 - lr: 1.0000e-04\n",
      "Epoch 1236/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 106.1163 - mae: 106.1163 - mse: 69846.2891 - val_loss: 567.3442 - val_mae: 567.3442 - val_mse: 1150524.0000 - lr: 1.0000e-04\n",
      "Epoch 1237/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.6200 - mae: 107.6200 - mse: 67877.6016 - val_loss: 567.5551 - val_mae: 567.5551 - val_mse: 1149161.3750 - lr: 1.0000e-04\n",
      "Epoch 1238/5000\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 107.1681 - mae: 107.1681 - mse: 70647.5938 - val_loss: 567.6659 - val_mae: 567.6659 - val_mse: 1152213.0000 - lr: 1.0000e-04\n",
      "Epoch 1239/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.1256 - mae: 108.1256 - mse: 68084.0469 - val_loss: 568.1896 - val_mae: 568.1896 - val_mse: 1150080.8750 - lr: 1.0000e-04\n",
      "Epoch 1240/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 106.7861 - mae: 106.7861 - mse: 70369.3672 - val_loss: 570.3251 - val_mae: 570.3251 - val_mse: 1158897.2500 - lr: 1.0000e-04\n",
      "Epoch 1241/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 105.5811 - mae: 105.5811 - mse: 67403.0469 - val_loss: 567.7652 - val_mae: 567.7652 - val_mse: 1149669.6250 - lr: 1.0000e-04\n",
      "Epoch 1242/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 105.3500 - mae: 105.3500 - mse: 69243.6797 - val_loss: 567.5275 - val_mae: 567.5275 - val_mse: 1151822.3750 - lr: 1.0000e-04\n",
      "Epoch 1243/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 105.7442 - mae: 105.7442 - mse: 67386.7344 - val_loss: 567.3308 - val_mae: 567.3308 - val_mse: 1150501.1250 - lr: 1.0000e-04\n",
      "Epoch 1244/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 106.7224 - mae: 106.7224 - mse: 70293.2266 - val_loss: 567.2896 - val_mae: 567.2896 - val_mse: 1149767.3750 - lr: 1.0000e-04\n",
      "Epoch 1245/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.7901 - mae: 108.7901 - mse: 68291.5703 - val_loss: 567.5995 - val_mae: 567.5995 - val_mse: 1149103.7500 - lr: 1.0000e-04\n",
      "Epoch 1246/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 108.3705 - mae: 108.3705 - mse: 71547.7109 - val_loss: 568.5987 - val_mae: 568.5987 - val_mse: 1154596.5000 - lr: 1.0000e-04\n",
      "Epoch 1247/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 108.7206 - mae: 108.7206 - mse: 68306.5000 - val_loss: 568.5457 - val_mae: 568.5457 - val_mse: 1150338.7500 - lr: 1.0000e-04\n",
      "Epoch 1248/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.3000 - mae: 107.3000 - mse: 70754.0156 - val_loss: 569.1979 - val_mae: 569.1979 - val_mse: 1156077.8750 - lr: 1.0000e-04\n",
      "Epoch 1249/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 107.1678 - mae: 107.1678 - mse: 67777.4375 - val_loss: 568.1849 - val_mae: 568.1849 - val_mse: 1149983.6250 - lr: 1.0000e-04\n",
      "Epoch 1250/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 106.1285 - mae: 106.1285 - mse: 69856.4766 - val_loss: 568.2980 - val_mae: 568.2980 - val_mse: 1154149.1250 - lr: 1.0000e-04\n",
      "Epoch 1251/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 106.2773 - mae: 106.2773 - mse: 67525.8203 - val_loss: 567.9529 - val_mae: 567.9529 - val_mse: 1149817.5000 - lr: 1.0000e-04\n",
      "Epoch 1252/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 105.5161 - mae: 105.5161 - mse: 69383.3203 - val_loss: 567.4257 - val_mae: 567.4257 - val_mse: 1150823.5000 - lr: 1.0000e-04\n",
      "Epoch 1253/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 106.7811 - mae: 106.7811 - mse: 67625.9531 - val_loss: 567.5557 - val_mae: 567.5557 - val_mse: 1149339.5000 - lr: 1.0000e-04\n",
      "Epoch 1254/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 106.2419 - mae: 106.2419 - mse: 69957.3516 - val_loss: 567.3535 - val_mae: 567.3535 - val_mse: 1150180.3750 - lr: 1.0000e-04\n",
      "Epoch 1255/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.0140 - mae: 108.0140 - mse: 68009.5000 - val_loss: 567.8685 - val_mae: 567.8685 - val_mse: 1149385.0000 - lr: 1.0000e-04\n",
      "Epoch 1256/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 106.8036 - mae: 106.8036 - mse: 70390.0625 - val_loss: 569.2411 - val_mae: 569.2411 - val_mse: 1156136.8750 - lr: 1.0000e-04\n",
      "Epoch 1257/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 106.1197 - mae: 106.1197 - mse: 67505.6719 - val_loss: 568.1517 - val_mae: 568.1517 - val_mse: 1149953.8750 - lr: 1.0000e-04\n",
      "Epoch 1258/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 105.1945 - mae: 105.1945 - mse: 69127.8594 - val_loss: 567.8388 - val_mae: 567.8388 - val_mse: 1152656.8750 - lr: 1.0000e-04\n",
      "Epoch 1259/5000\n",
      "3/3 [==============================] - 1s 212ms/step - loss: 105.3066 - mae: 105.3066 - mse: 67289.4844 - val_loss: 567.3342 - val_mae: 567.3342 - val_mse: 1149851.1250 - lr: 1.0000e-04\n",
      "Epoch 1260/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 105.9402 - mae: 105.9402 - mse: 69724.3125 - val_loss: 567.3232 - val_mae: 567.3232 - val_mse: 1149263.2500 - lr: 1.0000e-04\n",
      "Epoch 1261/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 108.0103 - mae: 108.0103 - mse: 67976.7969 - val_loss: 567.4704 - val_mae: 567.4704 - val_mse: 1148569.7500 - lr: 1.0000e-04\n",
      "Epoch 1262/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 107.4336 - mae: 107.4336 - mse: 70866.9688 - val_loss: 567.7462 - val_mae: 567.7462 - val_mse: 1151501.1250 - lr: 1.0000e-04\n",
      "Epoch 1263/5000\n",
      "3/3 [==============================] - 1s 213ms/step - loss: 108.5173 - mae: 108.5173 - mse: 68190.6094 - val_loss: 567.5028 - val_mae: 567.5028 - val_mse: 1148467.0000 - lr: 1.0000e-04\n",
      "Epoch 1264/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 108.5648 - mae: 108.5648 - mse: 71705.7734 - val_loss: 569.0664 - val_mae: 569.0664 - val_mse: 1155028.3750 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1265/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 108.5714 - mae: 108.5714 - mse: 68239.5156 - val_loss: 568.5517 - val_mae: 568.5517 - val_mse: 1149981.0000 - lr: 1.0000e-04\n",
      "Epoch 1266/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 107.1972 - mae: 107.1972 - mse: 70696.2578 - val_loss: 568.8721 - val_mae: 568.8721 - val_mse: 1154998.6250 - lr: 1.0000e-04\n",
      "Epoch 1267/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 107.4098 - mae: 107.4098 - mse: 67838.4531 - val_loss: 568.6708 - val_mae: 568.6708 - val_mse: 1150486.6250 - lr: 1.0000e-04\n",
      "Epoch 1268/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 105.8941 - mae: 105.8941 - mse: 69682.1484 - val_loss: 568.2004 - val_mae: 568.2004 - val_mse: 1153627.8750 - lr: 1.0000e-04\n",
      "Epoch 1269/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 106.2652 - mae: 106.2652 - mse: 67510.6016 - val_loss: 567.8406 - val_mae: 567.8406 - val_mse: 1149741.7500 - lr: 1.0000e-04\n",
      "Epoch 1270/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 105.6904 - mae: 105.6904 - mse: 69530.0703 - val_loss: 567.5955 - val_mae: 567.5955 - val_mse: 1151538.3750 - lr: 1.0000e-04\n",
      "Epoch 1271/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 106.5837 - mae: 106.5837 - mse: 67578.2031 - val_loss: 567.6270 - val_mae: 567.6270 - val_mse: 1149369.5000 - lr: 1.0000e-04\n",
      "Epoch 1272/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 106.1136 - mae: 106.1136 - mse: 69865.6172 - val_loss: 567.5025 - val_mae: 567.5025 - val_mse: 1150929.1250 - lr: 1.0000e-04\n",
      "Epoch 1273/5000\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 107.3850 - mae: 107.3850 - mse: 67809.0078 - val_loss: 567.4668 - val_mae: 567.4668 - val_mse: 1149248.7500 - lr: 1.0000e-04\n",
      "Epoch 1274/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 107.3894 - mae: 107.3894 - mse: 70836.6719 - val_loss: 567.6683 - val_mae: 567.6683 - val_mse: 1151770.2500 - lr: 1.0000e-04\n",
      "Epoch 1275/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 108.6750 - mae: 108.6750 - mse: 68274.4375 - val_loss: 567.8162 - val_mae: 567.8162 - val_mse: 1149407.5000 - lr: 1.0000e-04\n",
      "Epoch 1276/5000\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 108.3566 - mae: 108.3566 - mse: 71568.6562 - val_loss: 569.4656 - val_mae: 569.4656 - val_mse: 1156675.6250 - lr: 1.0000e-04\n",
      "Epoch 1277/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 108.0769 - mae: 108.0769 - mse: 68100.2422 - val_loss: 568.9770 - val_mae: 568.9770 - val_mse: 1151052.3750 - lr: 1.0000e-04\n",
      "Epoch 1278/5000\n",
      "3/3 [==============================] - 1s 231ms/step - loss: 106.5203 - mae: 106.5203 - mse: 70198.0469 - val_loss: 571.1207 - val_mae: 571.1207 - val_mse: 1160542.1250 - lr: 1.0000e-04\n",
      "Epoch 1279/5000\n",
      "3/3 [==============================] - ETA: 0s - loss: 105.2324 - mae: 105.2324 - mse: 67321.5391\n",
      "Epoch 1279: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 105.2324 - mae: 105.2324 - mse: 67321.5391 - val_loss: 567.8146 - val_mae: 567.8146 - val_mse: 1149598.6250 - lr: 1.0000e-04\n",
      "Epoch 1280/5000\n",
      "3/3 [==============================] - 1s 239ms/step - loss: 103.5039 - mae: 103.5039 - mse: 67262.6406 - val_loss: 567.5429 - val_mae: 567.5429 - val_mse: 1150978.1250 - lr: 1.0000e-05\n",
      "Epoch 1281/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.5347 - mae: 103.5347 - mse: 67475.1641 - val_loss: 567.8326 - val_mae: 567.8326 - val_mse: 1152310.3750 - lr: 1.0000e-05\n",
      "Epoch 1282/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.5450 - mae: 103.5450 - mse: 67494.6328 - val_loss: 567.5712 - val_mae: 567.5712 - val_mse: 1151086.8750 - lr: 1.0000e-05\n",
      "Epoch 1283/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.4811 - mae: 103.4811 - mse: 67343.0547 - val_loss: 567.5095 - val_mae: 567.5095 - val_mse: 1149567.5000 - lr: 1.0000e-05\n",
      "Epoch 1284/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.5053 - mae: 103.5053 - mse: 67181.8672 - val_loss: 568.0032 - val_mae: 568.0032 - val_mse: 1149586.5000 - lr: 1.0000e-05\n",
      "Epoch 1285/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 103.6302 - mae: 103.6302 - mse: 67098.0156 - val_loss: 568.5522 - val_mae: 568.5522 - val_mse: 1150214.8750 - lr: 1.0000e-05\n",
      "Epoch 1286/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 103.7130 - mae: 103.7130 - mse: 67068.2031 - val_loss: 568.6725 - val_mae: 568.6725 - val_mse: 1150274.5000 - lr: 1.0000e-05\n",
      "Epoch 1287/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.6915 - mae: 103.6915 - mse: 67069.9297 - val_loss: 568.2713 - val_mae: 568.2713 - val_mse: 1149691.8750 - lr: 1.0000e-05\n",
      "Epoch 1288/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.6123 - mae: 103.6123 - mse: 67094.2188 - val_loss: 567.8944 - val_mae: 567.8944 - val_mse: 1149134.6250 - lr: 1.0000e-05\n",
      "Epoch 1289/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 103.5284 - mae: 103.5284 - mse: 67137.2109 - val_loss: 567.6178 - val_mae: 567.6178 - val_mse: 1148902.8750 - lr: 1.0000e-05\n",
      "Epoch 1290/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 103.4782 - mae: 103.4782 - mse: 67181.6406 - val_loss: 567.4776 - val_mae: 567.4776 - val_mse: 1148881.6250 - lr: 1.0000e-05\n",
      "Epoch 1291/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 103.4597 - mae: 103.4597 - mse: 67204.8750 - val_loss: 567.4475 - val_mae: 567.4475 - val_mse: 1148794.8750 - lr: 1.0000e-05\n",
      "Epoch 1292/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.4576 - mae: 103.4576 - mse: 67192.7734 - val_loss: 567.4918 - val_mae: 567.4918 - val_mse: 1148606.0000 - lr: 1.0000e-05\n",
      "Epoch 1293/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.4662 - mae: 103.4662 - mse: 67164.7969 - val_loss: 567.5801 - val_mae: 567.5801 - val_mse: 1148443.6250 - lr: 1.0000e-05\n",
      "Epoch 1294/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 103.4822 - mae: 103.4822 - mse: 67135.0703 - val_loss: 567.6636 - val_mae: 567.6636 - val_mse: 1148343.0000 - lr: 1.0000e-05\n",
      "Epoch 1295/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.4951 - mae: 103.4951 - mse: 67117.3516 - val_loss: 567.6788 - val_mae: 567.6788 - val_mse: 1148245.2500 - lr: 1.0000e-05\n",
      "Epoch 1296/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.4931 - mae: 103.4931 - mse: 67113.9219 - val_loss: 567.6312 - val_mae: 567.6312 - val_mse: 1148122.0000 - lr: 1.0000e-05\n",
      "Epoch 1297/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 103.4794 - mae: 103.4794 - mse: 67120.5234 - val_loss: 567.5493 - val_mae: 567.5493 - val_mse: 1148000.5000 - lr: 1.0000e-05\n",
      "Epoch 1298/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 103.4625 - mae: 103.4625 - mse: 67131.9141 - val_loss: 567.4843 - val_mae: 567.4843 - val_mse: 1147898.5000 - lr: 1.0000e-05\n",
      "Epoch 1299/5000\n",
      "3/3 [==============================] - 1s 238ms/step - loss: 103.4532 - mae: 103.4532 - mse: 67135.2109 - val_loss: 567.4688 - val_mae: 567.4688 - val_mse: 1147789.1250 - lr: 1.0000e-05\n",
      "Epoch 1300/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 103.4518 - mae: 103.4518 - mse: 67127.6484 - val_loss: 567.4747 - val_mae: 567.4747 - val_mse: 1147669.6250 - lr: 1.0000e-05\n",
      "Epoch 1301/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.4519 - mae: 103.4519 - mse: 67120.1562 - val_loss: 567.4625 - val_mae: 567.4625 - val_mse: 1147558.5000 - lr: 1.0000e-05\n",
      "Epoch 1302/5000\n",
      "3/3 [==============================] - 1s 216ms/step - loss: 103.4479 - mae: 103.4479 - mse: 67117.4531 - val_loss: 567.4366 - val_mae: 567.4366 - val_mse: 1147453.8750 - lr: 1.0000e-05\n",
      "Epoch 1303/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.4424 - mae: 103.4424 - mse: 67117.3203 - val_loss: 567.4055 - val_mae: 567.4055 - val_mse: 1147356.6250 - lr: 1.0000e-05\n",
      "Epoch 1304/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.4360 - mae: 103.4360 - mse: 67118.8984 - val_loss: 567.3910 - val_mae: 567.3910 - val_mse: 1147254.8750 - lr: 1.0000e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1305/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 103.4365 - mae: 103.4365 - mse: 67111.2266 - val_loss: 567.3965 - val_mae: 567.3965 - val_mse: 1147146.1250 - lr: 1.0000e-05\n",
      "Epoch 1306/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 103.4373 - mae: 103.4373 - mse: 67104.6562 - val_loss: 567.3877 - val_mae: 567.3877 - val_mse: 1147045.7500 - lr: 1.0000e-05\n",
      "Epoch 1307/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.4352 - mae: 103.4352 - mse: 67101.8672 - val_loss: 567.3672 - val_mae: 567.3672 - val_mse: 1146947.6250 - lr: 1.0000e-05\n",
      "Epoch 1308/5000\n",
      "3/3 [==============================] - 1s 203ms/step - loss: 103.4310 - mae: 103.4310 - mse: 67101.7734 - val_loss: 567.3453 - val_mae: 567.3453 - val_mse: 1146856.0000 - lr: 1.0000e-05\n",
      "Epoch 1309/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 103.4256 - mae: 103.4256 - mse: 67103.1406 - val_loss: 567.3299 - val_mae: 567.3299 - val_mse: 1146773.8750 - lr: 1.0000e-05\n",
      "Epoch 1310/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 103.4230 - mae: 103.4230 - mse: 67101.3672 - val_loss: 567.3221 - val_mae: 567.3221 - val_mse: 1146690.1250 - lr: 1.0000e-05\n",
      "Epoch 1311/5000\n",
      "3/3 [==============================] - 1s 196ms/step - loss: 103.4222 - mae: 103.4222 - mse: 67097.1016 - val_loss: 567.3186 - val_mae: 567.3186 - val_mse: 1146608.7500 - lr: 1.0000e-05\n",
      "Epoch 1312/5000\n",
      "3/3 [==============================] - 1s 249ms/step - loss: 103.4220 - mae: 103.4220 - mse: 67091.8984 - val_loss: 567.3199 - val_mae: 567.3199 - val_mse: 1146533.1250 - lr: 1.0000e-05\n",
      "Epoch 1313/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 103.4224 - mae: 103.4224 - mse: 67086.1172 - val_loss: 567.3179 - val_mae: 567.3179 - val_mse: 1146459.2500 - lr: 1.0000e-05\n",
      "Epoch 1314/5000\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 103.4215 - mae: 103.4215 - mse: 67082.4844 - val_loss: 567.3074 - val_mae: 567.3074 - val_mse: 1146389.8750 - lr: 1.0000e-05\n",
      "Epoch 1315/5000\n",
      "3/3 [==============================] - 1s 248ms/step - loss: 103.4180 - mae: 103.4180 - mse: 67081.7188 - val_loss: 567.2952 - val_mae: 567.2952 - val_mse: 1146324.2500 - lr: 1.0000e-05\n",
      "Epoch 1316/5000\n",
      "3/3 [==============================] - 1s 237ms/step - loss: 103.4150 - mae: 103.4150 - mse: 67080.7500 - val_loss: 567.2836 - val_mae: 567.2836 - val_mse: 1146257.3750 - lr: 1.0000e-05\n",
      "Epoch 1317/5000\n",
      "3/3 [==============================] - 1s 234ms/step - loss: 103.4124 - mae: 103.4124 - mse: 67079.3203 - val_loss: 567.2767 - val_mae: 567.2767 - val_mse: 1146193.5000 - lr: 1.0000e-05\n",
      "Epoch 1318/5000\n",
      "3/3 [==============================] - 1s 243ms/step - loss: 103.4112 - mae: 103.4112 - mse: 67076.1719 - val_loss: 567.2708 - val_mae: 567.2708 - val_mse: 1146128.7500 - lr: 1.0000e-05\n",
      "Epoch 1319/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 103.4100 - mae: 103.4100 - mse: 67073.2188 - val_loss: 567.2646 - val_mae: 567.2646 - val_mse: 1146065.3750 - lr: 1.0000e-05\n",
      "Epoch 1320/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.4090 - mae: 103.4090 - mse: 67070.5469 - val_loss: 567.2558 - val_mae: 567.2558 - val_mse: 1146005.1250 - lr: 1.0000e-05\n",
      "Epoch 1321/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.4069 - mae: 103.4069 - mse: 67068.9297 - val_loss: 567.2453 - val_mae: 567.2453 - val_mse: 1145950.1250 - lr: 1.0000e-05\n",
      "Epoch 1322/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.4043 - mae: 103.4043 - mse: 67067.8594 - val_loss: 567.2337 - val_mae: 567.2337 - val_mse: 1145898.6250 - lr: 1.0000e-05\n",
      "Epoch 1323/5000\n",
      "3/3 [==============================] - 1s 240ms/step - loss: 103.4014 - mae: 103.4014 - mse: 67067.2109 - val_loss: 567.2248 - val_mae: 567.2248 - val_mse: 1145848.7500 - lr: 1.0000e-05\n",
      "Epoch 1324/5000\n",
      "3/3 [==============================] - 1s 252ms/step - loss: 103.3996 - mae: 103.3996 - mse: 67065.3125 - val_loss: 567.2198 - val_mae: 567.2198 - val_mse: 1145800.0000 - lr: 1.0000e-05\n",
      "Epoch 1325/5000\n",
      "3/3 [==============================] - 1s 241ms/step - loss: 103.3987 - mae: 103.3987 - mse: 67062.4844 - val_loss: 567.2135 - val_mae: 567.2135 - val_mse: 1145753.0000 - lr: 1.0000e-05\n",
      "Epoch 1326/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 103.3969 - mae: 103.3969 - mse: 67060.4922 - val_loss: 567.2048 - val_mae: 567.2048 - val_mse: 1145706.3750 - lr: 1.0000e-05\n",
      "Epoch 1327/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3946 - mae: 103.3946 - mse: 67059.1719 - val_loss: 567.1945 - val_mae: 567.1945 - val_mse: 1145660.5000 - lr: 1.0000e-05\n",
      "Epoch 1328/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 103.3920 - mae: 103.3920 - mse: 67058.2812 - val_loss: 567.1826 - val_mae: 567.1826 - val_mse: 1145614.3750 - lr: 1.0000e-05\n",
      "Epoch 1329/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3889 - mae: 103.3889 - mse: 67057.4688 - val_loss: 567.1772 - val_mae: 567.1772 - val_mse: 1145566.2500 - lr: 1.0000e-05\n",
      "Epoch 1330/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 103.3884 - mae: 103.3884 - mse: 67053.9766 - val_loss: 567.1721 - val_mae: 567.1721 - val_mse: 1145516.6250 - lr: 1.0000e-05\n",
      "Epoch 1331/5000\n",
      "3/3 [==============================] - 1s 245ms/step - loss: 103.3869 - mae: 103.3869 - mse: 67051.6797 - val_loss: 567.1641 - val_mae: 567.1641 - val_mse: 1145472.5000 - lr: 1.0000e-05\n",
      "Epoch 1332/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3848 - mae: 103.3848 - mse: 67050.2500 - val_loss: 567.1540 - val_mae: 567.1540 - val_mse: 1145426.1250 - lr: 1.0000e-05\n",
      "Epoch 1333/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.3824 - mae: 103.3824 - mse: 67049.2109 - val_loss: 567.1448 - val_mae: 567.1448 - val_mse: 1145384.6250 - lr: 1.0000e-05\n",
      "Epoch 1334/5000\n",
      "3/3 [==============================] - 1s 227ms/step - loss: 103.3797 - mae: 103.3797 - mse: 67048.2891 - val_loss: 567.1378 - val_mae: 567.1378 - val_mse: 1145340.6250 - lr: 1.0000e-05\n",
      "Epoch 1335/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 103.3784 - mae: 103.3784 - mse: 67045.9766 - val_loss: 567.1230 - val_mae: 567.1230 - val_mse: 1145308.3750 - lr: 1.0000e-05\n",
      "Epoch 1336/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3715 - mae: 103.3715 - mse: 67052.7969 - val_loss: 567.1036 - val_mae: 567.1036 - val_mse: 1145294.2500 - lr: 1.0000e-05\n",
      "Epoch 1337/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.3663 - mae: 103.3663 - mse: 67056.9531 - val_loss: 567.0958 - val_mae: 567.0958 - val_mse: 1145268.6250 - lr: 1.0000e-05\n",
      "Epoch 1338/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.3646 - mae: 103.3646 - mse: 67055.5547 - val_loss: 567.0947 - val_mae: 567.0947 - val_mse: 1145225.6250 - lr: 1.0000e-05\n",
      "Epoch 1339/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3657 - mae: 103.3657 - mse: 67050.2188 - val_loss: 567.0908 - val_mae: 567.0908 - val_mse: 1145190.6250 - lr: 1.0000e-05\n",
      "Epoch 1340/5000\n",
      "3/3 [==============================] - 1s 246ms/step - loss: 103.3623 - mae: 103.3623 - mse: 67052.7266 - val_loss: 567.0798 - val_mae: 567.0798 - val_mse: 1145176.1250 - lr: 1.0000e-05\n",
      "Epoch 1341/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3593 - mae: 103.3593 - mse: 67053.8750 - val_loss: 567.0768 - val_mae: 567.0768 - val_mse: 1145142.5000 - lr: 1.0000e-05\n",
      "Epoch 1342/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 103.3594 - mae: 103.3594 - mse: 67050.6172 - val_loss: 567.0712 - val_mae: 567.0712 - val_mse: 1145114.2500 - lr: 1.0000e-05\n",
      "Epoch 1343/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3550 - mae: 103.3550 - mse: 67054.7969 - val_loss: 567.0594 - val_mae: 567.0594 - val_mse: 1145105.6250 - lr: 1.0000e-05\n",
      "Epoch 1344/5000\n",
      "3/3 [==============================] - 1s 228ms/step - loss: 103.3517 - mae: 103.3517 - mse: 67056.7812 - val_loss: 567.0561 - val_mae: 567.0561 - val_mse: 1145070.7500 - lr: 1.0000e-05\n",
      "Epoch 1345/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3524 - mae: 103.3524 - mse: 67052.6953 - val_loss: 567.0513 - val_mae: 567.0513 - val_mse: 1145039.2500 - lr: 1.0000e-05\n",
      "Epoch 1346/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 103.3486 - mae: 103.3486 - mse: 67056.2344 - val_loss: 567.0437 - val_mae: 567.0437 - val_mse: 1145031.2500 - lr: 1.0000e-05\n",
      "Epoch 1347/5000\n",
      "3/3 [==============================] - 1s 221ms/step - loss: 103.3464 - mae: 103.3464 - mse: 67056.8281 - val_loss: 567.0371 - val_mae: 567.0371 - val_mse: 1145018.2500 - lr: 1.0000e-05\n",
      "Epoch 1348/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3417 - mae: 103.3417 - mse: 67062.7188 - val_loss: 567.0294 - val_mae: 567.0294 - val_mse: 1145018.1250 - lr: 1.0000e-05\n",
      "Epoch 1349/5000\n",
      "3/3 [==============================] - 1s 236ms/step - loss: 103.3397 - mae: 103.3397 - mse: 67063.2266 - val_loss: 567.0300 - val_mae: 567.0300 - val_mse: 1144972.8750 - lr: 1.0000e-05\n",
      "Epoch 1350/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3419 - mae: 103.3419 - mse: 67056.2188 - val_loss: 567.0310 - val_mae: 567.0310 - val_mse: 1144934.3750 - lr: 1.0000e-05\n",
      "Epoch 1351/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.3399 - mae: 103.3399 - mse: 67057.1484 - val_loss: 567.0215 - val_mae: 567.0215 - val_mse: 1144947.7500 - lr: 1.0000e-05\n",
      "Epoch 1352/5000\n",
      "3/3 [==============================] - 1s 235ms/step - loss: 103.3333 - mae: 103.3333 - mse: 67067.4531 - val_loss: 567.0125 - val_mae: 567.0125 - val_mse: 1144967.6250 - lr: 1.0000e-05\n",
      "Epoch 1353/5000\n",
      "3/3 [==============================] - 1s 225ms/step - loss: 103.3301 - mae: 103.3301 - mse: 67070.4375 - val_loss: 567.0118 - val_mae: 567.0118 - val_mse: 1144931.1250 - lr: 1.0000e-05\n",
      "Epoch 1354/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3315 - mae: 103.3315 - mse: 67063.8984 - val_loss: 567.0190 - val_mae: 567.0190 - val_mse: 1144853.8750 - lr: 1.0000e-05\n",
      "Epoch 1355/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.3377 - mae: 103.3377 - mse: 67051.2031 - val_loss: 567.0203 - val_mae: 567.0203 - val_mse: 1144816.7500 - lr: 1.0000e-05\n",
      "Epoch 1356/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.3322 - mae: 103.3322 - mse: 67057.7891 - val_loss: 567.0092 - val_mae: 567.0092 - val_mse: 1144847.6250 - lr: 1.0000e-05\n",
      "Epoch 1357/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.3275 - mae: 103.3275 - mse: 67063.4531 - val_loss: 567.0069 - val_mae: 567.0069 - val_mse: 1144820.7500 - lr: 1.0000e-05\n",
      "Epoch 1358/5000\n",
      "3/3 [==============================] - 1s 218ms/step - loss: 103.3281 - mae: 103.3281 - mse: 67059.1797 - val_loss: 567.0041 - val_mae: 567.0041 - val_mse: 1144811.5000 - lr: 1.0000e-05\n",
      "Epoch 1359/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.3223 - mae: 103.3223 - mse: 67069.6797 - val_loss: 566.9998 - val_mae: 566.9998 - val_mse: 1144856.2500 - lr: 1.0000e-05\n",
      "Epoch 1360/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3195 - mae: 103.3195 - mse: 67073.4219 - val_loss: 567.0013 - val_mae: 567.0013 - val_mse: 1144818.1250 - lr: 1.0000e-05\n",
      "Epoch 1361/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3220 - mae: 103.3220 - mse: 67064.7891 - val_loss: 567.0103 - val_mae: 567.0103 - val_mse: 1144732.5000 - lr: 1.0000e-05\n",
      "Epoch 1362/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 103.3307 - mae: 103.3307 - mse: 67049.1719 - val_loss: 567.0155 - val_mae: 567.0155 - val_mse: 1144692.1250 - lr: 1.0000e-05\n",
      "Epoch 1363/5000\n",
      "3/3 [==============================] - 1s 222ms/step - loss: 103.3267 - mae: 103.3267 - mse: 67054.1328 - val_loss: 567.0017 - val_mae: 567.0017 - val_mse: 1144781.1250 - lr: 1.0000e-05\n",
      "Epoch 1364/5000\n",
      "3/3 [==============================] - 1s 220ms/step - loss: 103.3147 - mae: 103.3147 - mse: 67081.1953 - val_loss: 567.0010 - val_mae: 567.0010 - val_mse: 1144851.6250 - lr: 1.0000e-05\n",
      "Epoch 1365/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 103.3167 - mae: 103.3167 - mse: 67071.8672 - val_loss: 567.0189 - val_mae: 567.0189 - val_mse: 1144730.5000 - lr: 1.0000e-05\n",
      "Epoch 1366/5000\n",
      "3/3 [==============================] - 1s 244ms/step - loss: 103.3300 - mae: 103.3300 - mse: 67048.1562 - val_loss: 567.0359 - val_mae: 567.0359 - val_mse: 1144673.0000 - lr: 1.0000e-05\n",
      "Epoch 1367/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 103.3307 - mae: 103.3307 - mse: 67047.3125 - val_loss: 567.0231 - val_mae: 567.0231 - val_mse: 1144738.1250 - lr: 1.0000e-05\n",
      "Epoch 1368/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 103.3182 - mae: 103.3182 - mse: 67070.6797 - val_loss: 567.0161 - val_mae: 567.0161 - val_mse: 1144859.1250 - lr: 1.0000e-05\n",
      "Epoch 1369/5000\n",
      "3/3 [==============================] - 1s 224ms/step - loss: 103.3125 - mae: 103.3125 - mse: 67084.1484 - val_loss: 567.0212 - val_mae: 567.0212 - val_mse: 1144834.1250 - lr: 1.0000e-05\n",
      "Epoch 1370/5000\n",
      "3/3 [==============================] - 1s 233ms/step - loss: 103.3183 - mae: 103.3183 - mse: 67067.2188 - val_loss: 567.0436 - val_mae: 567.0436 - val_mse: 1144709.2500 - lr: 1.0000e-05\n",
      "Epoch 1371/5000\n",
      "3/3 [==============================] - 1s 226ms/step - loss: 103.3339 - mae: 103.3339 - mse: 67042.2266 - val_loss: 567.0629 - val_mae: 567.0629 - val_mse: 1144660.0000 - lr: 1.0000e-05\n",
      "Epoch 1372/5000\n",
      "3/3 [==============================] - 1s 219ms/step - loss: 103.3343 - mae: 103.3343 - mse: 67041.6562 - val_loss: 567.0463 - val_mae: 567.0463 - val_mse: 1144714.8750 - lr: 1.0000e-05\n",
      "Epoch 1373/5000\n",
      "3/3 [==============================] - 1s 263ms/step - loss: 103.3196 - mae: 103.3196 - mse: 67065.3516 - val_loss: 567.0338 - val_mae: 567.0338 - val_mse: 1144825.5000 - lr: 1.0000e-05\n",
      "Epoch 1374/5000\n",
      "3/3 [==============================] - 1s 229ms/step - loss: 103.3128 - mae: 103.3128 - mse: 67079.9531 - val_loss: 567.0330 - val_mae: 567.0330 - val_mse: 1144846.1250 - lr: 1.0000e-05\n",
      "Epoch 1375/5000\n",
      "3/3 [==============================] - 1s 230ms/step - loss: 103.3124 - mae: 103.3124 - mse: 67078.8047 - val_loss: 567.0358 - val_mae: 567.0358 - val_mse: 1144783.8750 - lr: 1.0000e-05\n",
      "Epoch 1376/5000\n",
      "3/3 [==============================] - 1s 223ms/step - loss: 103.3165 - mae: 103.3165 - mse: 67066.4609 - val_loss: 567.0466 - val_mae: 567.0466 - val_mse: 1144683.7500 - lr: 1.0000e-05\n",
      "Epoch 1377/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 103.3267 - mae: 103.3267 - mse: 67047.9688 - val_loss: 567.0543 - val_mae: 567.0543 - val_mse: 1144636.7500 - lr: 1.0000e-05\n",
      "Epoch 1378/5000\n",
      "3/3 [==============================] - 1s 217ms/step - loss: 103.3233 - mae: 103.3233 - mse: 67051.8906 - val_loss: 567.0408 - val_mae: 567.0408 - val_mse: 1144684.5000 - lr: 1.0000e-05\n",
      "Epoch 1379/5000\n",
      "3/3 [==============================] - ETA: 0s - loss: 103.3148 - mae: 103.3148 - mse: 67066.0469\n",
      "Epoch 1379: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "3/3 [==============================] - 1s 232ms/step - loss: 103.3148 - mae: 103.3148 - mse: 67066.0469 - val_loss: 567.0352 - val_mae: 567.0352 - val_mse: 1144720.5000 - lr: 1.0000e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f0aaf5cf70>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "stack_input = tf.keras.layers.Input(shape=(INPUT_SIZE),name='stack_input')\n",
    "nbeats_block_layer = NBeatsBlock(input_size = INPUT_SIZE,\n",
    "                                  theta_size = THETA_SIZE,\n",
    "                                  horizon = HORIZON,\n",
    "                                  n_neurons = N_NEURONS,\n",
    "                                  n_layers = N_LAYERS,\n",
    "                                name='initialBlock')\n",
    "outputs = nbeats_block_layer(stack_input)\n",
    "model_custom = tf.keras.Model(inputs=stack_input,outputs=outputs)\n",
    "\n",
    "model_custom.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "# 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
    "model_custom.fit(train_dataset,\n",
    "            epochs=N_EPOCHS,\n",
    "            validation_data=test_dataset,\n",
    "           # verbose=0, # prevent large amounts of training outputs\n",
    "            # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79f56e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_custom1 = model_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "38896e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 261ms/step - loss: 566.9856 - mae: 566.9856 - mse: 1149188.1250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[566.985595703125, 566.985595703125, 1149188.125]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_custom.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f880111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step - loss: 576.6179 - mae: 576.6179 - mse: 1172728.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[576.6178588867188, 576.6178588867188, 1172728.25]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_custom.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956bbcba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4b597336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up dummy NBeatsBlock layer\n",
    "tf.random.set_seed(42)\n",
    "dummy_nbeats_block_layer = NBeatsBlock(input_size=WINDOW_SIZE,\n",
    "                                      theta_size=WINDOW_SIZE+HORIZON,\n",
    "                                      horizon = HORIZON,\n",
    "                                      n_neurons=128,\n",
    "                                      n_layers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3ec8df7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=array([[0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.zeros((1,7),dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6e3f6aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=float32, numpy=\n",
       "array([[0.9203983, 1.6748797, 3.8428683, 4.6938987, 5.3172054, 6.5698733,\n",
       "        7.639666 ]], dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.layers.subtract([tf.cast(dummy_inputs[:,:WINDOW_SIZE],dtype=tf.float32),backcast])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "28054d54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6, 7]])>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs[:,:WINDOW_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2227f026",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast = dummy_nbeats_block_layer(dummy_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d4ebe42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 7), dtype=int32, numpy=array([[1, 2, 3, 4, 5, 6, 7]])>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd22bf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 1), dtype=float32, numpy=array([[33.26951]], dtype=float32)>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722de1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_7 = tf.keras.Model(inputs=stack_input, \n",
    "                         outputs=forecast, \n",
    "                         name=\"model_7_N-BEATS\")\n",
    "\n",
    "# 8. Compile with MAE loss and Adam optimizer\n",
    "model_7.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "                metrics=[\"mae\", \"mse\"])\n",
    "\n",
    "# 9. Fit the model with EarlyStopping and ReduceLROnPlateau callbacks\n",
    "model_7.fit(train_dataset,\n",
    "            epochs=N_EPOCHS,\n",
    "            validation_data=test_dataset,\n",
    "            verbose=0, # prevent large amounts of training outputs\n",
    "            # callbacks=[create_model_checkpoint(model_name=stack_model.name)] # saving model every epoch consumes far too much time\n",
    "            callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=200, restore_best_weights=True),\n",
    "                      tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100, verbose=1)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
